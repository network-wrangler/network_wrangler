{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Network Wrangler is a Python library for managing travel model network scenarios.</p>"},{"location":"#system-requirements","title":"System Requirements","text":"<p>Network Wrangler should be operating system agonistic and has been tested on Ubuntu and Mac OS.</p> <p>Network Wrangler does require Python 3.7+.  If you have a different version of Python installed (e.g. from ArcGIS), <code>conda</code> or a similar virtual environment manager can care of installing it for you in the installation instructions below.</p> <p>installing conda</p> <p>In order to assist in installation, its helpful to have miniconda or another virtual environment manager installed to make sure the network wrangler dependencies don\u2019t interfer with any other package requirements you have. If you don\u2019t have any of these already, we recommend starting with Miniconda as it has the smallest footprint. <code>conda</code> is the environment manager that is contained within both the Anaconda and mini-conda applications.</p> installing conda or Anaconda (the GUI version) for the first time on computer with Cube or ArcGIS?<p>For ArcGIS / Cube users - Recommend Install conda by leaving boxes unchecked for advanced options \u2013 system path and register anaconda. On some systems, checking these boxes will break Cube and ArcGis systems.</p>"},{"location":"#installation","title":"Installation","text":"<p>Requirements for basic network_wranglerare functionality as well as enhanced development/testing, visualization and documentation functionalities are stored in <code>requirements*.txt</code> and <code>pyproject.toml</code> but are automatically installed when using <code>pip</code>.</p> <p>create a new conda environment for wrangler</p> <pre><code>conda config --add channels conda-forge\nconda create python=3.7 -n wrangler\nconda activate wrangler\n</code></pre> <p>tricky dependencies</p> <p><code>rtree</code>, <code>geopandas</code> and <code>osmnx</code> can have some tricky co-dependencies.  If don\u2019t already have an up-to-date installation of them, we\u2019ve had the best success installing them using conda (as opposed to pip).</p> <pre><code>conda install rtree geopandas osmnx\n</code></pre> <p>Ready to install network wrangler?</p> Latest Official VersionFrom GitHubFrom Clone <pre><code>pip install network-wrangler\n</code></pre> <pre><code>pip install git+https://github.com/wsp-sag/network_wrangler.git@master#egg=network_wrangler\n</code></pre> <p>Tip</p> <p>If you wanted to install from a specific tag/version number or branch, replace <code>@master</code> with <code>@&lt;branchname&gt;</code>  or <code>@tag</code></p> <p>If you are going to be working on Network Wrangler locally, you might want to clone it to your local machine and install it from the clone.  The -e will install it in editable mode.</p> <p>If you have GitHub desktop installed, you can either do this by using the GitHub user interface by clicking on the green button \u201cclone or download\u201d in the main network wrangler repository page.</p> <p>Otherwise, you can use the command prompt to navigate to the directory that you would like to store your network wrangler clone and then using a git command to clone it.</p> <pre><code>cd path to where you want to put wrangler\ngit clone https://github.com/wsp-sag/network_wrangler\n</code></pre> <p>Expected output:</p> <pre><code>cloning into network_wrangler...\nremote: Enumerating objects: 53, done.\nremote: Counting objects: 100% (53/53), done.\nremote: Compressing objects: 100% (34/34), done.\nremote: Total 307 (delta 28), reused 29 (delta 19), pack-reused 254\nReceiving objects: 100% (307/307), 15.94 MiB | 10.49 MiB/s, done.\nResolving deltas: 100% (140/140), done.\n</code></pre> <p>Then you should be able to install Network Wrangler in \u201cdevelop\u201d mode.</p> <p>Navigate your command prompt into the network wrangler folder and then install network wrangler in editable mode. This will take a few minutes because it is also installing all the prerequisites.</p> <pre><code>cd network_wrangler\npip install -e .\n</code></pre>"},{"location":"#common-installation-issues","title":"Common Installation Issues","text":"libstdc++ is deprecated <p>clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]`</p> <p>If you are using MacOS, you might need to update your xcode command line tools and headers</p> libspatialindex_c or Missing GEOS module <p>\u201cOSError: Could not find libspatialindex_c library file</p> <p>or</p> <p>Shapely, a pre-requisite, doesn\u2019t install propertly because it is missing GEOS module</p> <p>Try installing them using conda.</p> <pre><code>conda uninstall geopandas rtree shapely\nconda install rtree shapely geopandas\n</code></pre> Conda is unable to install a library or to update to a specific library version<p>Add libraries from conda-forge</p> <pre><code>conda install -c conda-forge *library*\n</code></pre> User does not have permission to install in directories<p>Try running Anaconda as an administrator, even if you are an admin on your machine.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>To get a feel for the API and using project cards, please refer to the \u201cWrangler Quickstart\u201d jupyter notebook.</p> <p>To start the notebook, open a command line in the network_wrangler top-level directory and type:</p> <p><code>jupyter notebook</code></p>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation can be built from the <code>/docs</code> folder using the command: <code>make html</code></p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import network_wrangler\n\n##todo this is just an example for now\n\nnetwork_wrangler.setup_logging()\n\n## Network Manipulation\nmy_network = network_wrangler.read_roadway_network(...) # returns\nmy_network.apply_project_card(...) # returns\nmy_network.write_roadway_network(...) # returns\n\n## Scenario Building\nmy_scenario = network_wrangler.create_scenario(\n        base_scenario=my_base_scenario,\n        card_search_dir=project_card_directory,\n        tags = [\"baseline-2050\"]\n        )\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/baseline\", \"baseline-2050\")\nmy_scenario.summarize(outfile=\"scenario_summary_baseline.txt\")\n\nmy_scenario.add_projects_from_files(list_of_build_project_card_files)\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/build\", \"baseline\")\n</code></pre>"},{"location":"#attribution","title":"Attribution","text":"<p>This project is built upon the ideas and concepts implemented in the network wrangler project by the San Francisco County Transportation Authority and expanded upon by the Metropolitan Transportation Commission.</p> <p>While Network Wrangler as written here is based on these concepts, the code is distinct and builds upon other packages such as <code>geopandas</code> and <code>pydantic</code> which hadn\u2019t been implemented when networkwrangler 1.0 was developed.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Pull requests are welcome. Please open an issue first to discuss what you would like to change. Please make sure to update tests as appropriate.</p>"},{"location":"#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"api/","title":"API Documentation","text":""},{"location":"api/#common-usage","title":"Common Usage","text":""},{"location":"api/#base-objects","title":"Base Objects","text":"<p>Scenario class and related functions for managing a scenario.</p> <p>Usage:</p> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_roadway(\n        links_file=STPAUL_LINK_FILE,\n        nodes_file=STPAUL_NODE_FILE,\n        shapes_file=STPAUL_SHAPE_FILE,\n    ),\n    \"transit_net\": load_transit(STPAUL_DIR),\n}\n\n# create a future baseline scenario from base by searching for all cards in dir w/ baseline tag\nproject_card_directory = os.path.join(STPAUL_DIR, \"project_cards\")\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags = [ \"baseline2050\" ]\n)\n\n# check project card queue and then apply the projects\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\n\n# check applied projects, write it out, and create a summary report.\nmy_scenario.applied_projects\nmy_scenario.write(\"baseline\")\nmy_scenario.summarize(outfile = \"baseline2050summary.txt\")\n\n# Add some projects to create a build scenario based on a list of files.\nbuild_card_filenames = [\n    \"3_multiple_roadway_attribute_change.yml\",\n    \"road.prop_changes.segment.yml\",\n    \"4_simple_managed_lane.yml\",\n]\nmy_scenario.add_projects_from_files(build_card_filenames)\nmy_scenario.write(\"build2050\")\nmy_scenario.summarize(outfile = \"build2050summary.txt\")\n</code></pre> <p>Roadway Network class and functions for Network Wrangler.</p> <p>Used to represent a roadway network and perform operations on it.</p> <p>Usage:</p> <pre><code>from network_wrangler import load_roadway_from_dir, write_roadway\n\nnet = load_roadway_from_dir(\"my_dir\")\nnet.get_selection({\"links\": [{\"name\": [\"I 35E\"]}]})\nnet.apply(\"my_project_card.yml\")\n\nwrite_roadway(net, \"my_out_prefix\", \"my_dir\", file_format = \"parquet\")\n</code></pre> <p>TransitNetwork class for representing a transit network.</p> <p>Transit Networks are represented as a Wrangler-flavored GTFS Feed and optionally mapped to a RoadwayNetwork object. The TransitNetwork object is the primary object for managing transit networks in Wrangler.</p> <p>Usage:</p> <pre><code>```python\nimport network_wrangler as wr\nt = wr.load_transit(stpaul_gtfs)\nt.road_net = wr.load_roadway(stpaul_roadway)\nt = t.apply(project_card)\nwrite_transit(t, \"output_dir\")\n```\n</code></pre>"},{"location":"api/#network_wrangler.scenario.ProjectCardError","title":"<code>ProjectCardError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a project card is not valid.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class ProjectCardError(Exception):\n    \"\"\"Raised when a project card is not valid.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario","title":"<code>Scenario</code>","text":"<p>               Bases: <code>object</code></p> <p>Holds information about a scenario.</p> <p>Typical usage example:</p> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_roadway(\n        links_file=STPAUL_LINK_FILE,\n        nodes_file=STPAUL_NODE_FILE,\n        shapes_file=STPAUL_SHAPE_FILE,\n    ),\n    \"transit_net\": load_transit(STPAUL_DIR),\n}\n\n# create a future baseline scenario from base by searching for all cards in dir w/ baseline tag\nproject_card_directory = os.path.join(STPAUL_DIR, \"project_cards\")\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags = [ \"baseline2050\" ]\n)\n\n# check project card queue and then apply the projects\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\n\n# check applied projects, write it out, and create a summary report.\nmy_scenario.applied_projects\nmy_scenario.write(\"baseline\")\nmy_scenario.summarize(outfile = \"baseline2050summary.txt\")\n\n# Add some projects to create a build scenario based on a list of files.\nbuild_card_filenames = [\n    \"3_multiple_roadway_attribute_change.yml\",\n    \"road.prop_changes.segment.yml\",\n    \"4_simple_managed_lane.yml\",\n]\nmy_scenario.add_projects_from_files(build_card_filenames)\nmy_scenario.write(\"build2050\")\nmy_scenario.summarize(outfile = \"build2050summary.txt\")\n</code></pre> <p>Attributes:</p> Name Type Description <code>base_scenario</code> <p>dictionary representation of a scenario</p> <code>road_net</code> <code>Optional[RoadwayNetwork]</code> <p>instance of RoadwayNetwork for the scenario</p> <code>transit_net</code> <code>Optional[TransitNetwork]</code> <p>instance of TransitNetwork for the scenario</p> <code>project_cards</code> <code>dict[str, ProjectCard]</code> <p>Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.</p> <code>queued_projects</code> <p>Projects which are \u201cshovel ready\u201d - have had pre-requisits checked and done any required re-ordering. Similar to a git staging, project cards aren\u2019t recognized in this collecton once they are moved to applied.</p> <code>applied_projects</code> <p>list of project names that have been applied</p> <code>projects</code> <p>list of all projects either planned, queued, or applied</p> <code>prerequisites</code> <p>dictionary storing prerequiste information</p> <code>corequisites</code> <p>dictionary storing corequisite information</p> <code>conflicts</code> <p>dictionary storing conflict information</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class Scenario(object):\n    \"\"\"Holds information about a scenario.\n\n    Typical usage example:\n\n    ```python\n    my_base_year_scenario = {\n        \"road_net\": load_roadway(\n            links_file=STPAUL_LINK_FILE,\n            nodes_file=STPAUL_NODE_FILE,\n            shapes_file=STPAUL_SHAPE_FILE,\n        ),\n        \"transit_net\": load_transit(STPAUL_DIR),\n    }\n\n    # create a future baseline scenario from base by searching for all cards in dir w/ baseline tag\n    project_card_directory = os.path.join(STPAUL_DIR, \"project_cards\")\n    my_scenario = create_scenario(\n        base_scenario=my_base_year_scenario,\n        card_search_dir=project_card_directory,\n        filter_tags = [ \"baseline2050\" ]\n    )\n\n    # check project card queue and then apply the projects\n    my_scenario.queued_projects\n    my_scenario.apply_all_projects()\n\n    # check applied projects, write it out, and create a summary report.\n    my_scenario.applied_projects\n    my_scenario.write(\"baseline\")\n    my_scenario.summarize(outfile = \"baseline2050summary.txt\")\n\n    # Add some projects to create a build scenario based on a list of files.\n    build_card_filenames = [\n        \"3_multiple_roadway_attribute_change.yml\",\n        \"road.prop_changes.segment.yml\",\n        \"4_simple_managed_lane.yml\",\n    ]\n    my_scenario.add_projects_from_files(build_card_filenames)\n    my_scenario.write(\"build2050\")\n    my_scenario.summarize(outfile = \"build2050summary.txt\")\n    ```\n\n    Attributes:\n        base_scenario: dictionary representation of a scenario\n        road_net: instance of RoadwayNetwork for the scenario\n        transit_net: instance of TransitNetwork for the scenario\n        project_cards: Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.\n        queued_projects: Projects which are \"shovel ready\" - have had pre-requisits checked and\n            done any required re-ordering. Similar to a git staging, project cards aren't\n            recognized in this collecton once they are moved to applied.\n        applied_projects: list of project names that have been applied\n        projects: list of all projects either planned, queued, or applied\n        prerequisites:  dictionary storing prerequiste information\n        corequisites:  dictionary storing corequisite information\n        conflicts: dictionary storing conflict information\n    \"\"\"\n\n    def __init__(\n        self,\n        base_scenario: Union[Scenario, dict],\n        project_card_list: Optional[list[ProjectCard]] = None,\n        name=\"\",\n    ):\n        \"\"\"Constructor.\n\n        Args:\n        base_scenario: A base scenario object to base this isntance off of, or a dict which\n            describes the scenario attributes including applied projects and respective conflicts.\n            `{\"applied_projects\": [],\"conflicts\":{...}}`\n        project_card_list: Optional list of ProjectCard instances to add to planned projects.\n            Defaults to None.\n        name: Optional name for the scenario.\n        \"\"\"\n        WranglerLogger.info(\"Creating Scenario\")\n\n        if project_card_list is None:\n            project_card_list = []\n\n        if isinstance(base_scenario, Scenario):\n            base_scenario = base_scenario.__dict__\n\n        if not set(BASE_SCENARIO_SUGGESTED_PROPS) &lt;= set(base_scenario.keys()):\n            WranglerLogger.warning(\n                f\"Base_scenario doesn't contain {BASE_SCENARIO_SUGGESTED_PROPS}\"\n            )\n\n        self.base_scenario = base_scenario\n        self.name = name\n        # if the base scenario had roadway or transit networks, use them as the basis.\n        self.road_net: Optional[RoadwayNetwork] = copy.deepcopy(self.base_scenario.get(\"road_net\"))\n        self.transit_net: Optional[TransitNetwork] = copy.deepcopy(\n            self.base_scenario.get(\"transit_net\")\n        )\n\n        self.project_cards: dict[str, ProjectCard] = {}\n        self._planned_projects: list[str] = []\n        self._queued_projects = None\n        self.applied_projects = self.base_scenario.get(\"applied_projects\", [])\n\n        self.prerequisites = self.base_scenario.get(\"prerequisites\", {})\n        self.corequisites = self.base_scenario.get(\"corequisites\", {})\n        self.conflicts = self.base_scenario.get(\"conflicts\", {})\n\n        for p in project_card_list:\n            self._add_project(p)\n\n    @property\n    def projects(self):\n        \"\"\"Returns a list of all projects in the scenario: applied and planned.\"\"\"\n        return self.applied_projects + self._planned_projects\n\n    @property\n    def queued_projects(self):\n        \"\"\"Returns a list version of _queued_projects queue.\n\n        Queued projects are thos that have been planned, have all pre-requisites satisfied, and\n        have been ordered based on pre-requisites.\n\n        If no queued projects, will dynamically generate from planned projects based on\n        pre-requisites and return the queue.\n        \"\"\"\n        if not self._queued_projects:\n            self._check_projects_requirements_satisfied(self._planned_projects)\n            self._queued_projects = self.order_projects(self._planned_projects)\n        return list(self._queued_projects)\n\n    def __str__(self):\n        \"\"\"String representation of the Scenario object.\"\"\"\n        s = [\"{}: {}\".format(key, value) for key, value in self.__dict__.items()]\n        return \"\\n\".join(s)\n\n    def _add_dependencies(self, project_name, dependencies: dict) -&gt; None:\n        \"\"\"Add dependencies from a project card to relevant scenario variables.\n\n        Updates existing \"prerequisites\", \"corequisites\" and \"conflicts\".\n        Lowercases everything to enable string matching.\n\n        Args:\n            project_name: name of project you are adding dependencies for.\n            dependencies: Dictionary of depndencies by dependency type and list of associated\n                projects.\n        \"\"\"\n        project_name = project_name.lower()\n\n        for d, v in dependencies.items():\n            _dep = list(map(str.lower, v))\n            WranglerLogger.debug(f\"Adding {_dep} to {project_name} dependency table.\")\n            self.__dict__[d].update({project_name: _dep})\n\n    def _add_project(\n        self,\n        project_card: ProjectCard,\n        validate: bool = True,\n        filter_tags: Collection[str] = [],\n    ) -&gt; None:\n        \"\"\"Adds a single ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Resets scenario queued_projects.\n\n        Args:\n            project_card (ProjectCard): ProjectCard instance to add to scenario.\n            validate (bool, optional): If True, will validate the projectcard before\n                being adding it to the scenario. Defaults to True.\n            filter_tags (Collection[str], optional): If used, will only add the project card if\n                its tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n\n        \"\"\"\n        project_name = project_card.project.lower()\n        filter_tags = list(map(str.lower, filter_tags))\n\n        if project_name in self.projects:\n            raise ProjectCardError(\n                f\"Names not unique from existing scenario projects: {project_card.project}\"\n            )\n\n        if filter_tags and set(project_card.tags).isdisjoint(set(filter_tags)):\n            WranglerLogger.debug(\n                f\"Skipping {project_name} - no overlapping tags with {filter_tags}.\"\n            )\n            return\n\n        if validate:\n            assert project_card.valid\n\n        WranglerLogger.info(f\"Adding {project_name} to scenario.\")\n        self.project_cards[project_name] = project_card\n        self._planned_projects.append(project_name)\n        self._queued_projects = None\n        self._add_dependencies(project_name, project_card.dependencies)\n\n    def add_project_cards(\n        self,\n        project_card_list: Collection[ProjectCard],\n        validate: bool = True,\n        filter_tags: Collection[str] = [],\n    ) -&gt; None:\n        \"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Args:\n            project_card_list (Collection[ProjectCard]): List of ProjectCard instances to add to\n                scenario.\n            validate (bool, optional): If True, will require each ProjectCard is validated before\n                being added to scenario. Defaults to True.\n            filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n                and only add those whose tags match one or more of these filter_tags.\n                Defaults to [] - which means no tag-filtering will occur.\n        \"\"\"\n        for p in project_card_list:\n            self._add_project(p, validate=validate, filter_tags=filter_tags)\n\n    def _check_projects_requirements_satisfied(self, project_list: Collection[str]):\n        \"\"\"Checks all requirements are satisified to apply this specific set of projects.\n\n        Including:\n        1. has an associaed project card\n        2. is in scenario's planned projects\n        3. pre-requisites satisfied\n        4. co-requisies satisfied by applied or co-applied projects\n        5. no conflicing applied or co-applied projects\n\n        Args:\n            project_list: list of projects to check requirements for.\n        \"\"\"\n        self._check_projects_planned(project_list)\n        self._check_projects_have_project_cards(project_list)\n        self._check_projects_prerequisites(project_list)\n        self._check_projects_corequisites(project_list)\n        self._check_projects_conflicts(project_list)\n\n    def _check_projects_planned(self, project_names: Collection[str]) -&gt; None:\n        \"\"\"Checks that a list of projects are in the scenario's planned projects.\"\"\"\n        _missing_ps = [p for p in self._planned_projects if p not in self._planned_projects]\n        if _missing_ps:\n            raise ValueError(\n                f\"Projects are not in planned projects: \\n {_missing_ps}. Add them by \\\n                using add_project_cards(), add_projects_from_files(), or \\\n                add_projects_from_directory().\"\n            )\n\n    def _check_projects_have_project_cards(self, project_list: Collection[str]) -&gt; bool:\n        \"\"\"Checks that a list of projects has an associated project card in the scenario.\"\"\"\n        _missing = [p for p in project_list if p not in self.project_cards]\n        if _missing:\n            WranglerLogger.error(\n                f\"Projects referenced which are missing project cards: {_missing}\"\n            )\n            return False\n        return True\n\n    def _check_projects_prerequisites(self, project_names: list[str]) -&gt; None:\n        \"\"\"Check a list of projects' pre-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.prerequisites.keys())):\n            return\n        _prereqs = []\n        for p in project_names:\n            _prereqs += self.prerequisites.get(p, [])\n        _projects_applied = self.applied_projects + project_names\n        _missing = list(set(_prereqs) - set(_projects_applied))\n        if _missing:\n            WranglerLogger.debug(\n                f\"project_names: {project_names}\\nprojects_have_or_will_be_applied: \\\n                    {_projects_applied}\\nmissing: {_missing}\"\n            )\n            raise ScenarioPrerequisiteError(f\"Missing {len(_missing)} pre-requisites: {_missing}\")\n\n    def _check_projects_corequisites(self, project_names: list[str]) -&gt; None:\n        \"\"\"Check a list of projects' co-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.corequisites.keys())):\n            return\n        _coreqs = []\n        for p in project_names:\n            _coreqs += self.corequisites.get(p, [])\n        _projects_applied = self.applied_projects + project_names\n        _missing = list(set(_coreqs) - set(_projects_applied))\n        if _missing:\n            WranglerLogger.debug(\n                f\"project_names: {project_names}\\nprojects_have_or_will_be_applied: \\\n                    {_projects_applied}\\nmissing: {_missing}\"\n            )\n            raise ScenarioCorequisiteError(f\"Missing {len(_missing)} corequisites: {_missing}\")\n\n    def _check_projects_conflicts(self, project_names: list[str]) -&gt; None:\n        \"\"\"Checks that list of projects' conflicts have not been or will be applied to scenario.\"\"\"\n        # WranglerLogger.debug(\"Checking Conflicts...\")\n        projects_to_check = project_names + self.applied_projects\n        # WranglerLogger.debug(f\"\\nprojects_to_check:{projects_to_check}\\nprojects_with_conflicts:{set(self.conflicts.keys())}\")\n        if set(projects_to_check).isdisjoint(set(self.conflicts.keys())):\n            # WranglerLogger.debug(\"Projects have no conflicts to check\")\n            return\n        _conflicts = []\n        for p in project_names:\n            _conflicts += self.conflicts.get(p, [])\n        _conflict_problems = [p for p in _conflicts if p in projects_to_check]\n        if _conflict_problems:\n            WranglerLogger.warning(f\"Conflict Problems: \\n{_conflict_problems}\")\n            _conf_dict = {\n                k: v\n                for k, v in self.conflicts.items()\n                if k in projects_to_check and not set(v).isdisjoint(set(_conflict_problems))\n            }\n            WranglerLogger.debug(f\"Problematic Conflicts: \\n{_conf_dict}\")\n            raise ScenarioConflictError(f\"Found {len(_conflicts)} conflicts: {_conflict_problems}\")\n\n    def order_projects(self, project_list: Collection[str]) -&gt; deque:\n        \"\"\"Orders a list of projects based on moving up pre-requisites into a deque.\n\n        Args:\n            project_list: list of projects to order\n\n        Returns: deque for applying projects.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n        assert self._check_projects_have_project_cards(project_list)\n\n        # build prereq (adjacency) list for topological sort\n        adjacency_list = defaultdict(list)\n        visited_list = defaultdict(bool)\n\n        for project in project_list:\n            visited_list[project] = False\n            if not self.prerequisites.get(project):\n                continue\n            for prereq in self.prerequisites[project]:\n                # this will always be true, else would have been flagged in missing \\\n                # prerequsite check, but just in case\n                if prereq.lower() in project_list:\n                    adjacency_list[prereq.lower()] = [project]\n\n        # sorted_project_names is topological sorted project card names (based on prerequsiite)\n        _ordered_projects = topological_sort(\n            adjacency_list=adjacency_list, visited_list=visited_list\n        )\n\n        if not set(_ordered_projects) == set(project_list):\n            _missing = list(set(project_list) - set(_ordered_projects))\n            raise ValueError(f\"Project sort resulted in missing projects: {_missing}\")\n\n        project_deque = deque(_ordered_projects)\n\n        WranglerLogger.debug(f\"Ordered Projects: \\n{project_deque}\")\n\n        return project_deque\n\n    def apply_all_projects(self):\n        \"\"\"Applies all planned projects in the queue.\"\"\"\n        # Call this to make sure projects are appropriately queued in hidden variable.\n        self.queued_projects\n\n        # Use hidden variable.\n        while self._queued_projects:\n            self._apply_project(self._queued_projects.popleft())\n\n        # set this so it will trigger re-queuing any more projects.\n        self._queued_projects = None\n\n    def _apply_change(self, change: Union[ProjectCard, SubProject]) -&gt; None:\n        \"\"\"Applies a specific change specified in a project card.\n\n        Change type must be in at least one of:\n        - ROADWAY_CATEGORIES\n        - TRANSIT_CATEGORIES\n\n        Args:\n            change: a project card or subproject card\n        \"\"\"\n        if change.change_type in ROADWAY_CARD_TYPES:\n            if not self.road_net:\n                raise ValueError(\"Missing Roadway Network\")\n            if change.change_type in SECONDARY_TRANSIT_CARD_TYPES and self.transit_net:\n                self.road_net.apply(change, transit_net = self.transit_net)\n            else:\n                self.road_net.apply(change)\n        if change.change_type in TRANSIT_CARD_TYPES:\n            if not self.transit_net:\n                raise ValueError(\"Missing Transit Network\")\n            self.transit_net.apply(change)\n\n        if change.change_type not in TRANSIT_CARD_TYPES + ROADWAY_CARD_TYPES:\n            raise ProjectCardError(\n                f\"Project {change.project}: Don't understand project cat: {change.change_type}\"\n            )\n\n    def _apply_project(self, project_name: str) -&gt; None:\n        \"\"\"Applies project card to scenario.\n\n        If a list of changes is specified in referenced project card, iterates through each change.\n\n        Args:\n            project_name (str): name of project to be applied.\n        \"\"\"\n        project_name = project_name.lower()\n\n        WranglerLogger.info(f\"Applying {project_name} from file:\\\n                            {self.project_cards[project_name].file}\")\n\n        p = self.project_cards[project_name]\n        WranglerLogger.debug(f\"types: {p.change_types}\")\n        WranglerLogger.debug(f\"type: {p.change_type}\")\n        if p._sub_projects:\n            for sp in p._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp)\n\n        else:\n            self._apply_change(p)\n\n        self._planned_projects.remove(project_name)\n        self.applied_projects.append(project_name)\n\n    def apply_projects(self, project_list: Collection[str]):\n        \"\"\"Applies a specific list of projects from the planned project queue.\n\n        Will order the list of projects based on pre-requisites.\n\n        NOTE: does not check co-requisites b/c that isn't possible when applying a sin\n\n        Args:\n            project_list: List of projects to be applied. All need to be in the planned project\n                queue.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n\n        self._check_projects_requirements_satisfied(project_list)\n        ordered_project_queue = self.order_projects(project_list)\n\n        while ordered_project_queue:\n            self._apply_project(ordered_project_queue.popleft())\n\n        # Set so that when called again it will retrigger queueing from planned projects.\n        self._ordered_projects = None\n\n    def write(self, path: Union[Path, str], name: str) -&gt; None:\n        \"\"\"_summary_.\n\n        Args:\n            path: Path to write scenario networks and scenario summary to.\n            name: Name to use.\n        \"\"\"\n        if self.road_net:\n            write_roadway(self.road_net, prefix=name, out_dir=path)\n        if self.transit_net:\n            write_transit(self.transit_net, prefix=name, out_dir=path)\n        self.summarize(outfile=os.path.join(path, name))\n\n    def summarize(self, project_detail: bool = True, outfile: str = \"\", mode: str = \"a\") -&gt; str:\n        \"\"\"A high level summary of the created scenario.\n\n        Args:\n            project_detail: If True (default), will write out project card summaries.\n            outfile: If specified, will write scenario summary to text file.\n            mode: Outfile open mode. 'a' to append 'w' to overwrite.\n\n        Returns:\n            string of summary\n\n        \"\"\"\n        return scenario_summary(self, project_detail, outfile, mode)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.projects","title":"<code>projects</code>  <code>property</code>","text":"<p>Returns a list of all projects in the scenario: applied and planned.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.queued_projects","title":"<code>queued_projects</code>  <code>property</code>","text":"<p>Returns a list version of _queued_projects queue.</p> <p>Queued projects are thos that have been planned, have all pre-requisites satisfied, and have been ordered based on pre-requisites.</p> <p>If no queued projects, will dynamically generate from planned projects based on pre-requisites and return the queue.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.__init__","title":"<code>__init__(base_scenario, project_card_list=None, name='')</code>","text":"<p>Constructor.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_scenario: Union[Scenario, dict],\n    project_card_list: Optional[list[ProjectCard]] = None,\n    name=\"\",\n):\n    \"\"\"Constructor.\n\n    Args:\n    base_scenario: A base scenario object to base this isntance off of, or a dict which\n        describes the scenario attributes including applied projects and respective conflicts.\n        `{\"applied_projects\": [],\"conflicts\":{...}}`\n    project_card_list: Optional list of ProjectCard instances to add to planned projects.\n        Defaults to None.\n    name: Optional name for the scenario.\n    \"\"\"\n    WranglerLogger.info(\"Creating Scenario\")\n\n    if project_card_list is None:\n        project_card_list = []\n\n    if isinstance(base_scenario, Scenario):\n        base_scenario = base_scenario.__dict__\n\n    if not set(BASE_SCENARIO_SUGGESTED_PROPS) &lt;= set(base_scenario.keys()):\n        WranglerLogger.warning(\n            f\"Base_scenario doesn't contain {BASE_SCENARIO_SUGGESTED_PROPS}\"\n        )\n\n    self.base_scenario = base_scenario\n    self.name = name\n    # if the base scenario had roadway or transit networks, use them as the basis.\n    self.road_net: Optional[RoadwayNetwork] = copy.deepcopy(self.base_scenario.get(\"road_net\"))\n    self.transit_net: Optional[TransitNetwork] = copy.deepcopy(\n        self.base_scenario.get(\"transit_net\")\n    )\n\n    self.project_cards: dict[str, ProjectCard] = {}\n    self._planned_projects: list[str] = []\n    self._queued_projects = None\n    self.applied_projects = self.base_scenario.get(\"applied_projects\", [])\n\n    self.prerequisites = self.base_scenario.get(\"prerequisites\", {})\n    self.corequisites = self.base_scenario.get(\"corequisites\", {})\n    self.conflicts = self.base_scenario.get(\"conflicts\", {})\n\n    for p in project_card_list:\n        self._add_project(p)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the Scenario object.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def __str__(self):\n    \"\"\"String representation of the Scenario object.\"\"\"\n    s = [\"{}: {}\".format(key, value) for key, value in self.__dict__.items()]\n    return \"\\n\".join(s)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.add_project_cards","title":"<code>add_project_cards(project_card_list, validate=True, filter_tags=[])</code>","text":"<p>Adds a list of ProjectCard instances to the Scenario.</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>project_card_list</code> <code>Collection[ProjectCard]</code> <p>List of ProjectCard instances to add to scenario.</p> required <code>validate</code> <code>bool</code> <p>If True, will require each ProjectCard is validated before being added to scenario. Defaults to True.</p> <code>True</code> <code>filter_tags</code> <code>Collection[str]</code> <p>If used, will filter ProjectCard instances and only add those whose tags match one or more of these filter_tags. Defaults to [] - which means no tag-filtering will occur.</p> <code>[]</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def add_project_cards(\n    self,\n    project_card_list: Collection[ProjectCard],\n    validate: bool = True,\n    filter_tags: Collection[str] = [],\n) -&gt; None:\n    \"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        project_card_list (Collection[ProjectCard]): List of ProjectCard instances to add to\n            scenario.\n        validate (bool, optional): If True, will require each ProjectCard is validated before\n            being added to scenario. Defaults to True.\n        filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n            and only add those whose tags match one or more of these filter_tags.\n            Defaults to [] - which means no tag-filtering will occur.\n    \"\"\"\n    for p in project_card_list:\n        self._add_project(p, validate=validate, filter_tags=filter_tags)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_all_projects","title":"<code>apply_all_projects()</code>","text":"<p>Applies all planned projects in the queue.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_all_projects(self):\n    \"\"\"Applies all planned projects in the queue.\"\"\"\n    # Call this to make sure projects are appropriately queued in hidden variable.\n    self.queued_projects\n\n    # Use hidden variable.\n    while self._queued_projects:\n        self._apply_project(self._queued_projects.popleft())\n\n    # set this so it will trigger re-queuing any more projects.\n    self._queued_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_projects","title":"<code>apply_projects(project_list)</code>","text":"<p>Applies a specific list of projects from the planned project queue.</p> <p>Will order the list of projects based on pre-requisites.</p> <p>NOTE: does not check co-requisites b/c that isn\u2019t possible when applying a sin</p> <p>Parameters:</p> Name Type Description Default <code>project_list</code> <code>Collection[str]</code> <p>List of projects to be applied. All need to be in the planned project queue.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_projects(self, project_list: Collection[str]):\n    \"\"\"Applies a specific list of projects from the planned project queue.\n\n    Will order the list of projects based on pre-requisites.\n\n    NOTE: does not check co-requisites b/c that isn't possible when applying a sin\n\n    Args:\n        project_list: List of projects to be applied. All need to be in the planned project\n            queue.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n\n    self._check_projects_requirements_satisfied(project_list)\n    ordered_project_queue = self.order_projects(project_list)\n\n    while ordered_project_queue:\n        self._apply_project(ordered_project_queue.popleft())\n\n    # Set so that when called again it will retrigger queueing from planned projects.\n    self._ordered_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.order_projects","title":"<code>order_projects(project_list)</code>","text":"<p>Orders a list of projects based on moving up pre-requisites into a deque.</p> <p>Parameters:</p> Name Type Description Default <code>project_list</code> <code>Collection[str]</code> <p>list of projects to order</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def order_projects(self, project_list: Collection[str]) -&gt; deque:\n    \"\"\"Orders a list of projects based on moving up pre-requisites into a deque.\n\n    Args:\n        project_list: list of projects to order\n\n    Returns: deque for applying projects.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n    assert self._check_projects_have_project_cards(project_list)\n\n    # build prereq (adjacency) list for topological sort\n    adjacency_list = defaultdict(list)\n    visited_list = defaultdict(bool)\n\n    for project in project_list:\n        visited_list[project] = False\n        if not self.prerequisites.get(project):\n            continue\n        for prereq in self.prerequisites[project]:\n            # this will always be true, else would have been flagged in missing \\\n            # prerequsite check, but just in case\n            if prereq.lower() in project_list:\n                adjacency_list[prereq.lower()] = [project]\n\n    # sorted_project_names is topological sorted project card names (based on prerequsiite)\n    _ordered_projects = topological_sort(\n        adjacency_list=adjacency_list, visited_list=visited_list\n    )\n\n    if not set(_ordered_projects) == set(project_list):\n        _missing = list(set(project_list) - set(_ordered_projects))\n        raise ValueError(f\"Project sort resulted in missing projects: {_missing}\")\n\n    project_deque = deque(_ordered_projects)\n\n    WranglerLogger.debug(f\"Ordered Projects: \\n{project_deque}\")\n\n    return project_deque\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.summarize","title":"<code>summarize(project_detail=True, outfile='', mode='a')</code>","text":"<p>A high level summary of the created scenario.</p> <p>Parameters:</p> Name Type Description Default <code>project_detail</code> <code>bool</code> <p>If True (default), will write out project card summaries.</p> <code>True</code> <code>outfile</code> <code>str</code> <p>If specified, will write scenario summary to text file.</p> <code>''</code> <code>mode</code> <code>str</code> <p>Outfile open mode. \u2018a\u2019 to append \u2018w\u2019 to overwrite.</p> <code>'a'</code> <p>Returns:</p> Type Description <code>str</code> <p>string of summary</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def summarize(self, project_detail: bool = True, outfile: str = \"\", mode: str = \"a\") -&gt; str:\n    \"\"\"A high level summary of the created scenario.\n\n    Args:\n        project_detail: If True (default), will write out project card summaries.\n        outfile: If specified, will write scenario summary to text file.\n        mode: Outfile open mode. 'a' to append 'w' to overwrite.\n\n    Returns:\n        string of summary\n\n    \"\"\"\n    return scenario_summary(self, project_detail, outfile, mode)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.write","title":"<code>write(path, name)</code>","text":"<p>summary.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[Path, str]</code> <p>Path to write scenario networks and scenario summary to.</p> required <code>name</code> <code>str</code> <p>Name to use.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def write(self, path: Union[Path, str], name: str) -&gt; None:\n    \"\"\"_summary_.\n\n    Args:\n        path: Path to write scenario networks and scenario summary to.\n        name: Name to use.\n    \"\"\"\n    if self.road_net:\n        write_roadway(self.road_net, prefix=name, out_dir=path)\n    if self.transit_net:\n        write_transit(self.transit_net, prefix=name, out_dir=path)\n    self.summarize(outfile=os.path.join(path, name))\n</code></pre>"},{"location":"api/#network_wrangler.scenario.ScenarioConflictError","title":"<code>ScenarioConflictError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a conflict is detected.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class ScenarioConflictError(Exception):\n    \"\"\"Raised when a conflict is detected.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.scenario.ScenarioCorequisiteError","title":"<code>ScenarioCorequisiteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a co-requisite is not satisfied.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class ScenarioCorequisiteError(Exception):\n    \"\"\"Raised when a co-requisite is not satisfied.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.scenario.ScenarioPrerequisiteError","title":"<code>ScenarioPrerequisiteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a pre-requisite is not satisfied.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class ScenarioPrerequisiteError(Exception):\n    \"\"\"Raised when a pre-requisite is not satisfied.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.scenario.build_scenario_from_config","title":"<code>build_scenario_from_config(config_dict)</code>","text":"<p>Builds a scenario from a dictionary configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>dictionary configuration of scenario.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def build_scenario_from_config(config_dict: dict):\n    \"\"\"Builds a scenario from a dictionary configuration.\n\n    Args:\n        config_dict: dictionary configuration of scenario.\n    \"\"\"\n    WranglerLogger.info(\"Building Scenario from Configuration\")\n    WranglerLogger.debug(\"{pprint.pformat(config_dict)}\")\n\n    base_network_dir = config_dict.get(\"base_network\").get(\"input_dir\")\n    base_shape_name = config_dict.get(\"base_network\").get(\"shape_file_name\")\n    base_link_name = config_dict.get(\"base_network\").get(\"link_file_name\")\n    base_node_name = config_dict.get(\"base_network\").get(\"node_file_name\")\n\n    project_card_filepath = config_dict.get(\"scenario\").get(\"project_card_filepath\")\n    project_tags = config_dict.get(\"scenario\").get(\"tags\")\n\n    write_out = config_dict.get(\"scenario\").get(\"write_out\")\n    out_dir = config_dict.get(\"scenario\").get(\"output_dir\")\n    out_prefix = config_dict.get(\"scenario\").get(\"out_prefix\")\n\n    if project_tags is None:\n        project_tags = []\n\n    if project_card_filepath is None:\n        project_card_filepath = []\n\n    # Create Base Network\n    base_scenario = create_base_scenario(\n        roadway_dir=base_network_dir,\n        base_shape_name=base_shape_name,\n        base_link_name=base_link_name,\n        base_node_name=base_node_name,\n        transit_dir=base_network_dir,\n    )\n\n    my_scenario = Scenario.create_scenario(\n        base_scenario=base_scenario,\n        project_card_filepath=project_card_filepath,\n        filter_tags=project_tags,\n    )\n\n    WranglerLogger.info(\"Applying these projects to the base scenario ...\")\n    WranglerLogger.info(\"\\n\".join(my_scenario.projects.keys()))\n\n    my_scenario.apply_all_projects()\n\n    if write_out:\n        write_roadway(my_scenario.road_net, prefix=out_prefix, out_dir=out_dir)\n        my_scenario.transit_net.write(filename=out_prefix, path=out_dir)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.build_scenario_from_config_file","title":"<code>build_scenario_from_config_file(config_file)</code>","text":"<p>Builds a scenario from a yaml configuration file.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>Path</code> <p>Path to the yaml configuration file.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def build_scenario_from_config_file(config_file: Path) -&gt; None:\n    \"\"\"Builds a scenario from a yaml configuration file.\n\n    Args:\n        config_file: Path to the yaml configuration file.\n    \"\"\"\n    config_path = Path(config_file)\n    if not config_path.exists():\n        raise FileNotFoundError(f\"Specified config file does not exist - {config_path}\")\n\n    with open(config_file, \"r\") as config:\n        config_dict = yaml.safe_load(config)\n    WranglerLogger.info(f\"Building Scenario from {config_file}\")\n    build_scenario_from_config(config_dict)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.create_base_scenario","title":"<code>create_base_scenario(base_shape_name, base_link_name, base_node_name, roadway_dir='', transit_dir='')</code>","text":"<p>Creates a base scenario dictionary from roadway and transit network files.</p> <p>Parameters:</p> Name Type Description Default <code>base_shape_name</code> <code>str</code> <p>filename of the base network shape</p> required <code>base_link_name</code> <code>str</code> <p>filename of the base network link</p> required <code>base_node_name</code> <code>str</code> <p>filename of the base network node</p> required <code>roadway_dir</code> <code>str</code> <p>optional path to the base scenario roadway network files</p> <code>''</code> <code>transit_dir</code> <code>str</code> <p>optional path to base scenario transit files</p> <code>''</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def create_base_scenario(\n    base_shape_name: str,\n    base_link_name: str,\n    base_node_name: str,\n    roadway_dir: str = \"\",\n    transit_dir: str = \"\",\n) -&gt; dict:\n    \"\"\"Creates a base scenario dictionary from roadway and transit network files.\n\n    Args:\n        base_shape_name: filename of the base network shape\n        base_link_name: filename of the base network link\n        base_node_name: filename of the base network node\n        roadway_dir: optional path to the base scenario roadway network files\n        transit_dir: optional path to base scenario transit files\n    \"\"\"\n    if roadway_dir:\n        base_network_shape_file = os.path.join(roadway_dir, base_shape_name)\n        base_network_link_file = os.path.join(roadway_dir, base_link_name)\n        base_network_node_file = os.path.join(roadway_dir, base_node_name)\n    else:\n        base_network_shape_file = base_shape_name\n        base_network_link_file = base_link_name\n        base_network_node_file = base_node_name\n\n    road_net = load_roadway(\n        links_file=base_network_link_file,\n        nodes_file=base_network_node_file,\n        shapes_file=base_network_shape_file,\n    )\n\n    if transit_dir:\n        transit_net = load_transit(transit_dir)\n        transit_net.road_net = road_net\n    else:\n        transit_net = None\n        WranglerLogger.info(\n            \"No transit directory specified, base scenario will have empty transit network.\"\n        )\n\n    base_scenario = {\"road_net\": road_net, \"transit_net\": transit_net}\n\n    return base_scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.create_scenario","title":"<code>create_scenario(base_scenario={}, project_card_list=None, project_card_filepath=None, filter_tags=[], validate=True)</code>","text":"<p>Creates scenario from a base scenario and adds project cards.</p> <p>Project cards can be added using any/all of the following methods: 1. List of ProjectCard instances 2. List of ProjectCard files 3. Directory and optional glob search to find project card files in</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>base_scenario</code> <code>Union[Scenario, dict]</code> <p>base Scenario scenario instances of dictionary of attributes.</p> <code>{}</code> <code>project_card_list</code> <p>List of ProjectCard instances to create Scenario from. Defaults to [].</p> <code>None</code> <code>project_card_filepath</code> <code>Optional[Union[Collection[str], str]]</code> <p>where the project card is.  A single path, list of paths,</p> <code>None</code> <code>filter_tags</code> <code>Collection[str]</code> <p>If used, will only add the project card if its tags match one or more of these filter_tags. Defaults to [] which means no tag-filtering will occur.</p> <code>[]</code> <code>validate</code> <code>bool</code> <p>If True, will validate the projectcard before being adding it to the scenario. Defaults to True.</p> <code>True</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def create_scenario(\n    base_scenario: Union[Scenario, dict] = {},\n    project_card_list = None,\n    project_card_filepath: Optional[Union[Collection[str], str]] = None,\n    filter_tags: Collection[str] = [],\n    validate=True,\n) -&gt; Scenario:\n    \"\"\"Creates scenario from a base scenario and adds project cards.\n\n    Project cards can be added using any/all of the following methods:\n    1. List of ProjectCard instances\n    2. List of ProjectCard files\n    3. Directory and optional glob search to find project card files in\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        base_scenario: base Scenario scenario instances of dictionary of attributes.\n        project_card_list: List of ProjectCard instances to create Scenario from. Defaults\n            to [].\n        project_card_filepath: where the project card is.  A single path, list of paths,\n        a directory, or a glob pattern. Defaults to None.\n        filter_tags (Collection[str], optional): If used, will only add the project card if\n            its tags match one or more of these filter_tags. Defaults to []\n            which means no tag-filtering will occur.\n        validate (bool, optional): If True, will validate the projectcard before\n            being adding it to the scenario. Defaults to True.\n    \"\"\"\n    if project_card_list is None:\n        project_card_list = []\n\n    scenario = Scenario(base_scenario)\n\n    if project_card_filepath:\n        project_card_list += list(\n            read_cards(project_card_filepath, filter_tags=filter_tags).values()\n        )\n\n    if project_card_list:\n        scenario.add_project_cards(project_card_list, filter_tags=filter_tags, validate=validate)\n\n    return scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.scenario_summary","title":"<code>scenario_summary(scenario, project_detail=True, outfile='', mode='a')</code>","text":"<p>A high level summary of the created scenario.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>Scenario</code> <p>Scenario instance to summarize.</p> required <code>project_detail</code> <code>bool</code> <p>If True (default), will write out project card summaries.</p> <code>True</code> <code>outfile</code> <code>str</code> <p>If specified, will write scenario summary to text file.</p> <code>''</code> <code>mode</code> <code>str</code> <p>Outfile open mode. \u2018a\u2019 to append \u2018w\u2019 to overwrite.</p> <code>'a'</code> <p>Returns:</p> Type Description <code>str</code> <p>string of summary</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def scenario_summary(\n    scenario: Scenario, project_detail: bool = True, outfile: str = \"\", mode: str = \"a\"\n) -&gt; str:\n    \"\"\"A high level summary of the created scenario.\n\n    Args:\n        scenario: Scenario instance to summarize.\n        project_detail: If True (default), will write out project card summaries.\n        outfile: If specified, will write scenario summary to text file.\n        mode: Outfile open mode. 'a' to append 'w' to overwrite.\n\n    Returns:\n        string of summary\n    \"\"\"\n    WranglerLogger.info(f\"Summarizing Scenario {scenario.name}\")\n    report_str = \"------------------------------\\n\"\n    report_str += f\"Scenario created on {datetime.now()}\\n\"\n\n    report_str += \"Base Scenario:\\n\"\n    report_str += \"--Road Network:\\n\"\n    report_str += f\"----Link File: {scenario.base_scenario['road_net']._links_file}\\n\"\n    report_str += f\"----Node File: {scenario.base_scenario['road_net']._nodes_file}\\n\"\n    report_str += f\"----Shape File: {scenario.base_scenario['road_net']._shapes_file}\\n\"\n    report_str += \"--Transit Network:\\n\"\n    report_str += f\"----Feed Path: {scenario.base_scenario['transit_net'].feed.feed_path}\\n\"\n\n    report_str += \"\\nProject Cards:\\n -\"\n    report_str += \"\\n-\".join([str(pc.file) for p, pc in scenario.project_cards.items()])\n\n    report_str += \"\\nApplied Projects:\\n-\"\n    report_str += \"\\n-\".join(scenario.applied_projects)\n\n    if project_detail:\n        report_str += \"\\n---Project Card Details---\\n\"\n        for p in scenario.project_cards:\n            report_str += \"\\n{}\".format(\n                pprint.pformat(\n                    [scenario.project_cards[p].__dict__ for p in scenario.applied_projects]\n                )\n            )\n\n    if outfile:\n        with open(outfile, mode) as f:\n            f.write(report_str)\n        WranglerLogger.info(f\"Wrote Scenario Report to: {outfile}\")\n\n    return report_str\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork","title":"<code>RoadwayNetwork</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Representation of a Roadway Network.</p> <p>Typical usage example:</p> <pre><code>net = load_roadway(\n    links_file=MY_LINK_FILE,\n    nodes_file=MY_NODE_FILE,\n    shapes_file=MY_SHAPE_FILE,\n)\nmy_selection = {\n    \"link\": [{\"name\": [\"I 35E\"]}],\n    \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n    \"B\": {\"osm_node_id\": \"2564047368\"},\n}\nnet.get_selection(my_selection)\n\nmy_change = [\n    {\n        'property': 'lanes',\n        'existing': 1,\n        'set': 2,\n    },\n    {\n        'property': 'drive_access',\n        'set': 0,\n    },\n]\n\nmy_net.apply_roadway_feature_change(\n    my_net.get_selection(my_selection),\n    my_change\n)\n\n    net.model_net\n    net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n    _, disconnected_nodes = net.assess_connectivity(\n        mode=\"walk\",\n        ignore_end_nodes=True,\n        nodes=self.m_nodes_df,\n        links=self.m_links_df\n    )\n    write_roadway(net,filename=my_out_prefix, path=my_dir, for_model = True)\n</code></pre> <p>Attributes:</p> Name Type Description <code>nodes_df</code> <code>RoadNodesTable</code> <p>dataframe of of node records.</p> <code>links_df</code> <code>RoadLinksTable</code> <p>dataframe of link records and associated properties.</p> <code>shapes_df</code> <code>RoadShapestable</code> <p>data from of detailed shape records  This is lazily created iff it is called because shapes files can be expensive to read.</p> <code>selections</code> <code>dict</code> <p>dictionary of stored roadway selection objects, mapped by <code>RoadwayLinkSelection.sel_key</code> or <code>RoadwayNodeSelection.sel_key</code> in case they are     made repeatedly.</p> <code>crs</code> <code>str</code> <p>coordinate reference system in ESPG number format. Defaults to DEFAULT_CRS which is set to 4326, WGS 84 Lat/Long</p> <code>network_hash</code> <code>str</code> <p>dynamic property of the hashed value of links_df and nodes_df. Used for quickly identifying if a network has changed since various expensive operations have taken place (i.e. generating a ModelRoadwayNetwork or a network graph)</p> <code>model_net</code> <code>ModelRoadwayNetwork</code> <p>referenced <code>ModelRoadwayNetwork</code> object which will be lazily created if None or if the <code>network_hash</code> has changed.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>class RoadwayNetwork(BaseModel):\n    \"\"\"Representation of a Roadway Network.\n\n    Typical usage example:\n\n    ```py\n    net = load_roadway(\n        links_file=MY_LINK_FILE,\n        nodes_file=MY_NODE_FILE,\n        shapes_file=MY_SHAPE_FILE,\n    )\n    my_selection = {\n        \"link\": [{\"name\": [\"I 35E\"]}],\n        \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n        \"B\": {\"osm_node_id\": \"2564047368\"},\n    }\n    net.get_selection(my_selection)\n\n    my_change = [\n        {\n            'property': 'lanes',\n            'existing': 1,\n            'set': 2,\n        },\n        {\n            'property': 'drive_access',\n            'set': 0,\n        },\n    ]\n\n    my_net.apply_roadway_feature_change(\n        my_net.get_selection(my_selection),\n        my_change\n    )\n\n        net.model_net\n        net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n        _, disconnected_nodes = net.assess_connectivity(\n            mode=\"walk\",\n            ignore_end_nodes=True,\n            nodes=self.m_nodes_df,\n            links=self.m_links_df\n        )\n        write_roadway(net,filename=my_out_prefix, path=my_dir, for_model = True)\n    ```\n\n    Attributes:\n        nodes_df (RoadNodesTable): dataframe of of node records.\n        links_df (RoadLinksTable): dataframe of link records and associated properties.\n        shapes_df (RoadShapestable): data from of detailed shape records  This is lazily\n            created iff it is called because shapes files can be expensive to read.\n        selections (dict): dictionary of stored roadway selection objects, mapped by\n            `RoadwayLinkSelection.sel_key` or `RoadwayNodeSelection.sel_key` in case they are\n                made repeatedly.\n        crs (str): coordinate reference system in ESPG number format. Defaults to DEFAULT_CRS\n            which is set to 4326, WGS 84 Lat/Long\n        network_hash: dynamic property of the hashed value of links_df and nodes_df. Used for\n            quickly identifying if a network has changed since various expensive operations have\n            taken place (i.e. generating a ModelRoadwayNetwork or a network graph)\n        model_net (ModelRoadwayNetwork): referenced `ModelRoadwayNetwork` object which will be\n            lazily created if None or if the `network_hash` has changed.\n    \"\"\"\n\n    crs: Literal[LAT_LON_CRS] = LAT_LON_CRS\n    nodes_df: DataFrame[RoadNodesTable]\n    links_df: DataFrame[RoadLinksTable]\n    _shapes_df: Optional[DataFrame[RoadShapesTable]] = None\n\n    _links_file: Optional[Path] = None\n    _nodes_file: Optional[Path] = None\n    _shapes_file: Optional[Path] = None\n\n    _shapes_params: ShapesParams = ShapesParams()\n    _model_net: Optional[ModelRoadwayNetwork] = None\n    _selections: dict[str, Selections] = {}\n    _modal_graphs: dict[str, dict] = defaultdict(lambda: {\"graph\": None, \"hash\": None})\n\n    @field_validator(\"nodes_df\", \"links_df\")\n    def coerce_crs(cls, v, info):\n        \"\"\"Coerce crs of nodes_df and links_df to network crs.\"\"\"\n        net_crs = info.data[\"crs\"]\n        if v.crs != net_crs:\n            WranglerLogger.warning(\n                f\"CRS of links_df ({v.crs}) doesn't match network crs {net_crs}. \\\n                    Changing to network crs.\"\n            )\n            v.to_crs(net_crs)\n        return v\n\n    @property\n    def shapes_df(self) -&gt; DataFrame[RoadShapesTable]:\n        \"\"\"Load and return RoadShapesTable.\n\n        If not already loaded, will read from shapes_file and return. If shapes_file is None,\n        will return an empty dataframe with the right schema. If shapes_df is already set, will\n        return that.\n        \"\"\"\n        if (self._shapes_df is None or self._shapes_df.empty) and self._shapes_file is not None:\n            self._shapes_df = read_shapes(\n                self._shapes_file,\n                in_crs=self.crs,\n                shapes_params=self._shapes_params,\n                filter_to_shape_ids=self.links_df.shape_id.to_list(),\n            )\n        # if there is NONE, then at least create an empty dataframe with right schema\n        elif self._shapes_df is None:\n            self._shapes_df = empty_df_from_datamodel(RoadShapesTable, crs=self.crs)\n            self._shapes_df.set_index(\"shape_id_idx\", inplace=True)\n\n        return self._shapes_df\n\n    @shapes_df.setter\n    def shapes_df(self, value):\n        self._shapes_df = df_to_shapes_df(value, shapes_params=self._shapes_params)\n\n    @property\n    def network_hash(self) -&gt; str:\n        \"\"\"Hash of the links and nodes dataframes.\"\"\"\n        _value = str.encode(self.links_df.df_hash() + \"-\" + self.nodes_df.df_hash())\n\n        _hash = hashlib.sha256(_value).hexdigest()\n        return _hash\n\n    @property\n    def model_net(self) -&gt; ModelRoadwayNetwork:\n        \"\"\"Return a ModelRoadwayNetwork object for this network.\"\"\"\n        if self._model_net is None or self._model_net._net_hash != self.network_hash:\n            self._model_net = ModelRoadwayNetwork(self)\n        return self._model_net\n\n    @property\n    def summary(self) -&gt; dict:\n        \"\"\"Quick summary dictionary of number of links, nodes.\"\"\"\n        d = {\n            \"links\": len(self.links_df),\n            \"nodes\": len(self.nodes_df),\n        }\n        return d\n\n    @property\n    def link_shapes_df(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Add shape geometry to links if available.\n\n        returns: shapes merged to nodes dataframe\n        \"\"\"\n        _links_df = copy.deepcopy(self.links_df)\n        link_shapes_df = _links_df.merge(\n            self.shapes_df,\n            left_on=self.links_df.params.fk_to_shape,\n            right_on=self.shapes_df.params.primary_key,\n            how=\"left\",\n        )\n        return link_shapes_df\n\n    def get_property_by_timespan_and_group(\n        self,\n        link_property: str,\n        category: Union[str, int] = DEFAULT_CATEGORY,\n        timespan: TimespanString = DEFAULT_TIMESPAN,\n        strict_timespan_match: bool = False,\n        min_overlap_minutes: int = 60,\n    ) -&gt; Any:\n        \"\"\"Returns a new dataframe with model_link_id and link property by category and timespan.\n\n        Convenience method for backward compatability.\n\n        Args:\n            link_property: link property to query\n            category: category to query or a list of categories. Defaults to DEFAULT_CATEGORY.\n            timespan: timespan to query in the form of [\"HH:MM\",\"HH:MM\"].\n                Defaults to DEFAULT_TIMESPAN.\n            strict_timespan_match: If True, will only return links that match the timespan exactly.\n                Defaults to False.\n            min_overlap_minutes: If strict_timespan_match is False, will return links that overlap\n                with the timespan by at least this many minutes. Defaults to 60.\n        \"\"\"\n        from .links.scopes import prop_for_scope\n\n        return prop_for_scope(\n            self.links_df,\n            link_property,\n            timespan=timespan,\n            category=category,\n            strict_timespan_match=strict_timespan_match,\n            min_overlap_minutes=min_overlap_minutes,\n        )\n\n    def get_selection(\n        self,\n        selection_dict: Union[dict, SelectFacility],\n        overwrite: bool = False,\n    ) -&gt; Union[RoadwayNodeSelection, RoadwayLinkSelection]:\n        \"\"\"Return selection if it already exists, otherwise performs selection.\n\n        Args:\n            selection_dict (dict): SelectFacility dictionary.\n            overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n        \"\"\"\n        key = _create_selection_key(selection_dict)\n        if (key in self._selections) and not overwrite:\n            WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n            return self._selections[key]\n\n        if isinstance(selection_dict, SelectFacility):\n            selection_data = selection_dict\n        elif isinstance(selection_dict, SelectLinksDict):\n            selection_data = SelectFacility(links=selection_dict)\n        elif isinstance(selection_dict, SelectNodesDict):\n            selection_data = SelectFacility(nodes=selection_dict)\n        elif isinstance(selection_dict, dict):\n            selection_data = SelectFacility(**selection_dict)\n        else:\n            WranglerLogger.error(f\"`selection_dict` arg must be a dictionary or SelectFacility\\\n                              model. Received: {selection_dict} of type {type(selection_dict)}\")\n            raise SelectionError(\"selection_dict arg must be a dictionary or SelectFacility model\")\n\n        WranglerLogger.debug(f\"Getting selection from key: {key}\")\n        if selection_data.feature_types in [\"links\", \"segment\"]:\n            return RoadwayLinkSelection(self, selection_dict)\n        elif selection_data.feature_types == \"nodes\":\n            return RoadwayNodeSelection(self, selection_dict)\n        else:\n            WranglerLogger.error(\"Selection data should be of type 'segment', 'links' or 'nodes'.\")\n            raise SelectionError(\"Selection data should be of type 'segment', 'links' or 'nodes'.\")\n\n    def modal_graph_hash(self, mode) -&gt; str:\n        \"\"\"Hash of the links in order to detect a network change from when graph created.\"\"\"\n        _value = str.encode(self.links_df.df_hash() + \"-\" + mode)\n        _hash = hashlib.sha256(_value).hexdigest()\n\n        return _hash\n\n    def get_modal_graph(self, mode) -&gt; MultiDiGraph:\n        \"\"\"Return a networkx graph of the network for a specific mode.\n\n        Args:\n            mode: mode of the network, one of `drive`,`transit`,`walk`, `bike`\n        \"\"\"\n        from .graph import net_to_graph\n\n        if self._modal_graphs[mode][\"hash\"] != self.modal_graph_hash(mode):\n            self._modal_graphs[mode][\"graph\"] = net_to_graph(self, mode)\n\n        return self._modal_graphs[mode][\"graph\"]\n\n    def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; RoadwayNetwork:\n        \"\"\"Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n        Args:\n            project_card: either a dictionary of the project card object or ProjectCard instance\n            **kwargs: keyword arguments to pass to project application\n        \"\"\"\n        if not (isinstance(project_card, ProjectCard) or isinstance(project_card, SubProject)):\n            project_card = ProjectCard(project_card)\n\n        # project_card.validate()\n        if not project_card.valid:\n            WranglerLogger.error(\"Invalid Project Card: {project_card}\")\n            raise ValueError(f\"Project card {project_card.project} not valid.\")\n\n        if project_card._sub_projects:\n            for sp in project_card._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp, **kwargs)\n            return self\n        else:\n            return self._apply_change(project_card, **kwargs)\n\n    def _apply_change(\n        self, \n        change: Union[ProjectCard, SubProject],\n        transit_net = None,\n    ) -&gt; RoadwayNetwork:\n        \"\"\"Apply a single change: a single-project project or a sub-project.\"\"\"\n        if not isinstance(change, SubProject):\n            WranglerLogger.info(f\"Applying Project to Roadway Network: {change.project}\")\n\n        if change.change_type == \"roadway_property_change\":\n            return apply_roadway_property_change(\n                self,\n                self.get_selection(change.facility),\n                change.roadway_property_change[\"property_changes\"],\n                project_name=change.project,\n            )\n\n        elif change.change_type == \"roadway_addition\":\n            return apply_new_roadway(\n                self,\n                change.roadway_addition,\n                project_name=change.project,\n            )\n\n        elif change.change_type == \"roadway_deletion\":\n            deleted_link_id_list = change.roadway_deletion[\"links\"][\"model_link_id\"]\n            deleted_links_df = self.links_df[self.links_df[\"model_link_id\"].isin(deleted_link_id_list)]\n            shapes_df = transit_net.feed.shapes.copy()\n\n            # sort the shapes_df by agency_raw_name, shape_id and shape_pt_sequence\n            if \"agency_raw_name\" in shapes_df.columns:\n                shapes_df = shapes_df.sort_values([\"agency_raw_name\", \"shape_id\", \"shape_pt_sequence\"])\n            else:\n                shapes_df = shapes_df.sort_values([\"shape_id\", \"shape_pt_sequence\"])\n            # create shape_model_node_id_next column by using the value of the next row's shape_model_node_id\n            shapes_df[\"shape_model_node_id_next\"] = shapes_df[\"shape_model_node_id\"].shift(-1)\n            # create shape_id_next column by using the value of the next row's shape_id\n            shapes_df[\"shape_id_next\"] = shapes_df[\"shape_id\"].shift(-1)\n            # keep rows with the same shape_id_next and the shape_id\n            shapes_df = shapes_df[shapes_df[\"shape_id_next\"] == shapes_df[\"shape_id\"]]\n            # make sure shape_model_node_id_next and shape_model_node_id_next are numeric\n            shapes_df[\"shape_model_node_id_next\"] = pd.to_numeric(shapes_df[\"shape_model_node_id_next\"])\n            shapes_df[\"shape_model_node_id\"] = pd.to_numeric(shapes_df[\"shape_model_node_id\"])\n\n            shapes_df = shapes_df.merge(\n                deleted_links_df[[\"model_link_id\", \"A\", \"B\"]], \n                how=\"left\",\n                left_on=[\"shape_model_node_id\", \"shape_model_node_id_next\"], \n                right_on=[\"A\", \"B\"]\n            )\n            shapes_df = shapes_df[shapes_df[\"model_link_id\"].notna()]\n            if len(shapes_df) &gt; 0:\n                msg = f\"Roadway deletion results in broken transit shape_ids: {shapes_df.shape_id.unique()}\"\n                # raise NotImplementedError(msg)\n                WranglerLogger.warning(msg)\n\n            return apply_roadway_deletion(\n                self,\n                change.roadway_deletion,\n            )\n\n        elif change.change_type == \"pycode\":\n            return apply_calculated_roadway(self, change.pycode)\n        else:\n            WranglerLogger.error(f\"Couldn't find project in: \\n{change.__dict__}\")\n            raise (ValueError(f\"Invalid Project Card Category: {change.change_type}\"))\n\n    def links_with_link_ids(self, link_ids: List[int]) -&gt; DataFrame[RoadLinksTable]:\n        \"\"\"Return subset of links_df based on link_ids list.\"\"\"\n        return filter_links_to_ids(self.links_df, link_ids)\n\n    def links_with_nodes(self, node_ids: List[int]) -&gt; DataFrame[RoadLinksTable]:\n        \"\"\"Return subset of links_df based on node_ids list.\"\"\"\n        return filter_links_to_node_ids(self.links_df, node_ids)\n\n    def nodes_in_links(self) -&gt; DataFrame[RoadNodesTable]:\n        \"\"\"Returns subset of self.nodes_df that are in self.links_df.\"\"\"\n        return filter_nodes_to_links(self.links_df, self.nodes_df)\n\n    def add_links(self, add_links_df: Union[pd.DataFrame, DataFrame[RoadLinksTable]]):\n        \"\"\"Validate combined links_df with LinksSchema before adding to self.links_df.\n\n        Args:\n            add_links_df: Dataframe of additional links to add.\n        \"\"\"\n        if not isinstance(add_links_df, RoadLinksTable):\n            add_links_df = data_to_links_df(add_links_df, nodes_df=self.nodes_df)\n        self.links_df = RoadLinksTable(pd.concat([self.links_df, add_links_df], axis=0))\n\n    def add_nodes(self, add_nodes_df: Union[pd.DataFrame, DataFrame[RoadNodesTable]]):\n        \"\"\"Validate combined nodes_df with NodesSchema before adding to self.nodes_df.\n\n        Args:\n            add_nodes_df: Dataframe of additional nodes to add.\n        \"\"\"\n        if not isinstance(add_nodes_df, RoadNodesTable):\n            add_nodes_df = data_to_nodes_df(add_nodes_df)\n        self.nodes_df = RoadNodesTable(pd.concat([self.nodes_df, add_nodes_df], axis=0))\n\n    def add_shapes(self, add_shapes_df: Union[pd.DataFrame, DataFrame[RoadShapesTable]]):\n        \"\"\"Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.\n\n        Args:\n            add_shapes_df: Dataframe of additional shapes to add.\n        \"\"\"\n        if not isinstance(add_shapes_df, RoadShapesTable):\n            add_shapes_df = df_to_shapes_df(add_shapes_df)\n        WranglerLogger.debug(f\"add_shapes_df: \\n{add_shapes_df}\")\n        WranglerLogger.debug(f\"self.shapes_df: \\n{self.shapes_df}\")\n        together_df = pd.concat([self.shapes_df, add_shapes_df])\n        WranglerLogger.debug(f\"together_df: \\n{together_df}\")\n        self.shapes_df = RoadShapesTable(pd.concat([self.shapes_df, add_shapes_df], axis=0))\n\n    def delete_links(\n        self,\n        selection_dict: SelectLinksDict,\n        clean_nodes: bool = False,\n        clean_shapes: bool = False,\n    ):\n        \"\"\"Deletes links based on selection dictionary and optionally associated nodes and shapes.\n\n        Args:\n            selection_dict (SelectLinks): Dictionary describing link selections as follows:\n                `all`: Optional[bool] = False. If true, will select all.\n                `name`: Optional[list[str]]\n                `ref`: Optional[list[str]]\n                `osm_link_id`:Optional[list[str]]\n                `model_link_id`: Optional[list[int]]\n                `modes`: Optional[list[str]]. Defaults to \"any\"\n                `ignore_missing`: if true, will not error when defaults to True.\n                ...plus any other link property to select on top of these.\n            clean_nodes (bool, optional): If True, will clean nodes uniquely associated with\n                deleted links. Defaults to False.\n            clean_shapes (bool, optional): If True, will clean nodes uniquely associated with\n                deleted links. Defaults to False.\n        \"\"\"\n        selection_dict = SelectLinksDict(**selection_dict).model_dump(\n            exclude_none=True, by_alias=True\n        )\n        selection = self.get_selection({\"links\": selection_dict})\n\n        if clean_nodes:\n            node_ids_to_delete = node_ids_unique_to_link_ids(\n                selection.selected_links, selection.selected_links_df, self.nodes_df\n            )\n            WranglerLogger.debug(\n                f\"Dropping nodes associated with dropped links: \\n{node_ids_to_delete}\"\n            )\n            self.nodes_df = delete_nodes_by_ids(self.nodes_df, del_node_ids=node_ids_to_delete)\n\n        if clean_shapes:\n            shape_ids_to_delete = shape_ids_unique_to_link_ids(\n                selection.selected_links, selection.selected_links_df, self.shapes_df\n            )\n            WranglerLogger.debug(\n                f\"Dropping shapes associated with dropped links: \\n{shape_ids_to_delete}\"\n            )\n            self.shapes_df = delete_shapes_by_ids(\n                self.shapes_df, del_shape_ids=shape_ids_to_delete\n            )\n\n        self.links_df = delete_links_by_ids(\n            self.links_df,\n            selection.selected_links,\n            ignore_missing=selection.ignore_missing,\n        )\n\n    def delete_nodes(\n        self,\n        selection_dict: Union[dict, SelectNodesDict],\n        remove_links: bool = False,\n    ) -&gt; None:\n        \"\"\"Deletes nodes from roadway network. Wont delete nodes used by links in network.\n\n        Args:\n            selection_dict: dictionary of node selection criteria in the form of a SelectNodesDict.\n            remove_links: if True, will remove any links that are associated with the nodes.\n                If False, will only remove nodes if they are not associated with any links.\n                Defaults to False.\n\n        raises:\n            NodeDeletionError: If not ignore_missing and selected nodes to delete aren't in network\n        \"\"\"\n        if not isinstance(selection_dict, SelectNodesDict):\n            selection_dict = SelectNodesDict(**selection_dict)\n        selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n        selection: RoadwayNodeSelection = self.get_selection(\n            {\"nodes\": selection_dict},\n        )\n        if remove_links:\n            del_node_ids = selection.selected_nodes\n            link_ids = self.links_with_nodes(selection.selected_nodes).model_link_id.to_list()\n            WranglerLogger.info(f\"Removing {len(link_ids)} links associated with nodes.\")\n            self.delete_links({\"model_link_id\": link_ids})\n        else:\n            unused_node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n            del_node_ids = list(set(selection.selected_nodes).intersection(unused_node_ids))\n\n        self.nodes_df = delete_nodes_by_ids(\n            self.nodes_df, del_node_ids, ignore_missing=selection.ignore_missing\n        )\n\n    def clean_unused_shapes(self):\n        \"\"\"Removes any unused shapes from network that aren't referenced by links_df.\"\"\"\n        from .shapes.shapes import shape_ids_without_links\n\n        del_shape_ids = shape_ids_without_links(self.shapes_df, self.links_df)\n        self.shapes_df = self.shapes_df.drop(del_shape_ids)\n\n    def clean_unused_nodes(self):\n        \"\"\"Removes any unused nodes from network that aren't referenced by links_df.\n\n        NOTE: does not check if these nodes are used by transit, so use with caution.\n        \"\"\"\n        from .nodes.nodes import node_ids_without_links\n\n        node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n        self.nodes_df = self.nodes_df.drop(node_ids)\n\n    def move_nodes(\n        self,\n        node_geometry_change_table: DataFrame[NodeGeometryChangeTable],\n    ):\n        \"\"\"Moves nodes based on updated geometry along with associated links and shape geometry.\n\n        Args:\n            node_geometry_change_table: a table with model_node_id, X, Y, and CRS.\n        \"\"\"\n        node_geometry_change_table = NodeGeometryChangeTable(node_geometry_change_table)\n        node_ids = node_geometry_change_table.model_node_id.to_list()\n        WranglerLogger.debug(f\"Moving nodes: {node_ids}\")\n        self.nodes_df = edit_node_geometry(self.nodes_df, node_geometry_change_table)\n        self.links_df = edit_link_geometry_from_nodes(self.links_df, self.nodes_df, node_ids)\n        self.shapes_df = edit_shape_geometry_from_nodes(\n            self.shapes_df, self.links_df, self.nodes_df, node_ids\n        )\n\n    def has_node(self, model_node_id: int) -&gt; bool:\n        \"\"\"Queries if network has node based on model_node_id.\n\n        Args:\n            model_node_id: model_node_id to check for.\n        \"\"\"\n        has_node = self.nodes_df[self.nodes_df.model_node_id].isin([model_node_id]).any()\n\n        return has_node\n\n    def has_link(self, ab: tuple) -&gt; bool:\n        \"\"\"Returns true if network has links with AB values.\n\n        Args:\n            ab: Tuple of values corresponding with A and B.\n        \"\"\"\n        sel_a, sel_b = ab\n        has_link = self.links_df[self.links_df[[\"A\", \"B\"]]].isin({\"A\": sel_a, \"B\": sel_b}).any()\n        return has_link\n\n    def is_connected(self, mode: str) -&gt; bool:\n        \"\"\"Determines if the network graph is \"strongly\" connected.\n\n        A graph is strongly connected if each vertex is reachable from every other vertex.\n\n        Args:\n            mode:  mode of the network, one of `drive`,`transit`,`walk`, `bike`\n        \"\"\"\n        is_connected = nx.is_strongly_connected(self.get_modal_graph(mode))\n\n        return is_connected\n\n    @staticmethod\n    def add_incident_link_data_to_nodes(\n        links_df: Optional[DataFrame[RoadLinksTable]] = None,\n        nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n        link_variables: list = [],\n    ) -&gt; DataFrame[RoadNodesTable]:\n        \"\"\"Add data from links going to/from nodes to node.\n\n        Args:\n            links_df: if specified, will assess connectivity of this\n                links list rather than self.links_df\n            nodes_df: if specified, will assess connectivity of this\n                nodes list rather than self.nodes_df\n            link_variables: list of columns in links dataframe to add to incident nodes\n\n        Returns:\n            nodes DataFrame with link data where length is N*number of links going in/out\n        \"\"\"\n        WranglerLogger.debug(\"Adding following link data to nodes: \".format())\n\n        _link_vals_to_nodes = [x for x in link_variables if x in links_df.columns]\n        if link_variables not in _link_vals_to_nodes:\n            WranglerLogger.warning(\n                \"Following columns not in links_df and wont be added to nodes: {} \".format(\n                    list(set(link_variables) - set(_link_vals_to_nodes))\n                )\n            )\n\n        _nodes_from_links_A = nodes_df.merge(\n            links_df[[links_df.params.from_node] + _link_vals_to_nodes],\n            how=\"outer\",\n            left_on=nodes_df.params.primary_key,\n            right_on=links_df.params.from_node,\n        )\n        _nodes_from_links_B = nodes_df.merge(\n            links_df[[links_df.params.to_node] + _link_vals_to_nodes],\n            how=\"outer\",\n            left_on=nodes_df.params.primary_key,\n            right_on=links_df.params.to_node,\n        )\n        _nodes_from_links_ab = pd.concat([_nodes_from_links_A, _nodes_from_links_B])\n\n        return _nodes_from_links_ab\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.link_shapes_df","title":"<code>link_shapes_df: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Add shape geometry to links if available.</p> <p>returns: shapes merged to nodes dataframe</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.model_net","title":"<code>model_net: ModelRoadwayNetwork</code>  <code>property</code>","text":"<p>Return a ModelRoadwayNetwork object for this network.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.network_hash","title":"<code>network_hash: str</code>  <code>property</code>","text":"<p>Hash of the links and nodes dataframes.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.shapes_df","title":"<code>shapes_df: DataFrame[RoadShapesTable]</code>  <code>property</code> <code>writable</code>","text":"<p>Load and return RoadShapesTable.</p> <p>If not already loaded, will read from shapes_file and return. If shapes_file is None, will return an empty dataframe with the right schema. If shapes_df is already set, will return that.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.summary","title":"<code>summary: dict</code>  <code>property</code>","text":"<p>Quick summary dictionary of number of links, nodes.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_incident_link_data_to_nodes","title":"<code>add_incident_link_data_to_nodes(links_df=None, nodes_df=None, link_variables=[])</code>  <code>staticmethod</code>","text":"<p>Add data from links going to/from nodes to node.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>Optional[DataFrame[RoadLinksTable]]</code> <p>if specified, will assess connectivity of this links list rather than self.links_df</p> <code>None</code> <code>nodes_df</code> <code>Optional[DataFrame[RoadNodesTable]]</code> <p>if specified, will assess connectivity of this nodes list rather than self.nodes_df</p> <code>None</code> <code>link_variables</code> <code>list</code> <p>list of columns in links dataframe to add to incident nodes</p> <code>[]</code> <p>Returns:</p> Type Description <code>DataFrame[RoadNodesTable]</code> <p>nodes DataFrame with link data where length is N*number of links going in/out</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>@staticmethod\ndef add_incident_link_data_to_nodes(\n    links_df: Optional[DataFrame[RoadLinksTable]] = None,\n    nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    link_variables: list = [],\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Add data from links going to/from nodes to node.\n\n    Args:\n        links_df: if specified, will assess connectivity of this\n            links list rather than self.links_df\n        nodes_df: if specified, will assess connectivity of this\n            nodes list rather than self.nodes_df\n        link_variables: list of columns in links dataframe to add to incident nodes\n\n    Returns:\n        nodes DataFrame with link data where length is N*number of links going in/out\n    \"\"\"\n    WranglerLogger.debug(\"Adding following link data to nodes: \".format())\n\n    _link_vals_to_nodes = [x for x in link_variables if x in links_df.columns]\n    if link_variables not in _link_vals_to_nodes:\n        WranglerLogger.warning(\n            \"Following columns not in links_df and wont be added to nodes: {} \".format(\n                list(set(link_variables) - set(_link_vals_to_nodes))\n            )\n        )\n\n    _nodes_from_links_A = nodes_df.merge(\n        links_df[[links_df.params.from_node] + _link_vals_to_nodes],\n        how=\"outer\",\n        left_on=nodes_df.params.primary_key,\n        right_on=links_df.params.from_node,\n    )\n    _nodes_from_links_B = nodes_df.merge(\n        links_df[[links_df.params.to_node] + _link_vals_to_nodes],\n        how=\"outer\",\n        left_on=nodes_df.params.primary_key,\n        right_on=links_df.params.to_node,\n    )\n    _nodes_from_links_ab = pd.concat([_nodes_from_links_A, _nodes_from_links_B])\n\n    return _nodes_from_links_ab\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_links","title":"<code>add_links(add_links_df)</code>","text":"<p>Validate combined links_df with LinksSchema before adding to self.links_df.</p> <p>Parameters:</p> Name Type Description Default <code>add_links_df</code> <code>Union[DataFrame, DataFrame[RoadLinksTable]]</code> <p>Dataframe of additional links to add.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_links(self, add_links_df: Union[pd.DataFrame, DataFrame[RoadLinksTable]]):\n    \"\"\"Validate combined links_df with LinksSchema before adding to self.links_df.\n\n    Args:\n        add_links_df: Dataframe of additional links to add.\n    \"\"\"\n    if not isinstance(add_links_df, RoadLinksTable):\n        add_links_df = data_to_links_df(add_links_df, nodes_df=self.nodes_df)\n    self.links_df = RoadLinksTable(pd.concat([self.links_df, add_links_df], axis=0))\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_nodes","title":"<code>add_nodes(add_nodes_df)</code>","text":"<p>Validate combined nodes_df with NodesSchema before adding to self.nodes_df.</p> <p>Parameters:</p> Name Type Description Default <code>add_nodes_df</code> <code>Union[DataFrame, DataFrame[RoadNodesTable]]</code> <p>Dataframe of additional nodes to add.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_nodes(self, add_nodes_df: Union[pd.DataFrame, DataFrame[RoadNodesTable]]):\n    \"\"\"Validate combined nodes_df with NodesSchema before adding to self.nodes_df.\n\n    Args:\n        add_nodes_df: Dataframe of additional nodes to add.\n    \"\"\"\n    if not isinstance(add_nodes_df, RoadNodesTable):\n        add_nodes_df = data_to_nodes_df(add_nodes_df)\n    self.nodes_df = RoadNodesTable(pd.concat([self.nodes_df, add_nodes_df], axis=0))\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_shapes","title":"<code>add_shapes(add_shapes_df)</code>","text":"<p>Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.</p> <p>Parameters:</p> Name Type Description Default <code>add_shapes_df</code> <code>Union[DataFrame, DataFrame[RoadShapesTable]]</code> <p>Dataframe of additional shapes to add.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_shapes(self, add_shapes_df: Union[pd.DataFrame, DataFrame[RoadShapesTable]]):\n    \"\"\"Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.\n\n    Args:\n        add_shapes_df: Dataframe of additional shapes to add.\n    \"\"\"\n    if not isinstance(add_shapes_df, RoadShapesTable):\n        add_shapes_df = df_to_shapes_df(add_shapes_df)\n    WranglerLogger.debug(f\"add_shapes_df: \\n{add_shapes_df}\")\n    WranglerLogger.debug(f\"self.shapes_df: \\n{self.shapes_df}\")\n    together_df = pd.concat([self.shapes_df, add_shapes_df])\n    WranglerLogger.debug(f\"together_df: \\n{together_df}\")\n    self.shapes_df = RoadShapesTable(pd.concat([self.shapes_df, add_shapes_df], axis=0))\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.apply","title":"<code>apply(project_card, **kwargs)</code>","text":"<p>Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>project_card</code> <code>Union[ProjectCard, dict]</code> <p>either a dictionary of the project card object or ProjectCard instance</p> required <code>**kwargs</code> <p>keyword arguments to pass to project application</p> <code>{}</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; RoadwayNetwork:\n    \"\"\"Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n    Args:\n        project_card: either a dictionary of the project card object or ProjectCard instance\n        **kwargs: keyword arguments to pass to project application\n    \"\"\"\n    if not (isinstance(project_card, ProjectCard) or isinstance(project_card, SubProject)):\n        project_card = ProjectCard(project_card)\n\n    # project_card.validate()\n    if not project_card.valid:\n        WranglerLogger.error(\"Invalid Project Card: {project_card}\")\n        raise ValueError(f\"Project card {project_card.project} not valid.\")\n\n    if project_card._sub_projects:\n        for sp in project_card._sub_projects:\n            WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n            self._apply_change(sp, **kwargs)\n        return self\n    else:\n        return self._apply_change(project_card, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.clean_unused_nodes","title":"<code>clean_unused_nodes()</code>","text":"<p>Removes any unused nodes from network that aren\u2019t referenced by links_df.</p> <p>NOTE: does not check if these nodes are used by transit, so use with caution.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def clean_unused_nodes(self):\n    \"\"\"Removes any unused nodes from network that aren't referenced by links_df.\n\n    NOTE: does not check if these nodes are used by transit, so use with caution.\n    \"\"\"\n    from .nodes.nodes import node_ids_without_links\n\n    node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n    self.nodes_df = self.nodes_df.drop(node_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.clean_unused_shapes","title":"<code>clean_unused_shapes()</code>","text":"<p>Removes any unused shapes from network that aren\u2019t referenced by links_df.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def clean_unused_shapes(self):\n    \"\"\"Removes any unused shapes from network that aren't referenced by links_df.\"\"\"\n    from .shapes.shapes import shape_ids_without_links\n\n    del_shape_ids = shape_ids_without_links(self.shapes_df, self.links_df)\n    self.shapes_df = self.shapes_df.drop(del_shape_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.coerce_crs","title":"<code>coerce_crs(v, info)</code>","text":"<p>Coerce crs of nodes_df and links_df to network crs.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>@field_validator(\"nodes_df\", \"links_df\")\ndef coerce_crs(cls, v, info):\n    \"\"\"Coerce crs of nodes_df and links_df to network crs.\"\"\"\n    net_crs = info.data[\"crs\"]\n    if v.crs != net_crs:\n        WranglerLogger.warning(\n            f\"CRS of links_df ({v.crs}) doesn't match network crs {net_crs}. \\\n                Changing to network crs.\"\n        )\n        v.to_crs(net_crs)\n    return v\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.delete_links","title":"<code>delete_links(selection_dict, clean_nodes=False, clean_shapes=False)</code>","text":"<p>Deletes links based on selection dictionary and optionally associated nodes and shapes.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>SelectLinks</code> <p>Dictionary describing link selections as follows: <code>all</code>: Optional[bool] = False. If true, will select all. <code>name</code>: Optional[list[str]] <code>ref</code>: Optional[list[str]] <code>osm_link_id</code>:Optional[list[str]] <code>model_link_id</code>: Optional[list[int]] <code>modes</code>: Optional[list[str]]. Defaults to \u201cany\u201d <code>ignore_missing</code>: if true, will not error when defaults to True. \u2026plus any other link property to select on top of these.</p> required <code>clean_nodes</code> <code>bool</code> <p>If True, will clean nodes uniquely associated with deleted links. Defaults to False.</p> <code>False</code> <code>clean_shapes</code> <code>bool</code> <p>If True, will clean nodes uniquely associated with deleted links. Defaults to False.</p> <code>False</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def delete_links(\n    self,\n    selection_dict: SelectLinksDict,\n    clean_nodes: bool = False,\n    clean_shapes: bool = False,\n):\n    \"\"\"Deletes links based on selection dictionary and optionally associated nodes and shapes.\n\n    Args:\n        selection_dict (SelectLinks): Dictionary describing link selections as follows:\n            `all`: Optional[bool] = False. If true, will select all.\n            `name`: Optional[list[str]]\n            `ref`: Optional[list[str]]\n            `osm_link_id`:Optional[list[str]]\n            `model_link_id`: Optional[list[int]]\n            `modes`: Optional[list[str]]. Defaults to \"any\"\n            `ignore_missing`: if true, will not error when defaults to True.\n            ...plus any other link property to select on top of these.\n        clean_nodes (bool, optional): If True, will clean nodes uniquely associated with\n            deleted links. Defaults to False.\n        clean_shapes (bool, optional): If True, will clean nodes uniquely associated with\n            deleted links. Defaults to False.\n    \"\"\"\n    selection_dict = SelectLinksDict(**selection_dict).model_dump(\n        exclude_none=True, by_alias=True\n    )\n    selection = self.get_selection({\"links\": selection_dict})\n\n    if clean_nodes:\n        node_ids_to_delete = node_ids_unique_to_link_ids(\n            selection.selected_links, selection.selected_links_df, self.nodes_df\n        )\n        WranglerLogger.debug(\n            f\"Dropping nodes associated with dropped links: \\n{node_ids_to_delete}\"\n        )\n        self.nodes_df = delete_nodes_by_ids(self.nodes_df, del_node_ids=node_ids_to_delete)\n\n    if clean_shapes:\n        shape_ids_to_delete = shape_ids_unique_to_link_ids(\n            selection.selected_links, selection.selected_links_df, self.shapes_df\n        )\n        WranglerLogger.debug(\n            f\"Dropping shapes associated with dropped links: \\n{shape_ids_to_delete}\"\n        )\n        self.shapes_df = delete_shapes_by_ids(\n            self.shapes_df, del_shape_ids=shape_ids_to_delete\n        )\n\n    self.links_df = delete_links_by_ids(\n        self.links_df,\n        selection.selected_links,\n        ignore_missing=selection.ignore_missing,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.delete_nodes","title":"<code>delete_nodes(selection_dict, remove_links=False)</code>","text":"<p>Deletes nodes from roadway network. Wont delete nodes used by links in network.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>Union[dict, SelectNodesDict]</code> <p>dictionary of node selection criteria in the form of a SelectNodesDict.</p> required <code>remove_links</code> <code>bool</code> <p>if True, will remove any links that are associated with the nodes. If False, will only remove nodes if they are not associated with any links. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>NodeDeletionError</code> <p>If not ignore_missing and selected nodes to delete aren\u2019t in network</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def delete_nodes(\n    self,\n    selection_dict: Union[dict, SelectNodesDict],\n    remove_links: bool = False,\n) -&gt; None:\n    \"\"\"Deletes nodes from roadway network. Wont delete nodes used by links in network.\n\n    Args:\n        selection_dict: dictionary of node selection criteria in the form of a SelectNodesDict.\n        remove_links: if True, will remove any links that are associated with the nodes.\n            If False, will only remove nodes if they are not associated with any links.\n            Defaults to False.\n\n    raises:\n        NodeDeletionError: If not ignore_missing and selected nodes to delete aren't in network\n    \"\"\"\n    if not isinstance(selection_dict, SelectNodesDict):\n        selection_dict = SelectNodesDict(**selection_dict)\n    selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n    selection: RoadwayNodeSelection = self.get_selection(\n        {\"nodes\": selection_dict},\n    )\n    if remove_links:\n        del_node_ids = selection.selected_nodes\n        link_ids = self.links_with_nodes(selection.selected_nodes).model_link_id.to_list()\n        WranglerLogger.info(f\"Removing {len(link_ids)} links associated with nodes.\")\n        self.delete_links({\"model_link_id\": link_ids})\n    else:\n        unused_node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n        del_node_ids = list(set(selection.selected_nodes).intersection(unused_node_ids))\n\n    self.nodes_df = delete_nodes_by_ids(\n        self.nodes_df, del_node_ids, ignore_missing=selection.ignore_missing\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_modal_graph","title":"<code>get_modal_graph(mode)</code>","text":"<p>Return a networkx graph of the network for a specific mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <p>mode of the network, one of <code>drive</code>,<code>transit</code>,<code>walk</code>, <code>bike</code></p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_modal_graph(self, mode) -&gt; MultiDiGraph:\n    \"\"\"Return a networkx graph of the network for a specific mode.\n\n    Args:\n        mode: mode of the network, one of `drive`,`transit`,`walk`, `bike`\n    \"\"\"\n    from .graph import net_to_graph\n\n    if self._modal_graphs[mode][\"hash\"] != self.modal_graph_hash(mode):\n        self._modal_graphs[mode][\"graph\"] = net_to_graph(self, mode)\n\n    return self._modal_graphs[mode][\"graph\"]\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_property_by_timespan_and_group","title":"<code>get_property_by_timespan_and_group(link_property, category=DEFAULT_CATEGORY, timespan=DEFAULT_TIMESPAN, strict_timespan_match=False, min_overlap_minutes=60)</code>","text":"<p>Returns a new dataframe with model_link_id and link property by category and timespan.</p> <p>Convenience method for backward compatability.</p> <p>Parameters:</p> Name Type Description Default <code>link_property</code> <code>str</code> <p>link property to query</p> required <code>category</code> <code>Union[str, int]</code> <p>category to query or a list of categories. Defaults to DEFAULT_CATEGORY.</p> <code>DEFAULT_CATEGORY</code> <code>timespan</code> <code>TimespanString</code> <p>timespan to query in the form of [\u201cHH:MM\u201d,\u201dHH:MM\u201d]. Defaults to DEFAULT_TIMESPAN.</p> <code>DEFAULT_TIMESPAN</code> <code>strict_timespan_match</code> <code>bool</code> <p>If True, will only return links that match the timespan exactly. Defaults to False.</p> <code>False</code> <code>min_overlap_minutes</code> <code>int</code> <p>If strict_timespan_match is False, will return links that overlap with the timespan by at least this many minutes. Defaults to 60.</p> <code>60</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_property_by_timespan_and_group(\n    self,\n    link_property: str,\n    category: Union[str, int] = DEFAULT_CATEGORY,\n    timespan: TimespanString = DEFAULT_TIMESPAN,\n    strict_timespan_match: bool = False,\n    min_overlap_minutes: int = 60,\n) -&gt; Any:\n    \"\"\"Returns a new dataframe with model_link_id and link property by category and timespan.\n\n    Convenience method for backward compatability.\n\n    Args:\n        link_property: link property to query\n        category: category to query or a list of categories. Defaults to DEFAULT_CATEGORY.\n        timespan: timespan to query in the form of [\"HH:MM\",\"HH:MM\"].\n            Defaults to DEFAULT_TIMESPAN.\n        strict_timespan_match: If True, will only return links that match the timespan exactly.\n            Defaults to False.\n        min_overlap_minutes: If strict_timespan_match is False, will return links that overlap\n            with the timespan by at least this many minutes. Defaults to 60.\n    \"\"\"\n    from .links.scopes import prop_for_scope\n\n    return prop_for_scope(\n        self.links_df,\n        link_property,\n        timespan=timespan,\n        category=category,\n        strict_timespan_match=strict_timespan_match,\n        min_overlap_minutes=min_overlap_minutes,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_selection","title":"<code>get_selection(selection_dict, overwrite=False)</code>","text":"<p>Return selection if it already exists, otherwise performs selection.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>dict</code> <p>SelectFacility dictionary.</p> required <code>overwrite</code> <code>bool</code> <p>if True, will overwrite any previously cached searches. Defaults to False.</p> <code>False</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_selection(\n    self,\n    selection_dict: Union[dict, SelectFacility],\n    overwrite: bool = False,\n) -&gt; Union[RoadwayNodeSelection, RoadwayLinkSelection]:\n    \"\"\"Return selection if it already exists, otherwise performs selection.\n\n    Args:\n        selection_dict (dict): SelectFacility dictionary.\n        overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n    \"\"\"\n    key = _create_selection_key(selection_dict)\n    if (key in self._selections) and not overwrite:\n        WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n        return self._selections[key]\n\n    if isinstance(selection_dict, SelectFacility):\n        selection_data = selection_dict\n    elif isinstance(selection_dict, SelectLinksDict):\n        selection_data = SelectFacility(links=selection_dict)\n    elif isinstance(selection_dict, SelectNodesDict):\n        selection_data = SelectFacility(nodes=selection_dict)\n    elif isinstance(selection_dict, dict):\n        selection_data = SelectFacility(**selection_dict)\n    else:\n        WranglerLogger.error(f\"`selection_dict` arg must be a dictionary or SelectFacility\\\n                          model. Received: {selection_dict} of type {type(selection_dict)}\")\n        raise SelectionError(\"selection_dict arg must be a dictionary or SelectFacility model\")\n\n    WranglerLogger.debug(f\"Getting selection from key: {key}\")\n    if selection_data.feature_types in [\"links\", \"segment\"]:\n        return RoadwayLinkSelection(self, selection_dict)\n    elif selection_data.feature_types == \"nodes\":\n        return RoadwayNodeSelection(self, selection_dict)\n    else:\n        WranglerLogger.error(\"Selection data should be of type 'segment', 'links' or 'nodes'.\")\n        raise SelectionError(\"Selection data should be of type 'segment', 'links' or 'nodes'.\")\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.has_link","title":"<code>has_link(ab)</code>","text":"<p>Returns true if network has links with AB values.</p> <p>Parameters:</p> Name Type Description Default <code>ab</code> <code>tuple</code> <p>Tuple of values corresponding with A and B.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def has_link(self, ab: tuple) -&gt; bool:\n    \"\"\"Returns true if network has links with AB values.\n\n    Args:\n        ab: Tuple of values corresponding with A and B.\n    \"\"\"\n    sel_a, sel_b = ab\n    has_link = self.links_df[self.links_df[[\"A\", \"B\"]]].isin({\"A\": sel_a, \"B\": sel_b}).any()\n    return has_link\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.has_node","title":"<code>has_node(model_node_id)</code>","text":"<p>Queries if network has node based on model_node_id.</p> <p>Parameters:</p> Name Type Description Default <code>model_node_id</code> <code>int</code> <p>model_node_id to check for.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def has_node(self, model_node_id: int) -&gt; bool:\n    \"\"\"Queries if network has node based on model_node_id.\n\n    Args:\n        model_node_id: model_node_id to check for.\n    \"\"\"\n    has_node = self.nodes_df[self.nodes_df.model_node_id].isin([model_node_id]).any()\n\n    return has_node\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.is_connected","title":"<code>is_connected(mode)</code>","text":"<p>Determines if the network graph is \u201cstrongly\u201d connected.</p> <p>A graph is strongly connected if each vertex is reachable from every other vertex.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>mode of the network, one of <code>drive</code>,<code>transit</code>,<code>walk</code>, <code>bike</code></p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def is_connected(self, mode: str) -&gt; bool:\n    \"\"\"Determines if the network graph is \"strongly\" connected.\n\n    A graph is strongly connected if each vertex is reachable from every other vertex.\n\n    Args:\n        mode:  mode of the network, one of `drive`,`transit`,`walk`, `bike`\n    \"\"\"\n    is_connected = nx.is_strongly_connected(self.get_modal_graph(mode))\n\n    return is_connected\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.links_with_link_ids","title":"<code>links_with_link_ids(link_ids)</code>","text":"<p>Return subset of links_df based on link_ids list.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def links_with_link_ids(self, link_ids: List[int]) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Return subset of links_df based on link_ids list.\"\"\"\n    return filter_links_to_ids(self.links_df, link_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.links_with_nodes","title":"<code>links_with_nodes(node_ids)</code>","text":"<p>Return subset of links_df based on node_ids list.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def links_with_nodes(self, node_ids: List[int]) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Return subset of links_df based on node_ids list.\"\"\"\n    return filter_links_to_node_ids(self.links_df, node_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.modal_graph_hash","title":"<code>modal_graph_hash(mode)</code>","text":"<p>Hash of the links in order to detect a network change from when graph created.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def modal_graph_hash(self, mode) -&gt; str:\n    \"\"\"Hash of the links in order to detect a network change from when graph created.\"\"\"\n    _value = str.encode(self.links_df.df_hash() + \"-\" + mode)\n    _hash = hashlib.sha256(_value).hexdigest()\n\n    return _hash\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.move_nodes","title":"<code>move_nodes(node_geometry_change_table)</code>","text":"<p>Moves nodes based on updated geometry along with associated links and shape geometry.</p> <p>Parameters:</p> Name Type Description Default <code>node_geometry_change_table</code> <code>DataFrame[NodeGeometryChangeTable]</code> <p>a table with model_node_id, X, Y, and CRS.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def move_nodes(\n    self,\n    node_geometry_change_table: DataFrame[NodeGeometryChangeTable],\n):\n    \"\"\"Moves nodes based on updated geometry along with associated links and shape geometry.\n\n    Args:\n        node_geometry_change_table: a table with model_node_id, X, Y, and CRS.\n    \"\"\"\n    node_geometry_change_table = NodeGeometryChangeTable(node_geometry_change_table)\n    node_ids = node_geometry_change_table.model_node_id.to_list()\n    WranglerLogger.debug(f\"Moving nodes: {node_ids}\")\n    self.nodes_df = edit_node_geometry(self.nodes_df, node_geometry_change_table)\n    self.links_df = edit_link_geometry_from_nodes(self.links_df, self.nodes_df, node_ids)\n    self.shapes_df = edit_shape_geometry_from_nodes(\n        self.shapes_df, self.links_df, self.nodes_df, node_ids\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.nodes_in_links","title":"<code>nodes_in_links()</code>","text":"<p>Returns subset of self.nodes_df that are in self.links_df.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def nodes_in_links(self) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Returns subset of self.nodes_df that are in self.links_df.\"\"\"\n    return filter_nodes_to_links(self.links_df, self.nodes_df)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork","title":"<code>TransitNetwork</code>","text":"<p>               Bases: <code>object</code></p> <p>Representation of a Transit Network.</p> <p>Typical usage example: <pre><code>import network_wrangler as wr\ntc=wr.load_transit(stpaul_gtfs)\n</code></pre></p> <p>Attributes:</p> Name Type Description <code>feed</code> <p>gtfs feed object with interlinked tables.</p> <code>road_net</code> <code>RoadwayNetwork</code> <p>Associated roadway network object.</p> <code>graph</code> <code>MultiDiGraph</code> <p>Graph for associated roadway network object.</p> <code>feed_path</code> <code>str</code> <p>Where the feed was read in from.</p> <code>validated_frequencies</code> <code>bool</code> <p>The frequencies have been validated.</p> <code>validated_road_network_consistency</code> <p>The network has been validated against the road network.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>class TransitNetwork(object):\n    \"\"\"Representation of a Transit Network.\n\n    Typical usage example:\n    ``` py\n    import network_wrangler as wr\n    tc=wr.load_transit(stpaul_gtfs)\n    ```\n\n    Attributes:\n        feed: gtfs feed object with interlinked tables.\n        road_net (RoadwayNetwork): Associated roadway network object.\n        graph (nx.MultiDiGraph): Graph for associated roadway network object.\n        feed_path (str): Where the feed was read in from.\n        validated_frequencies (bool): The frequencies have been validated.\n        validated_road_network_consistency (): The network has been validated against\n            the road network.\n    \"\"\"\n\n    TIME_COLS = [\"arrival_time\", \"departure_time\", \"start_time\", \"end_time\"]\n\n    def __init__(self, feed: Feed):\n        \"\"\"Constructor for TransitNetwork.\n\n        Args:\n            feed: Feed object representing the transit network gtfs tables\n        \"\"\"\n        WranglerLogger.debug(\"Creating new TransitNetwork.\")\n\n        self._road_net: Optional[RoadwayNetwork] = None\n        self.feed: Feed = feed\n        self.graph: nx.MultiDiGraph = None\n\n        # initialize\n        self._consistent_with_road_net = False\n\n        # cached selections\n        self._selections: dict[str, dict] = {}\n\n    @property\n    def feed_path(self):\n        \"\"\"Pass through property from Feed.\"\"\"\n        return self.feed.feed_path\n\n    @property\n    def config(self):\n        \"\"\"Pass through property from Feed.\"\"\"\n        return self.feed.config\n\n    @property\n    def feed(self):\n        \"\"\"Feed associated with the transit network.\"\"\"\n        return self._feed\n\n    @feed.setter\n    def feed(self, feed: Feed):\n        if not isinstance(feed, Feed):\n            msg = f\"TransitNetwork's feed value must be a valid Feed instance. \\\n                             This is a {type(feed)}.\"\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n        if self._road_net is None or transit_road_net_consistency(feed, self._road_net):\n            self._feed = feed\n            self._stored_feed_hash = copy.deepcopy(feed.hash)\n        else:\n            WranglerLogger.error(\"Can't assign Feed inconsistent with set Roadway Network.\")\n            raise TransitRoadwayConsistencyError(\n                \"Can't assign Feed inconsistent with set RoadwayNetwork.\"\n            )\n\n    @property\n    def road_net(self) -&gt; RoadwayNetwork:\n        \"\"\"Roadway network associated with the transit network.\"\"\"\n        return self._road_net\n\n    @road_net.setter\n    def road_net(self, road_net: RoadwayNetwork):\n        if not isinstance(road_net, RoadwayNetwork):\n            msg = f\"TransitNetwork's road_net: value must be a valid RoadwayNetwork instance. \\\n                             This is a {type(road_net)}.\"\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n        if transit_road_net_consistency(self.feed, road_net):\n            self._road_net = road_net\n            self._stored_road_net_hash = copy.deepcopy(self.road_net.network_hash)\n            self._consistent_with_road_net = True\n        else:\n            WranglerLogger.error(\n                \"Can't assign inconsistent RoadwayNetwork - Roadway Network not \\\n                                 set, but can be referenced separately.\"\n            )\n            raise TransitRoadwayConsistencyError(\"Can't assign inconsistent RoadwayNetwork.\")\n\n    @property\n    def feed_hash(self):\n        \"\"\"Return the hash of the feed.\"\"\"\n        return self.feed.hash\n\n    @property\n    def consistent_with_road_net(self) -&gt; bool:\n        \"\"\"Indicate if road_net is consistent with transit network.\n\n        Checks the network hash of when consistency was last evaluated. If transit network or\n        roadway network has changed, will re-evaluate consistency and return the updated value and\n        update self._stored_road_net_hash.\n\n        Returns:\n            Boolean indicating if road_net is consistent with transit network.\n        \"\"\"\n        updated_road = self.road_net.network_hash != self._stored_road_net_hash\n        updated_feed = self.feed_hash != self._stored_feed_hash\n\n        if updated_road or updated_feed:\n            self._consistent_with_road_net = transit_road_net_consistency(self.feed, self.road_net)\n            self._stored_road_net_hash = copy.deepcopy(self.road_net.network_hash)\n            self._stored_feed_hash = copy.deepcopy(self.feed_hash)\n        return self._consistent_with_road_net\n\n    def __deepcopy__(self, memo):\n        \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n        COPY_REF_NOT_VALUE = [\"_road_net\"]\n        # Create a new, empty instance\n        copied_net = self.__class__.__new__(self.__class__)\n        # Return the new TransitNetwork instance\n        attribute_dict = vars(self)\n\n        # Copy the attributes to the new instance\n        for attr_name, attr_value in attribute_dict.items():\n            # WranglerLogger.debug(f\"Copying {attr_name}\")\n            if attr_name in COPY_REF_NOT_VALUE:\n                # If the attribute is in the COPY_REF_NOT_VALUE list, assign the reference\n                setattr(copied_net, attr_name, attr_value)\n            else:\n                # WranglerLogger.debug(f\"making deep copy: {attr_name}\")\n                # For other attributes, perform a deep copy\n                setattr(copied_net, attr_name, copy.deepcopy(attr_value, memo))\n\n        return copied_net\n\n    def deepcopy(self):\n        \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n        return copy.deepcopy(self)\n\n    @property\n    def stops_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stops as a GeoDataFrame using set roadway geometry.\"\"\"\n        if self.road_net is not None:\n            ref_nodes = self.road_net.nodes_df\n        else:\n            ref_nodes = None\n        return to_points_gdf(self.feed.stops, nodes_df=ref_nodes)\n\n    @property\n    def shapes_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return aggregated shapes as a GeoDataFrame using set roadway geometry.\"\"\"\n        if self.road_net is not None:\n            ref_nodes = self.road_net.nodes_df\n        else:\n            ref_nodes = None\n        return shapes_to_trip_shapes_gdf(self.feed.shapes, ref_nodes_df=ref_nodes)\n\n    @property\n    def shape_links_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return shape-links as a GeoDataFrame using set roadway geometry.\"\"\"\n        if self.road_net is not None:\n            ref_nodes = self.road_net.nodes_df\n        else:\n            ref_nodes = None\n        return shapes_to_shape_links_gdf(self.feed.shapes, ref_nodes_df=ref_nodes)\n\n    @property\n    def stop_time_links_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stop-time-links as a GeoDataFrame using set roadway geometry.\"\"\"\n        if self.road_net is not None:\n            ref_nodes = self.road_net.nodes_df\n        else:\n            ref_nodes = None\n        return stop_times_to_stop_time_links_gdf(\n            self.feed.stop_times, self.feed.stops, ref_nodes_df=ref_nodes\n        )\n\n    @property\n    def stop_times_points_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stop-time-points as a GeoDataFrame using set roadway geometry.\"\"\"\n        if self.road_net is not None:\n            ref_nodes = self.road_net.nodes_df\n        else:\n            ref_nodes = None\n\n        return stop_times_to_stop_time_points_gdf(\n            self.feed.stop_times, self.feed.stops, ref_nodes_df=ref_nodes\n        )\n\n    def get_selection(\n        self,\n        selection_dict: dict,\n        overwrite: bool = False,\n    ) -&gt; TransitSelection:\n        \"\"\"Return selection if it already exists, otherwise performs selection.\n\n        Will raise an error if no trips found.\n\n        Args:\n            selection_dict (dict): _description_\n            overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n\n        Returns:\n            Selection: Selection object\n        \"\"\"\n        key = dict_to_hexkey(selection_dict)\n\n        if (key not in self._selections) or overwrite:\n            WranglerLogger.debug(f\"Performing selection from key: {key}\")\n            self._selections[key] = TransitSelection(self, selection_dict)\n        else:\n            WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n\n        if not self._selections[key]:\n            WranglerLogger.debug(\n                f\"No links or nodes found for selection dict: \\n {selection_dict}\"\n            )\n            raise ValueError(\"Selection not successful.\")\n        return self._selections[key]\n\n    def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; \"TransitNetwork\":\n        \"\"\"Wrapper method to apply a roadway project, returning a new TransitNetwork instance.\n\n        Args:\n            project_card: either a dictionary of the project card object or ProjectCard instance\n            **kwargs: keyword arguments to pass to project application\n        \"\"\"\n        if not (isinstance(project_card, ProjectCard) or isinstance(project_card, SubProject)):\n            project_card = ProjectCard(project_card)\n\n        if not project_card.valid:\n            WranglerLogger.error(\"Invalid Project Card: {project_card}\")\n            raise ValueError(f\"Project card {project_card.project} not valid.\")\n\n        if project_card._sub_projects:\n            for sp in project_card._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp, **kwargs)\n            return self\n        else:\n            return self._apply_change(project_card, **kwargs)\n\n    def _apply_change(\n        self,\n        change: Union[ProjectCard, SubProject],\n        reference_road_net: Optional[RoadwayNetwork] = None,\n    ) -&gt; TransitNetwork:\n        \"\"\"Apply a single change: a single-project project or a sub-project.\"\"\"\n        if not isinstance(change, SubProject):\n            WranglerLogger.info(f\"Applying Project to Transit Network: {change.project}\")\n\n        if change.change_type == \"transit_property_change\":\n            return apply_transit_property_change(\n                self,\n                self.get_selection(change.service),\n                change.transit_property_change,\n                project_name=change.project,\n            )\n\n        elif change.change_type == \"transit_routing_change\":\n            return apply_transit_routing_change(\n                self,\n                self.get_selection(change.service),\n                change.transit_routing_change,\n                reference_road_net=reference_road_net,\n                project_name=change.project,\n            )\n\n        elif change.change_type == \"transit_route_addition\":\n            return apply_transit_route_addtion(\n                self,\n                change.transit_route_addition,\n                reference_road_net=reference_road_net,\n            )\n\n        elif change.change_type == \"transit_service_deletion\":\n            return apply_transit_service_deletion(\n                self,\n                self.get_selection(change.service),\n            )\n\n        # elif change.change_type == \"roadway_deletion\":\n        #     # FIXME\n        #     raise NotImplementedError(\"Roadway deletion check not yet implemented.\")\n\n        elif change.change_type == \"pycode\":\n            return apply_calculated_transit(self, change.pycode)\n\n        else:\n            msg = f\"Not a currently valid transit project: {change}.\"\n            WranglerLogger.error(msg)\n            raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.config","title":"<code>config</code>  <code>property</code>","text":"<p>Pass through property from Feed.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.consistent_with_road_net","title":"<code>consistent_with_road_net: bool</code>  <code>property</code>","text":"<p>Indicate if road_net is consistent with transit network.</p> <p>Checks the network hash of when consistency was last evaluated. If transit network or roadway network has changed, will re-evaluate consistency and return the updated value and update self._stored_road_net_hash.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if road_net is consistent with transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed","title":"<code>feed</code>  <code>property</code> <code>writable</code>","text":"<p>Feed associated with the transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed_hash","title":"<code>feed_hash</code>  <code>property</code>","text":"<p>Return the hash of the feed.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed_path","title":"<code>feed_path</code>  <code>property</code>","text":"<p>Pass through property from Feed.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.road_net","title":"<code>road_net: RoadwayNetwork</code>  <code>property</code> <code>writable</code>","text":"<p>Roadway network associated with the transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.shape_links_gdf","title":"<code>shape_links_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return shape-links as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.shapes_gdf","title":"<code>shapes_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return aggregated shapes as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stop_time_links_gdf","title":"<code>stop_time_links_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return stop-time-links as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stop_times_points_gdf","title":"<code>stop_times_points_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return stop-time-points as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stops_gdf","title":"<code>stops_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return stops as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.__deepcopy__","title":"<code>__deepcopy__(memo)</code>","text":"<p>Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n    COPY_REF_NOT_VALUE = [\"_road_net\"]\n    # Create a new, empty instance\n    copied_net = self.__class__.__new__(self.__class__)\n    # Return the new TransitNetwork instance\n    attribute_dict = vars(self)\n\n    # Copy the attributes to the new instance\n    for attr_name, attr_value in attribute_dict.items():\n        # WranglerLogger.debug(f\"Copying {attr_name}\")\n        if attr_name in COPY_REF_NOT_VALUE:\n            # If the attribute is in the COPY_REF_NOT_VALUE list, assign the reference\n            setattr(copied_net, attr_name, attr_value)\n        else:\n            # WranglerLogger.debug(f\"making deep copy: {attr_name}\")\n            # For other attributes, perform a deep copy\n            setattr(copied_net, attr_name, copy.deepcopy(attr_value, memo))\n\n    return copied_net\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.__init__","title":"<code>__init__(feed)</code>","text":"<p>Constructor for TransitNetwork.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Feed</code> <p>Feed object representing the transit network gtfs tables</p> required Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def __init__(self, feed: Feed):\n    \"\"\"Constructor for TransitNetwork.\n\n    Args:\n        feed: Feed object representing the transit network gtfs tables\n    \"\"\"\n    WranglerLogger.debug(\"Creating new TransitNetwork.\")\n\n    self._road_net: Optional[RoadwayNetwork] = None\n    self.feed: Feed = feed\n    self.graph: nx.MultiDiGraph = None\n\n    # initialize\n    self._consistent_with_road_net = False\n\n    # cached selections\n    self._selections: dict[str, dict] = {}\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.apply","title":"<code>apply(project_card, **kwargs)</code>","text":"<p>Wrapper method to apply a roadway project, returning a new TransitNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>project_card</code> <code>Union[ProjectCard, dict]</code> <p>either a dictionary of the project card object or ProjectCard instance</p> required <code>**kwargs</code> <p>keyword arguments to pass to project application</p> <code>{}</code> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; \"TransitNetwork\":\n    \"\"\"Wrapper method to apply a roadway project, returning a new TransitNetwork instance.\n\n    Args:\n        project_card: either a dictionary of the project card object or ProjectCard instance\n        **kwargs: keyword arguments to pass to project application\n    \"\"\"\n    if not (isinstance(project_card, ProjectCard) or isinstance(project_card, SubProject)):\n        project_card = ProjectCard(project_card)\n\n    if not project_card.valid:\n        WranglerLogger.error(\"Invalid Project Card: {project_card}\")\n        raise ValueError(f\"Project card {project_card.project} not valid.\")\n\n    if project_card._sub_projects:\n        for sp in project_card._sub_projects:\n            WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n            self._apply_change(sp, **kwargs)\n        return self\n    else:\n        return self._apply_change(project_card, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.deepcopy","title":"<code>deepcopy()</code>","text":"<p>Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def deepcopy(self):\n    \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n    return copy.deepcopy(self)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.get_selection","title":"<code>get_selection(selection_dict, overwrite=False)</code>","text":"<p>Return selection if it already exists, otherwise performs selection.</p> <p>Will raise an error if no trips found.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>dict</code> <p>description</p> required <code>overwrite</code> <code>bool</code> <p>if True, will overwrite any previously cached searches. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Selection</code> <code>TransitSelection</code> <p>Selection object</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def get_selection(\n    self,\n    selection_dict: dict,\n    overwrite: bool = False,\n) -&gt; TransitSelection:\n    \"\"\"Return selection if it already exists, otherwise performs selection.\n\n    Will raise an error if no trips found.\n\n    Args:\n        selection_dict (dict): _description_\n        overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n\n    Returns:\n        Selection: Selection object\n    \"\"\"\n    key = dict_to_hexkey(selection_dict)\n\n    if (key not in self._selections) or overwrite:\n        WranglerLogger.debug(f\"Performing selection from key: {key}\")\n        self._selections[key] = TransitSelection(self, selection_dict)\n    else:\n        WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n\n    if not self._selections[key]:\n        WranglerLogger.debug(\n            f\"No links or nodes found for selection dict: \\n {selection_dict}\"\n        )\n        raise ValueError(\"Selection not successful.\")\n    return self._selections[key]\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitRoadwayConsistencyError","title":"<code>TransitRoadwayConsistencyError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when transit network is inconsistent with roadway network.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>class TransitRoadwayConsistencyError(Exception):\n    \"\"\"Error raised when transit network is inconsistent with roadway network.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#parameters","title":"Parameters","text":"<p>Parameters for Network Wrangler.</p>"},{"location":"api/#network_wrangler.params.COPY_FROM_GP_TO_ML","title":"<code>COPY_FROM_GP_TO_ML = ['ref', 'roadway', 'access', 'distance', 'bike_access', 'drive_access', 'walk_access', 'bus_only', 'rail_only']</code>  <code>module-attribute</code>","text":"<p>(list(str)): list of attributes copied from GP lanes to access and egress dummy links.</p>"},{"location":"api/#network_wrangler.params.COPY_TO_ACCESS_EGRESS","title":"<code>COPY_TO_ACCESS_EGRESS = ['ref', 'ML_access', 'ML_drive_access', 'ML_bus_only', 'ML_rail_only']</code>  <code>module-attribute</code>","text":"<p>(list(str)): list of attributes that must be provided in managed lanes</p>"},{"location":"api/#network_wrangler.params.DEFAULT_CATEGORY","title":"<code>DEFAULT_CATEGORY = 'any'</code>  <code>module-attribute</code>","text":"<p>Read sec / MB - WILL DEPEND ON SPECIFIC COMPUTER</p>"},{"location":"api/#network_wrangler.params.DEFAULT_DELETE_MODES","title":"<code>DEFAULT_DELETE_MODES = ['any']</code>  <code>module-attribute</code>","text":"<p>(int): default for initial number of links from name-based     selection that are traveresed before trying another shortest     path when searching for paths between A and B node</p>"},{"location":"api/#network_wrangler.params.DEFAULT_MAX_SEARCH_BREADTH","title":"<code>DEFAULT_MAX_SEARCH_BREADTH = 10</code>  <code>module-attribute</code>","text":"<p>Union(int, float)): default penalty assigned for each     degree of distance between a link and a link with the searched-for     name when searching for paths between A and B node</p>"},{"location":"api/#network_wrangler.params.DEFAULT_SEARCH_BREADTH","title":"<code>DEFAULT_SEARCH_BREADTH = 5</code>  <code>module-attribute</code>","text":"<p>(int): default for maximum number of links traversed between     links that match the searched name when searching for paths     between A and B node</p>"},{"location":"api/#network_wrangler.params.DEFAULT_SEARCH_MODES","title":"<code>DEFAULT_SEARCH_MODES = ['drive']</code>  <code>module-attribute</code>","text":"<p>(list(str)): default for searching for links to delete when no modes are specified.</p>"},{"location":"api/#network_wrangler.params.DEFAULT_SP_WEIGHT_COL","title":"<code>DEFAULT_SP_WEIGHT_COL = 'i'</code>  <code>module-attribute</code>","text":"<p>Default timespan for scoped values and GTFS.</p>"},{"location":"api/#network_wrangler.params.DEFAULT_SP_WEIGHT_FACTOR","title":"<code>DEFAULT_SP_WEIGHT_FACTOR = 100</code>  <code>module-attribute</code>","text":"<p>(str): default column to use as weights in the shortest path calculations.</p>"},{"location":"api/#network_wrangler.params.DEFAULT_TIMESPAN","title":"<code>DEFAULT_TIMESPAN = ['00:00', '24:00']</code>  <code>module-attribute</code>","text":"<p>Default category for scoped values.</p>"},{"location":"api/#network_wrangler.params.EST_PD_READ_SPEED","title":"<code>EST_PD_READ_SPEED = {'csv': 0.03, 'parquet': 0.005, 'geojson': 0.03, 'json': 0.15, 'txt': 0.04}</code>  <code>module-attribute</code>","text":"<p>(float): offset in meters for managed lanes centerlines</p>"},{"location":"api/#network_wrangler.params.MANAGED_LANES_LINK_ID_RANGE","title":"<code>MANAGED_LANES_LINK_ID_RANGE = (950000, 999999)</code>  <code>module-attribute</code>","text":"<p>Range of model_node_ids to use when creating an associated node for a parallel managed lane.</p>"},{"location":"api/#network_wrangler.params.MANAGED_LANES_REQUIRED_ATTRIBUTES","title":"<code>MANAGED_LANES_REQUIRED_ATTRIBUTES = ['A', 'B', 'model_link_id']</code>  <code>module-attribute</code>","text":"<p>Range of model_link_ids to use when creating an associated link for a parallel managed lane.</p>"},{"location":"api/#network_wrangler.params.ML_OFFSET_METERS","title":"<code>ML_OFFSET_METERS = -5</code>  <code>module-attribute</code>","text":"<p>(list(str)): list of attributes to copy from a general purpose lane to managed lane so long as a ML_ doesn\u2019t exist."},{"location":"api/#network_wrangler.params.SECONDARY_TRANSIT_CARD_TYPES","title":"<code>SECONDARY_TRANSIT_CARD_TYPES = ['roadway_deletion']</code>  <code>module-attribute</code>","text":"<p>(list(str)): default for search modes when searching for paths between A and B node     when no modes are specified.</p>"},{"location":"api/#network_wrangler.params.LinksParams","title":"<code>LinksParams</code>  <code>dataclass</code>","text":"<p>Parameters for RoadLinksTable.</p> Source code in <code>network_wrangler/params.py</code> <pre><code>@dataclass\nclass LinksParams:\n    \"\"\"Parameters for RoadLinksTable.\"\"\"\n\n    primary_key: str = field(default=\"model_link_id\")\n    _addtl_unique_ids: list[str] = field(default_factory=lambda: [])\n    _addtl_explicit_ids: list[str] = field(default_factory=lambda: [\"osm_link_id\"])\n    from_node: str = field(default=\"A\")\n    to_node: str = field(default=\"B\")\n    fk_to_shape: str = field(default=\"shape_id\")\n    table_type: Literal[\"links\"] = field(default=\"links\")\n    source_file: str = field(default=None)\n    modes_to_network_link_variables: dict = field(\n        default_factory=lambda: MODES_TO_NETWORK_LINK_VARIABLES\n    )\n\n    @property\n    def idx_col(self):\n        \"\"\"Column to make the index of the table.\"\"\"\n        return self.primary_key + \"_idx\"\n\n    @property\n    def fks_to_nodes(self):\n        \"\"\"Foreign keys to nodes in the network.\"\"\"\n        return [self.from_node, self.to_node]\n\n    @property\n    def unique_ids(self) -&gt; List[str]:\n        \"\"\"List of unique ids for the table.\"\"\"\n        _uids = self._addtl_unique_ids + [self.primary_key]\n        return list(set(_uids))\n\n    @property\n    def explicit_ids(self) -&gt; List[str]:\n        \"\"\"List of columns that can be used to easily find specific row sin the table.\"\"\"\n        return list(set(self.unique_ids + self._addtl_explicit_ids))\n\n    @property\n    def display_cols(self) -&gt; List[str]:\n        \"\"\"List of columns to display in the table.\"\"\"\n        _addtl = [\"lanes\"]\n        return list(set(self.explicit_ids + self.fks_to_nodes + _addtl))\n</code></pre>"},{"location":"api/#network_wrangler.params.LinksParams.display_cols","title":"<code>display_cols: List[str]</code>  <code>property</code>","text":"<p>List of columns to display in the table.</p>"},{"location":"api/#network_wrangler.params.LinksParams.explicit_ids","title":"<code>explicit_ids: List[str]</code>  <code>property</code>","text":"<p>List of columns that can be used to easily find specific row sin the table.</p>"},{"location":"api/#network_wrangler.params.LinksParams.fks_to_nodes","title":"<code>fks_to_nodes</code>  <code>property</code>","text":"<p>Foreign keys to nodes in the network.</p>"},{"location":"api/#network_wrangler.params.LinksParams.idx_col","title":"<code>idx_col</code>  <code>property</code>","text":"<p>Column to make the index of the table.</p>"},{"location":"api/#network_wrangler.params.LinksParams.unique_ids","title":"<code>unique_ids: List[str]</code>  <code>property</code>","text":"<p>List of unique ids for the table.</p>"},{"location":"api/#network_wrangler.params.NodesParams","title":"<code>NodesParams</code>  <code>dataclass</code>","text":"<p>Parameters for RoadNodesTable.</p> Source code in <code>network_wrangler/params.py</code> <pre><code>@dataclass\nclass NodesParams:\n    \"\"\"Parameters for RoadNodesTable.\"\"\"\n\n    primary_key: str = field(default=\"model_node_id\")\n    _addtl_unique_ids: list[str] = field(default_factory=lambda: [\"osm_node_id\"])\n    _addtl_explicit_ids: list[str] = field(default_factory=lambda: [])\n    source_file: str = field(default=None)\n    table_type: Literal[\"nodes\"] = field(default=\"nodes\")\n    x_field: str = field(default=\"X\")\n    y_field: str = field(default=\"Y\")\n\n    @property\n    def geometry_props(self) -&gt; List[str]:\n        \"\"\"List of geometry properties.\"\"\"\n        return [self.x_field, self.y_field, \"geometry\"]\n\n    @property\n    def idx_col(self) -&gt; str:\n        \"\"\"Column to make the index of the table.\"\"\"\n        return self.primary_key + \"_idx\"\n\n    @property\n    def unique_ids(self) -&gt; List[str]:\n        \"\"\"List of unique ids for the table.\"\"\"\n        _uids = self._addtl_unique_ids + [self.primary_key]\n        return list(set(_uids))\n\n    @property\n    def explicit_ids(self) -&gt; List[str]:\n        \"\"\"List of columns that can be used to easily find specific records the table.\"\"\"\n        _eids = self._addtl_unique_ids + self.unique_ids\n        return list(set(_eids))\n\n    @property\n    def display_cols(self) -&gt; List[str]:\n        \"\"\"Columns to display in the table.\"\"\"\n        return self.explicit_ids\n</code></pre>"},{"location":"api/#network_wrangler.params.NodesParams.display_cols","title":"<code>display_cols: List[str]</code>  <code>property</code>","text":"<p>Columns to display in the table.</p>"},{"location":"api/#network_wrangler.params.NodesParams.explicit_ids","title":"<code>explicit_ids: List[str]</code>  <code>property</code>","text":"<p>List of columns that can be used to easily find specific records the table.</p>"},{"location":"api/#network_wrangler.params.NodesParams.geometry_props","title":"<code>geometry_props: List[str]</code>  <code>property</code>","text":"<p>List of geometry properties.</p>"},{"location":"api/#network_wrangler.params.NodesParams.idx_col","title":"<code>idx_col: str</code>  <code>property</code>","text":"<p>Column to make the index of the table.</p>"},{"location":"api/#network_wrangler.params.NodesParams.unique_ids","title":"<code>unique_ids: List[str]</code>  <code>property</code>","text":"<p>List of unique ids for the table.</p>"},{"location":"api/#network_wrangler.params.ShapesParams","title":"<code>ShapesParams</code>  <code>dataclass</code>","text":"<p>Parameters for RoadShapesTable.</p> Source code in <code>network_wrangler/params.py</code> <pre><code>@dataclass\nclass ShapesParams:\n    \"\"\"Parameters for RoadShapesTable.\"\"\"\n\n    primary_key: str = field(default=\"shape_id\")\n    _addtl_unique_ids: list[str] = field(default_factory=lambda: [])\n    table_type: Literal[\"shapes\"] = field(default=\"shapes\")\n    source_file: str = field(default=None)\n\n    @property\n    def idx_col(self) -&gt; str:\n        \"\"\"Column to make the index of the table.\"\"\"\n        return self.primary_key + \"_idx\"\n\n    @property\n    def unique_ids(self) -&gt; list[str]:\n        \"\"\"List of unique ids for the table.\"\"\"\n        return list(set(self._addtl_unique_ids.append(self.primary_key)))\n</code></pre>"},{"location":"api/#network_wrangler.params.ShapesParams.idx_col","title":"<code>idx_col: str</code>  <code>property</code>","text":"<p>Column to make the index of the table.</p>"},{"location":"api/#network_wrangler.params.ShapesParams.unique_ids","title":"<code>unique_ids: list[str]</code>  <code>property</code>","text":"<p>List of unique ids for the table.</p>"},{"location":"api/#projects","title":"Projects","text":"<p>Projects are how you manipulate the networks. Each project type is defined in a module in the <code>projects</code> folder and accepts a RoadwayNetwork and or TransitNetwork as an input and returns the same objects (manipulated) as an output.  </p>"},{"location":"api/#roadway","title":"Roadway","text":"<p>The roadway module contains submodules which define and extend the links, nodes, and shapes dataframe objects which within a RoadwayNetwork object as well as other classes and methods which support and extend the RoadwayNetwork class.</p>"},{"location":"api/#network-objects","title":"Network Objects","text":"<p>Submodules which define and extend the links, nodes, and shapes dataframe objects which within a RoadwayNetwork object.  Includes classes which define:</p> <ul> <li>dataframe schemas to be used for dataframe validation using <code>pandera</code></li> <li>methods which extend the dataframes</li> </ul>"},{"location":"api/#links","title":"Links","text":"<p>:: network_wrangler.roadway.links.io :: network_wrangler.roadway.links.create :: network_wrangler.roadway.links.delete :: network_wrangler.roadway.links.edit :: network_wrangler.roadway.links.filters :: network_wrangler.roadway.links.geo :: network_wrangler.roadway.links.scopes :: network_wrangler.roadway.links.summary :: network_wrangler.roadway.links.validate :: network_wrangler.roadway.links.df_accessors</p>"},{"location":"api/#nodes","title":"Nodes","text":"<p>:: network_wrangler.roadway.nodes.io :: network_wrangler.roadway.nodes.create :: network_wrangler.roadway.nodes.delete :: network_wrangler.roadway.nodes.edit :: network_wrangler.roadway.nodes.filters :: network_wrangler.roadway.nodes</p>"},{"location":"api/#shapes","title":"Shapes","text":"<p>:: network_wrangler.roadway.shapes.io :: network_wrangler.roadway.shapes.create :: network_wrangler.roadway.shapes.edit :: network_wrangler.roadway.shapes.delete :: network_wrangler.roadway.shapes.filters :: network_wrangler.roadway.shapes.shapes</p>"},{"location":"api/#supporting-classes-methods-parameters","title":"Supporting Classes, Methods + Parameters","text":"<p>:: network_wrangler.roadway.segment :: network_wrangler.roadway.subnet :: network_wrangler.roadway.graph</p>"},{"location":"api/#utils-and-functions","title":"Utils and Functions","text":"<p>General utility functions used throughout package.</p> <p>Helper functions for reading and writing files to reduce boilerplate.</p> <p>Helper functions for data models.</p> <p>Functions to help with network manipulations in dataframes.</p> <p>Functions related to parsing and comparing time objects and series.</p> <p>Internal function terminology for timespan scopes:</p> <ul> <li><code>matching</code>: a scope that could be applied for a given timespan combination.     This includes the default timespan as well as scopes wholely contained within.</li> <li><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan.     This includes the default timespan, all <code>matching</code> timespans and all timespans where     at least one minute overlap.</li> <li><code>conflicting</code>: a timespan that is overlapping but not matching. By definition default      scope values are not conflicting.</li> <li><code>independent</code> a timespan that is not overlapping.</li> </ul> <p>Utility functions for pandas data manipulation.</p> <p>Helper geographic manipulation functions.</p> <p>Dataframe accessors that allow functions to be called directly on the dataframe.</p> <p>Logging utilities for Network Wrangler.</p>"},{"location":"api/#network_wrangler.utils.utils.check_one_or_one_superset_present","title":"<code>check_one_or_one_superset_present(mixed_list, all_fields_present)</code>","text":"<p>Checks that exactly one of the fields in mixed_list is in fields_present or one superset.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def check_one_or_one_superset_present(\n    mixed_list: list[Union[str, list[str]]], all_fields_present: list[str]\n) -&gt; bool:\n    \"\"\"Checks that exactly one of the fields in mixed_list is in fields_present or one superset.\"\"\"\n    normalized_list = normalize_to_lists(mixed_list)\n\n    list_items_present = [i for i in normalized_list if set(i).issubset(all_fields_present)]\n\n    if len(list_items_present) == 1:\n        return True\n\n    return list_elements_subset_of_single_element(list_items_present)\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.combine_unique_unhashable_list","title":"<code>combine_unique_unhashable_list(list1, list2)</code>","text":"<p>Combines lists preserving order of first and removing duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>list</code> <p>The first list.</p> required <code>list2</code> <code>list</code> <p>The second list.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A new list containing the elements from list1 followed by the</p> <p>unique elements from list2.</p> Example <p>list1 = [1, 2, 3] list2 = [2, 3, 4, 5] combine_unique_unhashable_list(list1, list2) [1, 2, 3, 4, 5]</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def combine_unique_unhashable_list(list1: list, list2: list):\n    \"\"\"Combines lists preserving order of first and removing duplicates.\n\n    Args:\n        list1 (list): The first list.\n        list2 (list): The second list.\n\n    Returns:\n        list: A new list containing the elements from list1 followed by the\n        unique elements from list2.\n\n    Example:\n        &gt;&gt;&gt; list1 = [1, 2, 3]\n        &gt;&gt;&gt; list2 = [2, 3, 4, 5]\n        &gt;&gt;&gt; combine_unique_unhashable_list(list1, list2)\n        [1, 2, 3, 4, 5]\n    \"\"\"\n    return [item for item in list1 if item not in list2] + list2\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.delete_keys_from_dict","title":"<code>delete_keys_from_dict(dictionary, keys)</code>","text":"<p>Removes list of keys from potentially nested dictionary.</p> <p>SOURCE: https://stackoverflow.com/questions/3405715/ User: @mseifert</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>dict</code> <p>dictionary to remove keys from</p> required <code>keys</code> <code>list</code> <p>list of keys to remove</p> required Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def delete_keys_from_dict(dictionary: dict, keys: list) -&gt; dict:\n    \"\"\"Removes list of keys from potentially nested dictionary.\n\n    SOURCE: https://stackoverflow.com/questions/3405715/\n    User: @mseifert\n\n    Args:\n        dictionary: dictionary to remove keys from\n        keys: list of keys to remove\n\n    \"\"\"\n    keys_set = set(keys)  # Just an optimization for the \"if key in keys\" lookup.\n\n    modified_dict = {}\n    for key, value in dictionary.items():\n        if key not in keys_set:\n            if isinstance(value, dict):\n                modified_dict[key] = delete_keys_from_dict(value, keys_set)\n            else:\n                modified_dict[key] = (\n                    value  # or copy.deepcopy(value) if a copy is desired for non-dicts.\n                )\n    return modified_dict\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.dict_to_hexkey","title":"<code>dict_to_hexkey(d)</code>","text":"<p>Converts a dictionary to a hexdigest of the sha1 hash of the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>dictionary to convert to string</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>hexdigest of the sha1 hash of dictionary</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def dict_to_hexkey(d: dict) -&gt; str:\n    \"\"\"Converts a dictionary to a hexdigest of the sha1 hash of the dictionary.\n\n    Args:\n        d (dict): dictionary to convert to string\n\n    Returns:\n        str: hexdigest of the sha1 hash of dictionary\n    \"\"\"\n    return hashlib.sha1(str(d).encode()).hexdigest()\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.findkeys","title":"<code>findkeys(node, kv)</code>","text":"<p>Returns values of all keys in various objects.</p> <p>Adapted from arainchi on Stack Overflow: https://stackoverflow.com/questions/9807634/find-all-occurrences-of-a-key-in-nested-dictionaries-and-lists</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def findkeys(node, kv):\n    \"\"\"Returns values of all keys in various objects.\n\n    Adapted from arainchi on Stack Overflow:\n    https://stackoverflow.com/questions/9807634/find-all-occurrences-of-a-key-in-nested-dictionaries-and-lists\n    \"\"\"\n    if isinstance(node, list):\n        for i in node:\n            for x in findkeys(i, kv):\n                yield x\n    elif isinstance(node, dict):\n        if kv in node:\n            yield node[kv]\n        for j in node.values():\n            for x in findkeys(j, kv):\n                yield x\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.generate_list_of_new_ids","title":"<code>generate_list_of_new_ids(input_ids, existing_ids, id_scalar, iter_val=10, max_iter=1000)</code>","text":"<p>Generates a list of new IDs based on the input IDs, existing IDs, and other parameters.</p> <p>Parameters:</p> Name Type Description Default <code>input_ids</code> <code>list[str]</code> <p>The input IDs for which new IDs need to be generated.</p> required <code>existing_ids</code> <code>Series</code> <p>The existing IDs that should be avoided when generating new IDs.</p> required <code>id_scalar</code> <code>int</code> <p>The scalar value used to generate new IDs.</p> required <code>iter_val</code> <code>int</code> <p>The iteration value used in the generation process. Defaults to 10.</p> <code>10</code> <code>max_iter</code> <code>int</code> <p>The maximum number of iterations allowed in the generation process. Defaults to 1000.</p> <code>1000</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of new IDs generated based on the input IDs and other parameters.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def generate_list_of_new_ids(\n    input_ids: list[str],\n    existing_ids: pd.Series,\n    id_scalar: int,\n    iter_val: int = 10,\n    max_iter: int = 1000,\n) -&gt; list[str]:\n    \"\"\"Generates a list of new IDs based on the input IDs, existing IDs, and other parameters.\n\n    Args:\n        input_ids (list[str]): The input IDs for which new IDs need to be generated.\n        existing_ids (pd.Series): The existing IDs that should be avoided when generating new IDs.\n        id_scalar (int): The scalar value used to generate new IDs.\n        iter_val (int, optional): The iteration value used in the generation process.\n            Defaults to 10.\n        max_iter (int, optional): The maximum number of iterations allowed in the generation\n            process. Defaults to 1000.\n\n    Returns:\n        list[str]: A list of new IDs generated based on the input IDs and other parameters.\n    \"\"\"\n    # keep new_ids as list to preserve order\n    new_ids = []\n    existing_ids = set(existing_ids)\n    for i in input_ids:\n        new_id = generate_new_id(\n            i,\n            pd.Series(list(existing_ids)),\n            id_scalar,\n            iter_val=iter_val,\n            max_iter=max_iter,\n        )\n        new_ids.append(new_id)\n        existing_ids.add(new_id)\n    return new_ids\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.generate_new_id","title":"<code>generate_new_id(input_id, existing_ids, id_scalar, iter_val=10, max_iter=1000)</code>","text":"<p>Generate a new ID that isn\u2019t in existing_ids.</p> <p>TODO: check a registry rather than existing IDs</p> <p>Parameters:</p> Name Type Description Default <code>input_id</code> <code>str</code> <p>id to use to generate new id.</p> required <code>existing_ids</code> <code>Series</code> <p>series that has existing IDs that should be unique</p> required <code>id_scalar</code> <code>int</code> <p>scalar value to initially use to create the new id.</p> required <code>iter_val</code> <code>int</code> <p>iteration value to use in the generation process.</p> <code>10</code> <code>max_iter</code> <code>int</code> <p>maximum number of iterations allowed in the generation process.</p> <code>1000</code> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def generate_new_id(\n    input_id: str,\n    existing_ids: pd.Series,\n    id_scalar: int,\n    iter_val: int = 10,\n    max_iter: int = 1000,\n) -&gt; str:\n    \"\"\"Generate a new ID that isn't in existing_ids.\n\n    TODO: check a registry rather than existing IDs\n\n    Args:\n        input_id: id to use to generate new id.\n        existing_ids: series that has existing IDs that should be unique\n        id_scalar: scalar value to initially use to create the new id.\n        iter_val: iteration value to use in the generation process.\n        max_iter: maximum number of iterations allowed in the generation process.\n    \"\"\"\n    str_prefix, input_id, str_suffix = split_string_prefix_suffix_from_num(input_id)\n\n    for i in range(1, max_iter + 1):\n        new_id = f\"{str_prefix}{int(input_id) + id_scalar + (iter_val * i)}{str_suffix}\"\n        if new_id not in existing_ids.values:\n            return new_id\n        elif i == max_iter:\n            WranglerLogger.error(f\"Cannot generate new id within max iters of {max_iter}.\")\n            raise ValueError(\"Cannot create unique new id.\")\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.get_overlapping_range","title":"<code>get_overlapping_range(ranges)</code>","text":"<p>Returns the overlapping range for a list of ranges or tuples defining ranges.</p> <p>Parameters:</p> Name Type Description Default <code>ranges</code> <code>list[Union[tuple[int], range]]</code> <p>A list of ranges or tuples defining ranges.</p> required <p>Returns:</p> Type Description <code>Union[None, range]</code> <p>Union[None, range]: The overlapping range if found, otherwise None.</p> Example <p>ranges = [(1, 5), (3, 7), (6, 10)] get_overlapping_range(ranges) range(3, 5)</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def get_overlapping_range(ranges: list[Union[tuple[int], range]]) -&gt; Union[None, range]:\n    \"\"\"Returns the overlapping range for a list of ranges or tuples defining ranges.\n\n    Args:\n        ranges (list[Union[tuple[int], range]]): A list of ranges or tuples defining ranges.\n\n    Returns:\n        Union[None, range]: The overlapping range if found, otherwise None.\n\n    Example:\n        &gt;&gt;&gt; ranges = [(1, 5), (3, 7), (6, 10)]\n        &gt;&gt;&gt; get_overlapping_range(ranges)\n        range(3, 5)\n\n    \"\"\"\n    _ranges = [r if isinstance(r, range) else range(r[0], r[1]) for r in ranges]\n\n    _overlap_start = max(r.start for r in _ranges)\n    _overlap_end = min(r.stop for r in _ranges)\n\n    if _overlap_start &lt; _overlap_end:\n        return range(_overlap_start, _overlap_end)\n    else:\n        return None\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.list_elements_subset_of_single_element","title":"<code>list_elements_subset_of_single_element(mixed_list)</code>","text":"<p>Find the first list in the mixed_list.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def list_elements_subset_of_single_element(mixed_list: list[Union[str, list[str]]]) -&gt; bool:\n    \"\"\"Find the first list in the mixed_list.\"\"\"\n    potential_supersets = []\n    for item in mixed_list:\n        if isinstance(item, list) and len(item) &gt; 0:\n            potential_supersets.append(set(item))\n\n    # If no list is found, return False\n    if not potential_supersets:\n        return False\n\n    normalized_list = normalize_to_lists(mixed_list)\n\n    valid_supersets = []\n    for ss in potential_supersets:\n        if all(ss.issuperset(i) for i in normalized_list):\n            valid_supersets.append(ss)\n\n    return len(valid_supersets) == 1\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.make_slug","title":"<code>make_slug(text, delimiter='_')</code>","text":"<p>Makes a slug from text.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def make_slug(text: str, delimiter: str = \"_\") -&gt; str:\n    \"\"\"Makes a slug from text.\"\"\"\n    text = re.sub(\"[,.;@#?!&amp;$']+\", \"\", text.lower())\n    return re.sub(\"[\\ ]+\", delimiter, text)  # noqa: W605\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.normalize_to_lists","title":"<code>normalize_to_lists(mixed_list)</code>","text":"<p>Turn a mixed list of scalars and lists into a list of lists.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def normalize_to_lists(mixed_list: list[Union[str, list]]) -&gt; list[list]:\n    \"\"\"Turn a mixed list of scalars and lists into a list of lists.\"\"\"\n    normalized_list = []\n    for item in mixed_list:\n        if isinstance(item, str):\n            normalized_list.append([item])\n        else:\n            normalized_list.append(item)\n    return normalized_list\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.split_string_prefix_suffix_from_num","title":"<code>split_string_prefix_suffix_from_num(input_string)</code>","text":"<p>Split a string prefix and suffix from last number.</p> <p>Parameters:</p> Name Type Description Default <code>input_string</code> <code>str</code> <p>The input string to be processed.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the prefix (including preceding numbers),    the last numeric part as an integer, and the suffix.</p> Notes <p>This function uses regular expressions to split a string into three parts: the prefix, the last numeric part, and the suffix. The prefix includes any preceding numbers, the last numeric part is converted to an integer, and the suffix includes any non-digit characters after the last numeric part.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"abc123def456\")\n('abc', 123, 'def456')\n</code></pre> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"hello\")\n('hello', 0, '')\n</code></pre> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"123\")\n('', 123, '')\n</code></pre> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def split_string_prefix_suffix_from_num(input_string: str):\n    \"\"\"Split a string prefix and suffix from *last* number.\n\n    Args:\n        input_string (str): The input string to be processed.\n\n    Returns:\n        tuple: A tuple containing the prefix (including preceding numbers),\n               the last numeric part as an integer, and the suffix.\n\n    Notes:\n        This function uses regular expressions to split a string into three parts:\n        the prefix, the last numeric part, and the suffix. The prefix includes any\n        preceding numbers, the last numeric part is converted to an integer, and\n        the suffix includes any non-digit characters after the last numeric part.\n\n    Examples:\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"abc123def456\")\n        ('abc', 123, 'def456')\n\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"hello\")\n        ('hello', 0, '')\n\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"123\")\n        ('', 123, '')\n\n    \"\"\"\n    input_string = str(input_string)\n    pattern = re.compile(r\"(.*?)(\\d+)(\\D*)$\")\n    match = pattern.match(input_string)\n\n    if match:\n        # Extract the groups: prefix (including preceding numbers), last numeric part, suffix\n        prefix, numeric_part, suffix = match.groups()\n        # Convert the numeric part to an integer\n        num_variable = int(numeric_part)\n        return prefix, num_variable, suffix\n    else:\n        return input_string, 0, \"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.topological_sort","title":"<code>topological_sort(adjacency_list, visited_list)</code>","text":"<p>Topological sorting for Acyclic Directed Graph.</p> <p>Parameters: - adjacency_list (dict): A dictionary representing the adjacency list of the graph. - visited_list (list): A list representing the visited status of each vertex in the graph.</p> <p>Returns: - output_stack (list): A list containing the vertices in topological order.</p> <p>This function performs a topological sort on an acyclic directed graph. It takes an adjacency list and a visited list as input. The adjacency list represents the connections between vertices in the graph, and the visited list keeps track of the visited status of each vertex.</p> <p>The function uses a recursive helper function to perform the topological sort. It starts by iterating over each vertex in the visited list. For each unvisited vertex, it calls the helper function, which recursively visits all the neighbors of the vertex and adds them to the output stack in reverse order. Finally, it returns the output stack, which contains the vertices in topological order.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def topological_sort(adjacency_list, visited_list):\n    \"\"\"Topological sorting for Acyclic Directed Graph.\n\n    Parameters:\n    - adjacency_list (dict): A dictionary representing the adjacency list of the graph.\n    - visited_list (list): A list representing the visited status of each vertex in the graph.\n\n    Returns:\n    - output_stack (list): A list containing the vertices in topological order.\n\n    This function performs a topological sort on an acyclic directed graph. It takes an adjacency\n    list and a visited list as input. The adjacency list represents the connections between\n    vertices in the graph, and the visited list keeps track of the visited status of each vertex.\n\n    The function uses a recursive helper function to perform the topological sort. It starts by\n    iterating over each vertex in the visited list. For each unvisited vertex, it calls the helper\n    function, which recursively visits all the neighbors of the vertex and adds them to the output\n    stack in reverse order. Finally, it returns the output stack, which contains the vertices in\n    topological order.\n    \"\"\"\n    output_stack = []\n\n    def _topology_sort_util(vertex):\n        if not visited_list[vertex]:\n            visited_list[vertex] = True\n            for neighbor in adjacency_list[vertex]:\n                _topology_sort_util(neighbor)\n            output_stack.insert(0, vertex)\n\n    for vertex in visited_list:\n        _topology_sort_util(vertex)\n\n    return output_stack\n</code></pre>"},{"location":"api/#network_wrangler.utils.io.FileReadError","title":"<code>FileReadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error reading a file.</p> Source code in <code>network_wrangler/utils/io.py</code> <pre><code>class FileReadError(Exception):\n    \"\"\"Raised when there is an error reading a file.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.io.FileWriteError","title":"<code>FileWriteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error writing a file.</p> Source code in <code>network_wrangler/utils/io.py</code> <pre><code>class FileWriteError(Exception):\n    \"\"\"Raised when there is an error writing a file.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.io.convert_file_serialization","title":"<code>convert_file_serialization(input_file, output_file, overwrite=True, boundary_gdf=None, boundary_geocode=None, boundary_file=None, node_filter_s=None, chunk_size=None)</code>","text":"<p>Convert a file serialization format to another and optionally filter to a boundary.</p> <p>If the input file is a JSON file that is larger than a reasonable portion of available memory, and the output file is a Parquet file the JSON file will be read in chunks.</p> <p>If the input file is a Geographic data type (shp, geojon, geoparquet) and a boundary is provided, the data will be filtered to the boundary.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>Path</code> <p>Path to the input JSON or GEOJSON file.</p> required <code>output_file</code> <code>Path</code> <p>Path to the output Parquet file.</p> required <code>overwrite</code> <code>bool</code> <p>If True, overwrite the output file if it exists.</p> <code>True</code> <code>boundary_gdf</code> <code>Optional[GeoDataFrame]</code> <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_geocode</code> <code>Optional[str]</code> <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Optional[Path]</code> <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>node_filter_s</code> <code>Optional[Series]</code> <p>If provided, will filter links in .json file to only those that connect to nodes. Defaults to None.</p> <code>None</code> <code>chunk_size</code> <code>Optional[int]</code> <p>Number of JSON objects to process in each chunk. Only works for JSON to Parquet. If None, will determine if chunking needed and what size.</p> <code>None</code> Source code in <code>network_wrangler/utils/io.py</code> <pre><code>def convert_file_serialization(\n    input_file: Path,\n    output_file: Path,\n    overwrite: bool = True,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    node_filter_s: Optional[pd.Series] = None,\n    chunk_size: Optional[int] = None,\n):\n    \"\"\"Convert a file serialization format to another and optionally filter to a boundary.\n\n    If the input file is a JSON file that is larger than a reasonable portion of available\n    memory, *and* the output file is a Parquet file the JSON file will be read in chunks.\n\n    If the input file is a Geographic data type (shp, geojon, geoparquet) and a boundary is\n    provided, the data will be filtered to the boundary.\n\n    Args:\n        input_file: Path to the input JSON or GEOJSON file.\n        output_file: Path to the output Parquet file.\n        overwrite: If True, overwrite the output file if it exists.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        node_filter_s: If provided, will filter links in .json file to only those that connect to\n            nodes. Defaults to None.\n        chunk_size: Number of JSON objects to process in each chunk. Only works for\n            JSON to Parquet. If None, will determine if chunking needed and what size.\n    \"\"\"\n    WranglerLogger.debug(f\"Converting {input_file} to {output_file}.\")\n\n    if output_file.exists() and not overwrite:\n        raise FileExistsError(f\"File {output_file} already exists and overwrite is False.\")\n\n    if Path(input_file).suffix == \".json\" and Path(output_file).suffix == \".parquet\":\n        if chunk_size is None:\n            chunk_size = _suggest_json_chunk_size(input_file)\n        if chunk_size is None:\n            df = read_table(input_file)\n            if node_filter_s is not None and \"A\" in df.columns and \"B\" in df.columns:\n                df = df[df[\"A\"].isin(node_filter_s) | df[\"B\"].isin(node_filter_s)]\n            write_table(df, output_file, overwrite=overwrite)\n        else:\n            _json_to_parquet_in_chunks(input_file, output_file, chunk_size)\n\n    df = read_table(\n        input_file,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n    if node_filter_s is not None and \"A\" in df.columns and \"B\" in df.columns:\n        df = df[df[\"A\"].isin(node_filter_s) | df[\"B\"].isin(node_filter_s)]\n    write_table(df, output_file, overwrite=overwrite)\n</code></pre>"},{"location":"api/#network_wrangler.utils.io.read_table","title":"<code>read_table(filename, sub_filename=None, boundary_gdf=None, boundary_geocode=None, boundary_file=None)</code>","text":"<p>Read file and return a dataframe or geodataframe.</p> <p>If filename is a zip file, will unzip to a temporary directory.</p> <p>If filename is a geojson or shapefile, will filter the data to the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only provide one of these boundary filters.</p> <p>If filename is a geoparquet file, will filter the data to the bounding box of the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only provide one of these boundary filters.</p> <p>NOTE:  if you are accessing multiple files from this zip file you will want to unzip it first and THEN access the table files so you don\u2019t create multiple duplicate unzipped tmp dirs.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path</code> <p>filename to load.</p> required <code>sub_filename</code> <code>str</code> <p>if the file is a zip, the sub_filename to load.</p> <code>None</code> <code>boundary_gdf</code> <code>Optional[GeoDataFrame]</code> <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_geocode</code> <code>Optional[str]</code> <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Optional[Path]</code> <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> Source code in <code>network_wrangler/utils/io.py</code> <pre><code>def read_table(\n    filename: Path,\n    sub_filename: str = None,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n) -&gt; Union[pd.DataFrame, gpd.GeoDataFrame]:\n    \"\"\"Read file and return a dataframe or geodataframe.\n\n    If filename is a zip file, will unzip to a temporary directory.\n\n    If filename is a geojson or shapefile, will filter the data\n    to the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only\n    provide one of these boundary filters.\n\n    If filename is a geoparquet file, will filter the data to the *bounding box* of the\n    boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only\n    provide one of these boundary filters.\n\n    NOTE:  if you are accessing multiple files from this zip file you will want to unzip it first\n    and THEN access the table files so you don't create multiple duplicate unzipped tmp dirs.\n\n    Args:\n        filename (Path): filename to load.\n        sub_filename: if the file is a zip, the sub_filename to load.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n    \"\"\"\n    filename = Path(filename)\n    if not filename.exists():\n        raise FileNotFoundError(f\"Input file {filename} does not exist.\")\n    if filename.stat().st_size == 0:\n        raise FileExistsError(f\"File {filename} is empty.\")\n    if filename.suffix == \".zip\":\n        filename = unzip_file(filename) / sub_filename\n    WranglerLogger.debug(f\"Estimated read time: {_estimate_read_time_of_file(filename)}.\")\n\n    # will result in None if no boundary is provided\n    mask_gdf = get_bounding_polygon(\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n\n    if any([x in filename.suffix for x in [\"geojson\", \"shp\", \"csv\"]]):\n        try:\n            # masking only supported by fiona engine, which is slower.\n            if mask_gdf is None:\n                return gpd.read_file(filename, engine=\"pyogrio\")\n            else:\n                return gpd.read_file(filename, mask=mask_gdf, engine=\"fiona\")\n        except:  # noqa: E722\n            if \"csv\" in filename.suffix:\n                return pd.read_csv(filename)\n            raise FileReadError\n    elif \"parquet\" in filename.suffix:\n        return _read_parquet_table(filename, mask_gdf)\n    elif \"json\" in filename.suffix:\n        with open(filename) as f:\n            return pd.read_json(f, orient=\"records\")\n    raise NotImplementedError(f\"Filetype {filename.suffix} not implemented.\")\n</code></pre>"},{"location":"api/#network_wrangler.utils.io.unzip_file","title":"<code>unzip_file(path)</code>","text":"<p>Unzips a file to a temporary directory and returns the directory path.</p> Source code in <code>network_wrangler/utils/io.py</code> <pre><code>def unzip_file(path: Path) -&gt; Path:\n    \"\"\"Unzips a file to a temporary directory and returns the directory path.\"\"\"\n    tmpdir = tempfile.mkdtemp()\n    shutil.unpack_archive(path, tmpdir)\n\n    def finalize() -&gt; None:\n        shutil.rmtree(tmpdir)\n\n    # Lazy cleanup\n    weakref.finalize(tmpdir, finalize)\n\n    return tmpdir\n</code></pre>"},{"location":"api/#network_wrangler.utils.io.write_table","title":"<code>write_table(df, filename, overwrite=False, **kwargs)</code>","text":"<p>Write a dataframe or geodataframe to a file.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataframe to write.</p> required <code>filename</code> <code>Path</code> <p>filename to write to.</p> required <code>overwrite</code> <code>bool</code> <p>whether to overwrite the file if it exists. Defaults to False.</p> <code>False</code> <code>kwargs</code> <p>additional arguments to pass to the writer.</p> <code>{}</code> Source code in <code>network_wrangler/utils/io.py</code> <pre><code>def write_table(\n    df: Union[pd.DataFrame, gpd.GeoDataFrame],\n    filename: Path,\n    overwrite: bool = False,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Write a dataframe or geodataframe to a file.\n\n    Args:\n        df (pd.DataFrame): dataframe to write.\n        filename (Path): filename to write to.\n        overwrite (bool): whether to overwrite the file if it exists. Defaults to False.\n        kwargs: additional arguments to pass to the writer.\n\n    \"\"\"\n    filename = Path(filename)\n    if filename.exists() and not overwrite:\n        raise FileExistsError(f\"File {filename} already exists and overwrite is False.\")\n\n    if filename.parent.is_dir() and not filename.parent.exists():\n        filename.parent.mkdir(parents=True)\n\n    WranglerLogger.debug(f\"Writing to {filename}.\")\n\n    if \"shp\" in filename.suffix:\n        df.to_file(filename, index=False, **kwargs)\n    elif \"parquet\" in filename.suffix:\n        df.to_parquet(filename, index=False, **kwargs)\n    elif \"csv\" in filename.suffix:\n        df.to_csv(filename, index=False, date_format=\"%H:%M:%S\", **kwargs)\n    elif \"txt\" in filename.suffix:\n        df.to_csv(filename, index=False, date_format=\"%H:%M:%S\", **kwargs)\n    elif \"geojson\" in filename.suffix:\n        # required due to issues with list-like columns\n        if isinstance(df, gpd.GeoDataFrame):\n            data = df.to_json(drop_id=True)\n        else:\n            data = df.to_json(orient=\"records\", index=False)\n        with open(filename, \"w\", encoding=\"utf-8\") as file:\n            file.write(data)\n    elif \"json\" in filename.suffix:\n        with open(filename, \"w\") as f:\n            f.write(df.to_json(orient=\"records\"))\n    else:\n        raise NotImplementedError(f\"Filetype {filename.suffix} not implemented.\")\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.DatamodelDataframeIncompatableError","title":"<code>DatamodelDataframeIncompatableError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a data model and a dataframe are not compatable.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>class DatamodelDataframeIncompatableError(Exception):\n    \"\"\"Raised when a data model and a dataframe are not compatable.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.TableValidationError","title":"<code>TableValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a table validation fails.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>class TableValidationError(Exception):\n    \"\"\"Raised when a table validation fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.coerce_extra_fields_to_type_in_df","title":"<code>coerce_extra_fields_to_type_in_df(data, model, df)</code>","text":"<p>Coerce extra fields in data that aren\u2019t specified in Pydantic model to the type in the df.</p> <p>Note: will not coerce lists of submodels, etc.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>The data to coerce.</p> required <code>model</code> <code>BaseModel</code> <p>The Pydantic model to validate the data against.</p> required <code>df</code> <code>DataFrame</code> <p>The DataFrame to coerce the data to.</p> required Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def coerce_extra_fields_to_type_in_df(\n    data: BaseModel, model: BaseModel, df: pd.DataFrame\n) -&gt; BaseModel:\n    \"\"\"Coerce extra fields in data that aren't specified in Pydantic model to the type in the df.\n\n    Note: will not coerce lists of submodels, etc.\n\n    Args:\n        data (dict): The data to coerce.\n        model (BaseModel): The Pydantic model to validate the data against.\n        df (pd.DataFrame): The DataFrame to coerce the data to.\n    \"\"\"\n    out_data = copy.deepcopy(data)\n\n    # Coerce submodels\n    for field in submodel_fields_in_model(model, data):\n        out_data.__dict__[field] = coerce_extra_fields_to_type_in_df(\n            data.__dict__[field], model.__annotations__[field], df\n        )\n\n    for field in extra_attributes_undefined_in_model(data, model):\n        try:\n            v = coerce_val_to_df_types(field, data.model_extra[field], df)\n        except ValueError as e:\n            raise DatamodelDataframeIncompatableError(e)\n        out_data.model_extra[field] = v\n    return out_data\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.default_from_datamodel","title":"<code>default_from_datamodel(data_model, field)</code>","text":"<p>Returns default value from pandera data model for a given field name.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def default_from_datamodel(data_model: pa.DataFrameModel, field: str):\n    \"\"\"Returns default value from pandera data model for a given field name.\"\"\"\n    if field in data_model.__fields__:\n        if hasattr(data_model.__fields__[field][1], \"default\"):\n            return data_model.__fields__[field][1].default\n    return None\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.empty_df_from_datamodel","title":"<code>empty_df_from_datamodel(model, crs=LAT_LON_CRS)</code>","text":"<p>Create an empty DataFrame or GeoDataFrame with the specified columns.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>A pandera data model to create empty [Geo]DataFrame from.</p> required <code>crs</code> <code>int</code> <p>if schema has geometry, will use this as the geometry\u2019s crs. Defaults to LAT_LONG_CRS</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def empty_df_from_datamodel(\n    model: DataFrameModel, crs: int = LAT_LON_CRS\n) -&gt; Union[gpd.GeoDataFrame, pd.DataFrame]:\n    \"\"\"Create an empty DataFrame or GeoDataFrame with the specified columns.\n\n    Args:\n        model (BaseModel): A pandera data model to create empty [Geo]DataFrame from.\n        crs: if schema has geometry, will use this as the geometry's crs. Defaults to LAT_LONG_CRS\n    Returns:\n        An empty [Geo]DataFrame that validates to the specified model.\n    \"\"\"\n    schema = model.to_schema()\n    data = {col: [] for col in schema.columns.keys()}\n\n    if \"geometry\" in data:\n        return model(gpd.GeoDataFrame(data, crs=crs))\n\n    return model(pd.DataFrame(data))\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.extra_attributes_undefined_in_model","title":"<code>extra_attributes_undefined_in_model(instance, model)</code>","text":"<p>Find the extra attributes in a pydantic model that are not defined in the model.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def extra_attributes_undefined_in_model(instance: BaseModel, model: BaseModel) -&gt; list:\n    \"\"\"Find the extra attributes in a pydantic model that are not defined in the model.\"\"\"\n    defined_fields = model.model_fields\n    all_attributes = list(instance.model_dump(exclude_none=True, by_alias=True).keys())\n    extra_attributes = [a for a in all_attributes if a not in defined_fields]\n    return extra_attributes\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.identify_model","title":"<code>identify_model(data, models)</code>","text":"<p>Identify the model that the input data conforms to.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, dict]</code> <p>The input data to identify.</p> required <code>models</code> <code>list[DataFrameModel, BaseModel]</code> <p>A list of models to validate the input data against.</p> required Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def identify_model(\n    data: Union[pd.DataFrame, dict], models: list[DataFrameModel, BaseModel]\n) -&gt; Union[DataFrameModel, BaseModel]:\n    \"\"\"Identify the model that the input data conforms to.\n\n    Args:\n        data (Union[pd.DataFrame, dict]): The input data to identify.\n        models (list[DataFrameModel,BaseModel]): A list of models to validate the input\n          data against.\n    \"\"\"\n    for m in models:\n        try:\n            if isinstance(data, pd.DataFrame):\n                validate_df_to_model(data, m)\n            else:\n                m(**data)\n            return m\n        except ValidationError:\n            continue\n        except SchemaError:\n            continue\n\n    WranglerLogger.error(\n        f\"The input data isn't consistant with any provided data model.\\\n                         \\nInput data: {data}\\\n                         \\nData Models: {models}\"\n    )\n    raise ValueError(\"The input dictionary does not conform to any of the provided models.\")\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.submodel_fields_in_model","title":"<code>submodel_fields_in_model(model, instance=None)</code>","text":"<p>Find the fields in a pydantic model that are submodels.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def submodel_fields_in_model(model: BaseModel, instance: Optional[BaseModel] = None) -&gt; list:\n    \"\"\"Find the fields in a pydantic model that are submodels.\"\"\"\n    types = get_type_hints(model)\n    model_type = Union[ModelMetaclass, BaseModel]\n    submodels = [f for f in model.model_fields if isinstance(types.get(f), model_type)]\n    if instance is not None:\n        defined = list(instance.model_dump(exclude_none=True, by_alias=True).keys())\n        return [f for f in submodels if f in defined]\n    return submodels\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.validate_df_to_model","title":"<code>validate_df_to_model(df, model, output_file='validation_failure_cases.csv')</code>","text":"<p>Wrapper to validate a DataFrame against a Pandera DataFrameModel with better logging.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to validate.</p> required <code>model</code> <code>DataFrameModel</code> <p>Pandera DataFrameModel to validate against.</p> required <code>output_file</code> <code>Path</code> <p>Optional file to write validation errors to. Defaults to validation_failure_cases.csv.</p> <code>'validation_failure_cases.csv'</code> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef validate_df_to_model(\n    df: DataFrame, model: DataFrameModel, output_file: Path = \"validation_failure_cases.csv\"\n) -&gt; DataFrame:\n    \"\"\"Wrapper to validate a DataFrame against a Pandera DataFrameModel with better logging.\n\n    Args:\n        df: DataFrame to validate.\n        model: Pandera DataFrameModel to validate against.\n        output_file: Optional file to write validation errors to. Defaults to\n            validation_failure_cases.csv.\n    \"\"\"\n    try:\n        model_df = model.validate(df, lazy=True)\n        for c in model_df.columns:\n            default_value = default_from_datamodel(model, c)\n            if default_value is None:\n                model_df[c] = model_df[c].where(pd.notna(model_df[c]), None)\n            else:\n                model_df[c] = model_df[c].fillna(default_value)\n\n        return model_df\n\n    except SchemaErrors or TypeError or ValueError as e:\n        # Log the summary of errors\n        WranglerLogger.error(\n            f\"Validation to {model.__name__} failed with {len(e.failure_cases)} \\\n            errors: \\n{e.failure_cases}\"\n        )\n\n        # If there are many errors, save them to a file\n        if len(e.failure_cases) &gt; 5:\n            error_file = output_file\n            e.failure_cases.to_csv(error_file)\n            WranglerLogger.info(f\"Detailed error cases written to {error_file}\")\n        else:\n            # Otherwise log the errors directly\n            WranglerLogger.error(\"Detailed failure cases:\\n%s\", e.failure_cases)\n        raise TableValidationError(f\"Validation to {model.__name__} failed.\")\n    except SchemaError as e:\n        WranglerLogger.error(f\"Validation to {model.__name__} failed with error: {e}\")\n        WranglerLogger.error(f\"Failure Cases:\\n{e.failure_cases}\")\n        raise TableValidationError(f\"Validation to {model.__name__} failed.\")\n</code></pre>"},{"location":"api/#network_wrangler.utils.net.point_seq_to_links","title":"<code>point_seq_to_links(point_seq_df, id_field, seq_field, node_id_field, from_field='A', to_field='B')</code>","text":"<p>Translates a df with tidy data representing a sequence of points into links.</p> <p>Parameters:</p> Name Type Description Default <code>point_seq_df</code> <code>DataFrame</code> <p>Dataframe with source breadcrumbs</p> required <code>id_field</code> <code>str</code> <p>Trace ID</p> required <code>seq_field</code> <code>str</code> <p>Order of breadcrumbs within ID_field</p> required <code>node_id_field</code> <code>str</code> <p>field denoting the node ID</p> required <code>from_field</code> <code>str</code> <p>Field to export from_field to. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_field</code> <code>str</code> <p>Field to export to_field to. Defaults to \u201cB\u201d.</p> <code>'B'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Link records with id_field, from_field, to_field</p> Source code in <code>network_wrangler/utils/net.py</code> <pre><code>def point_seq_to_links(\n    point_seq_df: DataFrame,\n    id_field: str,\n    seq_field: str,\n    node_id_field: str,\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; DataFrame:\n    \"\"\"Translates a df with tidy data representing a sequence of points into links.\n\n    Args:\n        point_seq_df (pd.DataFrame): Dataframe with source breadcrumbs\n        id_field (str): Trace ID\n        seq_field (str): Order of breadcrumbs within ID_field\n        node_id_field (str): field denoting the node ID\n        from_field (str, optional): Field to export from_field to. Defaults to \"A\".\n        to_field (str, optional): Field to export to_field to. Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: Link records with id_field, from_field, to_field\n    \"\"\"\n    point_seq_df = point_seq_df.sort_values(by=[id_field, seq_field])\n\n    links = point_seq_df.add_suffix(f\"_{from_field}\").join(\n        point_seq_df.shift(-1).add_suffix(f\"_{to_field}\")\n    )\n\n    links = links[links[f\"{id_field}_{to_field}\"] == links[f\"{id_field}_{from_field}\"]]\n\n    links = links.drop(columns=[f\"{id_field}_{to_field}\"])\n    links = links.rename(\n        columns={\n            f\"{id_field}_{from_field}\": id_field,\n            f\"{node_id_field}_{from_field}\": from_field,\n            f\"{node_id_field}_{to_field}\": to_field,\n        }\n    )\n\n    links = links.dropna(subset=[from_field, to_field])\n    # Since join with a shift() has some NAs, we need to recast the columns to int\n    _int_cols = [to_field, f\"{seq_field}_{to_field}\"]\n    links[_int_cols] = links[_int_cols].astype(int)\n    return links\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.convert_timespan_to_start_end_dt","title":"<code>convert_timespan_to_start_end_dt(timespan_s)</code>","text":"<p>Covert a timespan string [\u201812:00\u2019,\u201814:00] to start_time and end_time datetime cols in df.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def convert_timespan_to_start_end_dt(timespan_s: pd.Serie[str]) -&gt; pd.DataFrame:\n    \"\"\"Covert a timespan string ['12:00','14:00] to start_time and end_time datetime cols in df.\"\"\"\n    start_time = timespan_s.apply(lambda x: str_to_time(x[0]))\n    end_time = timespan_s.apply(lambda x: str_to_time(x[1]))\n    return pd.DataFrame({\"start_time\": start_time, \"end_time\": end_time})\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_contains","title":"<code>dt_contains(timespan1, timespan2)</code>","text":"<p>Check timespan1 inclusively contains timespan2.</p> <p>Parameters:</p> Name Type Description Default <code>timespan1</code> <code>list[time]</code> <p>The first timespan represented as a list containing the start time and end time.</p> required <code>timespan2</code> <code>list[time]</code> <p>The second timespan represented as a list containing the start time and end time.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the first timespan contains the second timespan, False otherwise.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef dt_contains(timespan1: list[datetime], timespan2: list[datetime]) -&gt; bool:\n    \"\"\"Check timespan1 inclusively contains timespan2.\n\n    Args:\n        timespan1 (list[time]): The first timespan represented as a list containing the start\n            time and end time.\n        timespan2 (list[time]): The second timespan represented as a list containing the start\n            time and end time.\n\n    Returns:\n        bool: True if the first timespan contains the second timespan, False otherwise.\n    \"\"\"\n    start_time_dt, end_time_dt = timespan1\n    start_time_dt2, end_time_dt2 = timespan2\n    return (start_time_dt &lt;= start_time_dt2) and (end_time_dt &gt;= end_time_dt2)\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_list_overlaps","title":"<code>dt_list_overlaps(timespans)</code>","text":"<p>Check if any of the timespans overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def dt_list_overlaps(timespans: list[list[datetime]]) -&gt; bool:\n    \"\"\"Check if any of the timespans overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    if filter_dt_list_to_overlaps(timespans):\n        return True\n    return False\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_overlap_duration","title":"<code>dt_overlap_duration(timedelta1, timedelta2)</code>","text":"<p>Check if two timespans overlap and return the amount of overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef dt_overlap_duration(timedelta1: timedelta, timedelta2: timedelta) -&gt; timedelta:\n    \"\"\"Check if two timespans overlap and return the amount of overlap.\"\"\"\n    overlap_start = max(timedelta1.start_time, timedelta2.start_time)\n    overlap_end = min(timedelta1.end_time, timedelta2.end_time)\n    overlap_duration = max(overlap_end - overlap_start, timedelta(0))\n    return overlap_duration\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_overlaps","title":"<code>dt_overlaps(timespan1, timespan2)</code>","text":"<p>Check if two timespans overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef dt_overlaps(timespan1: list[datetime], timespan2: list[datetime]) -&gt; bool:\n    \"\"\"Check if two timespans overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    time1_start, time1_end = timespan1\n    time2_start, time2_end = timespan2\n    return (time1_start &lt; time2_end) and (time2_start &lt; time1_end)\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_to_seconds_from_midnight","title":"<code>dt_to_seconds_from_midnight(dt)</code>","text":"<p>Convert a datetime object to the number of seconds since midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef dt_to_seconds_from_midnight(dt: datetime) -&gt; int:\n    \"\"\"Convert a datetime object to the number of seconds since midnight.\"\"\"\n    return (dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.duration_dt","title":"<code>duration_dt(start_time_dt, end_time_dt)</code>","text":"<p>Returns a datetime.timedelta object representing the duration of the timespan.</p> <p>If end_time is less than start_time, the duration will assume that it crosses over midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def duration_dt(start_time_dt: datetime, end_time_dt: datetime) -&gt; timedelta:\n    \"\"\"Returns a datetime.timedelta object representing the duration of the timespan.\n\n    If end_time is less than start_time, the duration will assume that it crosses over\n    midnight.\n    \"\"\"\n    if end_time_dt &lt; start_time_dt:\n        return timedelta(\n            hours=24 - start_time_dt.hour + end_time_dt.hour,\n            minutes=end_time_dt.minute - start_time_dt.minute,\n            seconds=end_time_dt.second - start_time_dt.second,\n        )\n    else:\n        return end_time_dt - start_time_dt\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.filter_df_to_max_overlapping_timespans","title":"<code>filter_df_to_max_overlapping_timespans(orig_df, query_timespan, strict_match=False, min_overlap_minutes=1, keep_max_of_cols=['model_link_id'])</code>","text":"<p>Filters dataframe for entries that have maximum overlap with the given query timespan.</p> <p>Parameters:</p> Name Type Description Default <code>orig_df</code> <code>DataFrame</code> <p>dataframe to query timespans for with <code>start_time</code> and <code>end_time</code> fields.</p> required <code>query_timespan</code> <code>list[TimeString]</code> <p>TimespanString of format [\u2018HH:MM\u2019,\u2019HH:MM\u2019] to query orig_df for overlapping records.</p> required <code>strict_match</code> <code>bool</code> <p>boolean indicating if the returned df should only contain records that fully contain the query timespan. If set to True, min_overlap_minutes does not apply. Defaults to False.</p> <code>False</code> <code>min_overlap_minutes</code> <code>int</code> <p>minimum number of minutes the timespans need to overlap to keep. Defaults to 1.</p> <code>1</code> <code>keep_max_of_cols</code> <code>list[str]</code> <p>list of fields to return the maximum value of overlap for.  If None, will return all overlapping time periods. Defaults to <code>['model_link_id']</code></p> <code>['model_link_id']</code> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef filter_df_to_max_overlapping_timespans(\n    orig_df: pd.DataFrame,\n    query_timespan: list[TimeString],\n    strict_match: bool = False,\n    min_overlap_minutes: int = 1,\n    keep_max_of_cols: list[str] = [\"model_link_id\"],\n) -&gt; pd.DataFrame:\n    \"\"\"Filters dataframe for entries that have maximum overlap with the given query timespan.\n\n    Args:\n        orig_df: dataframe to query timespans for with `start_time` and `end_time` fields.\n        query_timespan: TimespanString of format ['HH:MM','HH:MM'] to query orig_df for overlapping\n            records.\n        strict_match: boolean indicating if the returned df should only contain\n            records that fully contain the query timespan. If set to True, min_overlap_minutes\n            does not apply. Defaults to False.\n        min_overlap_minutes: minimum number of minutes the timespans need to overlap to keep.\n            Defaults to 1.\n        keep_max_of_cols: list of fields to return the maximum value of overlap for.  If None,\n            will return all overlapping time periods. Defaults to `['model_link_id']`\n    \"\"\"\n    if \"start_time\" not in orig_df.columns or \"end_time\" not in orig_df.columns:\n        raise ValueError(\"DataFrame must have 'start_time' and 'end_time' columns\")\n    q_start, q_end = str_to_time_list(query_timespan)\n\n    overlap_start = orig_df[\"start_time\"].combine(q_start, max)\n    overlap_end = orig_df[\"end_time\"].combine(q_end, min)\n    orig_df[\"overlap_duration\"] = (overlap_end - overlap_start).dt.total_seconds() / 60\n\n    if strict_match:\n        overlap_df = orig_df.loc[(orig_df.start_time &lt;= q_start) &amp; (orig_df.end_time &gt;= q_end)]\n    else:\n        overlap_df = orig_df.loc[orig_df.overlap_duration &gt; min_overlap_minutes]\n    WranglerLogger.debug(f\"overlap_df: \\n{overlap_df}\")\n    if keep_max_of_cols:\n        # keep only the maximum overlap\n        idx = overlap_df.groupby(keep_max_of_cols)[\"overlap_duration\"].idxmax()\n        overlap_df = overlap_df.loc[idx]\n    return overlap_df\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.filter_df_to_overlapping_timespans","title":"<code>filter_df_to_overlapping_timespans(orig_df, query_timespans)</code>","text":"<p>Filters dataframe for entries that have any overlap with ANY of the given query timespans.</p> <p>Parameters:</p> Name Type Description Default <code>orig_df</code> <code>DataFrame</code> <p>dataframe to query timespans for with <code>start_time</code> and <code>end_time</code> fields.</p> required <code>query_timespans</code> <code>list[TimespanString]</code> <p>List of a list of TimespanStr of format [\u2018HH:MM\u2019,\u2019HH:MM\u2019] to query orig_df for overlapping records.</p> required Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef filter_df_to_overlapping_timespans(\n    orig_df: pd.DataFrame,\n    query_timespans: list[TimespanString],\n) -&gt; pd.DataFrame:\n    \"\"\"Filters dataframe for entries that have any overlap with ANY of the given query timespans.\n\n    Args:\n        orig_df: dataframe to query timespans for with `start_time` and `end_time` fields.\n        query_timespans: List of a list of TimespanStr of format ['HH:MM','HH:MM'] to query orig_df\n            for overlapping records.\n    \"\"\"\n    if \"start_time\" not in orig_df.columns or \"end_time\" not in orig_df.columns:\n        raise ValueError(\"DataFrame must have 'start_time' and 'end_time' columns\")\n    mask = pd.Series([False] * len(orig_df), index=orig_df.index)\n    for query_timespan in query_timespans:\n        q_start_time, q_end_time = str_to_time_list(query_timespan)\n        this_ts_mask = (orig_df[\"start_time\"] &lt; q_end_time) &amp; (q_start_time &lt; orig_df[\"end_time\"])\n        mask |= this_ts_mask\n    return orig_df.loc[mask]\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.filter_dt_list_to_overlaps","title":"<code>filter_dt_list_to_overlaps(timespans)</code>","text":"<p>Filter a list of timespans to only include those that overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef filter_dt_list_to_overlaps(timespans: list[list[datetime]]) -&gt; list[list[datetime]]:\n    \"\"\"Filter a list of timespans to only include those that overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    overlaps = []\n    for i in range(len(timespans)):\n        for j in range(i + 1, len(timespans)):\n            if dt_overlaps(timespans[i], timespans[j]):\n                overlaps += [timespans[i], timespans[j]]\n\n    # remove dupes\n    overlaps = list(map(list, set(map(tuple, overlaps))))\n    return overlaps\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.format_seconds_to_legible_str","title":"<code>format_seconds_to_legible_str(seconds)</code>","text":"<p>Formats seconds into a human-friendly string for log files.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def format_seconds_to_legible_str(seconds: int) -&gt; str:\n    \"\"\"Formats seconds into a human-friendly string for log files.\"\"\"\n    if seconds &lt; 60:\n        return f\"{int(seconds)} seconds\"\n    elif seconds &lt; 3600:\n        return f\"{int(seconds // 60)} minutes\"\n    else:\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        return f\"{hours} hours and {minutes} minutes\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.is_increasing","title":"<code>is_increasing(datetimes)</code>","text":"<p>Check if a list of datetime objects is increasing in time.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def is_increasing(datetimes: list[datetime]) -&gt; bool:\n    \"\"\"Check if a list of datetime objects is increasing in time.\"\"\"\n    for i in range(len(datetimes) - 1):\n        if datetimes[i] &gt; datetimes[i + 1]:\n            return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.seconds_from_midnight_to_str","title":"<code>seconds_from_midnight_to_str(seconds)</code>","text":"<p>Convert the number of seconds since midnight to a TimeString (HH:MM).</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef seconds_from_midnight_to_str(seconds: int) -&gt; TimeString:\n    \"\"\"Convert the number of seconds since midnight to a TimeString (HH:MM).\"\"\"\n    return str(timedelta(seconds=seconds))\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_seconds_from_midnight","title":"<code>str_to_seconds_from_midnight(time_str)</code>","text":"<p>Convert a TimeString (HH:MM&lt;:SS&gt;) to the number of seconds since midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef str_to_seconds_from_midnight(time_str: TimeString) -&gt; int:\n    \"\"\"Convert a TimeString (HH:MM&lt;:SS&gt;) to the number of seconds since midnight.\"\"\"\n    dt = str_to_time(time_str)\n    return dt_to_seconds_from_midnight(dt)\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_time","title":"<code>str_to_time(time_str, base_date=None)</code>","text":"<p>Convert TimeString (HH:MM&lt;:SS&gt;) to datetime object.</p> <p>If HH &gt; 24, will add a day to the base_date.</p> <p>Parameters:</p> Name Type Description Default <code>time_str</code> <code>TimeString</code> <p>TimeString in HH:MM:SS or HH:MM format.</p> required <code>base_date</code> <code>Optional[date]</code> <p>optional date to base the datetime on. Defaults to None. If not provided, will use today.</p> <code>None</code> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef str_to_time(time_str: TimeString, base_date: Optional[datetime.date] = None) -&gt; datetime:\n    \"\"\"Convert TimeString (HH:MM&lt;:SS&gt;) to datetime object.\n\n    If HH &gt; 24, will add a day to the base_date.\n\n    Args:\n        time_str: TimeString in HH:MM:SS or HH:MM format.\n        base_date: optional date to base the datetime on. Defaults to None.\n            If not provided, will use today.\n    \"\"\"\n    # Set the base date to today if not provided\n    if base_date is None:\n        base_date = date.today()\n\n    # Split the time string to extract hours, minutes, and seconds\n    parts = time_str.split(\":\")\n    hours = int(parts[0])\n    minutes = int(parts[1])\n    seconds = int(parts[2]) if len(parts) == 3 else 0\n\n    # Calculate total number of days to add to base_date based on hours\n    days_to_add = hours // 24\n    hours = hours % 24\n\n    # Create a time object with the adjusted hours, minutes, and seconds\n    adjusted_time = datetime.strptime(f\"{hours:02}:{minutes:02}:{seconds:02}\", \"%H:%M:%S\").time()\n\n    # Combine the base date with the adjusted time and add the extra days if needed\n    combined_datetime = datetime.combine(base_date, adjusted_time) + timedelta(days=days_to_add)\n\n    return combined_datetime\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_time_list","title":"<code>str_to_time_list(timespan)</code>","text":"<p>Convert list of TimeStrings (HH:MM&lt;:SS&gt;) to list of datetime.time objects.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef str_to_time_list(timespan: list[TimeString]) -&gt; list[list[datetime]]:\n    \"\"\"Convert list of TimeStrings (HH:MM&lt;:SS&gt;) to list of datetime.time objects.\"\"\"\n    timespan = list(map(str_to_time, timespan))\n    if not is_increasing(timespan):\n        WranglerLogger.error(f\"Timespan is not in increasing order: {timespan}\")\n        raise ValueError(\"Timespan is not in increasing order.\")\n    return timespan\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_time_series","title":"<code>str_to_time_series(time_str_s, base_date=None)</code>","text":"<p>Convert panda series of TimeString (HH:MM&lt;:SS&gt;) to datetime object.</p> <p>If HH &gt; 24, will add a day to the base_date.</p> <p>Parameters:</p> Name Type Description Default <code>time_str_s</code> <code>Series</code> <p>Pandas Series of TimeStrings in HH:MM:SS or HH:MM format.</p> required <code>base_date</code> <code>Optional[Union[Series, date]]</code> <p>optional date to base the datetime on. Defaults to None. If not provided, will use today. Can be either a single instance or a series of  same length as time_str_s</p> <code>None</code> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef str_to_time_series(\n    time_str_s: pd.Series,\n    base_date: Optional[Union[pd.Series, datetime.date]] = None\n) -&gt; pd.Series:\n    \"\"\"Convert panda series of TimeString (HH:MM&lt;:SS&gt;) to datetime object.\n\n    If HH &gt; 24, will add a day to the base_date.\n\n    Args:\n        time_str_s: Pandas Series of TimeStrings in HH:MM:SS or HH:MM format.\n        base_date: optional date to base the datetime on. Defaults to None.\n            If not provided, will use today. Can be either a single instance or a series of \n            same length as time_str_s\n    \"\"\"\n    TimeStrSeriesSchema.validate(time_str_s)\n\n    # Set the base date to today if not provided\n    if base_date is None:\n        base_date = pd.Series([date.today()] * len(time_str_s))\n    elif isinstance(base_date, date):\n        base_date = pd.Series([base_date] * len(time_str_s))\n    elif len(base_date) != len(time_str_s):\n        raise ValueError(\"base_date must be the same length as time_str_s\")\n\n    # Filter out the string elements\n    is_string = time_str_s.apply(lambda x: isinstance(x, str))\n    time_strings = time_str_s[is_string]\n    base_dates = base_date[is_string]\n\n    # Split the time string to extract hours, minutes, and seconds\n    time_parts = time_strings.str.split(\":\", expand=True).astype(int)\n    hours = time_parts[0]\n    minutes = time_parts[1]\n    seconds = time_parts[2] if time_parts.shape[1] == 3 else 0\n\n    # Calculate total number of days to add to base_date based on hours\n    days_to_add = hours // 24\n    hours = hours % 24\n\n    # Combine the base date with the adjusted time and add the extra days if needed\n    combined_datetimes = pd.to_datetime(base_dates)\\\n        + pd.to_timedelta(days_to_add, unit='d')\\\n        + pd.to_timedelta(hours, unit='h')\\\n        + pd.to_timedelta(minutes, unit='m')\\\n        + pd.to_timedelta(seconds, unit='s')\n\n    # Combine the results back into the original series\n    result = time_str_s.copy()\n    result[is_string] = combined_datetimes\n    result = result.astype('datetime64[ns]')\n    return result\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.timespan_str_list_to_dt","title":"<code>timespan_str_list_to_dt(timespans)</code>","text":"<p>Convert list of TimespanStrings to list of datetime.time objects.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef timespan_str_list_to_dt(timespans: list[TimespanString]) -&gt; list[list[datetime]]:\n    \"\"\"Convert list of TimespanStrings to list of datetime.time objects.\"\"\"\n    [str_to_time_list(ts) for ts in timespans]\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.timespans_overlap","title":"<code>timespans_overlap(timespan1, timespan2)</code>","text":"<p>Check if two timespan strings overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config=dict(arbitrary_types_allowed=True))\ndef timespans_overlap(timespan1: list[TimespanString], timespan2: list[TimespanString]) -&gt; bool:\n    \"\"\"Check if two timespan strings overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    timespan1 = str_to_time_list(timespan1)\n    timespan2 = str_to_time_list(timespan2)\n    return dt_overlaps(timespan1, timespan2)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.InvalidJoinFieldError","title":"<code>InvalidJoinFieldError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when the join field is not unique.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class InvalidJoinFieldError(Exception):\n    \"\"\"Raised when the join field is not unique.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.MissingPropertiesError","title":"<code>MissingPropertiesError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when properties are missing from the dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class MissingPropertiesError(Exception):\n    \"\"\"Raised when properties are missing from the dataframe.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.attach_parameters_to_df","title":"<code>attach_parameters_to_df(df, params)</code>","text":"<p>Attatch params as a dataframe attribute which will be copied with dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def attach_parameters_to_df(df: pd.DataFrame, params) -&gt; pd.DataFrame:\n    \"\"\"Attatch params as a dataframe attribute which will be copied with dataframe.\"\"\"\n    if not df.__dict__.get(\"params\"):\n        df.__dict__[\"params\"] = params\n        # need to add params to _metadata in order to make sure it is copied.\n        # see: https://stackoverflow.com/questions/50372509/\n        df._metadata += [\"params\"]\n    # WranglerLogger.debug(f\"DFParams: {df.params}\")\n    return df\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_dict_to_df_types","title":"<code>coerce_dict_to_df_types(d, df, skip_keys=[], return_skipped=False)</code>","text":"<p>Coerce dictionary values to match the type of a dataframe columns matching dict keys.</p> <p>Will also coerce a list of values.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>dictionary to coerce with singleton or list values</p> required <code>df</code> <code>DataFrame</code> <p>dataframe to get types from</p> required <code>skip_keys</code> <code>list</code> <p>list of dict keys to skip. Defaults to []/</p> <code>[]</code> <code>return_skipped</code> <code>bool</code> <p>keep the uncoerced, skipped keys/vals in the resulting dict. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>dict with coerced types</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_dict_to_df_types(\n    d: dict, df: pd.DataFrame, skip_keys: list = [], return_skipped: bool = False\n) -&gt; dict:\n    \"\"\"Coerce dictionary values to match the type of a dataframe columns matching dict keys.\n\n    Will also coerce a list of values.\n\n    Args:\n        d (dict): dictionary to coerce with singleton or list values\n        df (pd.DataFrame): dataframe to get types from\n        skip_keys: list of dict keys to skip. Defaults to []/\n        return_skipped: keep the uncoerced, skipped keys/vals in the resulting dict.\n            Defaults to False.\n\n    Returns:\n        dict: dict with coerced types\n    \"\"\"\n    coerced_dict = {}\n    for k, vals in d.items():\n        if k in skip_keys:\n            if return_skipped:\n                coerced_dict[k] = vals\n            continue\n        if k not in df.columns:\n            raise ValueError(f\"Key {k} not in dataframe columns.\")\n        if pd.api.types.infer_dtype(df[k]) == \"integer\":\n            if isinstance(vals, list):\n                coerced_v = [int(float(v)) for v in vals]\n            else:\n                coerced_v = int(float(vals))\n        elif pd.api.types.infer_dtype(df[k]) == \"floating\":\n            if isinstance(vals, list):\n                coerced_v = [float(v) for v in vals]\n            else:\n                coerced_v = float(vals)\n        elif pd.api.types.infer_dtype(df[k]) == \"boolean\":\n            if isinstance(vals, list):\n                coerced_v = [bool(v) for v in vals]\n            else:\n                coerced_v = bool(vals)\n        else:\n            if isinstance(vals, list):\n                coerced_v = [str(v) for v in vals]\n            else:\n                coerced_v = str(vals)\n        coerced_dict[k] = coerced_v\n    return coerced_dict\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_gdf","title":"<code>coerce_gdf(df, geometry=None, in_crs=LAT_LON_CRS)</code>","text":"<p>Coerce a DataFrame to a GeoDataFrame, optionally with a new geometry.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_gdf(\n    df: pd.DataFrame, geometry: GeoSeries = None, in_crs: int = LAT_LON_CRS\n) -&gt; GeoDataFrame:\n    \"\"\"Coerce a DataFrame to a GeoDataFrame, optionally with a new geometry.\"\"\"\n    if isinstance(df, GeoDataFrame):\n        if df.crs is None:\n            df.crs = in_crs\n        return df\n    p = None\n    if \"params\" in df.__dict__:\n        p = copy.deepcopy(df.params)\n\n    if \"geometry\" not in df and geometry is None:\n        raise ValueError(\"Must give geometry argument if don't have Geometry in dataframe\")\n\n    geometry = geometry if geometry is not None else df[\"geometry\"]\n    if not isinstance(geometry, GeoSeries):\n        try:\n            geometry = GeoSeries(geometry)\n        except:  # noqa: E722\n            geometry = geometry.apply(wkt.loads)\n    df = GeoDataFrame(df, geometry=geometry, crs=in_crs)\n\n    if p is not None:\n        # GeoPandas seems to lose parameters if we don't re-attach them.\n        df.__dict__[\"params\"] = p\n    return df\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_val_to_df_types","title":"<code>coerce_val_to_df_types(field, val, df)</code>","text":"<p>Coerce field value to match the type of a matching dataframe columns.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>field to lookup</p> required <code>val</code> <code>Union[str, int, float, bool, list[Union[str, int, float, bool]]]</code> <p>value or list of values to coerce</p> required <code>df</code> <code>DataFrame</code> <p>dataframe to get types from</p> required Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_val_to_df_types(\n    field: str,\n    val: Union[str, int, float, bool, list[Union[str, int, float, bool]]],\n    df: pd.DataFrame,\n) -&gt; dict:\n    \"\"\"Coerce field value to match the type of a matching dataframe columns.\n\n    Args:\n        field: field to lookup\n        val: value or list of values to coerce\n        df (pd.DataFrame): dataframe to get types from\n\n    Returns: coerced value or list of values\n    \"\"\"\n    if field not in df.columns:\n        raise ValueError(f\"Field {field} not in dataframe columns.\")\n    if pd.api.types.infer_dtype(df[field]) == \"integer\":\n        if isinstance(val, list):\n            return [int(float(v)) for v in val]\n        return int(float(val))\n    elif pd.api.types.infer_dtype(df[field]) == \"floating\":\n        if isinstance(val, list):\n            return [float(v) for v in val]\n        return float(val)\n    elif pd.api.types.infer_dtype(df[field]) == \"boolean\":\n        if isinstance(val, list):\n            return [bool(v) for v in val]\n        return bool(val)\n    else:\n        if isinstance(val, list):\n            return [str(v) for v in val]\n        return str(val)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_val_to_series_type","title":"<code>coerce_val_to_series_type(val, s)</code>","text":"<p>Coerces a value to match type of pandas series.</p> <p>Will try not to fail so if you give it a value that can\u2019t convert to a number, it will return a string.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <p>Any type of singleton value</p> required <code>s</code> <code>Series</code> <p>series to match the type to</p> required Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_val_to_series_type(val, s: pd.Series):\n    \"\"\"Coerces a value to match type of pandas series.\n\n    Will try not to fail so if you give it a value that can't convert to a number, it will\n    return a string.\n\n    Args:\n        val: Any type of singleton value\n        s (pd.Series): series to match the type to\n    \"\"\"\n    # WranglerLogger.debug(f\"Input val: {val} of type {type(val)} to match with series type \\\n    #    {pd.api.types.infer_dtype(s)}.\")\n    if pd.api.types.infer_dtype(s) in [\"integer\", \"floating\"]:\n        try:\n            v = float(val)\n        except:  # noqa: E722\n            v = str(val)\n    elif pd.api.types.infer_dtype(s) == \"boolean\":\n        v = bool(val)\n    else:\n        v = str(val)\n    # WranglerLogger.debug(f\"Return value: {v}\")\n    return v\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.compare_df_values","title":"<code>compare_df_values(df1, df2, join_col=None, ignore=[], atol=1e-05)</code>","text":"<p>Compare overlapping part of dataframes and returns where there are differences.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def compare_df_values(df1, df2, join_col: str = None, ignore: list[str] = [], atol=1e-5):\n    \"\"\"Compare overlapping part of dataframes and returns where there are differences.\"\"\"\n    comp_c = [\n        c\n        for c in df1.columns\n        if c in df2.columns and c not in ignore and not isinstance(df1[c], GeoSeries)\n    ]\n    if join_col is None:\n        comp_df = df1[comp_c].merge(\n            df2[comp_c],\n            how=\"inner\",\n            right_index=True,\n            left_index=True,\n            suffixes=[\"_a\", \"_b\"],\n        )\n    else:\n        comp_df = df1[comp_c].merge(df2[comp_c], how=\"inner\", on=join_col, suffixes=[\"_a\", \"_b\"])\n\n    # Filter columns by data type\n    numeric_cols = [col for col in comp_c if np.issubdtype(df1[col].dtype, np.number)]\n    ll_cols = list(set(list_like_columns(df1) + list_like_columns(df2)))\n    other_cols = [col for col in comp_c if col not in numeric_cols and col not in ll_cols]\n\n    # For numeric columns, use np.isclose\n    if numeric_cols:\n        numeric_a = comp_df[[f\"{col}_a\" for col in numeric_cols]]\n        numeric_b = comp_df[[f\"{col}_b\" for col in numeric_cols]]\n        is_close = np.isclose(numeric_a, numeric_b, atol=atol, equal_nan=True)\n        comp_df[numeric_cols] = ~is_close\n\n    if ll_cols:\n        for ll_c in ll_cols:\n            comp_df[ll_c] = diff_list_like_series(comp_df[ll_c + \"_a\"], comp_df[ll_c + \"_b\"])\n\n    # For non-numeric columns, use direct comparison\n    if other_cols:\n        for col in other_cols:\n            comp_df[col] = (comp_df[f\"{col}_a\"] != comp_df[f\"{col}_b\"]) &amp; ~(\n                comp_df[f\"{col}_a\"].isna() &amp; comp_df[f\"{col}_b\"].isna()\n            )\n\n    # Filter columns and rows where no differences\n    cols_w_diffs = [col for col in comp_c if comp_df[col].any()]\n    out_cols = [col for subcol in cols_w_diffs for col in (f\"{subcol}_a\", f\"{subcol}_b\", subcol)]\n    comp_df = comp_df[out_cols]\n    comp_df = comp_df.loc[comp_df[cols_w_diffs].any(axis=1)]\n\n    return comp_df\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.compare_lists","title":"<code>compare_lists(list1, list2)</code>","text":"<p>Compare two lists.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def compare_lists(list1, list2) -&gt; bool:\n    \"\"\"Compare two lists.\"\"\"\n    list1 = convert_numpy_to_list(list1)\n    list2 = convert_numpy_to_list(list1)\n    return list1 != list2\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.convert_numpy_to_list","title":"<code>convert_numpy_to_list(item)</code>","text":"<p>Function to recursively convert numpy arrays to lists.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def convert_numpy_to_list(item):\n    \"\"\"Function to recursively convert numpy arrays to lists.\"\"\"\n    if isinstance(item, np.ndarray):\n        return item.tolist()\n    elif isinstance(item, list):\n        return [convert_numpy_to_list(sub_item) for sub_item in item]\n    elif isinstance(item, dict):\n        return {key: convert_numpy_to_list(value) for key, value in item.items()}\n    return item\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.dict_fields_in_df","title":"<code>dict_fields_in_df(d, df)</code>","text":"<p>Check if all fields in dict are in dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def dict_fields_in_df(d: dict, df: pd.DataFrame) -&gt; bool:\n    \"\"\"Check if all fields in dict are in dataframe.\"\"\"\n    missing_fields = [f for f in d.keys() if f not in df.columns]\n    if missing_fields:\n        WranglerLogger.error(f\"Fields in dictionary missing from dataframe: {missing_fields}.\")\n        raise ValueError(f\"Fields in dictionary missing from dataframe: {missing_fields}.\")\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.dict_to_query","title":"<code>dict_to_query(selection_dict)</code>","text":"<p>Generates the query of from selection_dict.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>Mapping[str, Any]</code> <p>selection dictionary</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <code>str</code> <p>Query value</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def dict_to_query(\n    selection_dict: Mapping[str, Any],\n) -&gt; str:\n    \"\"\"Generates the query of from selection_dict.\n\n    Args:\n        selection_dict: selection dictionary\n\n    Returns:\n        _type_: Query value\n    \"\"\"\n    WranglerLogger.debug(\"Building selection query\")\n\n    def _kv_to_query_part(k, v, _q_part=\"\"):\n        if isinstance(v, list):\n            _q_part += \"(\" + \" or \".join([_kv_to_query_part(k, i) for i in v]) + \")\"\n            return _q_part\n        if isinstance(v, str):\n            return k + '.str.contains(\"' + v + '\")'\n        else:\n            return k + \"==\" + str(v)\n\n    query = \"(\" + \" and \".join([_kv_to_query_part(k, v) for k, v in selection_dict.items()]) + \")\"\n    WranglerLogger.debug(f\"Selection query: \\n{query}\")\n    return query\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.diff_dfs","title":"<code>diff_dfs(df1, df2, ignore=[])</code>","text":"<p>Returns True if two dataframes are different and log differences.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def diff_dfs(df1, df2, ignore: list[str] = []) -&gt; bool:\n    \"\"\"Returns True if two dataframes are different and log differences.\"\"\"\n    diff = False\n    if set(df1.columns) != set(df2.columns):\n        WranglerLogger.warning(\n            f\" Columns are different 1vs2 \\n    {set(df1.columns) ^ set(df2.columns)}\"\n        )\n        common_cols = [col for col in df1.columns if col in df2.columns]\n        df1 = df1[common_cols]\n        df2 = df2[common_cols]\n        diff = True\n\n    cols_to_compare = [col for col in df1.columns if col not in ignore]\n    df1 = df1[cols_to_compare]\n    df2 = df2[cols_to_compare]\n\n    if len(df1) != len(df2):\n        WranglerLogger.warning(\n            f\" Length is different /\" f\"DF1: {len(df1)} vs /\" f\"DF2: {len(df2)}\\n /\"\n        )\n        diff = True\n\n    diff_df = compare_df_values(df1, df2)\n\n    if not diff_df.empty:\n        WranglerLogger.error(f\"!!! Differences dfs: \\n{diff_df}\")\n        return True\n\n    if not diff:\n        WranglerLogger.info(\"...no differences in df found.\")\n    return diff\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.diff_list_like_series","title":"<code>diff_list_like_series(s1, s2)</code>","text":"<p>Compare two series that contain list-like items as strings.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def diff_list_like_series(s1, s2) -&gt; bool:\n    \"\"\"Compare two series that contain list-like items as strings.\"\"\"\n    diff_df = pd.concat([s1, s2], axis=1, keys=[\"s1\", \"s2\"])\n    # diff_df[\"diff\"] = diff_df.apply(lambda x: str(x[\"s1\"]) != str(x[\"s2\"]), axis=1)\n    diff_df[\"diff\"] = diff_df.apply(lambda x: compare_lists(x[\"s1\"], x[\"s2\"]), axis=1)\n    if diff_df[\"diff\"].any():\n        WranglerLogger.info(\"List-Like differences:\")\n        WranglerLogger.info(diff_df)\n        return True\n    return False\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.fk_in_pk","title":"<code>fk_in_pk(pk, fk, ignore_nan=True)</code>","text":"<p>Check if all foreign keys are in the primary keys, optionally ignoring NaN.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def fk_in_pk(\n    pk: Union[pd.Series, list], fk: Union[pd.Series, list], ignore_nan: bool = True\n) -&gt; Tuple[bool, list]:\n    \"\"\"Check if all foreign keys are in the primary keys, optionally ignoring NaN.\"\"\"\n    if isinstance(fk, list):\n        fk = pd.Series(fk)\n\n    if ignore_nan:\n        fk = fk.dropna()\n\n    missing_flag = ~fk.isin(pk)\n\n    if missing_flag.any():\n        WranglerLogger.warning(\n            f\"Following keys referenced in {fk.name} but missing in\\\n            primary key table: \\n{fk[missing_flag]} \"\n        )\n        return False, fk[missing_flag].tolist()\n\n    return True, []\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.list_like_columns","title":"<code>list_like_columns(df, item_type=None)</code>","text":"<p>Find columns in a dataframe that contain list-like items that can\u2019t be json-serialized.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>dataframe to check</p> required <code>item_type</code> <code>type</code> <p>if not None, will only return columns where all items are of this type by checking only the first item in the column.  Defaults to None.</p> <code>None</code> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def list_like_columns(df, item_type: type = None) -&gt; list[str]:\n    \"\"\"Find columns in a dataframe that contain list-like items that can't be json-serialized.\n\n    Args:\n        df: dataframe to check\n        item_type: if not None, will only return columns where all items are of this type by\n            checking **only** the first item in the column.  Defaults to None.\n    \"\"\"\n    list_like_columns = []\n\n    for column in df.columns:\n        if df[column].apply(lambda x: isinstance(x, (list, ndarray))).any():\n            if item_type is not None:\n                if not isinstance(df[column].iloc[0], item_type):\n                    continue\n            list_like_columns.append(column)\n    return list_like_columns\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.segment_data_by_selection","title":"<code>segment_data_by_selection(item_list, data, field=None, end_val=0)</code>","text":"<p>Segment a dataframe or series into before, middle, and end segments based on item_list.</p> <p>selected segment = everything from the first to last item in item_list inclusive of the first     and last items. Before segment = everything before After segment = everything after</p> <p>Parameters:</p> Name Type Description Default <code>item_list</code> <code>list</code> <p>List of items to segment data by. If longer than two, will only use the first and last items.</p> required <code>data</code> <code>Union[Series, DataFrame]</code> <p>Data to segment into before, middle, and after.</p> required <code>field</code> <code>str</code> <p>If a dataframe, specifies which field to reference. Defaults to None.</p> <code>None</code> <code>end_val</code> <code>int</code> <p>Notation for util the end or from the begining. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If item list isn\u2019t found in data in correct order.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[Union[Series, list, DataFrame]]</code> <p>data broken out by beofore, selected segment, and after.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def segment_data_by_selection(\n    item_list: list,\n    data: Union[list, pd.DataFrame, pd.Series],\n    field: str = None,\n    end_val=0,\n) -&gt; tuple[Union[pd.Series, list, pd.DataFrame]]:\n    \"\"\"Segment a dataframe or series into before, middle, and end segments based on item_list.\n\n    selected segment = everything from the first to last item in item_list inclusive of the first\n        and last items.\n    Before segment = everything before\n    After segment = everything after\n\n\n    Args:\n        item_list (list): List of items to segment data by. If longer than two, will only\n            use the first and last items.\n        data (Union[pd.Series, pd.DataFrame]): Data to segment into before, middle, and after.\n        field (str, optional): If a dataframe, specifies which field to reference.\n            Defaults to None.\n        end_val (int, optional): Notation for util the end or from the begining. Defaults to 0.\n\n    Raises:\n        ValueError: If item list isn't found in data in correct order.\n\n    Returns:\n        tuple: data broken out by beofore, selected segment, and after.\n    \"\"\"\n    ref_data = data\n    if isinstance(data, pd.DataFrame):\n        ref_data = data[field].tolist()\n    elif isinstance(data, pd.Series):\n        ref_data = data.tolist()\n\n    # ------- Replace \"to the end\" indicators with first or last value --------\n    start_item, end_item = item_list[0], item_list[-1]\n    if start_item == end_val:\n        start_item = ref_data[0]\n    if end_item == end_val:\n        end_item = ref_data[-1]\n\n    # --------Find the start and end indices -----------------------------------\n    start_idxs = list(set([i for i, item in enumerate(ref_data) if item == start_item]))\n    if not start_idxs:\n        raise ValueError(f\"Segment start item: {start_item} not in data.\")\n    if len(start_idxs) &gt; 1:\n        WranglerLogger.warning(\n            f\"Found multiple starting locations for data segment: {start_item}.\\\n                                Choosing first \u2013 largest segment being selected.\"\n        )\n    start_idx = min(start_idxs)\n\n    # find the end node starting from the start index.\n    end_idxs = [i + start_idx for i, item in enumerate(ref_data[start_idx:]) if item == end_item]\n    # WranglerLogger.debug(f\"End indexes: {end_idxs}\")\n    if not end_idxs:\n        raise ValueError(f\"Segment end item: {end_item} not in data after starting idx.\")\n    if len(end_idxs) &gt; 1:\n        WranglerLogger.warning(\n            f\"Found multiple ending locations for data segment: {end_item}.\\\n                                Choosing last \u2013 largest segment being selected.\"\n        )\n    end_idx = max(end_idxs) + 1\n    # WranglerLogger.debug(\n    # f\"Segmenting data fr {start_item} idx:{start_idx} to {end_item} idx:{end_idx}.\\n{ref_data}\")\n    # -------- Extract the segments --------------------------------------------\n    if isinstance(data, pd.DataFrame):\n        before_segment = data.iloc[:start_idx]\n        selected_segment = data.iloc[start_idx:end_idx]\n        after_segment = data.iloc[end_idx:]\n    else:\n        before_segment = data[:start_idx]\n        selected_segment = data[start_idx:end_idx]\n        after_segment = data[end_idx:]\n\n    if isinstance(data, pd.Series) or isinstance(data, pd.DataFrame):\n        before_segment = before_segment.reset_index(drop=True)\n        selected_segment = selected_segment.reset_index(drop=True)\n        after_segment = after_segment.reset_index(drop=True)\n\n    # WranglerLogger.debug(f\"Segmented data into before, selected, and after.\\n \\\n    #    Before:\\n{before_segment}\\nSelected:\\n{selected_segment}\\nAfter:\\n{after_segment}\")\n\n    return before_segment, selected_segment, after_segment\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.segment_data_by_selection_min_overlap","title":"<code>segment_data_by_selection_min_overlap(selection_list, data, field, replacements_list, end_val=0)</code>","text":"<p>Segments data based on item_list reducing overlap with replacement list.</p> <p>selected segment: everything from the first to last item in item_list inclusive of the first     and last items but not if first and last items overlap with replacement list. Before segment = everything before After segment = everything after</p> <p>Example: selection_list = [2,5] data = pd.DataFrame({\u201ci\u201d:[1,2,3,4,5,6]}) field = \u201ci\u201d replacements_list = [2,22,33]</p> <p>Returns:</p> Type Description <code>list</code> <p>[22,33]</p> <code>tuple[Union[Series, list, DataFrame]]</code> <p>[1], [2,3,4,5], [6]</p> <p>Parameters:</p> Name Type Description Default <code>selection_list</code> <code>list</code> <p>List of items to segment data by. If longer than two, will only use the first and last items.</p> required <code>data</code> <code>Union[Series, DataFrame]</code> <p>Data to segment into before, middle, and after.</p> required <code>field</code> <code>str</code> <p>Specifies which field to reference.</p> required <code>replacements_list</code> <code>list</code> <p>List of items to eventually replace the selected segment with.</p> required <code>end_val</code> <code>int</code> <p>Notation for util the end or from the begining. Defaults to 0.</p> <code>0</code> <p>tuple containing:</p> Type Description <code>list</code> <ul> <li>updated replacement_list</li> </ul> <code>tuple[Union[Series, list, DataFrame]]</code> <ul> <li>tuple of before, selected segment, and after data</li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def segment_data_by_selection_min_overlap(\n    selection_list: list,\n    data: pd.DataFrame,\n    field: str,\n    replacements_list: list,\n    end_val=0,\n) -&gt; tuple[list, tuple[Union[pd.Series, list, pd.DataFrame]]]:\n    \"\"\"Segments data based on item_list reducing overlap with replacement list.\n\n    *selected segment*: everything from the first to last item in item_list inclusive of the first\n        and last items but not if first and last items overlap with replacement list.\n    Before segment = everything before\n    After segment = everything after\n\n    Example:\n    selection_list = [2,5]\n    data = pd.DataFrame({\"i\":[1,2,3,4,5,6]})\n    field = \"i\"\n    replacements_list = [2,22,33]\n\n    returns:\n        [22,33]\n        [1], [2,3,4,5], [6]\n\n    Args:\n        selection_list (list): List of items to segment data by. If longer than two, will only\n            use the first and last items.\n        data (Union[pd.Series, pd.DataFrame]): Data to segment into before, middle, and after.\n        field (str): Specifies which field to reference.\n        replacements_list (list): List of items to eventually replace the selected segment with.\n        end_val (int, optional): Notation for util the end or from the begining. Defaults to 0.\n\n    Returns: tuple containing:\n        - updated replacement_list\n        - tuple of before, selected segment, and after data\n    \"\"\"\n    before_segment, segment_df, after_segment = segment_data_by_selection(\n        selection_list, data, field=field, end_val=end_val\n    )\n\n    if replacements_list[0] == segment_df[field].iat[0]:\n        # move first item from selected segment to the before_segment df\n        replacements_list = replacements_list[1:]\n        before_segment = pd.concat(\n            [before_segment, segment_df.iloc[:1]], ignore_index=True, sort=False\n        )\n        segment_df = segment_df.iloc[1:]\n        WranglerLogger.debug(f\"item start overlaps with replacement. Repl: {replacements_list}\")\n    if replacements_list and replacements_list[-1] == data[field].iat[-1]:\n        # move last item from selected segment to the after_segment df\n        replacements_list = replacements_list[:-1]\n        after_segment = pd.concat([data.iloc[-1:], after_segment], ignore_index=True, sort=False)\n        segment_df = segment_df.iloc[:-1]\n        WranglerLogger.debug(f\"item end overlaps with replacement. Repl: {replacements_list}\")\n\n    return replacements_list, (before_segment, segment_df, after_segment)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.update_df_by_col_value","title":"<code>update_df_by_col_value(destination_df, source_df, join_col, properties=None, fail_if_missing=True)</code>","text":"<p>Updates destination_df with ALL values in source_df for specified props with same join_col.</p> <p>Source_df can contain a subset of IDs of destination_df. If fail_if_missing is true, destination_df must have all the IDS in source DF - ensuring all source_df values are contained in resulting df.</p> <pre><code>&gt;&gt; destination_df\ntrip_id  property1  property2\n1         10      100\n2         20      200\n3         30      300\n4         40      400\n\n&gt;&gt; source_df\ntrip_id  property1  property2\n2         25      250\n3         35      350\n\n&gt;&gt; updated_df\ntrip_id  property1  property2\n0        1       10      100\n1        2       25      250\n2        3       35      350\n3        4       40      400\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>destination_df</code> <code>DataFrame</code> <p>Dataframe to modify.</p> required <code>source_df</code> <code>DataFrame</code> <p>Dataframe with updated columns</p> required <code>join_col</code> <code>str</code> <p>column to join on</p> required <code>properties</code> <code>list[str]</code> <p>List of properties to use. If None, will default to all in source_df.</p> <code>None</code> <code>fail_if_missing</code> <code>bool</code> <p>If True, will raise an error if there are missing IDs in destination_df that exist in source_df.</p> <code>True</code> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def update_df_by_col_value(\n    destination_df: pd.DataFrame,\n    source_df: pd.DataFrame,\n    join_col: str,\n    properties: list[str] = None,\n    fail_if_missing: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Updates destination_df with ALL values in source_df for specified props with same join_col.\n\n    Source_df can contain a subset of IDs of destination_df.\n    If fail_if_missing is true, destination_df must have all\n    the IDS in source DF - ensuring all source_df values are contained in resulting df.\n\n    ```\n    &gt;&gt; destination_df\n    trip_id  property1  property2\n    1         10      100\n    2         20      200\n    3         30      300\n    4         40      400\n\n    &gt;&gt; source_df\n    trip_id  property1  property2\n    2         25      250\n    3         35      350\n\n    &gt;&gt; updated_df\n    trip_id  property1  property2\n    0        1       10      100\n    1        2       25      250\n    2        3       35      350\n    3        4       40      400\n    ```\n\n    Args:\n        destination_df (pd.DataFrame): Dataframe to modify.\n        source_df (pd.DataFrame): Dataframe with updated columns\n        join_col (str): column to join on\n        properties (list[str]): List of properties to use. If None, will default to all\n            in source_df.\n        fail_if_missing (bool): If True, will raise an error if there are missing IDs in\n            destination_df that exist in source_df.\n    \"\"\"\n    # 1. Identify which properties should be updated; and if they exist in both DFs.\n    if properties is None:\n        properties = [\n            c for c in source_df.columns if c in destination_df.columns and c != join_col\n        ]\n    else:\n        _dest_miss = _df_missing_cols(destination_df, properties + [join_col])\n        if _dest_miss:\n            raise MissingPropertiesError(f\"Properties missing from destination_df: {_dest_miss}\")\n        _source_miss = _df_missing_cols(source_df, properties + [join_col])\n        if _source_miss:\n            raise MissingPropertiesError(f\"Properties missing from source_df: {_source_miss}\")\n\n    # 2. Identify if there are IDs missing from destination_df that exist in source_df\n    if fail_if_missing:\n        missing_ids = set(source_df[join_col]) - set(destination_df[join_col])\n        if missing_ids:\n            raise InvalidJoinFieldError(f\"IDs missing from source_df: \\n{missing_ids}\")\n\n    WranglerLogger.debug(f\"Updating properties for {len(source_df)} records: {properties}.\")\n\n    if not source_df[join_col].is_unique:\n        raise InvalidJoinFieldError(\n            \"Can't join from source_df when join_col: {join_col} is not unique.\"\n        )\n\n    if not destination_df[join_col].is_unique:\n        return _update_props_from_one_to_many(destination_df, source_df, join_col, properties)\n\n    return _update_props_for_common_idx(destination_df, source_df, join_col, properties)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.validate_existing_value_in_df","title":"<code>validate_existing_value_in_df(df, idx, field, expected_value)</code>","text":"<p>Validate if df[field]==expected_value for all indices in idx.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def validate_existing_value_in_df(df: pd.DataFrame, idx: list[int], field: str, expected_value):\n    \"\"\"Validate if df[field]==expected_value for all indices in idx.\"\"\"\n    if field not in df.columns:\n        WranglerLogger.warning(f\"!! {field} Not an existing field.\")\n        return False\n    if not df.loc[idx, field].eq(expected_value).all():\n        WranglerLogger.warning(\n            f\"Existing value defined for {field} in project card \\\n            does not match the value in the selection links. \\n\\\n            Specified Existing: {expected_value}\\n\\\n            Actual Existing: \\n {df.loc[idx, field]}.\"\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.InvalidCRSError","title":"<code>InvalidCRSError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a point is not valid for a given coordinate reference system.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>class InvalidCRSError(Exception):\n    \"\"\"Raised when a point is not valid for a given coordinate reference system.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.MissingNodesError","title":"<code>MissingNodesError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when referenced nodes are missing from the network.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>class MissingNodesError(Exception):\n    \"\"\"Raised when referenced nodes are missing from the network.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.check_point_valid_for_crs","title":"<code>check_point_valid_for_crs(point, crs)</code>","text":"<p>Check if a point is valid for a given coordinate reference system.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>Point</code> <p>Shapely Point</p> required <code>crs</code> <code>int</code> <p>coordinate reference system in ESPG code</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def check_point_valid_for_crs(point: Point, crs: int):\n    \"\"\"Check if a point is valid for a given coordinate reference system.\n\n    Args:\n        point: Shapely Point\n        crs: coordinate reference system in ESPG code\n\n    raises: InvalidCRSError if point is not valid for the given crs\n    \"\"\"\n    crs = CRS.from_user_input(crs)\n    minx, miny, maxx, maxy = crs.area_of_use.bounds\n    ok_bounds = True\n    if not minx &lt;= point.x &lt;= maxx:\n        WranglerLogger.error(f\"Invalid X coordinate for CRS {crs}: {point.x}\")\n        ok_bounds = False\n    if not miny &lt;= point.y &lt;= maxy:\n        WranglerLogger.error(f\"Invalid Y coordinate for CRS {crs}: {point.y}\")\n        ok_bounds = False\n\n    if not ok_bounds:\n        raise InvalidCRSError(f\"Invalid coordinate for CRS {crs}: {point.x}, {point.y}\")\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.get_bearing","title":"<code>get_bearing(lat1, lon1, lat2, lon2)</code>","text":"<p>Calculate the bearing (forward azimuth) b/w the two points.</p> <p>returns: bearing in radians</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_bearing(lat1, lon1, lat2, lon2):\n    \"\"\"Calculate the bearing (forward azimuth) b/w the two points.\n\n    returns: bearing in radians\n    \"\"\"\n    # bearing in degrees\n    brng = Geodesic.WGS84.Inverse(lat1, lon1, lat2, lon2)[\"azi1\"]\n\n    # convert bearing to radians\n    brng = math.radians(brng)\n\n    return brng\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.get_bounding_polygon","title":"<code>get_bounding_polygon(boundary_geocode=None, boundary_file=None, boundary_gdf=None, crs=LAT_LON_CRS)</code>","text":"<p>Get the bounding polygon for a given boundary.</p> <p>Will return None if no arguments given. Will raise a ValueError if more than one given.</p> <p>This function retrieves the bounding polygon for a given boundary. The boundary can be provided as a GeoDataFrame, a geocode string or dictionary, or a boundary file. The resulting polygon geometry is returned as a GeoSeries.</p> <p>Parameters:</p> Name Type Description Default <code>boundary_geocode</code> <code>Union[str, dict]</code> <p>A geocode string or dictionary representing the boundary. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Union[str, Path]</code> <p>A path to the boundary file. Only used if boundary_geocode is None. Defaults to None.</p> <code>None</code> <code>boundary_gdf</code> <code>GeoDataFrame</code> <p>A GeoDataFrame representing the boundary. Only used if boundary_geocode and boundary_file are None. Defaults to None.</p> <code>None</code> <code>crs</code> <code>int</code> <p>The coordinate reference system (CRS) code. Defaults to 4326 (WGS84).</p> <code>LAT_LON_CRS</code> <p>Returns:</p> Type Description <code>Union[None, GeoSeries]</code> <p>gpd.GeoSeries: The polygon geometry representing the bounding polygon.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_bounding_polygon(\n    boundary_geocode: Optional[Union[str, dict]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    crs: int = LAT_LON_CRS,  # WGS84\n) -&gt; Union[None, gpd.GeoSeries]:\n    \"\"\"Get the bounding polygon for a given boundary.\n\n    Will return None if no arguments given. Will raise a ValueError if more than one given.\n\n    This function retrieves the bounding polygon for a given boundary. The boundary can be provided\n    as a GeoDataFrame, a geocode string or dictionary, or a boundary file. The resulting polygon\n    geometry is returned as a GeoSeries.\n\n    Args:\n        boundary_geocode (Union[str, dict], optional): A geocode string or dictionary\n            representing the boundary. Defaults to None.\n        boundary_file (Union[str, Path], optional): A path to the boundary file. Only used if\n            boundary_geocode is None. Defaults to None.\n        boundary_gdf (gpd.GeoDataFrame, optional): A GeoDataFrame representing the boundary.\n            Only used if boundary_geocode and boundary_file are None. Defaults to None.\n        crs (int, optional): The coordinate reference system (CRS) code. Defaults to 4326 (WGS84).\n\n    Returns:\n        gpd.GeoSeries: The polygon geometry representing the bounding polygon.\n    \"\"\"\n    import osmnx as ox\n\n    nargs = sum(x is not None for x in [boundary_gdf, boundary_geocode, boundary_file])\n    if nargs == 0:\n        return None\n    if nargs != 1:\n        raise ValueError(\n            \"Exacly one of boundary_gdf, boundary_geocode, or boundary_shp must \\\n                         be provided\"\n        )\n\n    OK_BOUNDARY_SUFF = [\".shp\", \".geojson\", \".parquet\"]\n\n    if boundary_geocode is not None:\n        boundary_gdf = ox.geocode_to_gdf(boundary_geocode)\n    if boundary_file is not None:\n        boundary_file = Path(boundary_file)\n        if boundary_file.suffix not in OK_BOUNDARY_SUFF:\n            raise ValueError(\n                f\"Boundary file must have one of the following suffixes: {OK_BOUNDARY_SUFF}\"\n            )\n        if not boundary_file.exists():\n            raise FileNotFoundError(f\"Boundary file {boundary_file} does not exist\")\n        if boundary_file.suffix == \".parquet\":\n            boundary_gdf = gpd.read_parquet(boundary_file)\n        else:\n            boundary_gdf = gpd.read_file(boundary_file)\n            if boundary_file.suffix == \".geojson\":  # geojson standard is WGS84\n                boundary_gdf.crs = crs\n\n    if boundary_gdf.crs is not None:\n        boundary_gdf = boundary_gdf.to_crs(crs)\n    # make sure boundary_gdf is a polygon\n    if len(boundary_gdf.geom_type[boundary_gdf.geom_type != \"Polygon\"]) &gt; 0:\n        raise ValueError(\"boundary_gdf must all be Polygons\")\n    # get the boundary as a single polygon\n    boundary_gs = gpd.GeoSeries([boundary_gdf.geometry.unary_union], crs=crs)\n\n    return boundary_gs\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.get_point_geometry_from_linestring","title":"<code>get_point_geometry_from_linestring(polyline_geometry, pos=0)</code>","text":"<p>Get a point geometry from a linestring geometry.</p> <p>Parameters:</p> Name Type Description Default <code>polyline_geometry</code> <p>shapely LineString instance</p> required <code>pos</code> <code>int</code> <p>position in the linestring to get the point from. Defaults to 0.</p> <code>0</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_point_geometry_from_linestring(polyline_geometry, pos: int = 0):\n    \"\"\"Get a point geometry from a linestring geometry.\n\n    Args:\n        polyline_geometry: shapely LineString instance\n        pos: position in the linestring to get the point from. Defaults to 0.\n    \"\"\"\n    # WranglerLogger.debug(\n    #    f\"get_point_geometry_from_linestring.polyline_geometry.coords[0]: \\\n    #    {polyline_geometry.coords[0]}.\"\n    # )\n\n    # Note: when upgrading to shapely 2.0, will need to use following command\n    # _point_coords = get_coordinates(polyline_geometry).tolist()[pos]\n    return point_from_xy(*polyline_geometry.coords[pos])\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.length_of_linestring_miles","title":"<code>length_of_linestring_miles(gdf)</code>","text":"<p>Returns a Series with the linestring length in miles.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>Union[GeoSeries, GeoDataFrame]</code> <p>GeoDataFrame with linestring geometry.  If given a GeoSeries will attempt to convert to a GeoDataFrame.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def length_of_linestring_miles(gdf: Union[gpd.GeoSeries, gpd.GeoDataFrame]) -&gt; pd.Series:\n    \"\"\"Returns a Series with the linestring length in miles.\n\n    Args:\n        gdf: GeoDataFrame with linestring geometry.  If given a GeoSeries will attempt to convert\n            to a GeoDataFrame.\n    \"\"\"\n    # WranglerLogger.debug(f\"length_of_linestring_miles.gdf input:\\n{gdf}.\")\n    if isinstance(gdf, gpd.GeoSeries):\n        gdf = gpd.GeoDataFrame(geometry=gdf)\n\n    p_crs = gdf.estimate_utm_crs()\n    gdf = gdf.to_crs(p_crs)\n    METERS_IN_MILES = 1609.34\n    length_miles = gdf.geometry.length / METERS_IN_MILES\n    length_s = pd.Series(length_miles, index=gdf.index)\n\n    return length_s\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.linestring_from_lats_lons","title":"<code>linestring_from_lats_lons(df, lat_fields, lon_fields)</code>","text":"<p>Create a LineString geometry from a DataFrame with lon/lat fields.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>DataFrame with columns for lon/lat fields.</p> required <code>lat_fields</code> <p>list of column names for the lat fields.</p> required <code>lon_fields</code> <p>list of column names for the lon fields.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def linestring_from_lats_lons(df, lat_fields, lon_fields) -&gt; gpd.GeoSeries:\n    \"\"\"Create a LineString geometry from a DataFrame with lon/lat fields.\n\n    Args:\n        df: DataFrame with columns for lon/lat fields.\n        lat_fields: list of column names for the lat fields.\n        lon_fields: list of column names for the lon fields.\n    \"\"\"\n    if len(lon_fields) != len(lat_fields):\n        raise ValueError(\"lon_fields and lat_fields lists must have the same length\")\n\n    line_geometries = gpd.GeoSeries(\n        [\n            LineString([(row[lon], row[lat]) for lon, lat in zip(lon_fields, lat_fields)])\n            for _, row in df.iterrows()\n        ]\n    )\n\n    return gpd.GeoSeries(line_geometries)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.linestring_from_nodes","title":"<code>linestring_from_nodes(links_df, nodes_df, from_node='A', to_node='B', node_pk='model_node_id')</code>","text":"<p>Creates a LineString geometry GeoSeries from a DataFrame of links and a DataFrame of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>DataFrame</code> <p>DataFrame with columns for from_node and to_node.</p> required <code>nodes_df</code> <code>GeoDataFrame</code> <p>GeoDataFrame with geometry column.</p> required <code>from_node</code> <code>str</code> <p>column name in links_df for the from node. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_node</code> <code>str</code> <p>column name in links_df for the to node. Defaults to \u201cB\u201d.</p> <code>'B'</code> <code>node_pk</code> <code>str</code> <p>primary key column name in nodes_df. Defaults to \u201cmodel_node_id\u201d.</p> <code>'model_node_id'</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def linestring_from_nodes(\n    links_df: pd.DataFrame,\n    nodes_df: gpd.GeoDataFrame,\n    from_node: str = \"A\",\n    to_node: str = \"B\",\n    node_pk: str = \"model_node_id\",\n) -&gt; gpd.GeoSeries:\n    \"\"\"Creates a LineString geometry GeoSeries from a DataFrame of links and a DataFrame of nodes.\n\n    Args:\n        links_df: DataFrame with columns for from_node and to_node.\n        nodes_df: GeoDataFrame with geometry column.\n        from_node: column name in links_df for the from node. Defaults to \"A\".\n        to_node: column name in links_df for the to node. Defaults to \"B\".\n        node_pk: primary key column name in nodes_df. Defaults to \"model_node_id\".\n    \"\"\"\n    assert \"geometry\" in nodes_df.columns, \"nodes_df must have a 'geometry' column\"\n\n    idx_name = \"index\" if links_df.index.name is None else links_df.index.name\n    # WranglerLogger.debug(f\"Index name: {idx_name}\")\n    required_link_cols = [from_node, to_node]\n\n    if not all([col in links_df.columns for col in required_link_cols]):\n        WranglerLogger.error(\n            f\"links_df.columns missing required columns.\\n\\\n                            links_df.columns: {links_df.columns}\\n\\\n                            required_link_cols: {required_link_cols}\"\n        )\n        raise ValueError(\n            f\"links_df must have columns {required_link_cols} to create linestring from nodes\"\n        )\n\n    links_geo_df = copy.deepcopy(links_df[required_link_cols])\n    # need to continuously reset the index to make sure the index is the same as the link index\n    links_geo_df = (\n        links_geo_df.reset_index()\n        .merge(\n            nodes_df[[node_pk, \"geometry\"]],\n            left_on=from_node,\n            right_on=node_pk,\n            how=\"left\",\n        )\n        .set_index(idx_name)\n    )\n\n    links_geo_df = links_geo_df.rename(columns={\"geometry\": \"geometry_A\"})\n\n    links_geo_df = (\n        links_geo_df.reset_index()\n        .merge(\n            nodes_df[[node_pk, \"geometry\"]],\n            left_on=to_node,\n            right_on=node_pk,\n            how=\"left\",\n        )\n        .set_index(idx_name)\n    )\n\n    links_geo_df = links_geo_df.rename(columns={\"geometry\": \"geometry_B\"})\n\n    # makes sure all nodes exist\n    _missing_geo_links_df = links_geo_df[\n        links_geo_df[\"geometry_A\"].isnull() | links_geo_df[\"geometry_B\"].isnull()\n    ]\n    if not _missing_geo_links_df.empty:\n        missing_nodes = _missing_geo_links_df[[from_node, to_node]].values\n        WranglerLogger.error(\n            f\"Cannot create link geometry from nodes because the nodes are\\\n                             missing from the network. Missing nodes: {missing_nodes}\"\n        )\n        raise MissingNodesError(\"Specified from/to nodes are missing in nodes_df\")\n\n    # create geometry from points\n    links_geo_df[\"geometry\"] = links_geo_df.apply(\n        lambda row: LineString([row[\"geometry_A\"], row[\"geometry_B\"]]), axis=1\n    )\n\n    # convert to GeoDataFrame\n    links_gdf = gpd.GeoDataFrame(links_geo_df[\"geometry\"], geometry=links_geo_df[\"geometry\"])\n    return links_gdf[\"geometry\"]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.location_ref_from_point","title":"<code>location_ref_from_point(geometry, sequence=1, bearing=None, distance_to_next_ref=None)</code>","text":"<p>Generates a shared street point location reference.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Point</code> <p>Point shapely geometry</p> required <code>sequence</code> <code>int</code> <p>Sequence if part of polyline. Defaults to None.</p> <code>1</code> <code>bearing</code> <code>float</code> <p>Direction of line if part of polyline. Defaults to None.</p> <code>None</code> <code>distance_to_next_ref</code> <code>float</code> <p>Distnce to next point if part of polyline. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LocationReference</code> <code>LocationReference</code> <p>As defined by sharedStreets.io schema</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def location_ref_from_point(\n    geometry: Point,\n    sequence: int = 1,\n    bearing: float = None,\n    distance_to_next_ref: float = None,\n) -&gt; LocationReference:\n    \"\"\"Generates a shared street point location reference.\n\n    Args:\n        geometry (Point): Point shapely geometry\n        sequence (int, optional): Sequence if part of polyline. Defaults to None.\n        bearing (float, optional): Direction of line if part of polyline. Defaults to None.\n        distance_to_next_ref (float, optional): Distnce to next point if part of polyline.\n            Defaults to None.\n\n    Returns:\n        LocationReference: As defined by sharedStreets.io schema\n    \"\"\"\n    lr = {\n        \"point\": LatLongCoordinates(geometry.coords[0]),\n    }\n\n    for arg in [\"sequence\", \"bearing\", \"distance_to_next_ref\"]:\n        if locals()[arg] is not None:\n            lr[arg] = locals()[arg]\n\n    return LocationReference(**lr)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.location_refs_from_linestring","title":"<code>location_refs_from_linestring(geometry)</code>","text":"<p>Generates a shared street location reference from linestring.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>LineString</code> <p>Shapely LineString instance</p> required <p>Returns:</p> Name Type Description <code>LocationReferences</code> <code>List[LocationReference]</code> <p>As defined by sharedStreets.io schema</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def location_refs_from_linestring(geometry: LineString) -&gt; List[LocationReference]:\n    \"\"\"Generates a shared street location reference from linestring.\n\n    Args:\n        geometry (LineString): Shapely LineString instance\n\n    Returns:\n        LocationReferences: As defined by sharedStreets.io schema\n    \"\"\"\n    return [\n        location_ref_from_point(\n            point,\n            sequence=i + 1,\n            distance_to_next_ref=point.distance(geometry.coords[i + 1]),\n            bearing=get_bearing(*point.coords[0], *geometry.coords[i + 1]),\n        )\n        for i, point in enumerate(geometry.coords[:-1])\n    ]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.offset_geometry_meters","title":"<code>offset_geometry_meters(geo_s, offset_distance_meters)</code>","text":"<p>Offset a GeoSeries of LineStrings by a given distance in meters.</p> <p>Parameters:</p> Name Type Description Default <code>geo_s</code> <code>GeoSeries</code> <p>GeoSeries of LineStrings to offset.</p> required <code>offset_distance_meters</code> <code>float</code> <p>distance in meters to offset the LineStrings.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def offset_geometry_meters(geo_s: gpd.GeoSeries, offset_distance_meters: float) -&gt; gpd.GeoSeries:\n    \"\"\"Offset a GeoSeries of LineStrings by a given distance in meters.\n\n    Args:\n        geo_s: GeoSeries of LineStrings to offset.\n        offset_distance_meters: distance in meters to offset the LineStrings.\n    \"\"\"\n    og_crs = geo_s.crs\n    geo_s.to_crs(METERS_CRS)\n    offset_geo = geo_s.apply(lambda x: x.offset_curve(offset_distance_meters))\n    offset_geo = gpd.GeoSeries(offset_geo)\n    return offset_geo.to_crs(og_crs)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.offset_point_with_distance_and_bearing","title":"<code>offset_point_with_distance_and_bearing(lon, lat, distance, bearing)</code>","text":"<p>Get the new lon-lat (in degrees) given current point (lon-lat), distance and bearing.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float</code> <p>longitude of original point</p> required <code>lat</code> <code>float</code> <p>latitude of original point</p> required <code>distance</code> <code>float</code> <p>distance in meters to offset point by</p> required <code>bearing</code> <code>float</code> <p>direction to offset point to in radians</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def offset_point_with_distance_and_bearing(\n    lon: float, lat: float, distance: float, bearing: float\n) -&gt; List[float]:\n    \"\"\"Get the new lon-lat (in degrees) given current point (lon-lat), distance and bearing.\n\n    Args:\n        lon: longitude of original point\n        lat: latitude of original point\n        distance: distance in meters to offset point by\n        bearing: direction to offset point to in radians\n\n    returns: list of new offset lon-lat\n    \"\"\"\n    # Earth's radius in meters\n    radius = 6378137\n\n    # convert the lat long from degree to radians\n    lat_radians = math.radians(lat)\n    lon_radians = math.radians(lon)\n\n    # calculate the new lat long in radians\n    out_lat_radians = math.asin(\n        math.sin(lat_radians) * math.cos(distance / radius)\n        + math.cos(lat_radians) * math.sin(distance / radius) * math.cos(bearing)\n    )\n\n    out_lon_radians = lon_radians + math.atan2(\n        math.sin(bearing) * math.sin(distance / radius) * math.cos(lat_radians),\n        math.cos(distance / radius) - math.sin(lat_radians) * math.sin(lat_radians),\n    )\n    # convert the new lat long back to degree\n    out_lat = math.degrees(out_lat_radians)\n    out_lon = math.degrees(out_lon_radians)\n\n    return [out_lon, out_lat]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.point_from_xy","title":"<code>point_from_xy(x, y, xy_crs=LAT_LON_CRS, point_crs=LAT_LON_CRS)</code>","text":"<p>Creates point geometry from x and y coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>x coordinate, in xy_crs</p> required <code>y</code> <p>y coordinate, in xy_crs</p> required <code>xy_crs</code> <code>int</code> <p>coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)</p> <code>LAT_LON_CRS</code> <code>point_crs</code> <code>int</code> <p>coordinate reference system in ESPG code for point output. Defaults to 4326 (WGS84)</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def point_from_xy(x, y, xy_crs: int = LAT_LON_CRS, point_crs: int = LAT_LON_CRS):\n    \"\"\"Creates point geometry from x and y coordinates.\n\n    Args:\n        x: x coordinate, in xy_crs\n        y: y coordinate, in xy_crs\n        xy_crs: coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)\n        point_crs: coordinate reference system in ESPG code for point output.\n            Defaults to 4326 (WGS84)\n\n    Returns: Shapely Point in point_crs\n    \"\"\"\n    point = Point(x, y)\n\n    if xy_crs == point_crs:\n        check_point_valid_for_crs(point, point_crs)\n        return point\n\n    if (xy_crs, point_crs) not in transformers:\n        # store transformers in dictionary because they are an \"expensive\" operation\n        transformers[(xy_crs, point_crs)] = Transformer.from_proj(\n            Proj(init=\"epsg:\" + str(xy_crs)),\n            Proj(init=\"epsg:\" + str(point_crs)),\n            always_xy=True,  # required b/c Proj v6+ uses lon/lat instead of x/y\n        )\n\n    return transform(transformers[(xy_crs, point_crs)].transform, point)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.to_points_gdf","title":"<code>to_points_gdf(table, ref_nodes_df=None, ref_road_net=None)</code>","text":"<p>Convert a table to a GeoDataFrame.</p> <p>If the table is already a GeoDataFrame, return it as is. Otherwise, attempt to convert the table to a GeoDataFrame using the following methods: 1. If the table has a \u2018geometry\u2019 column, return a GeoDataFrame using that column. 2. If the table has \u2018lat\u2019 and \u2018lon\u2019 columns, return a GeoDataFrame using those columns. 3. If the table has a \u2018*model_node_id\u2019 or \u2018stop_id\u2019 column, return a GeoDataFrame using that column and the      nodes_df provided. If none of the above, raise a ValueError.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DataFrame</code> <p>DataFrame to convert to GeoDataFrame.</p> required <code>ref_nodes_df</code> <code>GeoDataFrame</code> <p>GeoDataFrame of nodes to use to convert model_node_id to geometry.</p> <code>None</code> <code>ref_road_net</code> <code>'RoadwayNetwork'</code> <p>RoadwayNetwork object to use to convert model_node_id to geometry.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GeoDataFrame</code> <code>GeoDataFrame</code> <p>GeoDataFrame representation of the table.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def to_points_gdf(\n    table: pd.DataFrame,\n    ref_nodes_df: gpd.GeoDataFrame = None,\n    ref_road_net: \"RoadwayNetwork\" = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Convert a table to a GeoDataFrame.\n\n    If the table is already a GeoDataFrame, return it as is. Otherwise, attempt to convert the\n    table to a GeoDataFrame using the following methods:\n    1. If the table has a 'geometry' column, return a GeoDataFrame using that column.\n    2. If the table has 'lat' and 'lon' columns, return a GeoDataFrame using those columns.\n    3. If the table has a '*model_node_id' or 'stop_id' column, return a GeoDataFrame using that column and the\n         nodes_df provided.\n    If none of the above, raise a ValueError.\n\n    Args:\n        table: DataFrame to convert to GeoDataFrame.\n        ref_nodes_df: GeoDataFrame of nodes to use to convert model_node_id to geometry.\n        ref_road_net: RoadwayNetwork object to use to convert model_node_id to geometry.\n\n    Returns:\n        GeoDataFrame: GeoDataFrame representation of the table.\n    \"\"\"\n    if table is gpd.GeoDataFrame:\n        return table\n\n    WranglerLogger.debug(\"Converting GTFS table to GeoDataFrame\")\n    if \"geometry\" in table.columns:\n        return gpd.GeoDataFrame(table, geometry=\"geometry\")\n\n    lat_cols = list(filter(lambda col: \"lat\" in col, table.columns))\n    lon_cols = list(filter(lambda col: \"lon\" in col, table.columns))\n    model_node_id_cols = [\n        c for c in [\"model_node_id\", \"stop_id\", \"shape_model_node_id\"] if c in table.columns\n    ]\n\n    if not (lat_cols and lon_cols) or not model_node_id_cols:\n        WranglerLogger.error(\n            \"Needed either lat/long or *model_node_id columns to convert \\\n            to GeoDataFrame. Columns found: {table.columns}\"\n        )\n        if not (lat_cols and lon_cols):\n            WranglerLogger.error(\"No lat/long cols found.\")\n        if not model_node_id_cols:\n            WranglerLogger.error(\"No *model_node_id cols found.\")\n        raise ValueError(\n            \"Could not find lat/long, geometry columns or *model_node_id column in \\\n                         table necessary to convert to GeoDataFrame\"\n        )\n\n    if lat_cols and lon_cols:\n        # using first found lat and lon columns\n        return gpd.GeoDataFrame(\n            table,\n            geometry=gpd.points_from_xy(table[lon_cols[0]], table[lat_cols[0]]),\n            crs=\"EPSG:4326\",\n        )\n\n    if model_node_id_cols:\n        node_id_col = model_node_id_cols[0]\n\n        if ref_nodes_df is None:\n            if ref_road_net is None:\n                raise ValueError(\n                    \"Must provide either nodes_df or road_net to convert \\\n                                 model_node_id to geometry\"\n                )\n            ref_nodes_df = ref_road_net.nodes_df\n\n        WranglerLogger.debug(\"Converting table to GeoDataFrame using model_node_id\")\n\n        _table = table.merge(\n            ref_nodes_df[[\"model_node_id\", \"geometry\"]],\n            left_on=node_id_col,\n            right_on=\"model_node_id\",\n        )\n        return gpd.GeoDataFrame(_table, geometry=\"geometry\")\n\n    raise ValueError(\n        \"Could not find lat/long, geometry columns or *model_node_id column in table \\\n                     necessary to convert to GeoDataFrame\"\n    )\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.update_nodes_in_linestring_geometry","title":"<code>update_nodes_in_linestring_geometry(original_df, updated_nodes_df, position)</code>","text":"<p>Updates the nodes in a linestring geometry and returns updated geometry.</p> <p>Parameters:</p> Name Type Description Default <code>original_df</code> <code>GeoDataFrame</code> <p>GeoDataFrame with the <code>model_node_id</code> and linestring geometry</p> required <code>updated_nodes_df</code> <code>GeoDataFrame</code> <p>GeoDataFrame with updated node geometries.</p> required <code>position</code> <code>int</code> <p>position in the linestring to update with the node.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_nodes_in_linestring_geometry(\n    original_df: gpd.GeoDataFrame,\n    updated_nodes_df: gpd.GeoDataFrame,\n    position: int,\n) -&gt; gpd.GeoSeries:\n    \"\"\"Updates the nodes in a linestring geometry and returns updated geometry.\n\n    Args:\n        original_df: GeoDataFrame with the `model_node_id` and linestring geometry\n        updated_nodes_df: GeoDataFrame with updated node geometries.\n        position: position in the linestring to update with the node.\n    \"\"\"\n    LINK_FK_NODE = [\"A\", \"B\"]\n    original_index = original_df.index\n\n    updated_df = original_df.reset_index().merge(\n        updated_nodes_df[[\"model_node_id\", \"geometry\"]],\n        left_on=LINK_FK_NODE[position],\n        right_on=\"model_node_id\",\n        suffixes=(\"\", \"_node\"),\n    )\n\n    updated_df[\"geometry\"] = updated_df.apply(\n        lambda row: update_points_in_linestring(\n            row[\"geometry\"], row[\"geometry_node\"].coords[0], position\n        ),\n        axis=1,\n    )\n\n    updated_df = updated_df.reset_index().set_index(original_index.names)\n\n    WranglerLogger.debug(f\"updated_df - AFTER: \\n {updated_df.geometry}\")\n    return updated_df[\"geometry\"]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.update_point_geometry","title":"<code>update_point_geometry(df, ref_point_df, lon_field='X', lat_field='Y', id_field='model_node_id', ref_lon_field='X', ref_lat_field='Y', ref_id_field='model_node_id')</code>","text":"<p>Returns copy of df with lat and long fields updated with geometry from ref_point_df.</p> <p>NOTE: does not update \u201cgeometry\u201d field if it exists.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_point_geometry(\n    df: pd.DataFrame,\n    ref_point_df: pd.DataFrame,\n    lon_field: str = \"X\",\n    lat_field: str = \"Y\",\n    id_field: str = \"model_node_id\",\n    ref_lon_field: str = \"X\",\n    ref_lat_field: str = \"Y\",\n    ref_id_field: str = \"model_node_id\",\n) -&gt; pd.DataFrame:\n    \"\"\"Returns copy of df with lat and long fields updated with geometry from ref_point_df.\n\n    NOTE: does not update \"geometry\" field if it exists.\n    \"\"\"\n    df = copy.deepcopy(df)\n\n    ref_df = ref_point_df.rename(\n        columns={\n            ref_lon_field: lon_field,\n            ref_lat_field: lat_field,\n            ref_id_field: id_field,\n        }\n    )\n\n    updated_df = update_df_by_col_value(\n        df,\n        ref_df[[id_field, lon_field, lat_field]],\n        id_field,\n        properties=[lat_field, lon_field],\n        fail_if_missing=False,\n    )\n    return updated_df\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.update_points_in_linestring","title":"<code>update_points_in_linestring(linestring, updated_coords, position)</code>","text":"<p>Replaces a point in a linestring with a new point.</p> <p>Parameters:</p> Name Type Description Default <code>linestring</code> <code>LineString</code> <p>original_linestring</p> required <code>updated_coords</code> <code>List[float]</code> <p>updated poimt coordinates</p> required <code>position</code> <code>int</code> <p>position in the linestring to update</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_points_in_linestring(\n    linestring: LineString, updated_coords: List[float], position: int\n):\n    \"\"\"Replaces a point in a linestring with a new point.\n\n    Args:\n        linestring (LineString): original_linestring\n        updated_coords (List[float]): updated poimt coordinates\n        position (int): position in the linestring to update\n    \"\"\"\n    coords = [c for c in linestring.coords]\n    coords[position] = updated_coords\n    return LineString(coords)\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.DictQueryAccessor","title":"<code>DictQueryAccessor</code>","text":"<p>Query link, node and shape dataframes using project selection dictionary.</p> <p>Will overlook any keys which are not columns in the dataframe.</p> <p>Usage:</p> <pre><code>selection_dict = {\n    \"lanes\":[1,2,3],\n    \"name\":['6th','Sixth','sixth'],\n    \"drive_access\": 1,\n}\nselected_links_df = links_df.dict_query(selection_dict)\n</code></pre> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"dict_query\")\nclass DictQueryAccessor:\n    \"\"\"Query link, node and shape dataframes using project selection dictionary.\n\n    Will overlook any keys which are not columns in the dataframe.\n\n    Usage:\n\n    ```\n    selection_dict = {\n        \"lanes\":[1,2,3],\n        \"name\":['6th','Sixth','sixth'],\n        \"drive_access\": 1,\n    }\n    selected_links_df = links_df.dict_query(selection_dict)\n    ```\n\n    \"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dictionary query accessor.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self, selection_dict: dict, return_all_if_none: bool = False):\n        \"\"\"Queries the dataframe using the selection dictionary.\n\n        Args:\n            selection_dict (dict): _description_\n            return_all_if_none (bool, optional): If True, will return entire df if dict has\n                 no values. Defaults to False.\n        \"\"\"\n        _selection_dict = {\n            k: v for k, v in selection_dict.items() if k in self._obj.columns and v is not None\n        }\n\n        if not _selection_dict:\n            if return_all_if_none:\n                return self._obj\n            raise ValueError(f\"Relevant part of selection dictionary is empty: {selection_dict}\")\n\n        _sel_query = dict_to_query(_selection_dict)\n        WranglerLogger.debug(f\"_sel_query: \\n   {_sel_query}\")\n        _df = self._obj.query(_sel_query, engine=\"python\")\n\n        if len(_df) == 0:\n            WranglerLogger.warning(\n                f\"No records found in df \\\n                  using selection: {selection_dict}\"\n            )\n        return _df\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.DictQueryAccessor.__call__","title":"<code>__call__(selection_dict, return_all_if_none=False)</code>","text":"<p>Queries the dataframe using the selection dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>dict</code> <p>description</p> required <code>return_all_if_none</code> <code>bool</code> <p>If True, will return entire df if dict has  no values. Defaults to False.</p> <code>False</code> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self, selection_dict: dict, return_all_if_none: bool = False):\n    \"\"\"Queries the dataframe using the selection dictionary.\n\n    Args:\n        selection_dict (dict): _description_\n        return_all_if_none (bool, optional): If True, will return entire df if dict has\n             no values. Defaults to False.\n    \"\"\"\n    _selection_dict = {\n        k: v for k, v in selection_dict.items() if k in self._obj.columns and v is not None\n    }\n\n    if not _selection_dict:\n        if return_all_if_none:\n            return self._obj\n        raise ValueError(f\"Relevant part of selection dictionary is empty: {selection_dict}\")\n\n    _sel_query = dict_to_query(_selection_dict)\n    WranglerLogger.debug(f\"_sel_query: \\n   {_sel_query}\")\n    _df = self._obj.query(_sel_query, engine=\"python\")\n\n    if len(_df) == 0:\n        WranglerLogger.warning(\n            f\"No records found in df \\\n              using selection: {selection_dict}\"\n        )\n    return _df\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.DictQueryAccessor.__init__","title":"<code>__init__(pandas_obj)</code>","text":"<p>Initialization function for the dictionary query accessor.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dictionary query accessor.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.dfHash","title":"<code>dfHash</code>","text":"<p>Creates a dataframe hash that is compatable with geopandas and various metadata.</p> <p>Definitely not the fastest, but she seems to work where others have failed.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"df_hash\")\nclass dfHash:\n    \"\"\"Creates a dataframe hash that is compatable with geopandas and various metadata.\n\n    Definitely not the fastest, but she seems to work where others have failed.\n    \"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dataframe hash.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self):\n        \"\"\"Function to hash the dataframe.\"\"\"\n        _value = str(self._obj.values).encode()\n        hash = hashlib.sha1(_value).hexdigest()\n        return hash\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.dfHash.__call__","title":"<code>__call__()</code>","text":"<p>Function to hash the dataframe.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self):\n    \"\"\"Function to hash the dataframe.\"\"\"\n    _value = str(self._obj.values).encode()\n    hash = hashlib.sha1(_value).hexdigest()\n    return hash\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.dfHash.__init__","title":"<code>__init__(pandas_obj)</code>","text":"<p>Initialization function for the dataframe hash.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dataframe hash.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api/#network_wrangler.logger.setup_logging","title":"<code>setup_logging(info_log_filename=None, debug_log_filename='wrangler_{}.debug.log'.format(datetime.now().strftime('%Y_%m_%d__%H_%M_%S')), std_out_level='info')</code>","text":"<p>Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.</p> <p>Called by the test_logging fixture in conftest.py and can be called by the user to setup logging for their session. If called multiple times, the logger will be reset.</p> <p>Parameters:</p> Name Type Description Default <code>info_log_filename</code> <code>str</code> <p>the location of the log file that will get created to add the INFO log. The INFO Log is terse, just gives the bare minimum of details. Defaults to file in cwd() <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> <code>None</code> <code>debug_log_filename</code> <code>str</code> <p>the location of the log file that will get created to add the DEBUG log The DEBUG log is very noisy, for debugging. Defaults to file in cwd() <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> <code>format(strftime('%Y_%m_%d__%H_%M_%S'))</code> <code>std_out_level</code> <code>str</code> <p>the level of logging to the console. One of \u201cinfo\u201d, \u201cwarning\u201d, \u201cdebug\u201d. Defaults to \u201cinfo\u201d but will be set to ERROR if nothing provided matches.</p> <code>'info'</code> Source code in <code>network_wrangler/logger.py</code> <pre><code>def setup_logging(\n    info_log_filename: str = None,\n    debug_log_filename: str = \"wrangler_{}.debug.log\".format(\n        datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n    ),\n    std_out_level: str = \"info\",\n):\n    \"\"\"Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.\n\n    Called by the test_logging fixture in conftest.py and can be called by the user to setup\n    logging for their session. If called multiple times, the logger will be reset.\n\n    Args:\n        info_log_filename: the location of the log file that will get created to add the INFO log.\n            The INFO Log is terse, just gives the bare minimum of details.\n            Defaults to file in cwd() `wrangler_[datetime].log`. To turn off logging to a file,\n            use log_filename = None.\n        debug_log_filename: the location of the log file that will get created to add the DEBUG log\n            The DEBUG log is very noisy, for debugging. Defaults to file in cwd()\n            `wrangler_[datetime].log`. To turn off logging to a file, use log_filename = None.\n        std_out_level: the level of logging to the console. One of \"info\", \"warning\", \"debug\".\n            Defaults to \"info\" but will be set to ERROR if nothing provided matches.\n    \"\"\"\n    # add function variable so that we know if logging has been called\n    setup_logging.called = True\n\n    # Clear handles if any exist already\n    WranglerLogger.handlers = []\n\n    WranglerLogger.setLevel(logging.DEBUG)\n\n    FORMAT = logging.Formatter(\n        \"%(asctime)-15s %(levelname)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S,\"\n    )\n    if not info_log_filename:\n        info_log_filename = os.path.join(\n            os.getcwd(),\n            \"network_wrangler_{}.info.log\".format(datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")),\n        )\n\n    info_file_handler = logging.StreamHandler(open(info_log_filename, \"w\"))\n    info_file_handler.setLevel(logging.INFO)\n    info_file_handler.setFormatter(FORMAT)\n    WranglerLogger.addHandler(info_file_handler)\n\n    # create debug file only when debug_log_filename is provided\n    if debug_log_filename:\n        debug_log_handler = logging.StreamHandler(open(debug_log_filename, \"w\"))\n        debug_log_handler.setLevel(logging.DEBUG)\n        debug_log_handler.setFormatter(FORMAT)\n        WranglerLogger.addHandler(debug_log_handler)\n\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.DEBUG)\n    console_handler.setFormatter(FORMAT)\n    WranglerLogger.addHandler(console_handler)\n    if std_out_level == \"debug\":\n        console_handler.setLevel(logging.DEBUG)\n    elif std_out_level == \"info\":\n        console_handler.setLevel(logging.DEBUG)\n    elif std_out_level == \"warning\":\n        console_handler.setLevel(logging.WARNING)\n    else:\n        console_handler.setLevel(logging.ERROR)\n</code></pre>"},{"location":"data_models/","title":"Data Models","text":""},{"location":"data_models/#roadway","title":"Roadway","text":""},{"location":"data_models/#tables","title":"Tables","text":"<p>Datamodels for Roadway Network Tables.</p> <p>This module contains the datamodels used to validate the format and types of Roadway Network tables.</p> <p>Includes: - RoadLinksTable - RoadNodesTable - RoadShapesTable - ExplodedScopedLinkPropertyTable</p>"},{"location":"data_models/#network_wrangler.models.roadway.tables.ExplodedScopedLinkPropertyTable","title":"<code>ExplodedScopedLinkPropertyTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate an exploded links_df by scope.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class ExplodedScopedLinkPropertyTable(DataFrameModel):\n    \"\"\"Datamodel used to validate an exploded links_df by scope.\"\"\"\n\n    model_link_id: Series[int]\n    category: Series[Any]\n    timespan: Series[list[str]]\n    start_time: Series[dt.datetime]\n    end_time: Series[dt.datetime]\n    scoped: Series[Any] = pa.Field(default=None, nullable=True)\n\n    class Config:\n        \"\"\"Config for ExplodedScopedLinkPropertySchema.\"\"\"\n\n        name = \"ExplodedScopedLinkPropertySchema\"\n        coerce = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.ExplodedScopedLinkPropertyTable.Config","title":"<code>Config</code>","text":"<p>Config for ExplodedScopedLinkPropertySchema.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for ExplodedScopedLinkPropertySchema.\"\"\"\n\n    name = \"ExplodedScopedLinkPropertySchema\"\n    coerce = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable","title":"<code>RoadLinksTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadLinksTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\"\"\"\n\n    model_link_id: Series[int] = pa.Field(coerce=True, unique=True)\n    model_link_id_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True)\n    A: Series[int] = pa.Field(nullable=False, coerce=True)\n    B: Series[int] = pa.Field(nullable=False, coerce=True)\n    geometry: GeoSeries = pa.Field(nullable=False)\n    name: Series[str] = pa.Field(nullable=False, default=\"unknown\")\n    rail_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    bus_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    drive_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    bike_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    walk_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    distance: Series[float] = pa.Field(coerce=True, nullable=False)\n\n    roadway: Series[str] = pa.Field(nullable=False, default=\"road\")\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    managed: Series[int] = pa.Field(coerce=True, nullable=False, default=0)\n\n    shape_id: Series[str] = pa.Field(coerce=True, nullable=True)\n    lanes: Series[int] = pa.Field(coerce=True, nullable=False)\n    price: Series[float] = pa.Field(coerce=True, nullable=False, default=0)\n\n    # Optional Fields\n\n    access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    sc_lanes: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n    sc_price: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    ML_projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    ML_lanes: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    ML_price: Optional[Series[float]] = pa.Field(coerce=True, nullable=True, default=0)\n    ML_access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=True)\n    ML_access_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    ML_egress_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    sc_ML_lanes: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_price: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_access: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n\n    ML_geometry: Optional[GeoSeries] = pa.Field(nullable=True, coerce=True, default=None)\n    ML_shape_id: Optional[Series[str]] = pa.Field(nullable=True, coerce=True, default=None)\n\n    truck_access: Optional[Series[bool]] = pa.Field(coerce=True, nullable=True, default=True)\n    osm_link_id: Series[str] = pa.Field(coerce=True, nullable=True, default=\"\")\n    # todo this should be List[dict] but ranch output something else so had to have it be Any.\n    locationReferences: Optional[Series[Any]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n\n    GP_A: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    GP_B: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    class Config:\n        \"\"\"Config for RoadLinksTable.\"\"\"\n\n        name = \"RoadLinksTable\"\n        add_missing_columns = True\n        coerce = True\n        unique = [\"A\", \"B\"]\n\n    @pa.check(\"sc_*\", regex=True, element_wise=True)\n    def check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n        \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n        Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n        against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n        \"\"\"\n        if not scoped_value or pd.isna(scoped_value):\n            return True\n        return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadLinksTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadLinksTable.\"\"\"\n\n    name = \"RoadLinksTable\"\n    add_missing_columns = True\n    coerce = True\n    unique = [\"A\", \"B\"]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable.check_scoped_fields","title":"<code>check_scoped_fields(scoped_value)</code>","text":"<p>Checks that all fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 are valid ScopedLinkValueList.</p> <p>Custom check to validate fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 against a ScopedLinkValueItem model, handling both mandatory and optional fields.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>@pa.check(\"sc_*\", regex=True, element_wise=True)\ndef check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n    \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n    Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n    against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n    \"\"\"\n    if not scoped_value or pd.isna(scoped_value):\n        return True\n    return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadNodesTable","title":"<code>RoadNodesTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadNodesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\"\"\"\n\n    model_node_id: Series[int] = pa.Field(coerce=True, unique=True, nullable=False)\n    model_node_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True, nullable=False)\n    geometry: GeoSeries\n    X: Series[float] = pa.Field(coerce=True, nullable=False)\n    Y: Series[float] = pa.Field(coerce=True, nullable=False)\n\n    # optional fields\n    osm_node_id: Series[str] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    inboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n    outboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadNodesTable.\"\"\"\n\n        name = \"RoadNodesTable\"\n        add_missing_columns = True\n        coerce = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadNodesTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadNodesTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadNodesTable.\"\"\"\n\n    name = \"RoadNodesTable\"\n    add_missing_columns = True\n    coerce = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadShapesTable","title":"<code>RoadShapesTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadShapesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\"\"\"\n\n    shape_id: Series[str] = pa.Field(unique=True)\n    shape_id_idx: Optional[Series[int]] = pa.Field(unique=True)\n\n    geometry: GeoSeries = pa.Field()\n    ref_shape_id: Optional[Series] = pa.Field(nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadShapesTable.\"\"\"\n\n        name = \"ShapesSchema\"\n        coerce = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadShapesTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadShapesTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadShapesTable.\"\"\"\n\n    name = \"ShapesSchema\"\n    coerce = True\n</code></pre>"},{"location":"data_models/#types","title":"Types","text":"<p>Complex roadway types defined using Pydantic models to facilitation validation.</p>"},{"location":"data_models/#network_wrangler.models.roadway.types.LocationReferences","title":"<code>LocationReferences = conlist(LocationReference, min_length=2)</code>  <code>module-attribute</code>","text":"<p>List of at least two LocationReferences which define a path.</p>"},{"location":"data_models/#network_wrangler.models.roadway.types.LocationReference","title":"<code>LocationReference</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>SharedStreets-defined object for location reference.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class LocationReference(BaseModel):\n    \"\"\"SharedStreets-defined object for location reference.\"\"\"\n\n    sequence: PositiveInt\n    point: LatLongCoordinates\n    bearing: float = Field(None, ge=-360, le=360)\n    distanceToNextRef: NonNegativeFloat\n    intersectionId: str\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopeLinkValueError","title":"<code>ScopeLinkValueError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with ScopedLinkValueList.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class ScopeLinkValueError(Exception):\n    \"\"\"Raised when there is an issue with ScopedLinkValueList.\"\"\"\n\n    pass\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueItem","title":"<code>ScopedLinkValueItem</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Define a link property scoped by timespan or category.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class ScopedLinkValueItem(RecordModel):\n    \"\"\"Define a link property scoped by timespan or category.\"\"\"\n\n    require_any_of = [\"category\", \"timespan\"]\n    model_config = ConfigDict(extra=\"forbid\")\n    category: Optional[Union[str, int]] = Field(default=DEFAULT_CATEGORY)\n    timespan: Optional[list[TimeString]] = Field(default=DEFAULT_TIMESPAN)\n    value: Union[int, float, str]\n\n    @property\n    def timespan_dt(self) -&gt; list[list[datetime]]:\n        \"\"\"Convert timespan to list of datetime objects.\"\"\"\n        return str_to_time_list(self.timespan)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueItem.timespan_dt","title":"<code>timespan_dt: list[list[datetime]]</code>  <code>property</code>","text":"<p>Convert timespan to list of datetime objects.</p>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueList","title":"<code>ScopedLinkValueList</code>","text":"<p>               Bases: <code>RootListMixin</code>, <code>RootModel</code></p> <p>List of non-conflicting ScopedLinkValueItems.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class ScopedLinkValueList(RootListMixin, RootModel):\n    \"\"\"List of non-conflicting ScopedLinkValueItems.\"\"\"\n\n    root: list[ScopedLinkValueItem]\n\n    def overlapping_timespans(self, timespan: Timespan):\n        \"\"\"Identify overlapping timespans in the list.\"\"\"\n        timespan_dt = str_to_time_list(timespan)\n        return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n\n    @model_validator(mode=\"after\")\n    def check_conflicting_scopes(self):\n        \"\"\"Check for conflicting scopes in the list.\"\"\"\n        conflicts = []\n        for i in self:\n            if i.timespan == DEFAULT_TIMESPAN:\n                continue\n            overlapping_ts_i = self.overlapping_timespans(i.timespan)\n            for j in overlapping_ts_i:\n                if j == i:\n                    continue\n                if j.category == i.category:\n                    conflicts.append((i, j))\n        if conflicts:\n            WranglerLogger.error(\"Found conflicting scopes in ScopedPropertySetList:\\n{conflicts}\")\n            raise ScopeLinkValueError(\"Conflicting scopes in ScopedPropertySetList\")\n\n        return self\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueList.check_conflicting_scopes","title":"<code>check_conflicting_scopes()</code>","text":"<p>Check for conflicting scopes in the list.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_conflicting_scopes(self):\n    \"\"\"Check for conflicting scopes in the list.\"\"\"\n    conflicts = []\n    for i in self:\n        if i.timespan == DEFAULT_TIMESPAN:\n            continue\n        overlapping_ts_i = self.overlapping_timespans(i.timespan)\n        for j in overlapping_ts_i:\n            if j == i:\n                continue\n            if j.category == i.category:\n                conflicts.append((i, j))\n    if conflicts:\n        WranglerLogger.error(\"Found conflicting scopes in ScopedPropertySetList:\\n{conflicts}\")\n        raise ScopeLinkValueError(\"Conflicting scopes in ScopedPropertySetList\")\n\n    return self\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueList.overlapping_timespans","title":"<code>overlapping_timespans(timespan)</code>","text":"<p>Identify overlapping timespans in the list.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>def overlapping_timespans(self, timespan: Timespan):\n    \"\"\"Identify overlapping timespans in the list.\"\"\"\n    timespan_dt = str_to_time_list(timespan)\n    return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n</code></pre>"},{"location":"data_models/#transit","title":"Transit","text":"<p>Main functionality for GTFS tables including Feed object.</p>"},{"location":"data_models/#network_wrangler.transit.feed.feed.Feed","title":"<code>Feed</code>","text":"<p>               Bases: <code>DBModelMixin</code></p> <p>Wrapper class around Wrangler flavored GTFS feed.</p> <p>Most functionality derives from mixin class DBModelMixin which provides: - validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df) - validation of fks when setting a table attribute (e.g. self.trips = trips_df) - hashing and deep copy functionality - overload of eq to apply only to tables in table_names. - convenience methods for accessing tables</p> <p>Attributes:</p> Name Type Description <code>table_names</code> <p>list of table names in GTFS feed.</p> <code>tables</code> <p>list tables as dataframes.</p> <code>stop_times</code> <p>stop_times dataframe with roadway node_ids</p> <code>stops</code> <p>stops dataframe</p> <code>shapes</code> <p>shapes dataframe</p> <code>trips</code> <p>trips dataframe</p> <code>frequencies</code> <p>frequencies dataframe</p> <code>routes</code> <p>route dataframe</p> <code>net</code> <p>TransitNetwork object</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>class Feed(DBModelMixin):\n    \"\"\"Wrapper class around Wrangler flavored GTFS feed.\n\n    Most functionality derives from mixin class DBModelMixin which provides:\n    - validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)\n    - validation of fks when setting a table attribute (e.g. self.trips = trips_df)\n    - hashing and deep copy functionality\n    - overload of __eq__ to apply only to tables in table_names.\n    - convenience methods for accessing tables\n\n    Attributes:\n        table_names: list of table names in GTFS feed.\n        tables: list tables as dataframes.\n        stop_times: stop_times dataframe with roadway node_ids\n        stops: stops dataframe\n        shapes: shapes dataframe\n        trips: trips dataframe\n        frequencies: frequencies dataframe\n        routes: route dataframe\n        net: TransitNetwork object\n    \"\"\"\n\n    # the ordering here matters because the stops need to be added before stop_times if\n    # stop times needs to be converted\n    _table_models = {\n        \"agencies\": AgenciesTable,\n        \"frequencies\": WranglerFrequenciesTable,\n        \"routes\": RoutesTable,\n        \"shapes\": WranglerShapesTable,\n        \"stops\": WranglerStopsTable,\n        \"trips\": WranglerTripsTable,\n        \"stop_times\": WranglerStopTimesTable,\n    }\n\n    # Define the converters if the table needs to be converted to a Wrangler table.\n    # Format: \"table_name\": converter_function\n    _converters = {}\n\n    table_names = [\n        \"frequencies\",\n        \"routes\",\n        \"shapes\",\n        \"stops\",\n        \"trips\",\n        \"stop_times\",\n    ]\n\n    optional_table_names = [\"agencies\"]\n\n    def __init__(self, **kwargs):\n        \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n        Args:\n            kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n        \"\"\"\n        self._net = None\n        self.feed_path: Path = None\n        self.initialize_tables(**kwargs)\n\n        # Set extra provided attributes but just FYI in logger.\n        extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n        if extra_attr:\n            WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n        for k, v in extra_attr:\n            self.__setattr__(k, v)\n\n    def set_by_id(\n        self,\n        table_name: str,\n        set_df: pd.DataFrame,\n        id_property: str = \"index\",\n        properties: list[str] = None,\n    ):\n        \"\"\"Set one or more property values based on an ID property for a given table.\n\n        Args:\n            table_name (str): Name of the table to modify.\n            set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n                values to set for the specified property where `&lt;id_property&gt;` is unique.\n            id_property: Property to use as ID to set by. Defaults to \"index\".\n            properties: List of properties to set which are in set_df. If not specified, will set\n                all properties.\n        \"\"\"\n        if not set_df[id_property].is_unique:\n            WranglerLogger.error(f\"{id_property} must be unique in set_df. \\\n                                 Found duplicates: {set_df[id_property].duplicated().sum()}\")\n            raise ValueError(f\"{id_property} must be unique in set_df.\")\n        table_df = self.get_table(table_name)\n        updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n        self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.Feed.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Create a Feed object from a dictionary of DataFrames representing a GTFS feed.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>A dictionary containing DataFrames representing the tables of a GTFS feed.</p> <code>{}</code> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n    Args:\n        kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n    \"\"\"\n    self._net = None\n    self.feed_path: Path = None\n    self.initialize_tables(**kwargs)\n\n    # Set extra provided attributes but just FYI in logger.\n    extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n    if extra_attr:\n        WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n    for k, v in extra_attr:\n        self.__setattr__(k, v)\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.Feed.set_by_id","title":"<code>set_by_id(table_name, set_df, id_property='index', properties=None)</code>","text":"<p>Set one or more property values based on an ID property for a given table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table to modify.</p> required <code>set_df</code> <code>DataFrame</code> <p>DataFrame with columns <code>&lt;id_property&gt;</code> and <code>value</code> containing values to set for the specified property where <code>&lt;id_property&gt;</code> is unique.</p> required <code>id_property</code> <code>str</code> <p>Property to use as ID to set by. Defaults to \u201cindex\u201d.</p> <code>'index'</code> <code>properties</code> <code>list[str]</code> <p>List of properties to set which are in set_df. If not specified, will set all properties.</p> <code>None</code> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def set_by_id(\n    self,\n    table_name: str,\n    set_df: pd.DataFrame,\n    id_property: str = \"index\",\n    properties: list[str] = None,\n):\n    \"\"\"Set one or more property values based on an ID property for a given table.\n\n    Args:\n        table_name (str): Name of the table to modify.\n        set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n            values to set for the specified property where `&lt;id_property&gt;` is unique.\n        id_property: Property to use as ID to set by. Defaults to \"index\".\n        properties: List of properties to set which are in set_df. If not specified, will set\n            all properties.\n    \"\"\"\n    if not set_df[id_property].is_unique:\n        WranglerLogger.error(f\"{id_property} must be unique in set_df. \\\n                             Found duplicates: {set_df[id_property].duplicated().sum()}\")\n        raise ValueError(f\"{id_property} must be unique in set_df.\")\n    table_df = self.get_table(table_name)\n    updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n    self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.FeedValidationError","title":"<code>FeedValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with the validation of the GTFS data.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>class FeedValidationError(Exception):\n    \"\"\"Raised when there is an issue with the validation of the GTFS data.\"\"\"\n\n    pass\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.merge_shapes_to_stop_times","title":"<code>merge_shapes_to_stop_times(stop_times, shapes, trips)</code>","text":"<p>Add shape_id and shape_pt_sequence to stop_times dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>stop_times dataframe to add shape_id and shape_pt_sequence to.</p> required <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>shapes dataframe to add to stop_times.</p> required <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>trips dataframe to link stop_times to shapes</p> required <p>Returns:</p> Type Description <code>DataFrame[WranglerStopTimesTable]</code> <p>stop_times dataframe with shape_id and shape_pt_sequence added.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def merge_shapes_to_stop_times(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Add shape_id and shape_pt_sequence to stop_times dataframe.\n\n    Args:\n        stop_times: stop_times dataframe to add shape_id and shape_pt_sequence to.\n        shapes: shapes dataframe to add to stop_times.\n        trips: trips dataframe to link stop_times to shapes\n\n    Returns:\n        stop_times dataframe with shape_id and shape_pt_sequence added.\n    \"\"\"\n    stop_times_w_shape_id = stop_times.merge(\n        trips[[\"trip_id\", \"shape_id\"]], on=\"trip_id\", how=\"left\"\n    )\n\n    stop_times_w_shapes = stop_times_w_shape_id.merge(\n        shapes,\n        how=\"left\",\n        left_on=[\"shape_id\", \"stop_id\"],\n        right_on=[\"shape_id\", \"shape_model_node_id\"],\n    )\n    stop_times_w_shapes = stop_times_w_shapes.drop(columns=[\"shape_model_node_id\"])\n    return stop_times_w_shapes\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.stop_count_by_trip","title":"<code>stop_count_by_trip(stop_times)</code>","text":"<p>Returns dataframe with trip_id and stop_count from stop_times.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def stop_count_by_trip(\n    stop_times: DataFrame[WranglerStopTimesTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe with trip_id and stop_count from stop_times.\"\"\"\n    stops_count = stop_times.groupby(\"trip_id\").size()\n    return stops_count.reset_index(name=\"stop_count\")\n</code></pre>"},{"location":"data_models/#pure-gtfs-tables","title":"Pure GTFS Tables","text":"<p>Models for when you want to use vanilla (non wrangler) GTFS.</p>"},{"location":"data_models/#network_wrangler.models.gtfs.AgencyRecord","title":"<code>AgencyRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a transit agency.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class AgencyRecord(BaseModel):\n    \"\"\"Represents a transit agency.\"\"\"\n\n    agency_id: AgencyID\n    agency_name: Optional[AgencyName]\n    agency_url: Optional[HttpUrl]\n    agency_timezone: Timezone\n    agency_lang: Optional[Language]\n    agency_phone: Optional[AgencyPhone]\n    agency_fare_url: Optional[AgencyFareUrl]\n    agency_email: Optional[AgencyEmail]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.BikesAllowed","title":"<code>BikesAllowed</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates whether bicycles are allowed.</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class BikesAllowed(IntEnum):\n    \"\"\"Indicates whether bicycles are allowed.\"\"\"\n\n    NO_INFORMATION = 0\n    ALLOWED = 1\n    NOT_ALLOWED = 2\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.DirectionID","title":"<code>DirectionID</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the direction of travel for a trip.</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class DirectionID(IntEnum):\n    \"\"\"Indicates the direction of travel for a trip.\"\"\"\n\n    OUTBOUND = 0\n    INBOUND = 1\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.FrequencyRecord","title":"<code>FrequencyRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents headway (time between trips) for routes with variable frequency.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class FrequencyRecord(BaseModel):\n    \"\"\"Represents headway (time between trips) for routes with variable frequency.\"\"\"\n\n    trip_id: TripID\n    start_time: StartTime\n    end_time: EndTime\n    headway_secs: HeadwaySecs\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.LocationType","title":"<code>LocationType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the type of node the stop record represents.</p> <p>Full documentation: https://gtfs.org/schedule/reference/#stopstxt</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class LocationType(IntEnum):\n    \"\"\"Indicates the type of node the stop record represents.\n\n    Full documentation: https://gtfs.org/schedule/reference/#stopstxt\n    \"\"\"\n\n    STOP_PLATFORM = 0\n    STATION = 1\n    ENTRANCE_EXIT = 2\n    GENERIC_NODE = 3\n    BOARDING_AREA = 4\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.MockPaModel","title":"<code>MockPaModel</code>","text":"<p>Mock model for when Pandera is not installed.</p> Source code in <code>network_wrangler/models/gtfs/__init__.py</code> <pre><code>class MockPaModel:\n    \"\"\"Mock model for when Pandera is not installed.\"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Mock modle initiation.\"\"\"\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.MockPaModel.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Mock modle initiation.</p> Source code in <code>network_wrangler/models/gtfs/__init__.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Mock modle initiation.\"\"\"\n    for key, value in kwargs.items():\n        setattr(self, key, value)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.PickupDropoffType","title":"<code>PickupDropoffType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the pickup method for passengers at a stop.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class PickupDropoffType(IntEnum):\n    \"\"\"Indicates the pickup method for passengers at a stop.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    REGULAR = 0\n    NONE = 1\n    PHONE_AGENCY = 2\n    COORDINATE_WITH_DRIVER = 3\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.RouteRecord","title":"<code>RouteRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a transit route.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class RouteRecord(BaseModel):\n    \"\"\"Represents a transit route.\"\"\"\n\n    route_id: RouteID\n    agency_id: AgencyID\n    route_type: RouteType\n    route_short_name: RouteShortName\n    route_long_name: RouteLongName\n\n    # Optional\n    route_desc: Optional[RouteDesc]\n    route_url: Optional[RouteUrl]\n    route_color: Optional[RouteColor]\n    route_text_color: Optional[RouteTextColor]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.RouteType","title":"<code>RouteType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the type of transportation used on a route.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class RouteType(IntEnum):\n    \"\"\"Indicates the type of transportation used on a route.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    TRAM = 0\n    SUBWAY = 1\n    RAIL = 2\n    BUS = 3\n    FERRY = 4\n    CABLE_TRAM = 5\n    AERIAL_LIFT = 6\n    FUNICULAR = 7\n    TROLLEYBUS = 11\n    MONORAIL = 12\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.ShapeRecord","title":"<code>ShapeRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a point on a path (shape) that a transit vehicle takes.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class ShapeRecord(BaseModel):\n    \"\"\"Represents a point on a path (shape) that a transit vehicle takes.\"\"\"\n\n    shape_id: ShapeID\n    shape_pt_lat: Latitude\n    shape_pt_lon: Longitude\n    shape_pt_sequence: ShapePtSequence\n\n    # Optional\n    shape_dist_traveled: Optional[ShapeDistTraveled]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.StopRecord","title":"<code>StopRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a stop or station where vehicles pick up or drop off passengers.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class StopRecord(BaseModel):\n    \"\"\"Represents a stop or station where vehicles pick up or drop off passengers.\"\"\"\n\n    stop_id: StopID\n    stop_lat: Latitude\n    stop_lon: Longitude\n\n    # Optional\n    stop_code: Optional[StopCode]\n    stop_name: Optional[StopName]\n    tts_stop_name: Optional[TTSStopName]\n    stop_desc: Optional[StopDesc]\n    zone_id: Optional[ZoneID]\n    stop_url: Optional[StopUrl]\n    location_type: Optional[LocationType]\n    parent_station: Optional[ParentStation]\n    stop_timezone: Optional[Timezone]\n    wheelchair_boarding: Optional[WheelchairAccessible]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.StopTimeRecord","title":"<code>StopTimeRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Times that a vehicle arrives at and departs from stops for each trip.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class StopTimeRecord(BaseModel):\n    \"\"\"Times that a vehicle arrives at and departs from stops for each trip.\"\"\"\n\n    trip_id: TripID\n    arrival_time: ArrivalTime\n    departure_time: DepartureTime\n    stop_id: StopID\n    stop_sequence: StopSequence\n\n    # Optional\n    stop_headsign: Optional[StopHeadsign]\n    pickup_type: Optional[PickupType]\n    drop_off_type: Optional[DropoffType]\n    shape_dist_traveled: Optional[ShapeDistTraveled]\n    timepoint: Optional[Timepoint]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.TimepointType","title":"<code>TimepointType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates whether the specified time is exact or approximate.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class TimepointType(IntEnum):\n    \"\"\"Indicates whether the specified time is exact or approximate.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    APPROXIMATE = 0\n    EXACT = 1\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.TripRecord","title":"<code>TripRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Describes trips which are sequences of two or more stops that occur at specific time.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class TripRecord(BaseModel):\n    \"\"\"Describes trips which are sequences of two or more stops that occur at specific time.\"\"\"\n\n    route_id: RouteID\n    service_id: ServiceID\n    trip_id: TripID\n    trip_headsign: TripHeadsign\n    trip_short_name: TripShortName\n    direction_id: DirectionID\n    block_id: BlockID\n    shape_id: ShapeID\n    wheelchair_accessible: WheelchairAccessible\n    bikes_allowed: BikesAllowed\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.WheelchairAccessible","title":"<code>WheelchairAccessible</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates whether the trip is wheelchair accessible.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class WheelchairAccessible(IntEnum):\n    \"\"\"Indicates whether the trip is wheelchair accessible.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    NO_INFORMATION = 0\n    POSSIBLE = 1\n    NOT_POSSIBLE = 2\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.WranglerShapeRecord","title":"<code>WranglerShapeRecord</code>","text":"<p>               Bases: <code>ShapeRecord</code></p> <p>Wrangler-flavored ShapeRecord.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class WranglerShapeRecord(ShapeRecord):\n    \"\"\"Wrangler-flavored ShapeRecord.\"\"\"\n\n    shape_model_node_id: int\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.WranglerStopRecord","title":"<code>WranglerStopRecord</code>","text":"<p>               Bases: <code>StopRecord</code></p> <p>Wrangler-flavored StopRecord.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class WranglerStopRecord(StopRecord):\n    \"\"\"Wrangler-flavored StopRecord.\"\"\"\n\n    stop_id: int\n    stop_id_GTFS: Optional[StopID]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.WranglerStopTimeRecord","title":"<code>WranglerStopTimeRecord</code>","text":"<p>               Bases: <code>StopTimeRecord</code></p> <p>Wrangler-flavored StopTimeRecord.</p> Source code in <code>network_wrangler/models/gtfs/records.py</code> <pre><code>class WranglerStopTimeRecord(StopTimeRecord):\n    \"\"\"Wrangler-flavored StopTimeRecord.\"\"\"\n\n    stop_id: int\n    model_config = ConfigDict(\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"data_models/#project-cards","title":"Project Cards","text":""},{"location":"data_models/#projects","title":"Projects","text":"<p>For roadway deletion project card (e.g. to delete).</p> <p>Pydantic models for roadway property changes which align with ProjectCard schemas.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_deletion.RoadwayDeletion","title":"<code>RoadwayDeletion</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing roadway deletion project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/roadway_deletion.py</code> <pre><code>class RoadwayDeletion(RecordModel):\n    \"\"\"Requirements for describing roadway deletion project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"links\", \"nodes\"]]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    links: Optional[SelectLinksDict] = None\n    nodes: Optional[SelectNodesDict] = None\n    clean_shapes: Optional[bool] = False\n    clean_nodes: Optional[bool] = False\n\n    @field_validator(\"links\")\n    @classmethod\n    def set_to_all_modes(cls, links: Optional[SelectLinksDict] = None):\n        \"\"\"Set the search mode to 'any' if not specified explicitly.\"\"\"\n        if links is not None:\n            if links.modes == DEFAULT_SEARCH_MODES:\n                links.modes = DEFAULT_DELETE_MODES\n        return links\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_deletion.RoadwayDeletion.set_to_all_modes","title":"<code>set_to_all_modes(links=None)</code>  <code>classmethod</code>","text":"<p>Set the search mode to \u2018any\u2019 if not specified explicitly.</p> Source code in <code>network_wrangler/models/projects/roadway_deletion.py</code> <pre><code>@field_validator(\"links\")\n@classmethod\ndef set_to_all_modes(cls, links: Optional[SelectLinksDict] = None):\n    \"\"\"Set the search mode to 'any' if not specified explicitly.\"\"\"\n    if links is not None:\n        if links.modes == DEFAULT_SEARCH_MODES:\n            links.modes = DEFAULT_DELETE_MODES\n    return links\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.GroupedScopedPropertySetItem","title":"<code>GroupedScopedPropertySetItem</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Value for setting property value for a single time of day and category.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class GroupedScopedPropertySetItem(BaseModel):\n    \"\"\"Value for setting property value for a single time of day and category.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", exclude_none=True)\n\n    category: Optional[Union[str, int]] = None\n    timespan: Optional[TimespanString] = None\n    categories: Optional[list[Any]] = []\n    timespans: Optional[list[TimespanString]] = []\n    set: Optional[Any] = None\n    existing: Optional[Any] = None\n    change: Optional[Union[int, float]] = None\n    _examples = [\n        {\"category\": \"hov3\", \"timespan\": [\"6:00\", \"9:00\"], \"set\": 2.0},\n        {\"category\": \"hov2\", \"set\": 2.0},\n        {\"timespan\": [\"12:00\", \"2:00\"], \"change\": -1},\n    ]\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_set_or_change(cls, data: dict):\n        \"\"\"Validate that each item has a set or change value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        if \"set\" in data and \"change\" in data:\n            WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n            data[\"change\"] = None\n        return data\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_categories_or_timespans(cls, data: Any) -&gt; Any:\n        \"\"\"Validate that each item has a category or timespan value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        require_any_of = [\"category\", \"timespan\", \"categories\", \"timespans\"]\n        if not any([attr in data for attr in require_any_of]):\n            raise ValidationError(f\"Require at least one of {require_any_of}\")\n        return data\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.GroupedScopedPropertySetItem.check_categories_or_timespans","title":"<code>check_categories_or_timespans(data)</code>  <code>classmethod</code>","text":"<p>Validate that each item has a category or timespan value.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_categories_or_timespans(cls, data: Any) -&gt; Any:\n    \"\"\"Validate that each item has a category or timespan value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    require_any_of = [\"category\", \"timespan\", \"categories\", \"timespans\"]\n    if not any([attr in data for attr in require_any_of]):\n        raise ValidationError(f\"Require at least one of {require_any_of}\")\n    return data\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.GroupedScopedPropertySetItem.check_set_or_change","title":"<code>check_set_or_change(data)</code>  <code>classmethod</code>","text":"<p>Validate that each item has a set or change value.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_set_or_change(cls, data: dict):\n    \"\"\"Validate that each item has a set or change value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    if \"set\" in data and \"change\" in data:\n        WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n        data[\"change\"] = None\n    return data\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.IndivScopedPropertySetItem","title":"<code>IndivScopedPropertySetItem</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Value for setting property value for a single time of day and category.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class IndivScopedPropertySetItem(BaseModel):\n    \"\"\"Value for setting property value for a single time of day and category.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", exclude_none=True)\n\n    category: Optional[Union[str, int]] = DEFAULT_CATEGORY\n    timespan: Optional[TimespanString] = DEFAULT_TIMESPAN\n    set: Optional[Any] = None\n    existing: Optional[Any] = None\n    change: Optional[Union[int, float]] = None\n    _examples = [\n        {\"category\": \"hov3\", \"timespan\": [\"6:00\", \"9:00\"], \"set\": 2.0},\n        {\"category\": \"hov2\", \"set\": 2.0},\n        {\"timespan\": [\"12:00\", \"2:00\"], \"change\": -1},\n    ]\n\n    @property\n    def timespan_dt(self) -&gt; list[list[datetime]]:\n        \"\"\"Convert timespan to list of datetime objects.\"\"\"\n        return str_to_time_list(self.timespan)\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_set_or_change(cls, data: dict):\n        \"\"\"Validate that each item has a set or change value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        if data.get(\"set\") and data.get(\"change\"):\n            WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n            data[\"change\"] = None\n\n        WranglerLogger.debug(f\"Data: {data}\")\n        if data.get(\"set\", None) is None and data.get(\"change\", None) is None:\n            WranglerLogger.debug(\n                f\"Must have `set` or `change` in IndivScopedPropertySetItem. \\\n                           Found: {data}\"\n            )\n            raise ValueError(\"Must have `set` or `change` in IndivScopedPropertySetItem\")\n        return data\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_categories_or_timespans(cls, data: Any) -&gt; Any:\n        \"\"\"Validate that each item has a category or timespan value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        require_any_of = [\"category\", \"timespan\"]\n        if not any([attr in data for attr in require_any_of]):\n            raise ValidationError(f\"Require at least one of {require_any_of}\")\n        return data\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.IndivScopedPropertySetItem.timespan_dt","title":"<code>timespan_dt: list[list[datetime]]</code>  <code>property</code>","text":"<p>Convert timespan to list of datetime objects.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.IndivScopedPropertySetItem.check_categories_or_timespans","title":"<code>check_categories_or_timespans(data)</code>  <code>classmethod</code>","text":"<p>Validate that each item has a category or timespan value.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_categories_or_timespans(cls, data: Any) -&gt; Any:\n    \"\"\"Validate that each item has a category or timespan value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    require_any_of = [\"category\", \"timespan\"]\n    if not any([attr in data for attr in require_any_of]):\n        raise ValidationError(f\"Require at least one of {require_any_of}\")\n    return data\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.IndivScopedPropertySetItem.check_set_or_change","title":"<code>check_set_or_change(data)</code>  <code>classmethod</code>","text":"<p>Validate that each item has a set or change value.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_set_or_change(cls, data: dict):\n    \"\"\"Validate that each item has a set or change value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    if data.get(\"set\") and data.get(\"change\"):\n        WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n        data[\"change\"] = None\n\n    WranglerLogger.debug(f\"Data: {data}\")\n    if data.get(\"set\", None) is None and data.get(\"change\", None) is None:\n        WranglerLogger.debug(\n            f\"Must have `set` or `change` in IndivScopedPropertySetItem. \\\n                       Found: {data}\"\n        )\n        raise ValueError(\"Must have `set` or `change` in IndivScopedPropertySetItem\")\n    return data\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.NodeGeometryChange","title":"<code>NodeGeometryChange</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Value for setting node geometry given a model_node_id.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class NodeGeometryChange(RecordModel):\n    \"\"\"Value for setting node geometry given a model_node_id.\"\"\"\n\n    model_config = ConfigDict(extra=\"ignore\")\n    X: float\n    Y: float\n    in_crs: Optional[int] = LAT_LON_CRS\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.NodeGeometryChangeTable","title":"<code>NodeGeometryChangeTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>DataFrameModel for setting node geometry given a model_node_id.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class NodeGeometryChangeTable(DataFrameModel):\n    \"\"\"DataFrameModel for setting node geometry given a model_node_id.\"\"\"\n\n    model_node_id: Series[int]\n    X: Series[float] = Field(coerce=True)\n    Y: Series[float] = Field(coerce=True)\n    in_crs: Series[int] = Field(default=LAT_LON_CRS)\n\n    class Config:\n        \"\"\"Config for NodeGeometryChangeTable.\"\"\"\n\n        add_missing_columns = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.NodeGeometryChangeTable.Config","title":"<code>Config</code>","text":"<p>Config for NodeGeometryChangeTable.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class Config:\n    \"\"\"Config for NodeGeometryChangeTable.\"\"\"\n\n    add_missing_columns = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.RoadPropertyChange","title":"<code>RoadPropertyChange</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Value for setting property value for a time of day and category.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class RoadPropertyChange(RecordModel):\n    \"\"\"Value for setting property value for a time of day and category.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", exclude_none=True)\n\n    existing: Optional[Any] = None\n    change: Optional[Union[int, float]] = None\n    set: Optional[Any] = None\n    scoped: Optional[Union[None, ScopedPropertySetList]] = None\n\n    require_one_of: ClassVar[OneOf] = [[\"change\", \"set\"]]\n\n    _examples = [\n        {\"set\": 1},\n        {\"existing\": 2, \"change\": -1},\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\"timespan\": [\"6:00\", \"9:00\"], \"value\": 2.0},\n                {\"timespan\": [\"9:00\", \"15:00\"], \"value\": 4.0},\n            ],\n        },\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\n                    \"categories\": [\"hov3\", \"hov2\"],\n                    \"timespan\": [\"6:00\", \"9:00\"],\n                    \"value\": 2.0,\n                },\n                {\"category\": \"truck\", \"timespan\": [\"6:00\", \"9:00\"], \"value\": 4.0},\n            ],\n        },\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\"categories\": [\"hov3\", \"hov2\"], \"value\": 2.0},\n                {\"category\": \"truck\", \"value\": 4.0},\n            ],\n        },\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.ScopeConflictError","title":"<code>ScopeConflictError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is a scope conflict in a list of ScopedPropertySetItems.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class ScopeConflictError(Exception):\n    \"\"\"Raised when there is a scope conflict in a list of ScopedPropertySetItems.\"\"\"\n\n    pass\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.ScopedPropertySetList","title":"<code>ScopedPropertySetList</code>","text":"<p>               Bases: <code>RootListMixin</code>, <code>RootModel</code></p> <p>List of ScopedPropertySetItems used to evaluate and apply changes to roadway properties.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>class ScopedPropertySetList(RootListMixin, RootModel):\n    \"\"\"List of ScopedPropertySetItems used to evaluate and apply changes to roadway properties.\"\"\"\n\n    root: list[IndivScopedPropertySetItem]\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_set_or_change(cls, data: list):\n        \"\"\"Validate that each item has a set or change value.\"\"\"\n        data = _grouped_to_indiv_list_of_scopedpropsetitem(data)\n        return data\n\n    @model_validator(mode=\"after\")\n    def check_conflicting_scopes(self):\n        \"\"\"Check for conflicting scopes in the list of ScopedPropertySetItem.\"\"\"\n        conflicts = []\n        for i in self:\n            if i.timespan == DEFAULT_TIMESPAN:\n                continue\n            overlapping_ts_i = self.overlapping_timespans(i.timespan)\n            for j in overlapping_ts_i:\n                if j == i:\n                    continue\n                if j.category == i.category:\n                    conflicts.append((i, j))\n        if conflicts:\n            WranglerLogger.error(\"Found conflicting scopes in ScopedPropertySetList:\\n{conflicts}\")\n            raise ScopeConflictError(\"Conflicting scopes in ScopedPropertySetList\")\n\n        return self\n\n    def overlapping_timespans(self, timespan: TimespanString) -&gt; list[IndivScopedPropertySetItem]:\n        \"\"\"Return a list of items that overlap with the given timespan.\"\"\"\n        timespan_dt = str_to_time_list(timespan)\n        return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n\n    @property\n    def change_items(self) -&gt; list[IndivScopedPropertySetItem]:\n        \"\"\"Filter out items that do not have a change value.\"\"\"\n        WranglerLogger.debug(f\"self.root[0]: {self.root[0]}\")\n        return [i for i in self if i.change is not None]\n\n    @property\n    def set_items(self):\n        \"\"\"Filter out items that do not have a set value.\"\"\"\n        return [i for i in self if i.set is not None]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.ScopedPropertySetList.change_items","title":"<code>change_items: list[IndivScopedPropertySetItem]</code>  <code>property</code>","text":"<p>Filter out items that do not have a change value.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.ScopedPropertySetList.set_items","title":"<code>set_items</code>  <code>property</code>","text":"<p>Filter out items that do not have a set value.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.ScopedPropertySetList.check_conflicting_scopes","title":"<code>check_conflicting_scopes()</code>","text":"<p>Check for conflicting scopes in the list of ScopedPropertySetItem.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_conflicting_scopes(self):\n    \"\"\"Check for conflicting scopes in the list of ScopedPropertySetItem.\"\"\"\n    conflicts = []\n    for i in self:\n        if i.timespan == DEFAULT_TIMESPAN:\n            continue\n        overlapping_ts_i = self.overlapping_timespans(i.timespan)\n        for j in overlapping_ts_i:\n            if j == i:\n                continue\n            if j.category == i.category:\n                conflicts.append((i, j))\n    if conflicts:\n        WranglerLogger.error(\"Found conflicting scopes in ScopedPropertySetList:\\n{conflicts}\")\n        raise ScopeConflictError(\"Conflicting scopes in ScopedPropertySetList\")\n\n    return self\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.ScopedPropertySetList.check_set_or_change","title":"<code>check_set_or_change(data)</code>  <code>classmethod</code>","text":"<p>Validate that each item has a set or change value.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_set_or_change(cls, data: list):\n    \"\"\"Validate that each item has a set or change value.\"\"\"\n    data = _grouped_to_indiv_list_of_scopedpropsetitem(data)\n    return data\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_property_change.ScopedPropertySetList.overlapping_timespans","title":"<code>overlapping_timespans(timespan)</code>","text":"<p>Return a list of items that overlap with the given timespan.</p> Source code in <code>network_wrangler/models/projects/roadway_property_change.py</code> <pre><code>def overlapping_timespans(self, timespan: TimespanString) -&gt; list[IndivScopedPropertySetItem]:\n    \"\"\"Return a list of items that overlap with the given timespan.\"\"\"\n    timespan_dt = str_to_time_list(timespan)\n    return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n</code></pre>"},{"location":"data_models/#roadway-selections","title":"Roadway Selections","text":"<p>Pydantic Roadway Selection Models which should align with ProjectCard data models.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectFacility","title":"<code>SelectFacility</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Roadway Facility Selection.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectFacility(RecordModel):\n    \"\"\"Roadway Facility Selection.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [[\"links\", \"nodes\", [\"links\", \"from\", \"to\"]]]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    links: Optional[SelectLinksDict] = None\n    nodes: Optional[SelectNodesDict] = None\n    from_: Annotated[Optional[SelectNodeDict], Field(None, alias=\"from\")]\n    to: Optional[SelectNodeDict] = None\n\n    _examples = [\n        {\n            \"links\": {\"name\": [\"Main Street\"]},\n            \"from\": {\"model_node_id\": 1},\n            \"to\": {\"model_node_id\": 2},\n        },\n        {\"nodes\": {\"osm_node_id\": [\"1\", \"2\", \"3\"]}},\n        {\"nodes\": {\"model_node_id\": [1, 2, 3]}},\n        {\"links\": {\"model_link_id\": [1, 2, 3]}},\n    ]\n\n    @property\n    def feature_types(self) -&gt; str:\n        \"\"\"One of `segment`, `links`, or `nodes`.\"\"\"\n        if self.links and self.from_ and self.to:\n            return \"segment\"\n        if self.links:\n            return \"links\"\n        if self.nodes:\n            return \"nodes\"\n        raise ValueError(\"SelectFacility must have either links or nodes defined.\")\n\n    @property\n    def selection_type(self) -&gt; str:\n        \"\"\"One of `segment`, `links`, or `nodes`.\"\"\"\n        if self.feature_types == \"segment\":\n            return \"segment\"\n        if self.feature_types == \"links\":\n            return self.links.selection_type\n        if self.feature_types == \"nodes\":\n            return self.nodes.selection_type\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectFacility.feature_types","title":"<code>feature_types: str</code>  <code>property</code>","text":"<p>One of <code>segment</code>, <code>links</code>, or <code>nodes</code>.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectFacility.selection_type","title":"<code>selection_type: str</code>  <code>property</code>","text":"<p>One of <code>segment</code>, <code>links</code>, or <code>nodes</code>.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict","title":"<code>SelectLinksDict</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>requirements for describing links in the <code>facility</code> section of a project card.</p> <p>Examples:</p> <pre><code>    {'name': ['Main St'], 'modes': ['drive']}\n    {'osm_link_id': ['123456789']}\n    {'model_link_id': [123456789], 'modes': ['walk']}\n    {'all': 'True', 'modes': ['transit']}\n</code></pre> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectLinksDict(RecordModel):\n    \"\"\"requirements for describing links in the `facility` section of a project card.\n\n    Examples:\n    ```python\n        {'name': ['Main St'], 'modes': ['drive']}\n        {'osm_link_id': ['123456789']}\n        {'model_link_id': [123456789], 'modes': ['walk']}\n        {'all': 'True', 'modes': ['transit']}\n    ```\n\n    \"\"\"\n\n    require_conflicts: ClassVar[ConflictsWith] = [\n        [\"all\", \"osm_link_id\"],\n        [\"all\", \"model_link_id\"],\n        [\"all\", \"name\"],\n        [\"all\", \"ref\"],\n        [\"osm_link_id\", \"model_link_id\"],\n        [\"osm_link_id\", \"name\"],\n        [\"model_link_id\", \"name\"],\n    ]\n    require_any_of: ClassVar[AnyOf] = [[\"name\", \"ref\", \"osm_link_id\", \"model_link_id\", \"all\"]]\n    _initial_selection_fields: ClassVar[list[str]] = [\n        \"name\",\n        \"ref\",\n        \"osm_link_id\",\n        \"model_link_id\",\n        \"all\",\n    ]\n    _explicit_id_fields: ClassVar[list[str]] = [\"osm_link_id\", \"model_link_id\"]\n    _segment_id_fields: ClassVar[list[str]] = [\n        \"name\",\n        \"ref\",\n        \"osm_link_id\",\n        \"model_link_id\",\n        \"modes\",\n    ]\n    _special_fields: ClassVar[list[str]] = [\"modes\", \"ignore_missing\"]\n    model_config = ConfigDict(extra=\"allow\")\n\n    all: Optional[bool] = False\n    name: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    ref: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    osm_link_id: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    model_link_id: Annotated[Optional[list[int]], Field(None, min_length=1)]\n    modes: list[str] = DEFAULT_SEARCH_MODES\n    ignore_missing: Optional[bool] = True\n\n    _examples = [\n        {\"name\": [\"Main St\"], \"modes\": [\"drive\"]},\n        {\"osm_link_id\": [\"123456789\"]},\n        {\"model_link_id\": [123456789], \"modes\": [\"walk\"]},\n        {\"all\": \"True\", \"modes\": [\"transit\"]},\n    ]\n\n    @property\n    def asdict(self) -&gt; dict:\n        \"\"\"Model as a dictionary.\"\"\"\n        return self.model_dump(exclude_none=True, by_alias=True)\n\n    @property\n    def fields(self) -&gt; list[str]:\n        \"\"\"All fields in the selection.\"\"\"\n        return list(self.model_dump(exclude_none=True, by_alias=True).keys())\n\n    @property\n    def initial_selection_fields(self) -&gt; list[str]:\n        \"\"\"Fields used in the initial selection of links.\"\"\"\n        if self.all:\n            return [\"all\"]\n        return [f for f in self._initial_selection_fields if getattr(self, f)]\n\n    @property\n    def explicit_id_fields(self) -&gt; list[str]:\n        \"\"\"Fields that can be used in a slection on their own.\n\n        e.g. `osm_link_id` and `model_link_id`.\n        \"\"\"\n        return [k for k in self._explicit_id_fields if getattr(self, k)]\n\n    @property\n    def segment_id_fields(self) -&gt; list[str]:\n        \"\"\"Fields that can be used in an intial segment selection.\n\n        e.g. `name`, `ref`, `osm_link_id`, or `model_link_id`.\n        \"\"\"\n        return [k for k in self._segment_id_fields if getattr(self, k)]\n\n    @property\n    def additional_selection_fields(self):\n        \"\"\"Return a list of fields that are not part of the initial selection fields.\"\"\"\n        _potential = list(\n            set(self.fields) - set(self.initial_selection_fields) - set(self._special_fields)\n        )\n        return [f for f in _potential if getattr(self, f)]\n\n    @property\n    def selection_type(self):\n        \"\"\"One of `all`, `explicit_ids`, or `segment`.\"\"\"\n        if self.all:\n            return \"all\"\n        if self.explicit_id_fields:\n            return \"explicit_ids\"\n        if self.segment_id_fields:\n            return \"segment\"\n        else:\n            raise SelectionFormatError(\n                \"If not a segment, Select Links should have either `all` or an explicit id.\"\n            )\n\n    @property\n    def explicit_id_selection_dict(self):\n        \"\"\"Return a dictionary of fields that are explicit ids.\"\"\"\n        return {k: v for k, v in self.asdict.items() if k in self.explicit_id_fields}\n\n    @property\n    def segment_selection_dict(self):\n        \"\"\"Return a dictionary of fields that are explicit ids.\"\"\"\n        return {k: v for k, v in self.asdict.items() if k in self.segment_id_fields}\n\n    @property\n    def additional_selection_dict(self):\n        \"\"\"Return a dictionary of fields that are not part of the initial selection fields.\"\"\"\n        return {k: v for k, v in self.asdict.items() if k in self.additional_selection_fields}\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.additional_selection_dict","title":"<code>additional_selection_dict</code>  <code>property</code>","text":"<p>Return a dictionary of fields that are not part of the initial selection fields.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.additional_selection_fields","title":"<code>additional_selection_fields</code>  <code>property</code>","text":"<p>Return a list of fields that are not part of the initial selection fields.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.asdict","title":"<code>asdict: dict</code>  <code>property</code>","text":"<p>Model as a dictionary.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.explicit_id_fields","title":"<code>explicit_id_fields: list[str]</code>  <code>property</code>","text":"<p>Fields that can be used in a slection on their own.</p> <p>e.g. <code>osm_link_id</code> and <code>model_link_id</code>.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.explicit_id_selection_dict","title":"<code>explicit_id_selection_dict</code>  <code>property</code>","text":"<p>Return a dictionary of fields that are explicit ids.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.fields","title":"<code>fields: list[str]</code>  <code>property</code>","text":"<p>All fields in the selection.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.initial_selection_fields","title":"<code>initial_selection_fields: list[str]</code>  <code>property</code>","text":"<p>Fields used in the initial selection of links.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.segment_id_fields","title":"<code>segment_id_fields: list[str]</code>  <code>property</code>","text":"<p>Fields that can be used in an intial segment selection.</p> <p>e.g. <code>name</code>, <code>ref</code>, <code>osm_link_id</code>, or <code>model_link_id</code>.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.segment_selection_dict","title":"<code>segment_selection_dict</code>  <code>property</code>","text":"<p>Return a dictionary of fields that are explicit ids.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict.selection_type","title":"<code>selection_type</code>  <code>property</code>","text":"<p>One of <code>all</code>, <code>explicit_ids</code>, or <code>segment</code>.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodeDict","title":"<code>SelectNodeDict</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection of a single roadway node in the <code>facility</code> section of a project card.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectNodeDict(RecordModel):\n    \"\"\"Selection of a single roadway node in the `facility` section of a project card.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [[\"osm_node_id\", \"model_node_id\"]]\n    initial_selection_fields: ClassVar[list[str]] = [\"osm_node_id\", \"model_node_id\"]\n    explicit_id_fields: ClassVar[list[str]] = [\"osm_node_id\", \"model_node_id\"]\n    model_config = ConfigDict(extra=\"allow\")\n\n    osm_node_id: Optional[str] = None\n    model_node_id: Optional[int] = None\n\n    _examples = [{\"osm_node_id\": \"12345\"}, {\"model_node_id\": 67890}]\n\n    @property\n    def selection_type(self):\n        \"\"\"One of `all` or `explicit_ids`.\"\"\"\n        _explicit_ids = [k for k in self.explicit_id_fields if getattr(self, k)]\n        if _explicit_ids:\n            return \"explicit_ids\"\n        WranglerLogger.debug(\n            f\"SelectNode should have an explicit id: {self.explicit_id_fields} \\\n                Found none in selection dict: \\n{self.model_dump(by_alias=True)}\"\n        )\n        raise SelectionFormatError(\"Select Node should have either `all` or an explicit id.\")\n\n    @property\n    def explicit_id_selection_dict(self) -&gt; dict:\n        \"\"\"Return a dictionary of field that are explicit ids.\"\"\"\n        return {\n            k: [v]\n            for k, v in self.model_dump(exclude_none=True, by_alias=True).items()\n            if k in self.explicit_id_fields\n        }\n\n    @property\n    def additional_selection_fields(self) -&gt; list[str]:\n        \"\"\"Return a list of fields that are not part of the initial selection fields.\"\"\"\n        return list(\n            set(self.model_dump(exclude_none=True, by_alias=True).keys())\n            - set(self.initial_selection_fields)\n        )\n\n    @property\n    def additional_selection_dict(self) -&gt; dict:\n        \"\"\"Return a dictionary of fields that are not part of the initial selection fields.\"\"\"\n        return {\n            k: v\n            for k, v in self.model_dump(exclude_none=True, by_alias=True).items()\n            if k in self.additional_selection_fields\n        }\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodeDict.additional_selection_dict","title":"<code>additional_selection_dict: dict</code>  <code>property</code>","text":"<p>Return a dictionary of fields that are not part of the initial selection fields.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodeDict.additional_selection_fields","title":"<code>additional_selection_fields: list[str]</code>  <code>property</code>","text":"<p>Return a list of fields that are not part of the initial selection fields.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodeDict.explicit_id_selection_dict","title":"<code>explicit_id_selection_dict: dict</code>  <code>property</code>","text":"<p>Return a dictionary of field that are explicit ids.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodeDict.selection_type","title":"<code>selection_type</code>  <code>property</code>","text":"<p>One of <code>all</code> or <code>explicit_ids</code>.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodesDict","title":"<code>SelectNodesDict</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple nodes of a project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectNodesDict(RecordModel):\n    \"\"\"Requirements for describing multiple nodes of a project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"osm_node_id\", \"model_node_id\"]]\n    _explicit_id_fields: ClassVar[list[str]] = [\"osm_node_id\", \"model_node_id\"]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    all: Optional[bool] = False\n    osm_node_id: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    model_node_id: Annotated[Optional[list[int]], Field(min_length=1)]\n    ignore_missing: Optional[bool] = True\n\n    _examples = [\n        {\"osm_node_id\": [\"12345\", \"67890\"], \"model_node_id\": [12345, 67890]},\n        {\"osm_node_id\": [\"12345\", \"67890\"]},\n        {\"model_node_id\": [12345, 67890]},\n    ]\n\n    @property\n    def asdict(self) -&gt; dict:\n        \"\"\"Model as a dictionary.\"\"\"\n        return self.model_dump(exclude_none=True, by_alias=True)\n\n    @property\n    def fields(self) -&gt; list[str]:\n        \"\"\"List of fields in the selection.\"\"\"\n        return list(self.model_dump(exclude_none=True, by_alias=True).keys())\n\n    @property\n    def selection_type(self):\n        \"\"\"One of `all` or `explicit_ids`.\"\"\"\n        if self.all:\n            return \"all\"\n        if self.explicit_id_fields:\n            return \"explicit_ids\"\n        WranglerLogger.debug(\n            f\"SelectNodes should have either `all` or an explicit id: {self.explicit_id_fields}. \\\n                Found neither in nodes selection: \\n{self.model_dump(by_alias=True)}\"\n        )\n        raise SelectionFormatError(\"Select Node should have either `all` or an explicit id.\")\n\n    @property\n    def explicit_id_fields(self) -&gt; list[str]:\n        \"\"\"Fields which can be used in a selection on their own.\"\"\"\n        return [k for k in self._explicit_id_fields if getattr(self, k)]\n\n    @property\n    def explicit_id_selection_dict(self):\n        \"\"\"Return a dictionary of fields that are explicit ids.\"\"\"\n        return {k: v for k, v in self.asdict.items() if k in self.explicit_id_fields}\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodesDict.asdict","title":"<code>asdict: dict</code>  <code>property</code>","text":"<p>Model as a dictionary.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodesDict.explicit_id_fields","title":"<code>explicit_id_fields: list[str]</code>  <code>property</code>","text":"<p>Fields which can be used in a selection on their own.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodesDict.explicit_id_selection_dict","title":"<code>explicit_id_selection_dict</code>  <code>property</code>","text":"<p>Return a dictionary of fields that are explicit ids.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodesDict.fields","title":"<code>fields: list[str]</code>  <code>property</code>","text":"<p>List of fields in the selection.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodesDict.selection_type","title":"<code>selection_type</code>  <code>property</code>","text":"<p>One of <code>all</code> or <code>explicit_ids</code>.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectionFormatError","title":"<code>SelectionFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with the selection format.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectionFormatError(Exception):\n    \"\"\"Raised when there is an issue with the selection format.\"\"\"\n\n    pass\n</code></pre>"},{"location":"data_models/#transit-selections","title":"Transit Selections","text":"<p>Pydantic data models for transit selection properties.</p>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectRouteProperties","title":"<code>SelectRouteProperties</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit routes.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectRouteProperties(RecordModel):\n    \"\"\"Selection properties for transit routes.\"\"\"\n\n    route_short_name: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n    route_long_name: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n    agency_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n    route_type: Annotated[Optional[List[int]], Field(None, min_length=1)]\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTransitLinks","title":"<code>SelectTransitLinks</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple transit links of a project card.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitLinks(RecordModel):\n    \"\"\"Requirements for describing multiple transit links of a project card.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [\n        [\"ab_nodes\", \"model_link_id\"],\n    ]\n\n    model_link_id: Annotated[Optional[List[int]], Field(min_length=1)] = None\n    ab_nodes: Annotated[Optional[List[TransitABNodesModel]], Field(min_length=1)] = None\n    require: Optional[SelectionRequire] = \"any\"\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n    _examples = [\n        {\n            \"ab_nodes\": [{\"A\": \"75520\", \"B\": \"66380\"}, {\"A\": \"66380\", \"B\": \"75520\"}],\n            \"type\": \"any\",\n        },\n        {\n            \"model_link_id\": [123, 321],\n            \"type\": \"all\",\n        },\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTransitNodes","title":"<code>SelectTransitNodes</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple transit nodes of a project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitNodes(RecordModel):\n    \"\"\"Requirements for describing multiple transit nodes of a project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [\n        [\n            \"model_node_id\",\n            # \"gtfs_stop_id\", TODO Not implemented\n        ]\n    ]\n\n    # gtfs_stop_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)] TODO Not implemented\n    model_node_id: Annotated[List[int], Field(min_length=1)]\n    require: Optional[SelectionRequire] = \"any\"\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n\n    _examples = [\n        # {\"gtfstop_id\": [\"stop1\", \"stop2\"], \"require\": \"any\"},  TODO Not implemented\n        {\"model_node_id\": [1, 2], \"require\": \"all\"},\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTransitTrips","title":"<code>SelectTransitTrips</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit trips.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitTrips(RecordModel):\n    \"\"\"Selection properties for transit trips.\"\"\"\n\n    trip_properties: Optional[SelectTripProperties] = None\n    route_properties: Optional[SelectRouteProperties] = None\n    timespans: Annotated[Optional[List[TimespanString]], Field(None, min_length=1)]\n    nodes: Optional[SelectTransitNodes] = None\n    links: Optional[SelectTransitLinks] = None\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTripProperties","title":"<code>SelectTripProperties</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit trips.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTripProperties(RecordModel):\n    \"\"\"Selection properties for transit trips.\"\"\"\n\n    trip_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n    shape_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n    direction_id: Annotated[Optional[int], Field(None)]\n    service_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n    route_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n    trip_short_name: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)]\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.TransitABNodesModel","title":"<code>TransitABNodesModel</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Single transit link model.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class TransitABNodesModel(RecordModel):\n    \"\"\"Single transit link model.\"\"\"\n\n    A: Optional[int] = None  # model_node_id\n    B: Optional[int] = None  # model_node_id\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"design/","title":"Design","text":""},{"location":"design/#atomic-parts","title":"Atomic Parts","text":"<p>NetworkWrangler deals with four primary atomic parts:</p> <p>1. <code>Scenario</code> objects describe a Roadway Network, Transit Network, and collection of Projects. Scenarios manage the addition and construction of projects on the network via projct cards. Scenarios can be based on or tiered from other scenarios.</p> <p>2. <code>RoadwayNetwork</code> objects stores information about roadway nodes, directed links between nodes, and the shapes of links (note that the same shape can be shared between two or more links). Network Wrangler reads/writes roadway network objects from/to three files: <code>links.json</code>, <code>shapes.geojson</code>, and <code>nodes.geojson</code>. Their data is stored as GeoDataFrames in the object.</p> <p>3. <code>TransitNetwork</code> objects contain information about stops, routes, trips, shapes, stoptimes, and frequencies. Network Wrangler reads/writes transit network information from/to gtfs csv files and stores them as DataFrames within a <code>Partridge</code> <code>feed</code> object.  Transit networks can be associated with Roadway networks.</p> <p>4.<code>ProjectCard</code> objects store infromation (including  metadata) about changes to the network.  Network Wtanglr reads project cards from .yml files validates them, and manages them within a <code>Scenario</code> object.</p>"},{"location":"development/","title":"Development","text":""},{"location":"development/#contributing-to-network-wrangler","title":"Contributing to Network Wrangler","text":""},{"location":"development/#roles","title":"Roles","text":""},{"location":"development/#how-to-contribute","title":"How to Contribute","text":""},{"location":"development/#setup","title":"Setup","text":"<ol> <li>Make sure you have a GitHub account.  </li> <li>Make sure you have git, a terminal (e.g. Mac Terminal, CygWin, etc.), and a text editor installed on your local machine.  Optionally, you will likely find it easier to use GitHub Desktop, an IDE instead of a simple text editor like VSCode, Eclipse, Sublime Text, etc.  </li> <li>Fork the repository into your own GitHub account and clone it locally.  </li> <li>Install your <code>network_wrangler</code> clone in development mode: <code>pip install . -e</code></li> <li>Install documentation requirements: <code>pip install -r requirements.docs.txt</code></li> <li>Install development requirements: <code>pip install -r requirements.tests.txt</code></li> <li>[Optional] Install act to run github actions locally.  </li> </ol>"},{"location":"development/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create an issue for any features/bugs that you are working on.</li> <li>Create a branch to work on a new issue (or checkout an existing one where the issue is being worked on).  </li> <li>Develop comprehensive tests in the <code>/tests</code> folder.</li> <li>Modify code including inline documentation such that it passes all  tests (not just your new ones)</li> <li>Lint code using <code>pre-commit run --all-files</code></li> <li>Fill out information in the pull request template</li> <li>Submit all pull requests to the <code>develop</code> branch.</li> <li>Core developer will review your pull request and suggest changes.</li> <li>After requested changes are complete, core developer will sign off on pull-request merge.</li> </ol> <p>!tip: Keep pull requests small and focused. One issue is best.</p> <p>!tip: Don\u2019t forget to update any associated #documentation as well!</p>"},{"location":"development/#documentation","title":"Documentation","text":"<p>Documentation is produced by mkdocs:</p> <ul> <li><code>mkdocs build</code>: builds documentation</li> <li><code>mkdocs serve</code>: builds and serves documentation to review locally in browswer</li> </ul> <p>Documentation is built and deployed using the <code>mike</code> package and Github Actions configured in <code>.github/workflows/</code> for each \u201cref\u201d (i.e. branch) in the network_wrangler repository.</p>"},{"location":"development/#testing-and-continuous-integration","title":"Testing and Continuous Integration","text":"<p>Tests and test data reside in the <code>/tests</code> directory:</p> <ul> <li><code>pytest</code>: runs all tests</li> </ul> <p>Continuous Integration is managed by Github Actions in <code>.github/workflows</code>. All tests other than those with the decorator <code>@pytest.mark.skipci</code> will be run.</p>"},{"location":"development/#project-governance","title":"Project Governance","text":"<p>The project is currently governed by representatives of its two major organizational contributors:</p> <ul> <li>Metropolitan Council (MN)</li> <li>Metropolitan Transportation Commission (California)</li> </ul>"},{"location":"development/#code-of-conduct","title":"Code of Conduct","text":"<p>Contributors to the Network Wrangler Project are expected to read and follow the CODE_OF_CONDUCT for the project.</p>"},{"location":"development/#contributors","title":"Contributors","text":"<ol> <li>Lisa Zorn - initial Network Wrangler implementation at SFCTA</li> <li>Billy Charlton</li> <li>Elizabeh Sall</li> <li>Sijia Wang</li> <li>David Ory</li> <li>Ashish K.</li> </ol> <p>!Note: There are likely more contributors - feel free to add your name if we missed it!</p>"},{"location":"networks/","title":"Networks","text":""},{"location":"networks/#roadway-network-format","title":"Roadway Network Format","text":"<p>RoadwayNetworks must be defined in the following format, which leverages Open Street Map which uses a tag-based format (e.g. json, xml).  This may be changed in the future to align with the tabular-based General Modeling Network Specification.</p> <p>A network is defined by a set of nodes and links which connect them.  Shapes may be optionally specified for each link in a separate file.</p>"},{"location":"networks/#roadway-validation","title":"Roadway Validation","text":"<p>RoadwayNetworks can be validated using the following tools:</p> CLIPython API <p><pre><code>python validate_roadway.py &lt;network_directory&gt; &lt;network_suffix&gt; [-s] [--output_dir &lt;output_dir&gt;]\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>network_suffix</code>: The suffices of roadway network file name.</li> <li><code>-s</code>, <code>--strict</code>: Validate the roadway network strictly without parsing and filling in data.</li> <li><code>--output_dir</code>: The output directory for the validation report.</li> </ul> <p><pre><code>from network_wrangler.roadway.validate import validate_roadway_in_dir\nvalidate_roadway_in_dir(\n    directory=&lt;network_directory&gt;,\n    suffix=&lt;network_suffix&gt;,\n    strict=&lt;strict_bool&gt;&gt;,\n    output_dir=&lt;output_dir&gt;\n)\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>network_suffix</code>: The suffices of roadway network file name.</li> <li><code>strict</code>: Validate the roadway network strictly without parsing and filling in data.</li> <li><code>output_dir</code>: The output directory for the validation report.</li> </ul>"},{"location":"networks/#examples","title":"Examples","text":"<p>Network Wrangler is packaged with two examples located in the <code>/examples</code> directory:</p> <ul> <li>St Paul, MN</li> <li>Small which is a several block exerpt of St Paul and is infinitely easier to trouble-shoot quickly.</li> </ul>"},{"location":"networks/#nodes","title":"Nodes","text":"<p>A  valid <code>geojson</code> file with <code>point</code> features and the folowing <code>properties</code>.</p> <p>alternative file serializations</p> <p>Networks can also be stored \u2013 more efficiently \u2013\u00a0in parquet files with a similar structure. Other workable file serializations include shapefiles, csvs, and anything that can be read by pandas or geopandas.</p> Property Type Description model_node_id Any PrimaryKey. Most modeling assignment software requires this be an integer. osm_node_id str Reference to open street map node id. Used for querying. Not guaranteed to be unique. <p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadNodesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\"\"\"\n\n    model_node_id: Series[int] = pa.Field(coerce=True, unique=True, nullable=False)\n    model_node_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True, nullable=False)\n    geometry: GeoSeries\n    X: Series[float] = pa.Field(coerce=True, nullable=False)\n    Y: Series[float] = pa.Field(coerce=True, nullable=False)\n\n    # optional fields\n    osm_node_id: Series[str] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    inboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n    outboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadNodesTable.\"\"\"\n\n        name = \"RoadNodesTable\"\n        add_missing_columns = True\n        coerce = True\n</code></pre>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadNodesTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadNodesTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadNodesTable.\"\"\"\n\n    name = \"RoadNodesTable\"\n    add_missing_columns = True\n    coerce = True\n</code></pre>"},{"location":"networks/#links","title":"Links","text":"<p>A  valid <code>json</code> file with the following <code>properties</code>. Additional properites may be defined and are assumed to have the same definition of OpenStreetMap if they have overlapping property names.</p> Property Type Description model_link_id Any Required. PrimaryKey. shape_id Any Optional foreign key to <code>shapes</code>. A int Required. Foreign key to Nodes. From node. B int Required. Foreign key to Nodes. To node. name str Required. Name of link. roadway str Required. Uses OpenStreetMap.highway tag definition. distance Positive float Required, or will be calculated as a crow-fly distance from A to B node. Length in miles. managed [ 0,1] Indicator for managed lane presence.  Does not need to be edited in project cards as any project card applied that adds a value for a property with the prefix \u201cML_\u201d will automatically set this. lanes Positive int Required. Number of GP lanes. ML_access_point bool Point where managed lane may be accessed from general purpose lanes. ML_egress_point bool Point where managed lane may be exited to general purpose lanes. ML_lanes Positive int Number of managed lanes. sc_lanes Positive int Required. Number of GP lanes scoped by time of day and/or category. sc_ML_lanes Positive int Number of managed lanes scoped by time of day and/or category. price Number Required. Price of GP lanes . ML_price Number Price of managed lanes. sc_price Number Required. Price of GP lanes scoped by time of day and/or category. sc_ML_price Number Price of managed lanes scoped by time of day and/or category. drive_access bool Required. Allows driving access. bus_only bool Required. Bus Only facility rail_only bool Required. Bus Only facility bike_access bool Required. Bikes may use facility walk_access bool Required. Pedestrians may use facility truck_access bool Required. Trucks may use this facility osm_link_id str Reference to open street map node id. Used for querying. Not guaranteed to be unique. shstReferenceId str Shared Streets ID reference. Not used currently in network wrangler. <p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadLinksTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\"\"\"\n\n    model_link_id: Series[int] = pa.Field(coerce=True, unique=True)\n    model_link_id_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True)\n    A: Series[int] = pa.Field(nullable=False, coerce=True)\n    B: Series[int] = pa.Field(nullable=False, coerce=True)\n    geometry: GeoSeries = pa.Field(nullable=False)\n    name: Series[str] = pa.Field(nullable=False, default=\"unknown\")\n    rail_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    bus_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    drive_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    bike_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    walk_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    distance: Series[float] = pa.Field(coerce=True, nullable=False)\n\n    roadway: Series[str] = pa.Field(nullable=False, default=\"road\")\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    managed: Series[int] = pa.Field(coerce=True, nullable=False, default=0)\n\n    shape_id: Series[str] = pa.Field(coerce=True, nullable=True)\n    lanes: Series[int] = pa.Field(coerce=True, nullable=False)\n    price: Series[float] = pa.Field(coerce=True, nullable=False, default=0)\n\n    # Optional Fields\n\n    access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    sc_lanes: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n    sc_price: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    ML_projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    ML_lanes: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    ML_price: Optional[Series[float]] = pa.Field(coerce=True, nullable=True, default=0)\n    ML_access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=True)\n    ML_access_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    ML_egress_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    sc_ML_lanes: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_price: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_access: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n\n    ML_geometry: Optional[GeoSeries] = pa.Field(nullable=True, coerce=True, default=None)\n    ML_shape_id: Optional[Series[str]] = pa.Field(nullable=True, coerce=True, default=None)\n\n    truck_access: Optional[Series[bool]] = pa.Field(coerce=True, nullable=True, default=True)\n    osm_link_id: Series[str] = pa.Field(coerce=True, nullable=True, default=\"\")\n    # todo this should be List[dict] but ranch output something else so had to have it be Any.\n    locationReferences: Optional[Series[Any]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n\n    GP_A: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    GP_B: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    class Config:\n        \"\"\"Config for RoadLinksTable.\"\"\"\n\n        name = \"RoadLinksTable\"\n        add_missing_columns = True\n        coerce = True\n        unique = [\"A\", \"B\"]\n\n    @pa.check(\"sc_*\", regex=True, element_wise=True)\n    def check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n        \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n        Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n        against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n        \"\"\"\n        if not scoped_value or pd.isna(scoped_value):\n            return True\n        return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadLinksTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadLinksTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadLinksTable.\"\"\"\n\n    name = \"RoadLinksTable\"\n    add_missing_columns = True\n    coerce = True\n    unique = [\"A\", \"B\"]\n</code></pre>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadLinksTable.check_scoped_fields","title":"<code>check_scoped_fields(scoped_value)</code>","text":"<p>Checks that all fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 are valid ScopedLinkValueList.</p> <p>Custom check to validate fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 against a ScopedLinkValueItem model, handling both mandatory and optional fields.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>@pa.check(\"sc_*\", regex=True, element_wise=True)\ndef check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n    \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n    Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n    against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n    \"\"\"\n    if not scoped_value or pd.isna(scoped_value):\n        return True\n    return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"networks/#prefix-for-managed-lanes","title":"Prefix for Managed Lanes","text":"<p>(Almost) any property, including an ad-hoc one, can be made to apply to a parallel managed lane by applying the prefix <code>ML_</code>.  </p> <p>Example: <code>ML_lanes</code></p> <p>A handful of properties should not be assigned an <code>ML_</code> prefix by the user because they are assigned one within networkwrangler:</p> <ul> <li><code>name</code></li> <li><code>A</code></li> <li><code>B</code></li> <li><code>model_link_id</code></li> </ul>"},{"location":"networks/#scoped-properties","title":"Scoped Properties","text":"<p>The following above properties can be time-dependent, category-dependent, or both by adding <code>sc_</code>. The \u201cplain\u201d property without the prefix becomes the default when no scoped property applies.</p> <ul> <li>lanes: default # of lanes for general purpose lanes</li> <li>ML_lanes: default # of lanes for a managed lane</li> <li>sc_lanes: time- and/or category-dependent # of lanes for general purpose lanes</li> <li>sc_ML_lanes: time- and/or category-dependent # of lanes for a managed lane</li> <li>price: default price for general purpose lanes</li> <li>ML_price: default price for a managed lane</li> <li>sc_price: time- and/or category-dependent price for general purpose lanes</li> <li>sc_ML_price: time- and/or category-dependent price for a managed lane</li> </ul> <p>previous format for scoped properties</p> <p>Some previous tooling was developed around a previous method for serializing scoped properties.  In order to retain compatability with this format:</p> <ul> <li><code>load_roadway_from_dir()</code>, <code>read_links()</code>, and associated functions will \u201csniff\u201d the network for the old format and apply the converter function <code>translate_links_df_v0_to_v1()</code></li> <li><code>write_links()</code> has an boolean attribute to <code>convert_complex_properties_to_single_field</code> which can also be invoked from <code>write_roadway()</code> as <code>convert_complex_link_properties_to_single_field</code>.</li> </ul>"},{"location":"networks/#defining-time-dependent-properties","title":"Defining time-dependent properties","text":"<ul> <li>Time-dependent properties are defined as a list of dictionaries with timespans and values.</li> <li>Timespans must be defined as a list of HH:MM or HH:MM:SS using a 24-hour clock: <code>('06:00':'09:00')</code>.</li> <li>Timespans must not intersect.</li> </ul> <p>Time-dependent property</p> <p>$3 peak-period pricing</p> <pre><code># default price\n'price' = 0\n'sc_price':\n[\n    {\n        'time':['06:00':'09:00'],\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'value': 3,\n    }\n]\n</code></pre>"},{"location":"networks/#defining-time-and-category-dependent-properties","title":"Defining time- and category-dependent properties","text":"<ul> <li>Properties co-dependent on time- and category are defined as a list of dictionaries with value, category and time defined.</li> </ul> <p>time- and category-dependent property</p> <p>A pricing strategy which only applies in peak period for trucks and sovs:</p> <pre><code># default price\n\"price\": 0\n# price scoped by time of day\n\"sc_price\":\n[\n    {\n        'timespan':['06:00':'09:00'],\n        'category': ('sov','truck'),\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'category': ('sov','truck'),\n        'value': 3,\n    }\n]\n</code></pre> <p>Tip</p> <p>There is no limit on other, user-defined properties being listed as time-dependent or time- and category-dependent.</p> <p>User-defined variable by time of day</p> <p>Define a variable <code>access</code> to represent which categories can access the network and vary it by time of day.</p> <pre><code>#access\n{\n    # default value for access\n    'access': ('any'),\n    # scoped value for access\n    'sc_access': [\n        {\n            'timespan':['06:00':'09:00'],\n            'value': ('no-trucks')\n        },\n        {\n            'timespan':['16:00':'19:00'],\n            'value': ('hov2','hov3','trucks')\n        }\n    ]\n}\n</code></pre>"},{"location":"networks/#shapes","title":"Shapes","text":"<p>A  valid <code>geojson</code> file with <code>LineString</code> features and the folowing <code>properties</code>. Additional properties may be defined and if overlapping with SharedStreets are assumed to be defined in the same manner.</p> Property Type Description shape_id Any Required. PrimaryKey. <p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadShapesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\"\"\"\n\n    shape_id: Series[str] = pa.Field(unique=True)\n    shape_id_idx: Optional[Series[int]] = pa.Field(unique=True)\n\n    geometry: GeoSeries = pa.Field()\n    ref_shape_id: Optional[Series] = pa.Field(nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadShapesTable.\"\"\"\n\n        name = \"ShapesSchema\"\n        coerce = True\n</code></pre>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadShapesTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadShapesTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadShapesTable.\"\"\"\n\n    name = \"ShapesSchema\"\n    coerce = True\n</code></pre>"},{"location":"networks/#transit-network-format","title":"Transit Network Format","text":"<p>Transit Networks must use the the GTFS Schedule format with the following additional constraints:</p> <ol> <li>At this time, only frequency-based schedules are supported.</li> <li>Each <code>stop_id</code> must be a node in the RoadwayNetwork.</li> <li><code>shapes.txt</code> is required (it is optional in GTFS) and must have the added field <code>model_node_id</code> associating a specific location with a node on the <code>RoadwayNetwork</code>.</li> </ol>"},{"location":"networks/#transit-validation","title":"Transit Validation","text":"<p>TransitNetworks can be validated using the following tools:</p> CLIPython API <p><pre><code>python validate_transit.py &lt;network_directory&gt; &lt;network_suffix&gt; [-s] [--output_dir &lt;output_dir&gt;] [--road_dir &lt;road_dir&gt;] [--road_suffix &lt;road_suffix&gt;]\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>network_suffix</code>: The suffices of roadway network file name.</li> <li><code>--output_dir</code>: The output directory for the validation report.</li> <li><code>--road_dir</code>: The directory roadway network. if want to validate the transit network to it.</li> <li><code>--road_suffix</code>: The suffix for roadway network. Defaults to \u2018geojson\u2019.</li> </ul> <p><pre><code>from network_wrangler.transit.validate import validate_transit_in_dir\nvalidate_transit_in_dir(\n    directory=&lt;network_directory&gt;,\n    suffix=&lt;network_suffix&gt;,\n    road_dir=&lt;road_dir&gt;,\n    road_suffix=&lt;road_suffix&gt;,\n)\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>network_suffix</code>: The suffices of roadway network file name.</li> <li><code>road_dir</code>: The directory roadway network. if want to validate the transit network to it.</li> <li><code>road_suffix</code>: The suffix for roadway network. Defaults to \u2018geojson\u2019.</li> </ul>"},{"location":"networks/#project-cards","title":"Project Cards","text":"<p>Project Cards, which define changes to the roadway and transit networks must use the ProjectCard standard.</p>"},{"location":"networks/#model-roadway-network-export-format","title":"Model Roadway Network Export Format","text":"<p>In order to separately calculate the delay when the networks are assigned in static roadway network assignment the roadway network must be exported with separate managed lane links.</p> <p>To acheive this, RoadwayNetwork objects have the option to be exported in the ModelRoadwayNetwork format, which separates a link into two: set of managed lanes and a set of general purpose lanes which are connected by a set of dummy connector links.  </p>"},{"location":"networks/#managed-lane-links","title":"Managed Lane Links","text":"<p>All properties preceded by <code>ML_</code> will be copied, without that prefix, to the managed lane links.</p> <p>Geometry of these managed lanes will be defined as a shape offset by the parameter ML_OFFSET_METERS</p> <p>(list(str)): list of attributes to copy from a general purpose lane to managed lane so long as a ML_ doesn\u2019t exist. <p>Properties defined in the parameter <code>COPY_FROM_GP_TO_ML</code> are also copied from the parent link.</p> <p>(list(str)): list of attributes copied from GP lanes to access and egress dummy links.</p> <p>New <code>model_node_id</code> s and <code>model_link_ids</code> are generated based on the following ranges</p> <p>Range of model_node_ids to use when creating an associated node for a parallel managed lane.</p> <p><code>name</code> is created as \u201cmanaged lane of <code>name of GP link</code>\u201c</p> <p>Relationship to the general purpose lanes is retained using the fields <code>GP_A</code>, <code>GP_B</code>, <code>GP_model_link_id</code>.</p> <p>Managed-lane link-ids are generated as multiples of 10.</p>"},{"location":"networks/#dummy-connector-links","title":"Dummy Connector Links","text":"<p>Dummy connector links are generated between the general purpose lane links and managed lane links at points defined by the variable <code>ML_access_point</code> and <code>ML_egress_point</code>.  If a managed lane is created without explictly setting these values, network wrangler will assume that the managed lanes can be accessed at any node.</p> <p>The parameter  <code>COPY_TO_ACCESS_EGRESS</code> defines what additional attributes are copied from the general purpose lane to the access and egress links.</p> <p>(list(str)): list of attributes that must be provided in managed lanes</p> <p><code>name</code> is created as \u201c dummy link\u201d <p><code>model_link_id</code> is created as follows, noting that <code>model_link_id</code> s for managed lanes will be multiples of 10:</p> <ul> <li>1 + managed lane\u2019s <code>model_link_id</code> for access links</li> <li>2 + managed lane\u2019s <code>model_link_id</code> for access links</li> </ul>"},{"location":"networks/#network-management","title":"Network Management","text":"<p>Several functions assist in managing networks themselves including converting serialization formats and clipping to various geographic bounds.</p>"},{"location":"networks/#viewing","title":"Viewing","text":"<p>Because the roadway network is already in GeoDataFrames, they can be easily viewed in Jupyter Notebooks using commands such as:</p> <pre><code>my_small_net = SMALL_ROAD.links_df).explore(tiles=\"CartoDB positron\")\nSMALL_ROAD.nodes_df.explore(m=my_small_net, color=\"grey\")\nmy_small_net\n</code></pre> <p>For larger networks, you might want to sample objects if you are just trying to get the general picture in order to save memory.</p> <pre><code>stpaul_net = STPAUL_ROAD.links_df.sample(300).explore(tiles=\"CartoDB positron\")\nSTPAUL_ROAD.nodes_df.sample(300).explore(m=stpaul_net, color=\"grey\")\nstpaul_net\n</code></pre> <p>For transit, you have access to GeoDataFrames for both shapes and stops:</p> <pre><code>STPAUL_TRANSIT.shapes_gdf.explore(m=stpaul_net, color=\"limegreen\")\nSTPAUL_TRANSIT.stops_gdf.explore(m=stpaul_net, color=\"limegreen\")\nstpaul_net\n</code></pre>"},{"location":"networks/#clipping","title":"Clipping","text":"<p>There are two options for getting networks that are subsets of the larger one:</p> <ol> <li>clipping networks already loaded from files. Useful when you are already manipulating the objects.</li> <li>filtering the network when it is read in.</li> </ol> <p>In both instances, you have the option to filter based on one of three methods:</p> <ol> <li><code>boundary_file</code> which is a geojson or shapefile that you want to filter to.</li> <li><code>boundary_gdf</code> passing a geodataframe with a single polygon record that you want to filter to.</li> <li><code>boundary_geocode</code> which queries open streetmap for a jurisdiction matching the provided name, e.g. \u201cSt Paul, MN, USA\u201d.</li> </ol> <p>Transit additionally has the option to be filtered to a roadway network.</p>"},{"location":"networks/#clipping-loaded-networks","title":"Clipping loaded networks","text":"<p>If your network is already loaded from disk into a RoadwayNetwork or TransitNetwork, you can clip it using <code>clip_roadway()</code> or <code>clip_transit()</code>:</p> <pre><code>from network_wrangler.roadway import clip_roadway\nclipped_road_eco = clip_roadway(STPAUL_ROAD, boundary_file=TEST_DATA / \"ecolab.geojson\")\nclipped_road_eco.links_df.explore(m= color=\"hotpink\")\n</code></pre> <pre><code>from network_wrangler.transit import clip_transit\nclipped_transit_eco = clip_transit(STPAUL_TRANSIT, roadway_net=clipped_road_eco)\n</code></pre>"},{"location":"networks/#filtering-on-being-read-from-disk","title":"Filtering on being read from disk","text":"<p>To filter roadway networks on being read-in, you can use the same parameters (<code>boundary_gdf</code>, <code>boundary_geocode</code> or <code>boundary_file</code>, available in <code>load_roadway_from_dir</code>, and all associated methods.  </p> <pre><code>downtown_net = load_roadway_from_dir(STPAUL_DIR, boundary_geocode=\"Downtown, St Paul, MN, USA\")\n</code></pre> <p>This feature is not yet implemented in transit.</p>"},{"location":"networks/#converting-serialization","title":"Converting Serialization","text":"<p>To convert file serialization without reading it into objects, you can use the method <code>convert_roadway_file_serialization()</code>:</p> <pre><code>from roadway.io import convert_roadway_file_serialization\n\nconvert_roadway_file_serialization(\n    my_dir, # the path to the input directory.\n    \"geojson\", # the suffix of the input files. Defaults to \"geojson\".\n    my_new_dir, # the path were the output will be saved.\n    \"parquet\", # the format of the output files. Defaults to \"parquet\".\n    \"new\", # the name prefix of the roadway files that will be generated. Defaults to \"\".\n    overwrite = True, # if True, will overwrite the files if they already exist. Defaults to True.\n)\n</code></pre> <p>clip too</p> <p>Note you can also pass one of <code>boundary_geocode</code>, <code>boundary_gdf</code> or <code>boundary_file</code> to clip while you are converting the file serialization.</p>"}]}