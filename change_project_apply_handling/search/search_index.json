{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"network_wrangler","text":"<p>Network Wrangler is a Python library for managing travel model network scenarios.</p>"},{"location":"#system-requirements","title":"System Requirements","text":"<p>Network Wrangler should be operating system agonistic and has been tested on Ubuntu and Mac OS.</p> <p>In order to assist in installation, its helpful to have either miniconda, anaconda or Docker CE installed.  If you don\u2019t have any of these already, we reommend starting with Miniconda for Python 3.7 as it has the smallest footprint. <code>conda</code> is the environment manager that is contained within both the Anaconda and mini-conda applications. All commands described below should be entered into the <code>Ananconda Prompt</code> command window.</p> <p>Network Wrangler does require Python 3.7+.  If you have a different version of Python installed, <code>conda</code> will take care of installing it for you in the installation instructions below.</p>"},{"location":"#installation","title":"Installation","text":"<p>Network Wrangler uses Python 3.6 and above.  Requirements are stored in <code>requirements.txt</code> but are automatically installed when using <code>pip</code>.</p> <p>If you are managing multiple python versions, we suggest using <code>virtualenv</code> or <code>conda</code> virtual environments. <code>conda</code> is the environment manager that is contained within both the Anaconda and mini-conda applications. Do not add Anaconda to the system path during installation. This may cause problems with other programs that require python 2.7 to be placed in the system path.</p> <p>Example installing and running tests using conda in the command line:</p> <pre><code>conda config --add channels conda-forge\nconda create python=3.7 rtree geopandas osmnx -n &lt;my_wrangler_environment&gt;\nconda activate &lt;my_wrangler_environment&gt;\npip install network-wrangler\npytest\n</code></pre> <p>Network wrangler can be installed in several ways depending on the user\u2019s needs. Installing from github is the simplest method and is appropriate when the user does not anticipate needing to update network wrangler. An update will require rebuilding the network wrangler environment. Installing from clone is slightly more involved and requires the user to have a git manager on their machine, but permits the user to install network wrangler with the <code>-e</code>, edit, option so that their network wrangler installation can be updated through pulling new commits from the network wrangler repo without a full reinstallation.</p>"},{"location":"#from-github","title":"From GitHub","text":"<p>Use the package manager pip to install Network Wrangler from the source on GitHub.</p> <pre><code>conda config --add channels conda-forge\nconda create python=3.7 rtree geopandas osmnx -n &lt;my_wrangler_environment&gt;\nconda activate &lt;my_wrangler_environment&gt;\npip install git+https://github.com/wsp-sag/network_wrangler.git@master#egg=network_wrangler\n</code></pre> <p>Note: if you wanted to install from a specific tag/version number or branch, replace <code>@master</code> with <code>@&lt;branchname&gt;</code>  or <code>@tag</code></p>"},{"location":"#from-clone","title":"From Clone","text":"<p>If you are going to be working on Network Wrangler locally, you might want to clone it to your local machine and install it from the clone.  The -e will install it in editable mode.</p> <p>This is also useful if you want to continue to update your Network Wrangler as it is developed on GitHub.</p> <p>1. Open a terminal to get a command prompt.</p> <p>2. Consider using a virtual environment manager like conda.</p> <p>Create a new environment by typing the following commands into the command prompt (it might take a few minutes).  </p> <pre><code>conda create python=3.7 -n wrangler_env\nconda activate wrangler_env\n</code></pre> <p>I chose <code>wrangler_env</code> as the name of my environment, but you could choose something else\u2026just remember it so that you can access it later.</p> <p>NOTE in order to get back to \u201cthis\u201d conda environment (i.e. after you close this command prompt), you will need to access it from the command line by using the following command:</p> <pre><code>conda activate wrangler_env\n</code></pre> <p>3. Install finicky Requirements</p> <p>Some requirements are best installed using conda rather than \u201cpip\u201d</p> <pre><code>conda config --add channels conda-forge\nconda install rtree geopandas osmnx\n</code></pre> <p>4. \u201cClone\u201d (aka download) network wrangler from Github on to your machine</p> <p>If you have GitHub desktop installed, you can either do this by using the GitHub user interface by clicking on the green button \u201cclone or download\u201d in the main network wrangler repository page.</p> <p>Otherwise, you can use the command prompt to navigate to the directory that you would like to store your network wrangler clone and then using a git command to clone it.</p> <pre><code>cd path to where you want to put wrangler\ngit clone https://github.com/wsp-sag/network_wrangler\n</code></pre> <p>Expected output:</p> <pre><code>cloning into network_wrangler...\nremote: Enumerating objects: 53, done.\nremote: Counting objects: 100% (53/53), done.\nremote: Compressing objects: 100% (34/34), done.\nremote: Total 307 (delta 28), reused 29 (delta 19), pack-reused 254\nReceiving objects: 100% (307/307), 15.94 MiB | 10.49 MiB/s, done.\nResolving deltas: 100% (140/140), done.\n</code></pre> <p>5. Install Network Wrangler in \u201cdevelop\u201d mode.</p> <p>Navigate your command prompt into the network wrangler folder and then install network wrangler in editable mode. This will take a few minutes because it is also installing all the prerequisites.</p> <pre><code>cd network_wrangler\npip install -e .[tests]\n</code></pre> <p>Note: the <code>[tests]</code> flag makes sure to install the testing and development requirements as listed in <code>requirements.tests.txt</code></p> <p>There will be a lot of messy output, but it should end with something like:</p> <pre><code>Running setup.py develop for network-wrangler\nSuccessfully installed Rtree-0.8.3 attrs-19.1.0 cchardet-2.1.4 chardet-3.0.4 click-7.0 click-plugins-1.1.1 cligj-0.5.0 cycler-0.10.0 decorator-4.4.0 descartes-1.1.0 fiona-1.8.6 geojson-2.4.1 geopandas-0.5.1 idna-2.8 isoweek-1.3.3 jsonschema-3.0.2 kiwisolver-1.1.0 matplotlib-3.1.1 munch-2.3.2 network-wrangler networkx-2.3 numpy-1.17.0 osmnx-0.10 pandas-0.25.0 partridge-1.1.0 pyparsing-2.4.2 pyproj-2.2.1 pyrsistent-0.15.4 python-dateutil-2.8.0 pytz-2019.2 pyyaml-5.1.2 requests-2.22.0 shapely-1.6.4.post2 six-1.12.0 urllib3-1.25.3\n</code></pre> <p>6. Test the Installation</p> <p>You can test that network wrangler was properly installed by running the tests as follows:</p> <pre><code>pytest\n</code></pre> <p>Note: if you are not part of the project team and want to contribute code back to the project, please fork before you clone and then add the original repository to your upstream origin list per these directions on github.</p>"},{"location":"#using-docker","title":"Using Docker","text":"<ol> <li>Install Docker</li> <li>Clone git repository (see instructions above) NOTE: this is easiest way right now since repo is private. When it is public we can clone right from github without having to muck around with logins or keys</li> <li>From the cloned repository, open a terminal from the <code>/docker</code> folder and build and run the docker container corresponding to what you want to do by running <code>docker-compose run &lt;container name&gt; &lt;entry point (optional)&gt; --build</code></li> <li>Command to exit container: <code>exit</code></li> </ol> <p>Containers:  - <code>wrangler-jupyter</code> started by running <code>docker-compose run wrangler-jupyter --build</code> is appropriate for running and testing wrangler.    - Default action is to start jupyter notebook which can be found at http://127.0.0.1:8888    - Safe: It creates an empty folder to store jupyter notebooks within the container but wont overwrite the source files on your actual machine.    - Starting Bash: You can also start the container with a command line using <code>docker-compose run wrangler-jupyter /bin/bash --build</code>.    - Doesn\u2019t install development dependencies (although they can be installed from within the container)  - <code>wrangler-ci</code> is a small image without extras meant for running tests and deploying to continuous integration server.    - default command is to run pytest.    - contains development dependencies so that it can run tests and build docs.  - <code>wrangler-dev</code> is the most powerful but dangerous container <code>docker-compose run wrangler-dev /bin/bash --build</code>    - Warning: It will synchronize code edited from the container to your wrangler clone.  This is great for developing within an IDE, but please take this into account.</p>"},{"location":"#common-installation-issues","title":"Common Installation Issues","text":"<p>Issue: <code>clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]</code> If you are using MacOS, you might need to update your xcode command line tools and headers</p> <p>Issue: <code>OSError: Could not find libspatialindex_c library file</code>* Try installing rtree on its own from the Anaconda cloud</p> <p><pre><code>conda install rtree\n</code></pre> Issue: Shapely, a pre-requisite, doesn\u2019t install propertly because it is missing GEOS module Try installing shapely on its own from the Anaconda cloud</p> <p><pre><code>conda install shapely\n</code></pre> Issue: Conda is unable to install a library or to update to a specific library version Try installing libraries from conda-forge</p> <pre><code>conda install -c conda-forge *library*\n</code></pre> <p>Issue: User does not have permission to install in directories Try running Anaconda Prompt as an administrator.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>To get a feel for the API and using project cards, please refer to the \u201cWrangler Quickstart\u201d jupyter notebook.</p> <p>To start the notebook, open a command line in the network_wrangler top-level directory and type:</p> <p><code>jupyter notebook</code></p>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation can be built from the <code>/docs</code> folder using the command: <code>make html</code></p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import network_wrangler\n\n##todo this is just an example for now\n\nnetwork_wrangler.setup_logging()\n\n## Network Manipulation\nmy_network = network_wrangler.read_roadway_network(...) # returns\nmy_network.apply_project_card(...) # returns\nmy_network.write_roadway_network(...) # returns\n\n## Scenario Building\nmy_scenario = Scenario.create_scenario(\n          base_scenario=my_base_scenario,\n          card_search_dir=project_card_directory,\n          tags = [\"baseline-2050\"]\n        )\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/baseline\", \"baseline-2050\")\nmy_scenario.summarize(outfile=\"scenario_summary_baseline.txt\")\n\nmy_scenario.add_projects_from_files(list_of_build_project_card_files)\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/build\", \"baseline\")\n</code></pre>"},{"location":"#attribution","title":"Attribution","text":"<p>This project is built upon the ideas and concepts implemented in the network wrangler project by the San Francisco County Transportation Authority and expanded upon by the Metropolitan Transportation Commission.</p> <p>While Network Wrangler as written here is based on these concepts, the code is distinct and builds upon other packages such as <code>geopandas</code> and <code>partridge</code> which hadn\u2019t been implemented when networkwrangler 1.0 was developed.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Pull requests are welcome. Please open an issue first to discuss what you would like to change. Please make sure to update tests as appropriate.</p>"},{"location":"#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"api/","title":"API Documentation","text":""},{"location":"api/#base-classes","title":"Base Classes","text":""},{"location":"api/#network_wrangler.ProjectCard","title":"<code>network_wrangler.ProjectCard</code>","text":"<p>         Bases: <code>object</code></p> <p>Representation of a Project Card</p> <p>Attributes:</p> Name Type Description <code>__dict__</code> <p>Dictionary of project card attributes</p> <code>valid</code> <p>Boolean indicating if data conforms to project card data schema</p> Source code in <code>network_wrangler/projectcard.py</code> <pre><code>class ProjectCard(object):\n\"\"\"\n    Representation of a Project Card\n\n    Attributes:\n        __dict__: Dictionary of project card attributes\n        valid: Boolean indicating if data conforms to project card data schema\n    \"\"\"\n\n    FILE_TYPES = [\"wr\", \"wrangler\", \"yml\", \"yaml\"]\n\n    TRANSIT_CATEGORIES = [\"Transit Service Property Change\", \"Add Transit\"]\n\n    # categories that may affect transit, but only as a secondary\n    # effect of changing roadways\n    SECONDARY_TRANSIT_CATEGORIES = [\"Roadway Deletion\", \"Parallel Managed Lanes\"]\n\n    ROADWAY_CATEGORIES = [\n        \"Roadway Property Change\",\n        \"Roadway Deletion\",\n        \"Parallel Managed lanes\",\n        \"Add New Roadway\",\n        \"Calculated Roadway\",\n    ]\n\n    UNSPECIFIED_PROJECT_NAMES = [\"\", \"TO DO User Define\", \"USER TO define\"]\n\n    def __init__(self, attribute_dictonary: dict):\n\"\"\"\n        Constructor\n\n        args:\n        attribute_dictonary: a nested dictionary of attributes\n        \"\"\"\n        # add these first so they are first on write out\n        self.project = None\n        self.tags = \"\"\n        self.dependencies = \"\"\n\n        self.__dict__.update(attribute_dictonary)\n        self.valid = False\n\n        # todo more unstructuring of project card yaml\n\n    def __str__(self):\n        s = [\"{}: {}\".format(key, value) for key, value in self.__dict__.items()]\n        return \"\\n\".join(s)\n\n    @staticmethod\n    def read(path_to_card: str, validate: bool = True):\n\"\"\"\n        Reads and validates a Project card\n\n        args:\n        path_to_card: the path to the project card\n\n        Returns a Project Card object\n        \"\"\"\n        card_suffix = path_to_card.split(\".\")[-1].lower()\n\n        if card_suffix in [\"yaml\", \"yml\"]:\n            attribute_dictionary = ProjectCard.read_yml(path_to_card)\n        elif card_suffix in [\"wrangler\", \"wr\"]:\n            attribute_dictionary = ProjectCard.read_wrangler_card(path_to_card)\n        else:\n            msg = f\"Card should have a suffix of yaml, yml, wrangler, or wr. \\\n                Found suffix: {card_suffix}\"\n            raise ValueError(msg)\n\n        card = ProjectCard(attribute_dictionary)\n\n        if card.project in ProjectCard.UNSPECIFIED_PROJECT_NAMES:\n            msg = \"Card must have valid project name: {}\".format(path_to_card)\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n\n        card.valid = False\n        if validate:\n            card.valid = ProjectCard.validate_project_card_schema(path_to_card)\n\n        return card\n\n\n    @staticmethod\n    def read_wrangler_card(path_to_card: str) -&gt; dict:\n\"\"\"\n        Reads wrangler project cards with YAML front matter and then python code.\n\n        Args:\n            path_to_card: where the project card is\n\n        Returns: Attribute Dictionary for Project Card\n        \"\"\"\n        WranglerLogger.debug(\"Reading Wrangler-Style Project Card\")\n\n        with open(path_to_card, \"r\") as cardfile:\n            delim = cardfile.readline()\n            WranglerLogger.debug(\"Using delimiter: {}\".format(delim))\n            _yaml, _pycode = cardfile.read().split(delim)\n            WranglerLogger.debug(\"_yaml: {}\\n_pycode: {}\".format(_yaml, _pycode))\n\n        attribute_dictionary = yaml.safe_load(_yaml.lower())\n        attribute_dictionary[\"file\"] = path_to_card\n        attribute_dictionary[\"pycode\"] = _pycode.lstrip(\"\\n\")\n\n        return attribute_dictionary\n\n    @staticmethod\n    def read_yml(path_to_card: str) -&gt; dict:\n\"\"\"\n        Reads \"normal\" wrangler project cards defined in YAML.\n\n        Args:\n            path_to_card: where the project card is\n\n        Returns: Attribute Dictionary for Project Card\n        \"\"\"\n        WranglerLogger.debug(\"Reading YAML-Style Project Card\")\n\n        with open(path_to_card, \"r\") as cardfile:\n            attribute_dictionary = yaml.safe_load(cardfile.read())\n            attribute_dictionary[\"file\"] = path_to_card\n\n        return attribute_dictionary\n\n    def write(self, filename: str = None):\n\"\"\"\n        Writes project card dictionary to YAML file\n        \"\"\"\n        if not filename:\n            from network_wrangler.utils.geo import make_slug\n\n            filename = make_slug(self.project) + \".yml\"\n\n        # import collections\n        # out_dict = collections.OrderedDict()\n        out_dict = {}\n        out_dict[\"project\"] = None\n        out_dict[\"tags\"] = \"\"\n        out_dict[\"dependencies\"] = \"\"\n        out_dict.update(self.__dict__)\n\n        with open(filename, \"w\") as outfile:\n            yaml.dump(out_dict, outfile, default_flow_style=False, sort_keys=False)\n\n        WranglerLogger.info(\"Wrote project card to: {}\".format(filename))\n\n    @staticmethod\n    def validate_project_card_schema(\n        card_file, card_schema_file: str = \"project_card.json\"\n    ) -&gt; bool:\n\"\"\"\n        Tests project card schema validity by evaluating if it conforms to the schemas\n        returns: boolean\n        \"\"\"\n        if not os.path.exists(card_schema_file):\n            base_path = os.path.join(\n                os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n            )\n            card_schema_file = os.path.join(base_path, card_schema_file)\n\n        with open(card_schema_file) as schema_json_file:\n            schema = json.load(schema_json_file)\n\n        with open(card_file, \"r\") as card:\n            card_json = yaml.safe_load(card)\n\n        try:\n            validate(card_json, schema)\n            return True\n\n        except ValidationError as exc:\n            msg = \"Failed Project Card validation: Validation Error\\n\"\n            msg += f\"   Project Card File Loc:{card_file}\\n\"\n            msg += f\"   Project Card Schema Loc:{card_schema_file}\\n\"\n            msg += f\"      {exc.message}\\n\"\n            WranglerLogger.error(msg)\n\n        except SchemaError as exc:\n            msg = \"Failed Project Card schema validation: Schema Error\"\n            msg += f\"   Project Card Schema Loc:{card_schema_file}\"\n            msg += f\"      {exc.message}\\n\"\n            WranglerLogger.error(msg)\n\n        except yaml.YAMLError as exc:\n            WranglerLogger.error(exc.message)\n\n    def has_any_tags(self, tags: Collection[str]) -&gt; bool:\n\"\"\"Returns true if ProjectCard has at lest one tag in tags list.\n\n        args:\n            tags: list of tags to search for\n        \"\"\"\n        if tags and set(tags).isdisjoint(self.tags):\n            WranglerLogger.debug(\n                f\"Project card tags: {self.tags} don't match search tags: {tags}\"\n            )\n            return False\n        return True\n\n    @staticmethod\n    def build_selection_query(\n        selection: Mapping[str, Any],\n        type: str = \"links\",\n        unique_ids: Collection[str] = [],\n        mode: Collection[str] = [\"drive_access\"],\n        ignore: Collection[str] = [],\n    ):\n\"\"\"Generates the query for selecting links within links_df.\n\n        Args:\n            selection: Selection dictionary from project card.\n            type: one of \"links\" or \"nodes\"\n            unique_ids: Properties which are unique in network and can be used\n                for selecting individual links or nodes without other properties.\n            mode: Limits selection to certain modes.\n                Defaults to [\"drive_access\"].\n            ignore: _description_. Defaults to [].\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n        sel_query = \"(\"\n        count = 0\n\n        selection_keys = [k for li in selection[type] for k, v in li.items()]\n\n        unique_ids_sel = list(set(unique_ids) &amp; set(selection_keys))\n\n        for li in selection[type]:\n            for key, value in li.items():\n\n                if key in ignore:\n                    continue\n\n                if unique_ids_sel and key not in unique_ids:\n                    continue\n\n                count = count + 1\n\n                if isinstance(value, list):\n                    sel_query = sel_query + \"(\"\n                    v = 1\n                    for i in value:  # building an OR query with each element in list\n                        if isinstance(i, str):\n                            sel_query = sel_query + key + '.str.contains(\"' + i + '\")'\n                        else:\n                            sel_query = sel_query + key + \"==\" + str(i)\n                        if v != len(value):\n                            sel_query = sel_query + \" or \"\n                            v = v + 1\n                    sel_query = sel_query + \")\"\n                elif isinstance(value, str):\n                    sel_query = sel_query + key + \"==\" + '\"' + str(value) + '\"'\n                else:\n                    sel_query = sel_query + key + \"==\" + str(value)\n\n                if not unique_ids_sel and count != (len(selection[type]) - len(ignore)):\n                    sel_query = sel_query + \" and \"\n\n                if unique_ids_sel and count != len(unique_ids_sel):\n                    sel_query = sel_query + \" and \"\n\n        if not unique_ids_sel:\n            if count &gt; 0:\n                sel_query = sel_query + \" and \"\n\n            # add mode query\n            mode_sel = \"(\" + \" or \".join(m + \"==1\" for m in mode) + \")\"\n            sel_query = sel_query + mode_sel\n\n        sel_query = sel_query + \")\"\n\n        return sel_query\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.__init__","title":"<code>__init__(attribute_dictonary)</code>","text":"<p>Constructor</p> Source code in <code>network_wrangler/projectcard.py</code> <pre><code>def __init__(self, attribute_dictonary: dict):\n\"\"\"\n    Constructor\n\n    args:\n    attribute_dictonary: a nested dictionary of attributes\n    \"\"\"\n    # add these first so they are first on write out\n    self.project = None\n    self.tags = \"\"\n    self.dependencies = \"\"\n\n    self.__dict__.update(attribute_dictonary)\n    self.valid = False\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.build_selection_query","title":"<code>build_selection_query(selection, type='links', unique_ids=[], mode=['drive_access'], ignore=[])</code>  <code>staticmethod</code>","text":"<p>Generates the query for selecting links within links_df.</p> <p>Parameters:</p> Name Type Description Default <code>selection</code> <code>Mapping[str, Any]</code> <p>Selection dictionary from project card.</p> required <code>type</code> <code>str</code> <p>one of \u201clinks\u201d or \u201cnodes\u201d</p> <code>'links'</code> <code>unique_ids</code> <code>Collection[str]</code> <p>Properties which are unique in network and can be used for selecting individual links or nodes without other properties.</p> <code>[]</code> <code>mode</code> <code>Collection[str]</code> <p>Limits selection to certain modes. Defaults to [\u201cdrive_access\u201d].</p> <code>['drive_access']</code> <code>ignore</code> <code>Collection[str]</code> <p>description. Defaults to [].</p> <code>[]</code> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> Source code in <code>network_wrangler/projectcard.py</code> <pre><code>@staticmethod\ndef build_selection_query(\n    selection: Mapping[str, Any],\n    type: str = \"links\",\n    unique_ids: Collection[str] = [],\n    mode: Collection[str] = [\"drive_access\"],\n    ignore: Collection[str] = [],\n):\n\"\"\"Generates the query for selecting links within links_df.\n\n    Args:\n        selection: Selection dictionary from project card.\n        type: one of \"links\" or \"nodes\"\n        unique_ids: Properties which are unique in network and can be used\n            for selecting individual links or nodes without other properties.\n        mode: Limits selection to certain modes.\n            Defaults to [\"drive_access\"].\n        ignore: _description_. Defaults to [].\n\n    Returns:\n        _type_: _description_\n    \"\"\"\n    sel_query = \"(\"\n    count = 0\n\n    selection_keys = [k for li in selection[type] for k, v in li.items()]\n\n    unique_ids_sel = list(set(unique_ids) &amp; set(selection_keys))\n\n    for li in selection[type]:\n        for key, value in li.items():\n\n            if key in ignore:\n                continue\n\n            if unique_ids_sel and key not in unique_ids:\n                continue\n\n            count = count + 1\n\n            if isinstance(value, list):\n                sel_query = sel_query + \"(\"\n                v = 1\n                for i in value:  # building an OR query with each element in list\n                    if isinstance(i, str):\n                        sel_query = sel_query + key + '.str.contains(\"' + i + '\")'\n                    else:\n                        sel_query = sel_query + key + \"==\" + str(i)\n                    if v != len(value):\n                        sel_query = sel_query + \" or \"\n                        v = v + 1\n                sel_query = sel_query + \")\"\n            elif isinstance(value, str):\n                sel_query = sel_query + key + \"==\" + '\"' + str(value) + '\"'\n            else:\n                sel_query = sel_query + key + \"==\" + str(value)\n\n            if not unique_ids_sel and count != (len(selection[type]) - len(ignore)):\n                sel_query = sel_query + \" and \"\n\n            if unique_ids_sel and count != len(unique_ids_sel):\n                sel_query = sel_query + \" and \"\n\n    if not unique_ids_sel:\n        if count &gt; 0:\n            sel_query = sel_query + \" and \"\n\n        # add mode query\n        mode_sel = \"(\" + \" or \".join(m + \"==1\" for m in mode) + \")\"\n        sel_query = sel_query + mode_sel\n\n    sel_query = sel_query + \")\"\n\n    return sel_query\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.has_any_tags","title":"<code>has_any_tags(tags)</code>","text":"<p>Returns true if ProjectCard has at lest one tag in tags list.</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Collection[str]</code> <p>list of tags to search for</p> required Source code in <code>network_wrangler/projectcard.py</code> <pre><code>def has_any_tags(self, tags: Collection[str]) -&gt; bool:\n\"\"\"Returns true if ProjectCard has at lest one tag in tags list.\n\n    args:\n        tags: list of tags to search for\n    \"\"\"\n    if tags and set(tags).isdisjoint(self.tags):\n        WranglerLogger.debug(\n            f\"Project card tags: {self.tags} don't match search tags: {tags}\"\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.read","title":"<code>read(path_to_card, validate=True)</code>  <code>staticmethod</code>","text":"<p>Reads and validates a Project card</p> <p>Returns a Project Card object</p> Source code in <code>network_wrangler/projectcard.py</code> <pre><code>@staticmethod\ndef read(path_to_card: str, validate: bool = True):\n\"\"\"\n    Reads and validates a Project card\n\n    args:\n    path_to_card: the path to the project card\n\n    Returns a Project Card object\n    \"\"\"\n    card_suffix = path_to_card.split(\".\")[-1].lower()\n\n    if card_suffix in [\"yaml\", \"yml\"]:\n        attribute_dictionary = ProjectCard.read_yml(path_to_card)\n    elif card_suffix in [\"wrangler\", \"wr\"]:\n        attribute_dictionary = ProjectCard.read_wrangler_card(path_to_card)\n    else:\n        msg = f\"Card should have a suffix of yaml, yml, wrangler, or wr. \\\n            Found suffix: {card_suffix}\"\n        raise ValueError(msg)\n\n    card = ProjectCard(attribute_dictionary)\n\n    if card.project in ProjectCard.UNSPECIFIED_PROJECT_NAMES:\n        msg = \"Card must have valid project name: {}\".format(path_to_card)\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n\n    card.valid = False\n    if validate:\n        card.valid = ProjectCard.validate_project_card_schema(path_to_card)\n\n    return card\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.read_wrangler_card","title":"<code>read_wrangler_card(path_to_card)</code>  <code>staticmethod</code>","text":"<p>Reads wrangler project cards with YAML front matter and then python code.</p> <p>Parameters:</p> Name Type Description Default <code>path_to_card</code> <code>str</code> <p>where the project card is</p> required Source code in <code>network_wrangler/projectcard.py</code> <pre><code>@staticmethod\ndef read_wrangler_card(path_to_card: str) -&gt; dict:\n\"\"\"\n    Reads wrangler project cards with YAML front matter and then python code.\n\n    Args:\n        path_to_card: where the project card is\n\n    Returns: Attribute Dictionary for Project Card\n    \"\"\"\n    WranglerLogger.debug(\"Reading Wrangler-Style Project Card\")\n\n    with open(path_to_card, \"r\") as cardfile:\n        delim = cardfile.readline()\n        WranglerLogger.debug(\"Using delimiter: {}\".format(delim))\n        _yaml, _pycode = cardfile.read().split(delim)\n        WranglerLogger.debug(\"_yaml: {}\\n_pycode: {}\".format(_yaml, _pycode))\n\n    attribute_dictionary = yaml.safe_load(_yaml.lower())\n    attribute_dictionary[\"file\"] = path_to_card\n    attribute_dictionary[\"pycode\"] = _pycode.lstrip(\"\\n\")\n\n    return attribute_dictionary\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.read_yml","title":"<code>read_yml(path_to_card)</code>  <code>staticmethod</code>","text":"<p>Reads \u201cnormal\u201d wrangler project cards defined in YAML.</p> <p>Parameters:</p> Name Type Description Default <code>path_to_card</code> <code>str</code> <p>where the project card is</p> required Source code in <code>network_wrangler/projectcard.py</code> <pre><code>@staticmethod\ndef read_yml(path_to_card: str) -&gt; dict:\n\"\"\"\n    Reads \"normal\" wrangler project cards defined in YAML.\n\n    Args:\n        path_to_card: where the project card is\n\n    Returns: Attribute Dictionary for Project Card\n    \"\"\"\n    WranglerLogger.debug(\"Reading YAML-Style Project Card\")\n\n    with open(path_to_card, \"r\") as cardfile:\n        attribute_dictionary = yaml.safe_load(cardfile.read())\n        attribute_dictionary[\"file\"] = path_to_card\n\n    return attribute_dictionary\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.validate_project_card_schema","title":"<code>validate_project_card_schema(card_file, card_schema_file='project_card.json')</code>  <code>staticmethod</code>","text":"<p>Tests project card schema validity by evaluating if it conforms to the schemas</p> Source code in <code>network_wrangler/projectcard.py</code> <pre><code>@staticmethod\ndef validate_project_card_schema(\n    card_file, card_schema_file: str = \"project_card.json\"\n) -&gt; bool:\n\"\"\"\n    Tests project card schema validity by evaluating if it conforms to the schemas\n    returns: boolean\n    \"\"\"\n    if not os.path.exists(card_schema_file):\n        base_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n        )\n        card_schema_file = os.path.join(base_path, card_schema_file)\n\n    with open(card_schema_file) as schema_json_file:\n        schema = json.load(schema_json_file)\n\n    with open(card_file, \"r\") as card:\n        card_json = yaml.safe_load(card)\n\n    try:\n        validate(card_json, schema)\n        return True\n\n    except ValidationError as exc:\n        msg = \"Failed Project Card validation: Validation Error\\n\"\n        msg += f\"   Project Card File Loc:{card_file}\\n\"\n        msg += f\"   Project Card Schema Loc:{card_schema_file}\\n\"\n        msg += f\"      {exc.message}\\n\"\n        WranglerLogger.error(msg)\n\n    except SchemaError as exc:\n        msg = \"Failed Project Card schema validation: Schema Error\"\n        msg += f\"   Project Card Schema Loc:{card_schema_file}\"\n        msg += f\"      {exc.message}\\n\"\n        WranglerLogger.error(msg)\n\n    except yaml.YAMLError as exc:\n        WranglerLogger.error(exc.message)\n</code></pre>"},{"location":"api/#network_wrangler.projectcard.ProjectCard.write","title":"<code>write(filename=None)</code>","text":"<p>Writes project card dictionary to YAML file</p> Source code in <code>network_wrangler/projectcard.py</code> <pre><code>def write(self, filename: str = None):\n\"\"\"\n    Writes project card dictionary to YAML file\n    \"\"\"\n    if not filename:\n        from network_wrangler.utils.geo import make_slug\n\n        filename = make_slug(self.project) + \".yml\"\n\n    # import collections\n    # out_dict = collections.OrderedDict()\n    out_dict = {}\n    out_dict[\"project\"] = None\n    out_dict[\"tags\"] = \"\"\n    out_dict[\"dependencies\"] = \"\"\n    out_dict.update(self.__dict__)\n\n    with open(filename, \"w\") as outfile:\n        yaml.dump(out_dict, outfile, default_flow_style=False, sort_keys=False)\n\n    WranglerLogger.info(\"Wrote project card to: {}\".format(filename))\n</code></pre>"},{"location":"api/#network_wrangler.Scenario","title":"<code>network_wrangler.Scenario</code>","text":"<p>         Bases: <code>object</code></p> <p>Holds information about a scenario.</p> <p>Typical usage example:</p> <pre><code>my_base_year_scenario = {\n    \"road_net\": RoadwayNetwork.read(\n        link_file=STPAUL_LINK_FILE,\n        node_file=STPAUL_NODE_FILE,\n        shape_file=STPAUL_SHAPE_FILE,\n        fast=True,\n    ),\n    \"transit_net\": TransitNetwork.read(STPAUL_DIR),\n}\n\n# create a future baseline scenario from a base by searching for all cards in a dir w/ baseline tag\nproject_card_directory = os.path.join(STPAUL_DIR, \"project_cards\")\nmy_scenario = Scenario.create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags = [ \"baseline2050\" ]\n)\n\n# check project card queue and then apply the projects\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\n\n# check applied projects, write it out, and create a summary report.\nmy_scenario.applied_projects\nmy_scenario.write(\"baseline\")\nmy_scenario.summarize(outfile = \"baseline2050summary.txt\")\n\n# Add some projects to create a build scenario based on a list of files.\nbuild_card_filenames = [\n    \"3_multiple_roadway_attribute_change.yml\",\n    \"multiple_changes.yml\",\n    \"4_simple_managed_lane.yml\",\n]\nmy_scenario.add_projects_from_files(build_card_filenames)\nmy_scenario.write(\"build2050\")\nmy_scenario.summarize(outfile = \"build2050summary.txt\")\n</code></pre> <p>Attributes:</p> Name Type Description <code>base_scenario</code> <p>dictionary representation of a scenario</p> <code>road_net</code> <p>instance of RoadwayNetwork for the scenario</p> <code>transit_net</code> <p>instance of TransitNetwork for the scenario</p> <code>project_cards</code> <p>Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.</p> <code>queued_projects</code> <p>Projects which are \u201cshovel ready\u201d - have had pre-requisits checked and done any required re-ordering. Similar to a git staging, project cards aren\u2019t recognized in this collecton once they are moved to applied.</p> <code>applied_projects</code> <p>list of project names that have been applied</p> <code>projects</code> <p>list of all projects either planned, queued, or applied</p> <code>prerequisites</code> <p>dictionary storing prerequiste information</p> <code>corequisites</code> <p>dictionary storing corequisite information</p> <code>conflicts</code> <p>dictionary storing conflict information</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class Scenario(object):\n\"\"\"\n    Holds information about a scenario.\n\n    Typical usage example:\n\n    ```python\n    my_base_year_scenario = {\n        \"road_net\": RoadwayNetwork.read(\n            link_file=STPAUL_LINK_FILE,\n            node_file=STPAUL_NODE_FILE,\n            shape_file=STPAUL_SHAPE_FILE,\n            fast=True,\n        ),\n        \"transit_net\": TransitNetwork.read(STPAUL_DIR),\n    }\n\n    # create a future baseline scenario from a base by searching for all cards in a dir w/ baseline tag\n    project_card_directory = os.path.join(STPAUL_DIR, \"project_cards\")\n    my_scenario = Scenario.create_scenario(\n        base_scenario=my_base_year_scenario,\n        card_search_dir=project_card_directory,\n        filter_tags = [ \"baseline2050\" ]\n    )\n\n    # check project card queue and then apply the projects\n    my_scenario.queued_projects\n    my_scenario.apply_all_projects()\n\n    # check applied projects, write it out, and create a summary report.\n    my_scenario.applied_projects\n    my_scenario.write(\"baseline\")\n    my_scenario.summarize(outfile = \"baseline2050summary.txt\")\n\n    # Add some projects to create a build scenario based on a list of files.\n    build_card_filenames = [\n        \"3_multiple_roadway_attribute_change.yml\",\n        \"multiple_changes.yml\",\n        \"4_simple_managed_lane.yml\",\n    ]\n    my_scenario.add_projects_from_files(build_card_filenames)\n    my_scenario.write(\"build2050\")\n    my_scenario.summarize(outfile = \"build2050summary.txt\")\n    ```\n\n    Attributes:\n        base_scenario: dictionary representation of a scenario\n        road_net: instance of RoadwayNetwork for the scenario\n        transit_net: instance of TransitNetwork for the scenario\n        project_cards: Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.\n        queued_projects: Projects which are \"shovel ready\" - have had pre-requisits checked and\n            done any required re-ordering. Similar to a git staging, project cards aren't recognized\n            in this collecton once they are moved to applied.\n        applied_projects: list of project names that have been applied\n        projects: list of all projects either planned, queued, or applied\n        prerequisites:  dictionary storing prerequiste information\n        corequisites:  dictionary storing corequisite information\n        conflicts: dictionary storing conflict information\n    \"\"\"\n\n    def __init__(\n        self,\n        base_scenario: Union[Scenario, dict],\n        project_card_list: list[ProjectCard] = [],\n        name=\"\",\n    ):\n\"\"\"\n        Constructor\n\n        args:\n        base_scenario: A base scenario object to base this isntance off of, or a dict which \n            describes the scenario attributes including applied projects and respective conflicts.\n            `{\"applied_projects\": [],\"conflicts\":{...}}`\n        project_card_list: Optional list of ProjectCard instances to add to planned projects. \n        \"\"\"\n        WranglerLogger.info(\n            f\"Creating Scenario with {len(project_card_list)} project cards\"\n        )\n\n        if type(base_scenario) == \"Scenario\":\n            base_scenario = base_scenario.__dict__\n\n        if not set(BASE_SCENARIO_REQUIRES) &lt;= set(base_scenario.keys()):\n            raise ValueError(f\"base_scenario must contain {BASE_SCENARIO_REQUIRES}\")\n\n        self.base_scenario = base_scenario\n        self.name = name\n        # if the base scenario had roadway or transit networks, use them as the basis.\n        self.road_net = copy.deepcopy(self.base_scenario.get(\"road_net\"))\n        self.transit_net = copy.deepcopy(self.base_scenario.get(\"transit_net\"))\n\n        self.project_cards = {}\n        self._planned_projects = []\n        self._queued_projects = None\n        self.applied_projects = self.base_scenario[\"applied_projects\"]\n\n        self.prerequisites = self.base_scenario.get(\"prerequisites\", {})\n        self.corequisites = self.base_scenario.get(\"corequisites\", {})\n        self.conflicts = self.base_scenario[\"conflicts\"]\n\n        for p in project_card_list:\n            self._add_project(p)\n\n    @property\n    def projects(self):\n        return self.applied_projects + self.queued_projects\n\n    @property\n    def queued_projects(self):\n\"\"\"Returns a list version of _queued_projects queue.\"\"\"\n        if not self._queued_projects:\n            self._check_projects_requirements_satisfied(self._planned_projects)\n            self._queued_projects = self.order_projects(self._planned_projects)\n        return list(self._queued_projects)\n\n    def __str__(self):\n        s = [\"{}: {}\".format(key, value) for key, value in self.__dict__.items()]\n        return \"\\n\".join(s)\n\n    @staticmethod\n    def create_scenario(\n        base_scenario: Union[\"Scenario\", dict] = {},\n        project_card_list=[],\n        project_card_file_list=[],\n        card_search_dir: str = \"\",\n        glob_search=\"\",\n        filter_tags: Collection[str] = None,\n        validate=True,\n    ) -&gt; Scenario:\n\"\"\"\n        Creates scenario from a base scenario and adds project cards.\n\n        Project cards can be added using any/all of the following methods:\n        1. List of ProjectCard instances\n        2. List of ProjectCard files\n        3. Directory and optional glob search to find project card files in\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        args:\n            base_scenario: base Scenario scenario instances of dictionary of attributes.\n            project_card_list: List of ProjectCard instances to create Scenario from.\n            project_card_file_list: List of ProjectCard files to create Scenario from.\n            card_search_dir (str): Directory to search for project card files in.\n            glob_search (str, optional): Optional glob search parameters for card_search_dir.\n            filter_tags (Collection[str], optional): If used, will only add the project card if\n                its tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n            validate (bool, optional): If True, will validate the projectcard before\n                being adding it to the scenario. Defaults to True.\n        \"\"\"\n\n        scenario = Scenario(base_scenario)\n        if project_card_list:\n            scenario.add_project_cards(\n                project_card_list, filter_tags=filter_tags, validate=validate\n            )\n        if project_card_file_list:\n            scenario.add_projects_from_files(\n                project_card_file_list, filter_tags=filter_tags, validate=validate\n            )\n        if card_search_dir:\n            scenario.add_projects_from_directory(\n                card_search_dir,\n                glob_search=glob_search,\n                filter_tags=filter_tags,\n                validate=validate,\n            )\n\n        return scenario\n\n    def _add_dependencies(self, project_name, dependencies: dict) -&gt; None:\n\"\"\"Add dependencies from a project card to relevant scenario variables.\n\n        Updates existing \"prerequisites\", \"corequisites\" and \"conflicts\".\n        Lowercases everything to enable string matching.\n\n        Args:\n            project_name: name of project you are adding dependencies for.\n            dependencies: Dictionary of depndencies by dependency type and list of associated projects.\n        \"\"\"\n        project_name = project_name.lower()\n        WranglerLogger.debug(f\"Adding {project_name} dependencies:\\n{dependencies}\")\n        for d in [\"prerequisites\", \"corequisites\", \"conflicts\"]:\n            if d not in dependencies:\n                continue\n            _dep = {k.lower(): list(map(str.lower, v)) for k, v in dependencies[d].items()}\n            self.__dict__[d].update({project_name: _dep})\n\n    def _add_project(\n        self,\n        project_card: ProjectCard,\n        validate: bool = True,\n        filter_tags: Collection[str] = [],\n    ) -&gt; None:\n\"\"\"Adds a single ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Resets scenario queued_projects.\n\n        Args:\n            project_card (ProjectCard): ProjectCard instance to add to scenario.\n            validate (bool, optional): If True, will validate the projectcard before\n                being adding it to the scenario. Defaults to True.\n            filter_tags (Collection[str], optional): If used, will only add the project card if\n                its tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n\n        \"\"\"\n        project_name = project_card.project.lower()\n        filter_tags = list(map(str.lower, filter_tags))\n\n        if project_name in self.projects:\n            raise ValueError(\n                f\"Names not unique from existing scenario projects: {project_card.project}\"\n            )\n\n        if filter_tags and set(project_card.tags).isdisjoint(set(filter_tags)):\n            WranglerLogger.debug(\n                f\"Skipping {project_name} - no overlapping tags with {filter_tags}.\"\n            )\n            return\n\n        if validate:\n            project_card.validate_project_card_schema(project_card.file)\n\n        WranglerLogger.info(f\"Adding {project_name} to scenario.\")\n        self.project_cards[project_name] = project_card\n        self._planned_projects.append(project_name)\n        self._queued_projects = None\n        if \"dependencies\" in project_card:\n            self._add_dependencies(project_name, project_card.dependencies)\n\n    def add_project_cards(\n        self,\n        project_card_list: Collection[ProjectCard],\n        validate: bool = True,\n        filter_tags: Collection[str] = [],\n    ) -&gt; None:\n\"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Args:\n            project_card_list (Collection[ProjectCard]): List of ProjectCard instances to add to\n                scenario.\n            validate (bool, optional): If True, will require each ProjectCard is validated before\n                being added to scenario. Defaults to True.\n            filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n                and only add those whose tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n        \"\"\"\n        for p in project_card_list:\n            self._add_project(p, validate=validate, filter_tags=filter_tags)\n\n    def add_projects_from_files(\n        self,\n        project_card_file_list: Collection[str],\n        validate: bool = True,\n        filter_tags: Collection[str] = [],\n    ) -&gt; None:\n\"\"\"Adds a list of ProjectCard files  to the Scenario.\n\n        Creates ProjectCard instances from each file.\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Args:\n            project_card_file_list (Collection[str]): List of project card files to add to scenario.\n            validate (bool, optional): If True, will require each ProjectCard is validated before\n                being added to scenario. Defaults to True.\n            filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n                and only add those whose tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n        \"\"\"\n        _project_card_list = [\n            ProjectCard.read(_pc_file) for _pc_file in project_card_file_list\n        ]\n        self.add_project_cards(\n            _project_card_list, validate=validate, filter_tags=filter_tags\n        )\n\n    def add_projects_from_directory(\n        self,\n        search_dir: str,\n        glob_search: str = \"\",\n        validate: bool = True,\n        filter_tags: Collection[str] = [],\n    ) -&gt; None:\n\"\"\"Adds ProjectCards from project card files found in a directory to the Scenario.\n\n        Finds files in directory which have ProjectCard.FILE_TYPE suffices.\n        If provided, will filter directory search using glob_search pattern.\n        Creates ProjectCard instances from each file.\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Args:\n            search_dir (str): Search directory.\n            glob_search (str, optional): Optional glob search parameters.\n            validate (bool, optional): If True, will require each ProjectCard is validated before\n                being added to scenario. Defaults to True.\n            filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n                and only add those whse tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n        \"\"\"\n        _project_card_file_list = project_card_files_from_directory(\n            search_dir, glob_search\n        )\n        self.add_projects_from_files(\n            _project_card_file_list, validate=validate, filter_tags=filter_tags\n        )\n\n    def _check_projects_requirements_satisfied(self, project_list: Collection[str]):\n\"\"\"Checks that all requirements are satisified to apply this specific set of projects including:\n\n        1. has an associaed project card\n        2. is in scenario's planned projects\n        3. pre-requisites satisfied\n        4. co-requisies satisfied by applied or co-applied projects\n        5. no conflicing applied or co-applied projects\n\n        Args:\n            project_name (str): name of project.\n            co_applied_project_list (Collection[str]): List of projects that will be applied with this project.\n        \"\"\"\n        self._check_projects_planned(project_list)\n        self._check_projects_have_project_cards(project_list)\n        self._check_projects_prerequisites(project_list)\n        self._check_projects_corequisites(project_list)\n        self._check_projects_conflicts(project_list)\n\n    def _check_projects_planned(self, project_names: Collection[str]) -&gt; None:\n\"\"\"Checks that a list of projects are in the scenario's planned projects.\"\"\"\n        _missing_ps = [\n            p for p in self._planned_projects if p not in self._planned_projects\n        ]\n        if _missing_ps:\n            raise ValueError(\n                f\"Projects are not in planned projects:\\n {_missing_ps}. Add them by \\\n                using add_project_cards(), add_projects_from_files(), or add_projects_from_directory().\"\n            )\n\n    def _check_projects_have_project_cards(self, project_list: Collection[str]) -&gt; bool:\n\"\"\"Checks that a list of projects has an associated project card in the scenario.\"\"\"\n        _missing = [p for p in project_list if p not in self.project_cards]\n        if _missing:\n            WranglerLogger.error(\n                f\"Projects referenced which are missing project cards: {_missing}\"\n            )\n            return False\n        return True\n\n    def _check_projects_prerequisites(self, project_names: str) -&gt; None:\n\"\"\"Checks that a list of projects' pre-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.prerequisites)):\n            return\n        _prereqs = set(\n            [self.prerequisites[p] for p in project_names if p in self.prerequisites]\n        )\n        _projects_applied = set(self.applied_projects + project_names)\n        _missing = list(_prereqs - _projects_applied)\n        if _missing:\n            raise ValueError(f\"Missing {len(_missing)} pre-requites: {_missing}\")\n\n    def _check_projects_corequisites(self, project_names: str) -&gt; None:\n\"\"\"Checks that a list of projects' co-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.corequisites)):\n            return\n        _coreqs = set(\n            [self.corequisites[p] for p in project_names if p in self.corequisites]\n        )\n        _projects_applied = set(self.applied_projects + project_names)\n        _missing = list(_coreqs - _projects_applied)\n        if _missing:\n            raise ValueError(f\"Missing {len(_missing)} corequites: {_missing}\")\n\n    def _check_projects_conflicts(self, project_names: str) -&gt; None:\n\"\"\"Checks that a list of projects' conflicts have not been or will be applied to scenario.\"\"\"\n        projects_to_check = project_names + self.applied_projects\n        if set(projects_to_check).isdisjoint(set(self.conflicts)):\n            return\n        _conflicts = list(\n            set([self.conflicts[p] for p in projects_to_check if p in self.conflicts])\n        )\n        _conflict_problems = [p for p in _conflicts if p in projects_to_check]\n        if _conflict_problems:\n            WranglerLogger.warning(f\"Conflict Problems: \\n{_conflict_problems}\")\n            _conf_dict = {\n                k: v\n                for k, v in self.conflicts.items()\n                if k in projects_to_check and not set(v).isdisjoint(set(_conflict_problems))\n            }\n            WranglerLogger.debug(f\"Problematic Conflicts:\\n{_conf_dict}\")\n            raise ValueError(f\"Found {len(_conflicts)} conflicts: {_conflict_problems}\")\n\n    def order_projects(self, project_list: Collection[str]) -&gt; deque:\n\"\"\"\n        Orders a list of projects based on moving up pre-requisites into a deque.\n\n        args:\n            project_list: list of projects to order\n\n        Returns: deque for applying projects.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n        assert self._check_projects_have_project_cards(project_list)\n\n        # build prereq (adjacency) list for topological sort\n        adjacency_list = defaultdict(list)\n        visited_list = defaultdict()\n\n        for project in project_list:\n            visited_list[project] = False\n            if not self.prerequisites.get(project):\n                continue\n            for prereq in self.prerequisites[project]:\n                # this will always be true, else would have been flagged in missing \\\n                # prerequsite check, but just in case\n                if prereq.lower() in project_list:\n                    adjacency_list[prereq.lower()] = [project]\n\n        # sorted_project_names is topological sorted project card names (based on prerequsiite)\n        _ordered_projects = topological_sort(\n            adjacency_list=adjacency_list, visited_list=visited_list\n        )\n\n        if not set(_ordered_projects) == set(project_list):\n            _missing = list(set(project_list) - set(_ordered_projects))\n            raise ValueError(f\"Project sort resulted in missing projects:_missing\")\n\n        project_deque = deque(_ordered_projects)\n\n        WranglerLogger.debug(f\"Ordered Projects:\\n{project_deque}\")\n\n        return project_deque\n\n    def apply_all_projects(self):\n\"\"\"Applies all planned projects in the queue.\"\"\"\n        # Call this to make sure projects are appropriately queued in hidden variable.\n        self.queued_projects\n\n        # Use hidden variable.\n        while self._queued_projects:\n            self._apply_project(self._queued_projects.popleft())\n\n        # set this so it will trigger re-queuing any more projects.\n        self._queued_projects = None\n\n    def _apply_change(self, change: dict) -&gt; None:\n\"\"\"Applies a specific change specified in a project card.\n\n        \"category\" must be in at least one of:\n        - ROADWAY_CATEGORIES\n        - TRANSIT_CATEGORIES\n\n        Args:\n            change (dict): dictionary of a project card change\n        \"\"\"\n        if change[\"category\"] in ProjectCard.ROADWAY_CATEGORIES:\n            if not self.road_net:\n                raise (\"Missing Roadway Network\")\n            self.road_net.apply(change)\n        if change[\"category\"] in ProjectCard.TRANSIT_CATEGORIES:\n            if not self.transit_net:\n                raise (\"Missing Transit Network\")\n            self.transit_net.apply(change)\n        if (\n            change[\"category\"] in ProjectCard.SECONDARY_TRANSIT_CATEGORIES\n            and self.transit_net\n        ):\n            self.transit_net.apply(change)\n\n        if (\n            change[\"category\"]\n            not in ProjectCard.TRANSIT_CATEGORIES + ProjectCard.ROADWAY_CATEGORIES\n        ):\n            raise ValueError(f\"Don't understand project category: {change['category']}\")\n\n    def _apply_project(self, project_name: str) -&gt; None:\n\"\"\"Applies project card to scenario.\n\n        If a list of changes is specified in referenced project card, iterates through each change.\n\n        Args:\n            project_name (str): name of project to be applied.\n        \"\"\"\n        project_name = project_name.lower()\n\n        WranglerLogger.info(f\"Applying {project_name}\")\n\n        p = self.project_cards[project_name].__dict__\n        if \"changes\" in p:\n            for pc in p[\"changes\"]:\n                pc[\"project\"] = p[\"project\"]\n                self._apply_change(pc)\n\n        else:\n            self._apply_change(p)\n\n        self._planned_projects.remove(project_name)\n        self.applied_projects.append(project_name)\n\n    def apply_projects(self, project_list: Collection[str]):\n\"\"\"\n        Applies a specific list of projects from the planned project queue.\n\n        Will order the list of projects based on pre-requisites.\n\n        NOTE: does not check co-requisites b/c that isn't possible when applying a sin\n\n        Args:\n            project_list: List of projects to be applied. All need to be in the planned project queue.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n\n        self._check_projects_requirements_satisfied(project_list)\n        ordered_project_queue = self.order_projects(project_list)\n\n        while ordered_project_queue:\n            self._apply_project(ordered_project_queue.popleft())\n\n        # Set so that when called again it will retrigger queueing from planned projects.\n        self._ordered_projects = None\n\n    def write(self, path: Union(Path, str), name: str) -&gt; None:\n\"\"\"_summary_\n\n        Args:\n            path: Path to write scenario networks and scenario summary to.\n            name: Name to use.\n        \"\"\"\n        self.road_net.write(path, name)\n        self.transit_net.write(path, name)\n        self.summarize(outfile=os.path.join(path, name))\n\n    def summarize(\n        self, project_detail: bool = True, outfile: str = \"\", mode: str = \"a\"\n    ) -&gt; str:\n\"\"\"\n        A high level summary of the created scenario.\n\n        Args:\n            project_detail: If True (default), will write out project card summaries.\n            outfile: If specified, will write scenario summary to text file.\n            mode: Outfile open mode. 'a' to append 'w' to overwrite.\n\n        Returns:\n            string of summary\n\n        \"\"\"\n\n        WranglerLogger.info(f\"Summarizing Scenario {self.name}\")\n        report_str = \"------------------------------\\n\"\n        report_str += f\"Scenario created on {datetime.now()}\\n\"\n\n        report_str += \"Base Scenario:\\n\"\n        report_str += \"--Road Network:\\n\"\n        report_str += f\"----Link File: {self.base_scenario['road_net'].link_file}\\n\"\n        report_str += f\"----Node File: {self.base_scenario['road_net'].node_file}\\n\"\n        report_str += f\"----Shape File: {self.base_scenario['road_net'].shape_file}\\n\"\n        report_str += \"--Transit Network:\\n\"\n        report_str += f\"----Feed Path: {self.base_scenario['transit_net'].feed_path}\\n\"\n\n        report_str += \"\\nProject Cards:\\n -\"\n        report_str += \"\\n-\".join([pc.file for p, pc in self.project_cards.items()])\n\n        report_str += \"\\nApplied Projects:\\n-\"\n        report_str += \"\\n-\".join(self.applied_projects)\n\n        if project_detail:\n            report_str += \"\\n---Project Card Details---\\n\"\n            for p in self.project_cards:\n                report_str += \"\\n{}\".format(\n                    pprint.pformat(\n                        [self.project_cards[p].__dict__ for p in self.applied_projects]\n                    )\n                )\n\n        if outfile:\n            with open(outfile, mode) as f:\n                f.write(report_str)\n            WranglerLogger.info(f\"Wrote Scenario Report to: {outfile}\")\n\n        return report_str\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.queued_projects","title":"<code>queued_projects</code>  <code>property</code>","text":"<p>Returns a list version of _queued_projects queue.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.__init__","title":"<code>__init__(base_scenario, project_card_list=[], name='')</code>","text":"<p>Constructor</p> A base scenario object to base this isntance off of, or a dict which <p>describes the scenario attributes including applied projects and respective conflicts. <code>{\"applied_projects\": [],\"conflicts\":{...}}</code></p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_scenario: Union[Scenario, dict],\n    project_card_list: list[ProjectCard] = [],\n    name=\"\",\n):\n\"\"\"\n    Constructor\n\n    args:\n    base_scenario: A base scenario object to base this isntance off of, or a dict which \n        describes the scenario attributes including applied projects and respective conflicts.\n        `{\"applied_projects\": [],\"conflicts\":{...}}`\n    project_card_list: Optional list of ProjectCard instances to add to planned projects. \n    \"\"\"\n    WranglerLogger.info(\n        f\"Creating Scenario with {len(project_card_list)} project cards\"\n    )\n\n    if type(base_scenario) == \"Scenario\":\n        base_scenario = base_scenario.__dict__\n\n    if not set(BASE_SCENARIO_REQUIRES) &lt;= set(base_scenario.keys()):\n        raise ValueError(f\"base_scenario must contain {BASE_SCENARIO_REQUIRES}\")\n\n    self.base_scenario = base_scenario\n    self.name = name\n    # if the base scenario had roadway or transit networks, use them as the basis.\n    self.road_net = copy.deepcopy(self.base_scenario.get(\"road_net\"))\n    self.transit_net = copy.deepcopy(self.base_scenario.get(\"transit_net\"))\n\n    self.project_cards = {}\n    self._planned_projects = []\n    self._queued_projects = None\n    self.applied_projects = self.base_scenario[\"applied_projects\"]\n\n    self.prerequisites = self.base_scenario.get(\"prerequisites\", {})\n    self.corequisites = self.base_scenario.get(\"corequisites\", {})\n    self.conflicts = self.base_scenario[\"conflicts\"]\n\n    for p in project_card_list:\n        self._add_project(p)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.add_project_cards","title":"<code>add_project_cards(project_card_list, validate=True, filter_tags=[])</code>","text":"<p>Adds a list of ProjectCard instances to the Scenario.</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>project_card_list</code> <code>Collection[ProjectCard]</code> <p>List of ProjectCard instances to add to scenario.</p> required <code>validate</code> <code>bool</code> <p>If True, will require each ProjectCard is validated before being added to scenario. Defaults to True.</p> <code>True</code> <code>filter_tags</code> <code>Collection[str]</code> <p>If used, will filter ProjectCard instances and only add those whose tags match one or more of these filter_tags. Defaults to [] which means no tag-filtering will occur.</p> <code>[]</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def add_project_cards(\n    self,\n    project_card_list: Collection[ProjectCard],\n    validate: bool = True,\n    filter_tags: Collection[str] = [],\n) -&gt; None:\n\"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        project_card_list (Collection[ProjectCard]): List of ProjectCard instances to add to\n            scenario.\n        validate (bool, optional): If True, will require each ProjectCard is validated before\n            being added to scenario. Defaults to True.\n        filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n            and only add those whose tags match one or more of these filter_tags. Defaults to []\n            which means no tag-filtering will occur.\n    \"\"\"\n    for p in project_card_list:\n        self._add_project(p, validate=validate, filter_tags=filter_tags)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.add_projects_from_directory","title":"<code>add_projects_from_directory(search_dir, glob_search='', validate=True, filter_tags=[])</code>","text":"<p>Adds ProjectCards from project card files found in a directory to the Scenario.</p> <p>Finds files in directory which have ProjectCard.FILE_TYPE suffices. If provided, will filter directory search using glob_search pattern. Creates ProjectCard instances from each file. Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>search_dir</code> <code>str</code> <p>Search directory.</p> required <code>glob_search</code> <code>str</code> <p>Optional glob search parameters.</p> <code>''</code> <code>validate</code> <code>bool</code> <p>If True, will require each ProjectCard is validated before being added to scenario. Defaults to True.</p> <code>True</code> <code>filter_tags</code> <code>Collection[str]</code> <p>If used, will filter ProjectCard instances and only add those whse tags match one or more of these filter_tags. Defaults to [] which means no tag-filtering will occur.</p> <code>[]</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def add_projects_from_directory(\n    self,\n    search_dir: str,\n    glob_search: str = \"\",\n    validate: bool = True,\n    filter_tags: Collection[str] = [],\n) -&gt; None:\n\"\"\"Adds ProjectCards from project card files found in a directory to the Scenario.\n\n    Finds files in directory which have ProjectCard.FILE_TYPE suffices.\n    If provided, will filter directory search using glob_search pattern.\n    Creates ProjectCard instances from each file.\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        search_dir (str): Search directory.\n        glob_search (str, optional): Optional glob search parameters.\n        validate (bool, optional): If True, will require each ProjectCard is validated before\n            being added to scenario. Defaults to True.\n        filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n            and only add those whse tags match one or more of these filter_tags. Defaults to []\n            which means no tag-filtering will occur.\n    \"\"\"\n    _project_card_file_list = project_card_files_from_directory(\n        search_dir, glob_search\n    )\n    self.add_projects_from_files(\n        _project_card_file_list, validate=validate, filter_tags=filter_tags\n    )\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.add_projects_from_files","title":"<code>add_projects_from_files(project_card_file_list, validate=True, filter_tags=[])</code>","text":"<p>Adds a list of ProjectCard files  to the Scenario.</p> <p>Creates ProjectCard instances from each file. Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>project_card_file_list</code> <code>Collection[str]</code> <p>List of project card files to add to scenario.</p> required <code>validate</code> <code>bool</code> <p>If True, will require each ProjectCard is validated before being added to scenario. Defaults to True.</p> <code>True</code> <code>filter_tags</code> <code>Collection[str]</code> <p>If used, will filter ProjectCard instances and only add those whose tags match one or more of these filter_tags. Defaults to [] which means no tag-filtering will occur.</p> <code>[]</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def add_projects_from_files(\n    self,\n    project_card_file_list: Collection[str],\n    validate: bool = True,\n    filter_tags: Collection[str] = [],\n) -&gt; None:\n\"\"\"Adds a list of ProjectCard files  to the Scenario.\n\n    Creates ProjectCard instances from each file.\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        project_card_file_list (Collection[str]): List of project card files to add to scenario.\n        validate (bool, optional): If True, will require each ProjectCard is validated before\n            being added to scenario. Defaults to True.\n        filter_tags (Collection[str], optional): If used, will filter ProjectCard instances\n            and only add those whose tags match one or more of these filter_tags. Defaults to []\n            which means no tag-filtering will occur.\n    \"\"\"\n    _project_card_list = [\n        ProjectCard.read(_pc_file) for _pc_file in project_card_file_list\n    ]\n    self.add_project_cards(\n        _project_card_list, validate=validate, filter_tags=filter_tags\n    )\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_all_projects","title":"<code>apply_all_projects()</code>","text":"<p>Applies all planned projects in the queue.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_all_projects(self):\n\"\"\"Applies all planned projects in the queue.\"\"\"\n    # Call this to make sure projects are appropriately queued in hidden variable.\n    self.queued_projects\n\n    # Use hidden variable.\n    while self._queued_projects:\n        self._apply_project(self._queued_projects.popleft())\n\n    # set this so it will trigger re-queuing any more projects.\n    self._queued_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_projects","title":"<code>apply_projects(project_list)</code>","text":"<p>Applies a specific list of projects from the planned project queue.</p> <p>Will order the list of projects based on pre-requisites.</p> <p>NOTE: does not check co-requisites b/c that isn\u2019t possible when applying a sin</p> <p>Parameters:</p> Name Type Description Default <code>project_list</code> <code>Collection[str]</code> <p>List of projects to be applied. All need to be in the planned project queue.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_projects(self, project_list: Collection[str]):\n\"\"\"\n    Applies a specific list of projects from the planned project queue.\n\n    Will order the list of projects based on pre-requisites.\n\n    NOTE: does not check co-requisites b/c that isn't possible when applying a sin\n\n    Args:\n        project_list: List of projects to be applied. All need to be in the planned project queue.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n\n    self._check_projects_requirements_satisfied(project_list)\n    ordered_project_queue = self.order_projects(project_list)\n\n    while ordered_project_queue:\n        self._apply_project(ordered_project_queue.popleft())\n\n    # Set so that when called again it will retrigger queueing from planned projects.\n    self._ordered_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.create_scenario","title":"<code>create_scenario(base_scenario={}, project_card_list=[], project_card_file_list=[], card_search_dir='', glob_search='', filter_tags=None, validate=True)</code>  <code>staticmethod</code>","text":"<p>Creates scenario from a base scenario and adds project cards.</p> <p>Project cards can be added using any/all of the following methods: 1. List of ProjectCard instances 2. List of ProjectCard files 3. Directory and optional glob search to find project card files in</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>base_scenario</code> <code>Union[Scenario, dict]</code> <p>base Scenario scenario instances of dictionary of attributes.</p> <code>{}</code> <code>project_card_list</code> <p>List of ProjectCard instances to create Scenario from.</p> <code>[]</code> <code>project_card_file_list</code> <p>List of ProjectCard files to create Scenario from.</p> <code>[]</code> <code>card_search_dir</code> <code>str</code> <p>Directory to search for project card files in.</p> <code>''</code> <code>glob_search</code> <code>str</code> <p>Optional glob search parameters for card_search_dir.</p> <code>''</code> <code>filter_tags</code> <code>Collection[str]</code> <p>If used, will only add the project card if its tags match one or more of these filter_tags. Defaults to [] which means no tag-filtering will occur.</p> <code>None</code> <code>validate</code> <code>bool</code> <p>If True, will validate the projectcard before being adding it to the scenario. Defaults to True.</p> <code>True</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>@staticmethod\ndef create_scenario(\n    base_scenario: Union[\"Scenario\", dict] = {},\n    project_card_list=[],\n    project_card_file_list=[],\n    card_search_dir: str = \"\",\n    glob_search=\"\",\n    filter_tags: Collection[str] = None,\n    validate=True,\n) -&gt; Scenario:\n\"\"\"\n    Creates scenario from a base scenario and adds project cards.\n\n    Project cards can be added using any/all of the following methods:\n    1. List of ProjectCard instances\n    2. List of ProjectCard files\n    3. Directory and optional glob search to find project card files in\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    args:\n        base_scenario: base Scenario scenario instances of dictionary of attributes.\n        project_card_list: List of ProjectCard instances to create Scenario from.\n        project_card_file_list: List of ProjectCard files to create Scenario from.\n        card_search_dir (str): Directory to search for project card files in.\n        glob_search (str, optional): Optional glob search parameters for card_search_dir.\n        filter_tags (Collection[str], optional): If used, will only add the project card if\n            its tags match one or more of these filter_tags. Defaults to []\n            which means no tag-filtering will occur.\n        validate (bool, optional): If True, will validate the projectcard before\n            being adding it to the scenario. Defaults to True.\n    \"\"\"\n\n    scenario = Scenario(base_scenario)\n    if project_card_list:\n        scenario.add_project_cards(\n            project_card_list, filter_tags=filter_tags, validate=validate\n        )\n    if project_card_file_list:\n        scenario.add_projects_from_files(\n            project_card_file_list, filter_tags=filter_tags, validate=validate\n        )\n    if card_search_dir:\n        scenario.add_projects_from_directory(\n            card_search_dir,\n            glob_search=glob_search,\n            filter_tags=filter_tags,\n            validate=validate,\n        )\n\n    return scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.order_projects","title":"<code>order_projects(project_list)</code>","text":"<p>Orders a list of projects based on moving up pre-requisites into a deque.</p> <p>Parameters:</p> Name Type Description Default <code>project_list</code> <code>Collection[str]</code> <p>list of projects to order</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def order_projects(self, project_list: Collection[str]) -&gt; deque:\n\"\"\"\n    Orders a list of projects based on moving up pre-requisites into a deque.\n\n    args:\n        project_list: list of projects to order\n\n    Returns: deque for applying projects.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n    assert self._check_projects_have_project_cards(project_list)\n\n    # build prereq (adjacency) list for topological sort\n    adjacency_list = defaultdict(list)\n    visited_list = defaultdict()\n\n    for project in project_list:\n        visited_list[project] = False\n        if not self.prerequisites.get(project):\n            continue\n        for prereq in self.prerequisites[project]:\n            # this will always be true, else would have been flagged in missing \\\n            # prerequsite check, but just in case\n            if prereq.lower() in project_list:\n                adjacency_list[prereq.lower()] = [project]\n\n    # sorted_project_names is topological sorted project card names (based on prerequsiite)\n    _ordered_projects = topological_sort(\n        adjacency_list=adjacency_list, visited_list=visited_list\n    )\n\n    if not set(_ordered_projects) == set(project_list):\n        _missing = list(set(project_list) - set(_ordered_projects))\n        raise ValueError(f\"Project sort resulted in missing projects:_missing\")\n\n    project_deque = deque(_ordered_projects)\n\n    WranglerLogger.debug(f\"Ordered Projects:\\n{project_deque}\")\n\n    return project_deque\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.summarize","title":"<code>summarize(project_detail=True, outfile='', mode='a')</code>","text":"<p>A high level summary of the created scenario.</p> <p>Parameters:</p> Name Type Description Default <code>project_detail</code> <code>bool</code> <p>If True (default), will write out project card summaries.</p> <code>True</code> <code>outfile</code> <code>str</code> <p>If specified, will write scenario summary to text file.</p> <code>''</code> <code>mode</code> <code>str</code> <p>Outfile open mode. \u2018a\u2019 to append \u2018w\u2019 to overwrite.</p> <code>'a'</code> <p>Returns:</p> Type Description <code>str</code> <p>string of summary</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def summarize(\n    self, project_detail: bool = True, outfile: str = \"\", mode: str = \"a\"\n) -&gt; str:\n\"\"\"\n    A high level summary of the created scenario.\n\n    Args:\n        project_detail: If True (default), will write out project card summaries.\n        outfile: If specified, will write scenario summary to text file.\n        mode: Outfile open mode. 'a' to append 'w' to overwrite.\n\n    Returns:\n        string of summary\n\n    \"\"\"\n\n    WranglerLogger.info(f\"Summarizing Scenario {self.name}\")\n    report_str = \"------------------------------\\n\"\n    report_str += f\"Scenario created on {datetime.now()}\\n\"\n\n    report_str += \"Base Scenario:\\n\"\n    report_str += \"--Road Network:\\n\"\n    report_str += f\"----Link File: {self.base_scenario['road_net'].link_file}\\n\"\n    report_str += f\"----Node File: {self.base_scenario['road_net'].node_file}\\n\"\n    report_str += f\"----Shape File: {self.base_scenario['road_net'].shape_file}\\n\"\n    report_str += \"--Transit Network:\\n\"\n    report_str += f\"----Feed Path: {self.base_scenario['transit_net'].feed_path}\\n\"\n\n    report_str += \"\\nProject Cards:\\n -\"\n    report_str += \"\\n-\".join([pc.file for p, pc in self.project_cards.items()])\n\n    report_str += \"\\nApplied Projects:\\n-\"\n    report_str += \"\\n-\".join(self.applied_projects)\n\n    if project_detail:\n        report_str += \"\\n---Project Card Details---\\n\"\n        for p in self.project_cards:\n            report_str += \"\\n{}\".format(\n                pprint.pformat(\n                    [self.project_cards[p].__dict__ for p in self.applied_projects]\n                )\n            )\n\n    if outfile:\n        with open(outfile, mode) as f:\n            f.write(report_str)\n        WranglerLogger.info(f\"Wrote Scenario Report to: {outfile}\")\n\n    return report_str\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.write","title":"<code>write(path, name)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union(Path, str)</code> <p>Path to write scenario networks and scenario summary to.</p> required <code>name</code> <code>str</code> <p>Name to use.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def write(self, path: Union(Path, str), name: str) -&gt; None:\n\"\"\"_summary_\n\n    Args:\n        path: Path to write scenario networks and scenario summary to.\n        name: Name to use.\n    \"\"\"\n    self.road_net.write(path, name)\n    self.transit_net.write(path, name)\n    self.summarize(outfile=os.path.join(path, name))\n</code></pre>"},{"location":"api/#network_wrangler.RoadwayNetwork","title":"<code>network_wrangler.RoadwayNetwork</code>","text":"<p>         Bases: <code>object</code></p> <p>Representation of a Roadway Network.</p> <p>Typical usage example:</p> <pre><code>net = RoadwayNetwork.read(\n    link_file=MY_LINK_FILE,\n    node_file=MY_NODE_FILE,\n    shape_file=MY_SHAPE_FILE,\n)\nmy_selection = {\n    \"link\": [{\"name\": [\"I 35E\"]}],\n    \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n    \"B\": {\"osm_node_id\": \"2564047368\"},\n}\nnet.select_roadway_features(my_selection)\n\nmy_change = [\n    {\n        'property': 'lanes',\n        'existing': 1,\n        'set': 2,\n    },\n    {\n        'property': 'drive_access',\n        'set': 0,\n    },\n]\n\nmy_net.apply_roadway_feature_change(\n    my_net.select_roadway_features(my_selection),\n    my_change\n)\n\n    net = create_managed_lane_network(net)\n    net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n    _, disconnected_nodes = net.assess_connectivity(\n        mode=\"walk\",\n        ignore_end_nodes=True,\n        nodes=self.m_nodes_df,\n        links=self.m_links_df\n    )\n    net.write(filename=my_out_prefix, path=my_dir, for_model = True)\n</code></pre> <p>Attributes:</p> Name Type Description <code>nodes_df</code> <code>GeoDataFrame</code> <p>node data</p> <code>links_df</code> <code>GeoDataFrame</code> <p>link data, including start and end nodes and associated shape</p> <code>shapes_df</code> <code>GeoDataFrame</code> <p>detailed shape data</p> <code>selections</code> <code>dict</code> <p>dictionary storing selections in case they are made repeatedly</p> <code>BOOL_PROPERTIES</code> <code>list</code> <p>list of properties which should be coerced to booleans</p> <code>STR_PROPERTIES</code> <code>list</code> <p>list of properties which should be coerced to strings</p> <code>INT_PROPERTIES</code> <code>list</code> <p>list of properties which should be coerced to integers</p> <code>CRS</code> <code>str</code> <p>coordinate reference system in PROJ4 format. See https://proj.org/operations/projections/index.html#</p> <code>ESPG</code> <code>int</code> <p>integer representing coordinate system https://epsg.io/</p> <code>NODE_FOREIGN_KEY_TO_LINK</code> <code>str</code> <p>column in <code>nodes_df</code> associated with the LINK_FOREIGN_KEY</p> <code>LINK_FOREIGN_KEY_TO_NODE</code> <code>list(str</code> <p>list of columns in <code>links_df</code> that represent the NODE_FOREIGN_KEY</p> <code>UNIQUE_LINK_KEY</code> <code>str</code> <p>column that is a unique key for links</p> <code>UNIQUE_NODE_KEY</code> <code>str</code> <p>column that is a unique key for nodes</p> <code>UNIQUE_SHAPE_KEY</code> <code>str</code> <p>column that is a unique shape key</p> <code>UNIQUE_MODEL_LINK_IDENTIFIERS</code> <code>list(str</code> <p>list of all unique identifiers for links, including the UNIQUE_LINK_KEY</p> <code>EXPLICIT_LINK_IDENTIFIERS</code> <code>list(str</code> <p>list of identifiers which are explicit enough to use in project selection by themselves. Includes UNIQUE_MODEL_LINK_IDENFIERS as well as some identifiers which may be split across model links such as osm_link_id.</p> <code>UNIQUE_NODE_IDENTIFIERS</code> <code>list(str</code> <p>list of all unique identifiers for nodes, including the UNIQUE_NODE_KEY</p> <code>SEARCH_BREADTH</code> <code>int</code> <p>initial number of links from name-based selection that are traveresed before trying another shortest path when searching for paths between A and B node</p> <code>MAX_SEARCH_BREADTH</code> <code>int</code> <p>maximum number of links traversed between links that match the searched name when searching for paths between A and B node</p> <code>SP_WEIGHT_FACTOR</code> <code>Union(int, float</code> <p>penalty assigned for each degree of distance between a link and a link with the searched-for name when searching for paths between A and B node</p> <code>MANAGED_LANES_TO_NODE_ID_SCALAR</code> <code>int</code> <p>scalar value added to the general purpose lanes\u2019 <code>model_node_id</code> when creating an associated node for a parallel managed lane</p> <code>MANAGED_LANES_TO_LINK_ID_SCALAR</code> <code>int</code> <p>scalar value added to the general purpose lanes\u2019 <code>model_link_id</code> when creating an associated link for a parallel managed lane</p> <code>MANAGED_LANES_REQUIRED_ATTRIBUTES</code> <code>list(str</code> <p>list of attributes that must be provided in managed lanes</p> <code>KEEP_SAME_ATTRIBUTES_ML_AND_GP</code> <code>list(str</code> <p>list of attributes to copy from a general purpose lane to managed lane</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>class RoadwayNetwork(object):\n\"\"\"\n    Representation of a Roadway Network.\n\n    Typical usage example:\n\n    ```py\n    net = RoadwayNetwork.read(\n        link_file=MY_LINK_FILE,\n        node_file=MY_NODE_FILE,\n        shape_file=MY_SHAPE_FILE,\n    )\n    my_selection = {\n        \"link\": [{\"name\": [\"I 35E\"]}],\n        \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n        \"B\": {\"osm_node_id\": \"2564047368\"},\n    }\n    net.select_roadway_features(my_selection)\n\n    my_change = [\n        {\n            'property': 'lanes',\n            'existing': 1,\n            'set': 2,\n        },\n        {\n            'property': 'drive_access',\n            'set': 0,\n        },\n    ]\n\n    my_net.apply_roadway_feature_change(\n        my_net.select_roadway_features(my_selection),\n        my_change\n    )\n\n        net = create_managed_lane_network(net)\n        net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n        _, disconnected_nodes = net.assess_connectivity(\n            mode=\"walk\",\n            ignore_end_nodes=True,\n            nodes=self.m_nodes_df,\n            links=self.m_links_df\n        )\n        net.write(filename=my_out_prefix, path=my_dir, for_model = True)\n    ```\n\n    Attributes:\n        nodes_df (GeoDataFrame): node data\n\n        links_df (GeoDataFrame): link data, including start and end\n            nodes and associated shape\n\n        shapes_df (GeoDataFrame): detailed shape data\n\n        selections (dict): dictionary storing selections in case they are made repeatedly\n\n        BOOL_PROPERTIES (list): list of properties which should be coerced to booleans\n\n        STR_PROPERTIES (list): list of properties which should be coerced to strings\n\n        INT_PROPERTIES (list): list of properties which should be coerced to integers\n\n        CRS (str): coordinate reference system in PROJ4 format.\n            See https://proj.org/operations/projections/index.html#\n\n        ESPG (int): integer representing coordinate system https://epsg.io/\n\n        NODE_FOREIGN_KEY_TO_LINK (str): column in `nodes_df` associated with the\n            LINK_FOREIGN_KEY\n\n        LINK_FOREIGN_KEY_TO_NODE (list(str)): list of columns in `links_df` that\n            represent the NODE_FOREIGN_KEY\n\n        UNIQUE_LINK_KEY (str): column that is a unique key for links\n\n        UNIQUE_NODE_KEY (str): column that is a unique key for nodes\n\n        UNIQUE_SHAPE_KEY (str): column that is a unique shape key\n\n        UNIQUE_MODEL_LINK_IDENTIFIERS (list(str)): list of all unique\n            identifiers for links, including the UNIQUE_LINK_KEY\n\n        EXPLICIT_LINK_IDENTIFIERS (list(str)): list of identifiers which are explicit enough\n            to use in project selection by themselves. Includes UNIQUE_MODEL_LINK_IDENFIERS as\n            well as some identifiers which may be split across model links such as osm_link_id.\n\n        UNIQUE_NODE_IDENTIFIERS (list(str)): list of all unique identifiers\n            for nodes, including the UNIQUE_NODE_KEY\n\n        SEARCH_BREADTH (int): initial number of links from name-based\n            selection that are traveresed before trying another shortest\n            path when searching for paths between A and B node\n\n        MAX_SEARCH_BREADTH (int): maximum number of links traversed between\n            links that match the searched name when searching for paths\n            between A and B node\n\n        SP_WEIGHT_FACTOR (Union(int, float)): penalty assigned for each\n            degree of distance between a link and a link with the searched-for\n            name when searching for paths between A and B node\n\n        MANAGED_LANES_TO_NODE_ID_SCALAR (int): scalar value added to\n            the general purpose lanes' `model_node_id` when creating\n            an associated node for a parallel managed lane\n\n        MANAGED_LANES_TO_LINK_ID_SCALAR (int): scalar value added to\n            the general purpose lanes' `model_link_id` when creating\n            an associated link for a parallel managed lane\n\n        MANAGED_LANES_REQUIRED_ATTRIBUTES (list(str)): list of attributes\n            that must be provided in managed lanes\n\n        KEEP_SAME_ATTRIBUTES_ML_AND_GP (list(str)): list of attributes\n            to copy from a general purpose lane to managed lane\n    \"\"\"\n\n    # CRS = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n    CRS = 4326  # \"EPSG:4326\"\n\n    NODE_FOREIGN_KEY_TO_LINK = \"model_node_id\"\n    LINK_FOREIGN_KEY_TO_NODE = [\"A\", \"B\"]\n    LINK_FOREIGN_KEY_TO_SHAPE = \"shape_id\"\n\n    SEARCH_BREADTH = 5\n    MAX_SEARCH_BREADTH = 10\n    SP_WEIGHT_FACTOR = 100\n\n    UNIQUE_LINK_KEY = \"model_link_id\"\n    UNIQUE_NODE_KEY = \"model_node_id\"\n    UNIQUE_SHAPE_KEY = \"shape_id\"\n\n    UNIQUE_MODEL_LINK_IDENTIFIERS = [\"model_link_id\"]\n    EXPLICIT_LINK_IDENTIFIERS = UNIQUE_MODEL_LINK_IDENTIFIERS + [\"osm_link_id\"]\n    UNIQUE_NODE_IDENTIFIERS = [\"model_node_id\", \"osm_node_id\"]\n\n    BOOL_PROPERTIES = [\n        \"rail_only\",\n        \"bus_only\",\n        \"drive_access\",\n        \"bike_access\",\n        \"walk_access\",\n        \"truck_access\",\n    ]\n\n    STR_PROPERTIES = [\n        \"osm_link_id\",\n        \"osm_node_id\",\n        \"shape_id\",\n    ]\n\n    INT_PROPERTIES = [\"model_link_id\", \"model_node_id\", \"lanes\", \"ML_lanes\", \"A\", \"B\"]\n\n    GEOMETRY_PROPERTIES = [\"X\", \"Y\"]\n\n    MIN_LINK_REQUIRED_PROPS_DEFAULT = [\n        \"name\",\n        \"A\",\n        \"B\",\n        \"roadway\",\n        \"model_link_id\",\n        \"lanes\",\n        \"bus_only\",\n        \"rail_only\",\n        \"drive_access\",\n        \"walk_access\",\n        \"bike_access\",\n        \"locationReferences\",\n        \"geometry\",\n    ]\n\n    MIN_NODE_REQUIRED_PROPS_DEFAULT = [\n        \"model_node_id\",\n        \"transit_node\",\n        \"drive_node\",\n        \"walk_node\",\n        \"bike_node\",\n        \"geometry\",\n    ]\n\n    MANAGED_LANES_REQUIRED_ATTRIBUTES = [\n        \"A\",\n        \"B\",\n        \"model_link_id\",\n        \"locationReferences\",\n    ]\n\n    KEEP_SAME_ATTRIBUTES_ML_AND_GP = [\n        \"distance\",\n        \"bike_access\",\n        \"drive_access\",\n        \"transit_access\",\n        \"walk_access\",\n        \"maxspeed\",\n        \"name\",\n        \"oneway\",\n        \"ref\",\n        \"roadway\",\n        \"length\",\n        \"segment_id\",\n    ]\n\n    MANAGED_LANES_SCALAR = 500000\n\n    MODES_TO_NETWORK_LINK_VARIABLES = {\n        \"drive\": [\"drive_access\"],\n        \"bus\": [\"bus_only\", \"drive_access\"],\n        \"rail\": [\"rail_only\"],\n        \"transit\": [\"bus_only\", \"rail_only\", \"drive_access\"],\n        \"walk\": [\"walk_access\"],\n        \"bike\": [\"bike_access\"],\n    }\n\n    MODES_TO_NETWORK_NODE_VARIABLES = {\n        \"drive\": [\"drive_node\"],\n        \"rail\": [\"rail_only\", \"drive_node\"],\n        \"bus\": [\"bus_only\", \"drive_node\"],\n        \"transit\": [\"bus_only\", \"rail_only\", \"drive_node\"],\n        \"walk\": [\"walk_node\"],\n        \"bike\": [\"bike_node\"],\n    }\n\n    def __init__(self, nodes: GeoDataFrame, links: GeoDataFrame, shapes: GeoDataFrame):\n\"\"\"\n        Constructor\n        \"\"\"\n\n        if not RoadwayNetwork.validate_object_types(nodes, links, shapes):\n            sys.exit(\"RoadwayNetwork: Invalid constructor data type\")\n\n        self.nodes_df = nodes\n        self.links_df = links\n        self.shapes_df = shapes\n\n        # Model network\n        self.m_nodes_df = None\n        self.m_links_df = None\n        self.m_shapes_df = None\n\n        self.link_file = None\n        self.node_file = None\n        self.shape_file = None\n\n        # Add non-required fields if they aren't there.\n        # for field, default_value in RoadwayNetwork.OPTIONAL_FIELDS:\n        #    if field not in self.links_df.columns:\n        #        self.links_df[field] = default_value\n        if not self.validate_uniqueness():\n            raise ValueError(\"IDs in network not unique\")\n        self.selections = {}\n\n    @staticmethod\n    def read(\n        link_file: str, node_file: str, shape_file: str, fast: bool = True\n    ) -&gt; RoadwayNetwork:\n\"\"\"\n        Reads a network from the roadway network standard\n        Validates that it conforms to the schema\n\n        args:\n            link_file: full path to the link file\n            node_file: full path to the node file\n            shape_file: full path to the shape file\n            fast: boolean that will skip validation to speed up read time\n\n        Returns: a RoadwayNetwork instance\n\n        .. todo:: Turn off fast=True as default\n        \"\"\"\n\n        for fn in (link_file, node_file, shape_file):\n\n            if not os.path.exists(fn):\n                msg = f\"Specified file doesn't exist at: {fn}\"\n                WranglerLogger.error(msg)\n                raise ValueError(msg)\n\n        if not fast:\n            if not (\n                RoadwayNetwork.validate_node_schema(node_file)\n                and RoadwayNetwork.validate_link_schema(link_file)\n                and RoadwayNetwork.validate_shape_schema(shape_file)\n            ):\n                sys.exit(\"RoadwayNetwork: Data doesn't conform to schema\")\n\n        links_df = RoadwayNetwork.read_links(link_file)\n        nodes_df = RoadwayNetwork.read_nodes(node_file)\n        shapes_df = RoadwayNetwork.read_shapes(shape_file)\n\n        roadway_network = RoadwayNetwork(\n            nodes=nodes_df, links=links_df, shapes=shapes_df\n        )\n\n        roadway_network.link_file = link_file\n        roadway_network.node_file = node_file\n        roadway_network.shape_file = shape_file\n\n        return roadway_network\n\n    @classmethod\n    def coerce_types(\n        cls, df: pd.DataFrame, cols: Collection[str] = None\n    ) -&gt; pd.DataFrame:\n\"\"\"Coerces types to bool, str and int which might default to other types based on values.\n\n        Uses BOOL_PROPERTIES, INT_PROPERTIES and STR_PROPERTIES.\n\n        Args:\n            df: Dataframe to coerce type of\n            cols: optional list of fields to check and coerce. Defaults to all fields.\n\n        Returns:\n            pd.DataFrame: Dataframe with types coerced\n        \"\"\"\n        if cols is None:\n            cols = df.columns\n\n        for c in list(set(cls.BOOL_PROPERTIES) &amp; set(cols)):\n            df[c] = df[c].astype(bool)\n\n        for c in list(set(cls.STR_PROPERTIES) &amp; set(cols)):\n            df[c] = df[c].astype(str)\n\n        for c in list(set(cls.INT_PROPERTIES) &amp; set(cols)):\n            df[c] = df[c].astype(int)\n\n        return df\n\n    @classmethod\n    def read_links(cls, filename: str) -&gt; gpd.GeoDataFrame:\n\"\"\"Reads links and returns a geodataframe of links.\n\n        Args:\n            filename (str): file to read links in from.\n        \"\"\"\n        WranglerLogger.info(f\"Reading links from {filename}.\")\n        with open(filename) as f:\n            link_json = json.load(f)\n        WranglerLogger.debug(\"Read link file.\")\n        link_properties = pd.DataFrame(link_json)\n        link_geometries = [\n            line_string_from_location_references(g[\"locationReferences\"])\n            for g in link_json\n        ]\n        links_df = gpd.GeoDataFrame(link_properties, geometry=link_geometries)\n        links_df.crs = RoadwayNetwork.CRS\n        links_df.gdf_name = \"network_links\"\n\n        links_df = RoadwayNetwork.coerce_types(links_df)\n\n        links_df[RoadwayNetwork.UNIQUE_LINK_KEY + \"_idx\"] = links_df[\n            RoadwayNetwork.UNIQUE_LINK_KEY\n        ]\n        links_df.set_index(RoadwayNetwork.UNIQUE_LINK_KEY + \"_idx\", inplace=True)\n\n        WranglerLogger.info(f\"Read {len(links_df)} links.\")\n        return links_df\n\n    @classmethod\n    def read_nodes(cls, filename: str) -&gt; gpd.GeoDataFrame:\n\"\"\"Reads nodes and returns a geodataframe of nodes.\n\n        Args:\n            filename (str): file to read nodes in from.\n        \"\"\"\n        # geopandas uses fiona OGR drivers, which doesn't let you have\n        # a list as a property type. Therefore, must read in node_properties\n        # separately in a vanilla dataframe and then convert to geopandas\n        WranglerLogger.info(f\"Reading nodes from {filename}.\")\n        with open(filename) as f:\n            node_geojson = json.load(f)\n        WranglerLogger.debug(\"Read nodes file.\")\n        node_properties = pd.DataFrame(\n            [g[\"properties\"] for g in node_geojson[\"features\"]]\n        )\n        node_geometries = [\n            Point(g[\"geometry\"][\"coordinates\"]) for g in node_geojson[\"features\"]\n        ]\n\n        nodes_df = gpd.GeoDataFrame(node_properties, geometry=node_geometries)\n\n        nodes_df.gdf_name = \"network_nodes\"\n\n        # set a copy of the  foreign key to be the index so that the\n        # variable itself remains queryiable\n        ## TODO this should be more elegant\n        nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY + \"_idx\"] = nodes_df[\n            RoadwayNetwork.UNIQUE_NODE_KEY\n        ]\n        nodes_df.set_index(cls.UNIQUE_NODE_KEY + \"_idx\", inplace=True)\n\n        nodes_df.crs = RoadwayNetwork.CRS\n        nodes_df[\"X\"] = nodes_df[\"geometry\"].apply(lambda g: g.x)\n        nodes_df[\"Y\"] = nodes_df[\"geometry\"].apply(lambda g: g.y)\n\n        nodes_df = RoadwayNetwork.coerce_types(nodes_df)\n        WranglerLogger.info(f\"Read {len(nodes_df)} nodes.\")\n        return nodes_df\n\n    @classmethod\n    def read_shapes(cls, filename: str) -&gt; gpd.GeoDataFrame:\n\"\"\"Reads shapes and returns a geodataframe of shapes.\n\n        Also:\n        - drops records without geometry or id\n        - sets CRS to RoadwayNetwork.CRS\n\n        Args:\n            filename (str): file to read shapes in from.\n        \"\"\"\n        WranglerLogger.info(f\"Reading shapes from {filename}.\")\n        shapes_df = gpd.read_file(filename)\n        shapes_df.gdf_name = \"network_shapes\"\n        WranglerLogger.debug(\"Read shapes file.\")\n        shapes_df.dropna(subset=[\"geometry\", \"id\"], inplace=True)\n        shapes_df.crs = cls.CRS\n        WranglerLogger.info(f\"Read {len(shapes_df)} shapes.\")\n        return shapes_df\n\n    def write(\n        self,\n        path: str = \".\",\n        filename: str = None,\n        model: bool = False,\n    ) -&gt; None:\n\"\"\"\n        Writes a network in the roadway network standard\n\n        args:\n            path: the path were the output will be saved\n            filename: the name prefix of the roadway files that will be generated\n            model: determines if shoudl write model network with separated managed lanes,\n                or standard wrangler network. Defaults to False.\n        \"\"\"\n\n        if not os.path.exists(path):\n            WranglerLogger.debug(\"\\nPath [%s] doesn't exist; creating.\" % path)\n            os.mkdir(path)\n\n        if filename:\n            links_file = os.path.join(path, filename + \"_\" + \"link.json\")\n            nodes_file = os.path.join(path, filename + \"_\" + \"node.geojson\")\n            shapes_file = os.path.join(path, filename + \"_\" + \"shape.geojson\")\n        else:\n            links_file = os.path.join(path, \"link.json\")\n            nodes_file = os.path.join(path, \"node.geojson\")\n            shapes_file = os.path.join(path, \"shape.geojson\")\n\n        if model:\n            from .roadway import create_managed_lane_network\n\n            net = create_managed_lane_network(self)\n            links_df = net.m_links_df\n            nodes_df = net.m_nodes_df\n            shapes_df = net.m_shapes_df\n        else:\n            links_df = self.links_df\n            nodes_df = self.nodes_df\n            shapes_df = self.shapes_df\n\n        # Make sure types are correct\n        nodes_df = RoadwayNetwork.coerce_types(nodes_df)\n        links_df = RoadwayNetwork.coerce_types(links_df)\n\n        link_property_columns = links_df.columns.values.tolist()\n        link_property_columns.remove(\"geometry\")\n        links_json = links_df_to_json(links_df, link_property_columns)\n        with open(links_file, \"w\") as f:\n            json.dump(links_json, f)\n\n        # geopandas wont let you write to geojson because\n        # it uses fiona, which doesn't accept a list as one of the properties\n        # so need to convert the df to geojson manually first\n        property_columns = nodes_df.columns.values.tolist()\n        property_columns.remove(\"geometry\")\n\n        nodes_geojson = point_df_to_geojson(nodes_df, property_columns)\n\n        with open(nodes_file, \"w\") as f:\n            json.dump(nodes_geojson, f)\n\n        shapes_df.to_file(shapes_file, driver=\"GeoJSON\")\n\n    @staticmethod\n    def roadway_net_to_gdf(roadway_net: RoadwayNetwork) -&gt; gpd.GeoDataFrame:\n\"\"\"\n        Turn the roadway network into a GeoDataFrame\n        args:\n            roadway_net: the roadway network to export\n\n        returns: shapes dataframe\n\n        .. todo:: Make this much more sophisticated, for example attach link info to shapes\n        \"\"\"\n        return roadway_net.shapes_df\n\n    def validate_uniqueness(self) -&gt; bool:\n\"\"\"\n        Confirms that the unique identifiers are met.\n        \"\"\"\n        valid = True\n\n        for c in RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS:\n            if c not in self.links_df.columns:\n                valid = False\n                msg = f\"Network doesn't contain unique link identifier: {c}\"\n                WranglerLogger.error(msg)\n            if not self.links_df[c].is_unique:\n                valid = False\n                msg = f\"Unique identifier {c} is not unique in network links\"\n                WranglerLogger.error(msg)\n        for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE:\n            if c not in self.links_df.columns:\n                valid = False\n                msg = f\"Network doesn't contain link foreign key identifier: {c}\"\n                WranglerLogger.error(msg)\n        link_foreign_key = self.links_df[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE].apply(\n            lambda x: \"-\".join(x.map(str)), axis=1\n        )\n        if not link_foreign_key.is_unique:\n            valid = False\n            msg = f\"Foreign key: {RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE} is not unique in network links\"\n\n            WranglerLogger.error(msg)\n        for c in RoadwayNetwork.UNIQUE_NODE_IDENTIFIERS:\n            if c not in self.nodes_df.columns:\n                valid = False\n                msg = f\"Network doesn't contain unique node identifier: {c}\"\n                WranglerLogger.error(msg)\n            if not self.nodes_df[c].is_unique:\n                valid = False\n                msg = f\"Unique identifier {c} is not unique in network nodes\"\n                WranglerLogger.error(msg)\n        if RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK not in self.nodes_df.columns:\n            valid = False\n            msg = f\"Network doesn't contain node foreign key identifier: {RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK}\"\n            WranglerLogger.error(msg)\n        elif not self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].is_unique:\n            valid = False\n            msg = f\"Foreign key: {RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK} is not unique in network nodes\"\n            WranglerLogger.error(msg)\n        if RoadwayNetwork.UNIQUE_SHAPE_KEY not in self.shapes_df.columns:\n            valid = False\n            msg = \"Network doesn't contain unique shape id: {}\".format(\n                RoadwayNetwork.UNIQUE_SHAPE_KEY\n            )\n            WranglerLogger.error(msg)\n        elif not self.shapes_df[RoadwayNetwork.UNIQUE_SHAPE_KEY].is_unique:\n            valid = False\n            msg = \"Unique key: {} is not unique in network shapes\".format(\n                RoadwayNetwork.UNIQUE_SHAPE_KEY\n            )\n            WranglerLogger.error(msg)\n        return valid\n\n    @staticmethod\n    def validate_object_types(\n        nodes: GeoDataFrame, links: GeoDataFrame, shapes: GeoDataFrame\n    ):\n\"\"\"\n        Determines if the roadway network is being built with the right object types.\n        Does not validate schemas.\n\n        Args:\n            nodes: nodes geodataframe\n            links: link geodataframe\n            shapes: shape geodataframe\n\n        Returns: boolean\n        \"\"\"\n\n        errors = \"\"\n\n        if not isinstance(nodes, GeoDataFrame):\n            error_message = (\n                \"Incompatible nodes type:{}. Must provide a GeoDataFrame.  \".format(\n                    type(nodes)\n                )\n            )\n            WranglerLogger.error(error_message)\n            errors.append(error_message)\n        if not isinstance(links, GeoDataFrame):\n            error_message = (\n                \"Incompatible links type:{}. Must provide a GeoDataFrame.  \".format(\n                    type(links)\n                )\n            )\n            WranglerLogger.error(error_message)\n            errors.append(error_message)\n        if not isinstance(shapes, GeoDataFrame):\n            error_message = (\n                \"Incompatible shapes type:{}. Must provide a GeoDataFrame.  \".format(\n                    type(shapes)\n                )\n            )\n            WranglerLogger.error(error_message)\n            errors.append(error_message)\n\n        if errors:\n            return False\n        return True\n\n    @staticmethod\n    def validate_node_schema(\n        node_file, schema_location: str = \"roadway_network_node.json\"\n    ):\n\"\"\"\n        Validate roadway network data node schema and output a boolean\n        \"\"\"\n        if not os.path.exists(schema_location):\n            base_path = os.path.join(\n                os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n            )\n            schema_location = os.path.join(base_path, schema_location)\n\n        with open(schema_location) as schema_json_file:\n            schema = json.load(schema_json_file)\n\n        with open(node_file) as node_json_file:\n            json_data = json.load(node_json_file)\n\n        try:\n            validate(json_data, schema)\n            return True\n\n        except ValidationError as exc:\n            WranglerLogger.error(\"Failed Node schema validation: Validation Error\")\n            WranglerLogger.error(\"Node File Loc:{}\".format(node_file))\n            WranglerLogger.error(\"Node Schema Loc:{}\".format(schema_location))\n            WranglerLogger.error(exc.message)\n\n        except SchemaError as exc:\n            WranglerLogger.error(\"Invalid Node Schema\")\n            WranglerLogger.error(\"Node Schema Loc:{}\".format(schema_location))\n            WranglerLogger.error(json.dumps(exc.message, indent=2))\n\n        return False\n\n    @staticmethod\n    def validate_link_schema(\n        link_file, schema_location: str = \"roadway_network_link.json\"\n    ):\n\"\"\"\n        Validate roadway network data link schema and output a boolean\n        \"\"\"\n\n        if not os.path.exists(schema_location):\n            base_path = os.path.join(\n                os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n            )\n            schema_location = os.path.join(base_path, schema_location)\n\n        with open(schema_location) as schema_json_file:\n            schema = json.load(schema_json_file)\n\n        with open(link_file) as link_json_file:\n            json_data = json.load(link_json_file)\n\n        try:\n            validate(json_data, schema)\n            return True\n\n        except ValidationError as exc:\n            WranglerLogger.error(\"Failed Link schema validation: Validation Error\")\n            WranglerLogger.error(\"Link File Loc:{}\".format(link_file))\n            WranglerLogger.error(\"Path:{}\".format(exc.path))\n            WranglerLogger.error(exc.message)\n\n        except SchemaError as exc:\n            WranglerLogger.error(\"Invalid Link Schema\")\n            WranglerLogger.error(\"Link Schema Loc: {}\".format(schema_location))\n            WranglerLogger.error(json.dumps(exc.message, indent=2))\n\n        return False\n\n    @staticmethod\n    def validate_shape_schema(\n        shape_file, schema_location: str = \"roadway_network_shape.json\"\n    ):\n\"\"\"\n        Validate roadway network data shape schema and output a boolean\n        \"\"\"\n\n        if not os.path.exists(schema_location):\n            base_path = os.path.join(\n                os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n            )\n            schema_location = os.path.join(base_path, schema_location)\n\n        with open(schema_location) as schema_json_file:\n            schema = json.load(schema_json_file)\n\n        with open(shape_file) as shape_json_file:\n            json_data = json.load(shape_json_file)\n\n        try:\n            validate(json_data, schema)\n            return True\n\n        except ValidationError as exc:\n            WranglerLogger.error(\"Failed Shape schema validation: Validation Error\")\n            WranglerLogger.error(\"Shape File Loc:{}\".format(shape_file))\n            WranglerLogger.error(\"Path:{}\".format(exc.path))\n            WranglerLogger.error(exc.message)\n\n        except SchemaError as exc:\n            WranglerLogger.error(\"Invalid Shape Schema\")\n            WranglerLogger.error(\"Shape Schema Loc: {}\".format(schema_location))\n            WranglerLogger.error(json.dumps(exc.message, indent=2))\n\n        return False\n\n    @property\n    def num_managed_lane_links(self):\n        if \"managed\" in self.links_df.columns:\n            return len((self.links_df[self.links_df[\"managed\"] == 1]).index)\n        else:\n            return 0\n\n    def _validate_link_selection(self, selection: dict) -&gt; bool:\n\"\"\"Validates that link selection is complete/valid for given network.\n\n        Checks:\n        1. selection properties for links, a, and b are in links_df\n        2. either a unique ID or name + A &amp; B are specified\n\n        If selection for links is \"all\" it is assumed valid.\n\n        Args:\n            selection (dict): selection dictionary\n\n        Returns:\n            bool: True if link selection is valid and complete.\n        \"\"\"\n\n        if selection.get(\"links\") == \"all\":\n            return True\n\n        valid = True\n\n        _link_selection_props = [p for x in selection[\"links\"] for p in x.keys()]\n\n        _missing_link_props = set(_link_selection_props) - set(self.links_df.columns)\n\n        if _missing_link_props:\n            WranglerLogger.error(\n                f\"Link selection contains properties not found in the link dataframe:\\n\\\n{','.join(_missing_link_props)}\"\n            )\n            valid = False\n\n        _link_explicit_link_id = bool(\n            set(RoadwayNetwork.EXPLICIT_LINK_IDENTIFIERS).intersection(\n                set(_link_selection_props)\n            )\n        )\n        # if don't have an explicit link id, then require A and B nodes\n        _has_alternate_link_id = all(\n            [\n                selection.get(\"A\"),\n                selection.get(\"B\"),\n                any([x.get(\"name\") for x in selection[\"links\"]]),\n            ]\n        )\n\n        if not _link_explicit_link_id and not _has_alternate_link_id:\n            WranglerLogger.error(\n                \"Link selection does not contain unique link ID or alternate A and B nodes + 'name'.\"\n            )\n            valid = False\n\n        _node_selection_props = list(\n            set(\n                list(selection.get(\"A\", {}).keys())\n                + list(selection.get(\"B\", {}).keys())\n            )\n        )\n        _missing_node_props = set(_node_selection_props) - set(self.nodes_df.columns)\n\n        if _missing_node_props:\n            WranglerLogger.error(\n                f\"Node selection contains properties not found in the node dataframe:\\n\\\n{','.join(_missing_node_props)}\"\n            )\n            valid = False\n\n        if not valid:\n            raise ValueError(\"Link Selection is not valid for network.\")\n        return True\n\n    def _validate_node_selection(self, selection: dict) -&gt; bool:\n\"\"\"Validates that node selection is complete/valid for given network.\n\n        Checks:\n        1. selection properties for nodes are in nodes_df\n        2. Nodes identified by an explicit or implicit unique ID. A warning is given for using\n            a property as an identifier which isn't explicitly unique.\n\n        If selection for nodes is \"all\" it is assumed valid.\n\n        Args:\n            selection (dict): Project Card selection dictionary\n\n        Returns:\n            bool:True if node selection is valid and complete.\n        \"\"\"\n        valid = True\n\n        if selection.get(\"nodse\") == \"all\":\n            return True\n\n        _node_selection_props = [p for x in selection[\"nodes\"] for p in x.keys()]\n\n        _missing_node_props = set(_node_selection_props) - set(self.nodes_df.columns)\n\n        if _missing_node_props:\n            WranglerLogger.error(\n                f\"Node selection contains properties not found in the node dataframe:\\n\\\n{','.join(_missing_node_props)}\"\n            )\n            valid = False\n\n        _has_explicit_unique_node_id = bool(\n            set(RoadwayNetwork.UNIQUE_NODE_IDENTIFIERS).intersection(\n                set(_node_selection_props)\n            )\n        )\n\n        if not _has_explicit_unique_node_id:\n            if self.nodes_df[_node_selection_props].get_value_counts().min() == 1:\n                WranglerLogger.warning(\n                    f\"Link selection does not contain an explicit unique link ID: \\\n{RoadwayNetwork.UNIQUE_NODE_IDENTIFIERS}, \\\n                        but has properties which sufficiently select a single node. \\\n                        This selection may not work on other networks.\"\n                )\n            else:\n                WranglerLogger.error(\n                    \"Link selection does not contain unique link ID or alternate A and B nodes + 'name'.\"\n                )\n                valid = False\n        if not valid:\n            raise ValueError(\"Node Selection is not valid for network.\")\n        return True\n\n    def validate_selection(self, selection: dict) -&gt; bool:\n\"\"\"\n        Evaluate whetther the selection dictionary contains the\n        minimum required values.\n\n        Args:\n            selection: selection dictionary to be evaluated\n\n        Returns: boolean value as to whether the selection dictonary is valid.\n        \"\"\"\n        if selection.get(\"links\"):\n            return self._validate_link_selection(selection)\n\n        elif selection.get(\"nodes\"):\n            return self._validate_node_selection(selection)\n\n        else:\n            raise ValueError(\n                f\"Project Card Selection requires either 'links' or 'nodes' : \\\n                Selection provided: {selection.keys()}\"\n            )\n\n    def orig_dest_nodes_foreign_key(\n        self, selection: dict, node_foreign_key: str = \"\"\n    ) -&gt; tuple:\n\"\"\"\n        Returns the foreign key id (whatever is used in the u and v\n        variables in the links file) for the AB nodes as a tuple.\n\n        Args:\n            selection : selection dictionary with A and B keys\n            node_foreign_key: variable name for whatever is used by the u and v variable\n            in the links_df file.  If nothing is specified, assume whatever\n            default is (usually osm_node_id)\n\n        Returns: tuple of (A_id, B_id)\n        \"\"\"\n\n        if not node_foreign_key:\n            node_foreign_key = RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK\n        if len(selection[\"A\"]) &gt; 1:\n            raise (\"Selection A node dictionary should be of length 1\")\n        if len(selection[\"B\"]) &gt; 1:\n            raise (\"Selection B node dictionary should be of length 1\")\n\n        A_node_key, A_id = next(iter(selection[\"A\"].items()))\n        B_node_key, B_id = next(iter(selection[\"B\"].items()))\n\n        if A_node_key != node_foreign_key:\n            A_id = self.nodes_df[self.nodes_df[A_node_key] == A_id][\n                node_foreign_key\n            ].values[0]\n        if B_node_key != node_foreign_key:\n            B_id = self.nodes_df[self.nodes_df[B_node_key] == B_id][\n                node_foreign_key\n            ].values[0]\n\n        return (A_id, B_id)\n\n    @staticmethod\n    def ox_graph(nodes_df: GeoDataFrame, links_df: GeoDataFrame):\n\"\"\"\n        create an osmnx-flavored network graph\n\n        osmnx doesn't like values that are arrays, so remove the variables\n        that have arrays.  osmnx also requires that certain variables\n        be filled in, so do that too.\n\n        Args:\n            nodes_df : GeoDataFrame of nodes\n            links_df : GeoDataFrame of links\n\n        Returns: a networkx multidigraph\n        \"\"\"\n        WranglerLogger.debug(\"starting ox_graph()\")\n\n        if \"inboundReferenceIds\" in nodes_df.columns:\n            graph_nodes = nodes_df.copy().drop(\n                [\"inboundReferenceIds\", \"outboundReferenceIds\"], axis=1\n            )\n        else:\n            graph_nodes = nodes_df.copy()\n\n        graph_nodes.gdf_name = \"network_nodes\"\n        WranglerLogger.debug(\"GRAPH NODES: {}\".format(graph_nodes.columns))\n        graph_nodes[\"id\"] = graph_nodes[RoadwayNetwork.UNIQUE_NODE_KEY]\n\n        graph_nodes[\"x\"] = graph_nodes[\"X\"]\n        graph_nodes[\"y\"] = graph_nodes[\"Y\"]\n\n        if \"osm_link_id\" in links_df.columns:\n            graph_links = links_df.copy().drop(\n                [\"osm_link_id\", \"locationReferences\"], axis=1\n            )\n        else:\n            graph_links = links_df.copy().drop([\"locationReferences\"], axis=1)\n\n        # have to change this over into u,v b/c this is what osm-nx is expecting\n        graph_links[\"u\"] = graph_links[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE[0]]\n        graph_links[\"v\"] = graph_links[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE[1]]\n        graph_links[\"key\"] = graph_links[RoadwayNetwork.UNIQUE_LINK_KEY]\n\n        # Per osmnx u,v,key should be a multi-index;\n        #     https://osmnx.readthedocs.io/en/stable/osmnx.html#osmnx.utils_graph.graph_from_gdfs\n        # However - if the index is set before hand in osmnx version &lt;1.0 then it fails\n        #     on the set_index line *within* osmnx.utils_graph.graph_from_gdfs():\n        #           `for (u, v, k), row in gdf_edges.set_index([\"u\", \"v\", \"key\"]).iterrows():`\n\n        if int(ox.__version__.split(\".\")[0]) &gt;= 1:\n            graph_links = graph_links.set_index(keys=[\"u\", \"v\", \"key\"], drop=True)\n\n        WranglerLogger.debug(\"starting ox.gdfs_to_graph()\")\n        try:\n            G = ox.graph_from_gdfs(graph_nodes, graph_links)\n\n        except AttributeError as attr_error:\n            if (\n                attr_error.args[0]\n                == \"module 'osmnx' has no attribute 'graph_from_gdfs'\"\n            ):\n                # This is the only exception for which we have a workaround\n                # Does this still work given the u,v,key multi-indexing?\n                #\n                WranglerLogger.warn(\n                    \"Please upgrade your OSMNX package. For now, using deprecated\\\n                         osmnx.gdfs_to_graph because osmnx.graph_from_gdfs not found\"\n                )\n                G = ox.gdfs_to_graph(graph_nodes, graph_links)\n            else:\n                # for other AttributeErrors, raise further\n                raise attr_error\n        except Exception as e:\n            # for other Exceptions, raise further\n            raise e\n\n        WranglerLogger.debug(\"finished ox.gdfs_to_graph()\")\n        return G\n\n    @staticmethod\n    def selection_has_unique_link_id(selection_dict: dict) -&gt; bool:\n\"\"\"\n        Args:\n            selection_dictionary: Dictionary representation of selection\n                of roadway features, containing a \"links\" key.\n\n        Returns: A boolean indicating if the selection dictionary contains\n            a required unique link id.\n\n        \"\"\"\n        selection_keys = [k for li in selection_dict[\"links\"] for k, v in li.items()]\n        return bool(\n            set(RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS).intersection(\n                set(selection_keys)\n            )\n        )\n\n    def build_selection_key(self, selection_dict: dict) -&gt; tuple:\n\"\"\"\n        Selections are stored by a hash of the selection dictionary.\n\n        Args:\n            selection_dictonary: Selection Dictionary\n\n        Returns: Hex code for hash\n\n        \"\"\"\n\n        return hashlib.md5(b\"selection_dict\").hexdigest()\n\n    @staticmethod\n    def _get_fk_nodes(_links: gpd.GeoDataFrame):\n\"\"\"Find the nodes for the candidate links.\"\"\"\n        _n = list(\n            set(\n                [\n                    i\n                    for fk in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n                    for i in list(_links[fk])\n                ]\n            )\n        )\n        # WranglerLogger.debug(\"Node foreign key list: {}\".format(_n))\n        return _n\n\n    def shortest_path(\n        self,\n        graph_links_df: gpd.GeoDataFrame,\n        O_id,\n        D_id,\n        nodes_df: gpd.GeoDataFrame = None,\n        weight_column: str = \"i\",\n        weight_factor: float = 1.0,\n    ) -&gt; tuple:\n\"\"\"\n\n        Args:\n            graph_links_df:\n            O_id: foreign key for start node\n            D_id: foreign key for end node\n            nodes_df: optional nodes df, otherwise will use network instance\n            weight_column: column to use as a weight, defaults to \"i\"\n            weight_factor: any additional weighting to multiply the weight column by, defaults\n                to RoadwayNetwork.SP_WEIGHT_FACTOR\n\n        Returns: tuple with length of four\n        - Boolean if shortest path found\n        - nx Directed graph of graph links\n        - route of shortest path nodes as List\n        - links in shortest path selected from links_df\n        \"\"\"\n        WranglerLogger.debug(\n            f\"Calculating shortest path from {O_id} to {D_id} using {weight_column} as \\\n                weight with a factor of {weight_factor}\"\n        )\n\n        # Prep Graph Links\n        if weight_column not in graph_links_df.columns:\n            WranglerLogger.warning(\n                \"{} not in graph_links_df so adding and initializing to 1.\".format(\n                    weight_column\n                )\n            )\n            graph_links_df[weight_column] = 1\n\n        graph_links_df.loc[:, \"weight\"] = 1 + (\n            graph_links_df[weight_column] * weight_factor\n        )\n\n        # Select Graph Nodes\n        node_list_foreign_keys = RoadwayNetwork._get_fk_nodes(graph_links_df)\n\n        if O_id not in node_list_foreign_keys:\n            msg = \"O_id: {} not in Graph for finding shortest Path\".format(O_id)\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n        if D_id not in node_list_foreign_keys:\n            msg = \"D_id: {} not in Graph for finding shortest Path\".format(D_id)\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n\n        if not nodes_df:\n            nodes_df = self.nodes_df\n        graph_nodes_df = nodes_df.loc[node_list_foreign_keys]\n\n        # Create Graph\n        WranglerLogger.debug(\"Creating network graph\")\n        G = RoadwayNetwork.ox_graph(graph_nodes_df, graph_links_df)\n\n        try:\n            sp_route = nx.shortest_path(G, O_id, D_id, weight=\"weight\")\n            WranglerLogger.debug(\"Shortest path successfully routed\")\n        except nx.NetworkXNoPath:\n            WranglerLogger.debug(\"No SP from {} to {} Found.\".format(O_id, D_id))\n            return False, G, graph_links_df, None, None\n\n        sp_links = graph_links_df[\n            graph_links_df[\"A\"].isin(sp_route) &amp; graph_links_df[\"B\"].isin(sp_route)\n        ]\n\n        return True, G, graph_links_df, sp_route, sp_links\n\n    def path_search(\n        self,\n        candidate_links_df: gpd.GeoDataFrame,\n        O_id,\n        D_id,\n        weight_column: str = \"i\",\n        weight_factor: float = 1.0,\n    ):\n\"\"\"\n\n        Args:\n            candidate_links: selection of links geodataframe with links likely to be part of path\n            O_id: origin node foreigh key ID\n            D_id: destination node foreigh key ID\n            weight_column: column to use for weight of shortest path. Defaults to \"i\" (iteration)\n            weight_factor: optional weight to multiply the weight column by when finding\n                the shortest path\n\n        Returns\n\n        \"\"\"\n\n        def _add_breadth(\n            _candidate_links_df: gpd.GeoDataFrame,\n            _nodes_df: gpd.GeoDataFrame,\n            _links_df: gpd.GeoDataFrame,\n            i: int = None,\n        ):\n\"\"\"\n            Add outbound and inbound reference IDs to candidate links\n            from existing nodes\n\n            Args:\n                _candidate_links_df : df with the links from the previous iteration\n                _nodes_df : df of all nodes in the full network\n                _links_df : df of all links in the full network\n                i : iteration of adding breadth\n\n            Returns:\n                candidate_links : GeoDataFrame\n                    updated df with one more degree of added breadth\n\n                node_list_foreign_keys : list of foreign key ids for nodes in the updated\n                    candidate links to test if the A and B nodes are in there.\n            \"\"\"\n            WranglerLogger.debug(\"-Adding Breadth-\")\n\n            if not i:\n                WranglerLogger.warning(\"i not specified in _add_breadth, using 1\")\n                i = 1\n\n            _candidate_nodes_df = _nodes_df.loc[\n                RoadwayNetwork._get_fk_nodes(_candidate_links_df)\n            ]\n            WranglerLogger.debug(\"Candidate Nodes: {}\".format(len(_candidate_nodes_df)))\n\n            # Identify links to add based on outbound and inbound links from nodes\n            _links_shstRefId_to_add = list(\n                set(\n                    sum(_candidate_nodes_df[\"outboundReferenceIds\"].tolist(), [])\n                    + sum(_candidate_nodes_df[\"inboundReferenceIds\"].tolist(), [])\n                )\n                - set(_candidate_links_df[\"shstReferenceId\"].tolist())\n                - set([\"\"])\n            )\n            _links_to_add_df = _links_df[\n                _links_df.shstReferenceId.isin(_links_shstRefId_to_add)\n            ]\n\n            WranglerLogger.debug(\"Adding {} links.\".format(_links_to_add_df.shape[0]))\n\n            # Add information about what iteration the link was added in\n            _links_df[_links_df.model_link_id.isin(_links_shstRefId_to_add)][\"i\"] = i\n\n            # Append links and update node list\n            _candidate_links_df = pd.concat([_candidate_links_df, _links_to_add_df])\n            _node_list_foreign_keys = RoadwayNetwork._get_fk_nodes(_candidate_links_df)\n\n            return _candidate_links_df, _node_list_foreign_keys\n\n        # -----------------------------------\n        # Set search breadth to zero + set max\n        # -----------------------------------\n        i = 0\n        max_i = RoadwayNetwork.SEARCH_BREADTH\n        # -----------------------------------\n        # Add links to the graph until\n        #   (i) the A and B nodes are in the\n        #       foreign key list\n        #          - OR -\n        #   (ii) reach maximum search breadth\n        # -----------------------------------\n        node_list_foreign_keys = RoadwayNetwork._get_fk_nodes(candidate_links_df)\n        WranglerLogger.debug(\"Initial set of nodes: {}\".format(node_list_foreign_keys))\n        while (\n            O_id not in node_list_foreign_keys or D_id not in node_list_foreign_keys\n        ) and i &lt;= max_i:\n            WranglerLogger.debug(\n                \"Adding breadth - i: {}, Max i: {}] - {} and {} not found in node list.\".format(\n                    i, max_i, O_id, D_id\n                )\n            )\n            i += 1\n            candidate_links_df, node_list_foreign_keys = _add_breadth(\n                candidate_links_df, self.nodes_df, self.links_df, i=i\n            )\n        # -----------------------------------\n        #  Once have A and B in graph,\n        #  Try calculating shortest path\n        # -----------------------------------\n        WranglerLogger.debug(\"calculating shortest path from graph\")\n        (\n            sp_found,\n            graph,\n            candidate_links_df,\n            shortest_path_route,\n            shortest_path_links,\n        ) = self.shortest_path(candidate_links_df, O_id, D_id)\n        if sp_found:\n            return graph, candidate_links_df, shortest_path_route, shortest_path_links\n\n        if not sp_found:\n            WranglerLogger.debug(\n                \"No shortest path found with breadth of {i}, trying greater breadth until SP \\\n                    found or max breadth {max_i} reached.\"\n            )\n        while not sp_found and i &lt;= RoadwayNetwork.MAX_SEARCH_BREADTH:\n            WranglerLogger.debug(\n                \"Adding breadth, with shortest path iteration. i: {} Max i: {}\".format(\n                    i, max_i\n                )\n            )\n            i += 1\n            candidate_links_df, node_list_foreign_keys = _add_breadth(\n                candidate_links_df, self.nodes_df, self.links_df, i=i\n            )\n            (\n                sp_found,\n                graph,\n                candidate_links_df,\n                route,\n                shortest_path_links,\n            ) = self.shortest_path(candidate_links_df, O_id, D_id)\n\n        if sp_found:\n            return graph, candidate_links_df, route, shortest_path_links\n\n        if not sp_found:\n            msg = \"Couldn't find path from {} to {} after adding {} links in breadth\".format(\n                O_id, D_id, i\n            )\n            WranglerLogger.error(msg)\n            raise NoPathFound(msg)\n\n    def select_roadway_features(\n        self, selection: dict, search_mode=\"drive\", force_search=False\n    ) -&gt; list:\n\"\"\"\n        Selects roadway features that satisfy selection criteria\n\n        Example usage:\n            net.select_roadway_features(\n              selection = [ {\n                #   a match condition for the from node using osm,\n                #   shared streets, or model node number\n                'from': {'osm_model_link_id': '1234'},\n                #   a match for the to-node..\n                'to': {'shstid': '4321'},\n                #   a regex or match for facility condition\n                #   could be # of lanes, facility type, etc.\n                'facility': {'name':'Main St'},\n                }, ... ])\n\n        Args:\n            selection : dictionary with keys for:\n                 A - from node\n                 B - to node\n                 link - which includes at least a variable for `name` or 'all' if all selected\n            search_mode: will be overridden if 'link':'all'\n\n        Returns: a list of indices for the selected links or nodes\n        \"\"\"\n        WranglerLogger.debug(\"validating selection\")\n        self.validate_selection(selection)\n\n        # create a unique key for the selection so that we can cache it\n        sel_key = self.build_selection_key(selection)\n        WranglerLogger.debug(\"Selection Key: {}\".format(sel_key))\n\n        self.selections[sel_key] = {\"selection_found\": False}\n\n        if \"links\" in selection:\n            return self.select_roadway_link_features(\n                selection,\n                sel_key,\n                force_search=force_search,\n                search_mode=search_mode,\n            )\n        if \"nodes\" in selection:\n            return self.select_node_features(\n                selection,\n                sel_key,\n            )\n\n        raise ValueError(\"Invalid selection type. Must be either 'links' or 'nodes'.\")\n\n    def select_node_features(\n        self,\n        selection: dict,\n        sel_key: str,\n    ) -&gt; list:\n\"\"\"Select Node Features.\n\n        Args:\n            selection (dict): selection dictionary from project card.\n            sel_key (str): key to store selection in self.selections under.\n\n        Returns:\n            List of indices for selected nodes in self.nodes_df\n        \"\"\"\n        WranglerLogger.debug(\"Selecting nodes.\")\n        if selection.get(\"nodes\") == \"all\":\n            return self.nodes_df.index.tolist()\n\n        sel_query = ProjectCard.build_selection_query(\n            selection=selection,\n            type=\"nodes\",\n            unique_ids=RoadwayNetwork.UNIQUE_NODE_IDENTIFIERS,\n        )\n        WranglerLogger.debug(\"Selecting node features:\\n{}\".format(sel_query))\n\n        self.selections[sel_key][\"selected_nodes\"] = self.nodes_df.query(\n            sel_query, engine=\"python\"\n        )\n\n        if len(self.selections[sel_key][\"selected_nodes\"]) &gt; 0:\n            self.selections[sel_key][\"selection_found\"] = True\n        else:\n            raise ValueError(f\"No nodes found for selection: {selection}\")\n\n        return self.selections[sel_key][\"selected_nodes\"].index.tolist()\n\n    def select_roadway_link_features(\n        self,\n        selection: dict,\n        sel_key: str,\n        force_search: bool = False,\n        search_mode=\"drive\",\n    ) -&gt; list:\n\"\"\"_summary_\n\n        Args:\n            selection (dict): _description_\n            sel_key: selection key hash to store selection in\n            force_search (bool, optional): _description_. Defaults to False.\n            search_mode (str, optional): _description_. Defaults to \"drive\".\n\n        Returns:\n            List of indices for selected links in self.links_df\n        \"\"\"\n        WranglerLogger.debug(\"Selecting links.\")\n        if selection.get(\"links\") == \"all\":\n            return self.links_df.index.tolist()\n\n        # if this selection has been found before, return the previously selected links\n        if (\n            self.selections.get(sel_key, {}).get(\"selection_found\", None)\n            and not force_search\n        ):\n            return self.selections[sel_key][\"selected_links\"].index.tolist()\n\n        unique_model_link_identifer_in_selection = (\n            RoadwayNetwork.selection_has_unique_link_id(selection)\n        )\n        if not unique_model_link_identifer_in_selection:\n            A_id, B_id = self.orig_dest_nodes_foreign_key(selection)\n        # identify candidate links which match the initial query\n        # assign them as iteration = 0\n        # subsequent iterations that didn't match the query will be\n        # assigned a heigher weight in the shortest path\n        WranglerLogger.debug(\"Building selection query\")\n        # build a selection query based on the selection dictionary\n\n        sel_query = ProjectCard.build_selection_query(\n            selection=selection,\n            type=\"links\",\n            unique_ids=RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS,\n            mode=RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES[search_mode],\n        )\n        WranglerLogger.debug(\"Selecting link features:\\n{}\".format(sel_query))\n\n        self.selections[sel_key][\"candidate_links\"] = self.links_df.query(\n            sel_query, engine=\"python\"\n        )\n        WranglerLogger.debug(\"Completed query\")\n        candidate_links = self.selections[sel_key][\n            \"candidate_links\"\n        ]  # b/c too long to keep that way\n\n        candidate_links[\"i\"] = 0\n\n        if len(candidate_links.index) == 0 and unique_model_link_identifer_in_selection:\n            msg = \"No links found based on unique link identifiers.\\nSelection Failed.\"\n            WranglerLogger.error(msg)\n            raise Exception(msg)\n\n        if len(candidate_links.index) == 0:\n            WranglerLogger.debug(\n                \"No candidate links in initial search.\\nRetrying query using 'ref' instead of \\\n                    'name'\"\n            )\n            # if the query doesn't come back with something from 'name'\n            # try it again with 'ref' instead\n            selection_has_name_key = any(\"name\" in d for d in selection[\"links\"])\n\n            if not selection_has_name_key:\n                msg = \"Not able to complete search using 'ref' instead of 'name' because 'name' \\\n                    not in search.\"\n                WranglerLogger.error(msg)\n                raise Exception(msg)\n\n            if \"ref\" not in self.links_df.columns:\n                msg = \"Not able to complete search using 'ref' because 'ref' not in network.\"\n                WranglerLogger.error(msg)\n                raise Exception(msg)\n\n            WranglerLogger.debug(\"Trying selection query replacing 'name' with 'ref'\")\n            sel_query = sel_query.replace(\"name\", \"ref\")\n\n            self.selections[sel_key][\"candidate_links\"] = self.links_df.query(\n                sel_query, engine=\"python\"\n            )\n            candidate_links = self.selections[sel_key][\"candidate_links\"]\n\n            candidate_links[\"i\"] = 0\n\n            if len(candidate_links.index) == 0:\n                msg = \"No candidate links in search using either 'name' or 'ref' in query.\\\n                    Selection Failed.\"\n                WranglerLogger.error(msg)\n                raise Exception(msg)\n\n        if unique_model_link_identifer_in_selection:\n            # unique identifier exists and no need to go through big search\n            self.selections[sel_key][\"selected_links\"] = self.selections[sel_key][\n                \"candidate_links\"\n            ]\n            self.selections[sel_key][\"selection_found\"] = True\n\n            return self.selections[sel_key][\"selected_links\"].index.tolist()\n\n        else:\n            WranglerLogger.debug(\"Not a unique ID selection, conduct search.\")\n            (\n                self.selections[sel_key][\"graph\"],\n                self.selections[sel_key][\"candidate_links\"],\n                self.selections[sel_key][\"route\"],\n                self.selections[sel_key][\"links\"],\n            ) = self.path_search(\n                self.selections[sel_key][\"candidate_links\"],\n                A_id,\n                B_id,\n                weight_factor=RoadwayNetwork.SP_WEIGHT_FACTOR,\n            )\n\n            if len(selection[\"links\"]) == 1:\n                self.selections[sel_key][\"selected_links\"] = self.selections[sel_key][\n                    \"links\"\n                ]\n\n            # Conduct a \"selection on the selection\" if have additional requirements to satisfy\n            else:\n                resel_query = ProjectCard.build_selection_query(\n                    selection=selection,\n                    unique_ids=RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS,\n                    mode=RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES[search_mode],\n                    ignore=[\"name\"],\n                )\n                WranglerLogger.debug(\"Reselecting features:\\n{}\".format(resel_query))\n                self.selections[sel_key][\"selected_links\"] = self.selections[sel_key][\n                    \"links\"\n                ].query(resel_query, engine=\"python\")\n\n            if len(self.selections[sel_key][\"selected_links\"]) &gt; 0:\n                self.selections[sel_key][\"selection_found\"] = True\n            else:\n                raise ValueError(f\"No links found for selection: {selection}\")\n\n            self.selections[sel_key][\"selection_found\"] = True\n            return self.selections[sel_key][\"selected_links\"].index.tolist()\n\n    def validate_properties(\n        self,\n        df: pd.DataFrame,\n        properties: dict,\n        ignore_existing: bool = False,\n        require_existing_for_change: bool = False,\n    ) -&gt; bool:\n\"\"\"\n        If there are change or existing commands, make sure that that\n        property exists in the network.\n\n        Args:\n            properties : properties dictionary to be evaluated\n            df: links_df or nodes_df or shapes_df to check for compatibility with\n            ignore_existing: If True, will only warn about properties\n                that specify an \"existing\" value.  If False, will fail.\n            require_existing_for_change: If True, will fail if there isn't\n                a specified value in theproject card for existing when a\n                change is specified.\n\n        Returns: boolean value as to whether the properties dictonary is valid.\n        \"\"\"\n\n        valid = True\n        for p in properties:\n            if p[\"property\"] not in df.columns and p.get(\"change\"):\n                WranglerLogger.error(\n                    f'\"Change\" is specified for attribute { p[\"property\"]}, but doesn\\'t \\\n                            exist in base network'\n                )\n                valid = False\n            if (\n                p[\"property\"] not in df.columns\n                and p.get(\"existing\")\n                and not ignore_existing\n            ):\n                WranglerLogger.error(\n                    f'\"Existing\" is specified for attribute { p[\"property\"]}, but doesn\\'t \\\n                        exist in base network'\n                )\n                valid = False\n            if p.get(\"change\") and not p.get(\"existing\"):\n                if require_existing_for_change:\n                    WranglerLogger.error(\n                        f'\"Change\" is specified for attribute {p[\"property\"]}, but there \\\n                            isn\\'t a value for existing.\\nTo proceed, run with the setting \\\n                            require_existing_for_change=False'\n                    )\n                    valid = False\n                else:\n                    WranglerLogger.warning(\n                        f'\"Change\" is specified for attribute {p[\"property\"]}, but there \\\n                            isn\\'t a value for existing'\n                    )\n\n        if not valid:\n            raise ValueError(\"Property changes are not valid:\\n  {properties\")\n\n    def apply(\n        self, project_card_dictionary: dict, _subproject: bool = False\n    ) -&gt; \"RoadwayNetwork\":\n\"\"\"\n        Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n        Args:\n            project_card_dictionary: a dictionary of the project card object\n            _subproject: boolean indicating if this is a subproject under a \"changes\" heading.\n                Defaults to False. Will be set to true with code when necessary.\n\n        \"\"\"\n        if not _subproject:\n            WranglerLogger.info(\n                \"Applying Project to Roadway Network: {}\".format(\n                    project_card_dictionary[\"project\"]\n                )\n            )\n\n        if project_card_dictionary.get(\"changes\"):\n            for project_dictionary in project_card_dictionary[\"changes\"]:\n                return self.apply(project_dictionary, _subproject=True)\n        else:\n            project_dictionary = project_card_dictionary\n\n        _facility = project_dictionary.get(\"facility\")\n        _category = project_dictionary.get(\"category\").lower()\n\n        if _facility:\n            WranglerLogger.info(f\"Selecting Facility: {_facility}\")\n\n            _geometry_type = list({\"links\", \"nodes\"}.intersection(set(_facility)))\n            assert (\n                len(_geometry_type) == 1\n            ), \"Facility must have exactly one of 'links' or 'nodes'\"\n            _geometry_type = _geometry_type[0]\n\n            _df_idx = self.select_roadway_features(_facility)\n\n        if _category == \"roadway property change\":\n            return self.apply_roadway_feature_change(\n                _df_idx,\n                project_dictionary[\"properties\"],\n                geometry_type=_geometry_type,\n            )\n        elif _category == \"parallel managed lanes\":\n            return self.apply_managed_lane_feature_change(\n                _df_idx,\n                project_dictionary[\"properties\"],\n            )\n        elif _category == \"add new roadway\":\n            return self.add_new_roadway_feature_change(\n                project_dictionary.get(\"links\", []),\n                project_dictionary.get(\"nodes\", []),\n            )\n        elif _category == \"roadway deletion\":\n            return self.delete_roadway_feature_change(\n                project_dictionary.get(\"links\", []),\n                project_dictionary.get(\"nodes\", []),\n            )\n        elif _category == \"calculated roadway\":\n            return self.apply_python_calculation(\n                project_dictionary[\"pycode\"],\n            )\n        else:\n            raise (ValueError(f\"Invalid Project Card Category: {_category}\"))\n\n    def update_node_geometry(self, updated_nodes: List = None) -&gt; gpd.GeoDataFrame:\n\"\"\"Adds or updates the geometry of the nodes in the network based on XY coordinates.\n\n        Assumes XY are in self.crs.\n        Also updates the geometry of links and shapes that reference these nodes.\n\n        Args:\n            updated_nodes: List of nodes to update. Defaults to all nodes.\n\n        Returns:\n           gpd.GeoDataFrame: nodes geodataframe with updated geometry.\n        \"\"\"\n        if updated_nodes:\n            updated_nodes_df = copy.deepcopy(\n                self.nodes_df.loc[\n                    self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY].isin(updated_nodes)\n                ]\n            )\n        else:\n            updated_nodes_df = copy.deepcopy(self.nodes_df)\n            updated_nodes = self.nodes_df.index.values.tolist()\n\n        if len(updated_nodes_df) &lt; 25:\n            WranglerLogger.debug(\n                f\"Original Nodes:\\n{updated_nodes_df[['X','Y','geometry']]}\"\n            )\n\n        updated_nodes_df[\"geometry\"] = updated_nodes_df.apply(\n            lambda x: point_from_xy(\n                x[\"X\"],\n                x[\"Y\"],\n                xy_crs=updated_nodes_df.crs,\n                point_crs=updated_nodes_df.crs,\n            ),\n            axis=1,\n        )\n        WranglerLogger.debug(f\"{len(self.nodes_df)} nodes in network before update\")\n        if len(updated_nodes_df) &lt; 25:\n            WranglerLogger.debug(\n                f\"Updated Nodes:\\n{updated_nodes_df[['X','Y','geometry']]}\"\n            )\n        self.nodes_df.update(\n            updated_nodes_df[[RoadwayNetwork.UNIQUE_NODE_KEY, \"geometry\"]]\n        )\n        WranglerLogger.debug(f\"{len(self.nodes_df)} nodes in network after update\")\n        if len(self.nodes_df) &lt; 25:\n            WranglerLogger.debug(\n                f\"Updated self.nodes_df:\\n{self.nodes_df[['X','Y','geometry']]}\"\n            )\n\n        self._update_node_geometry_in_links_shapes(updated_nodes_df)\n\n    @staticmethod\n    def nodes_in_links(\n        links_df: pd.DataFrame,\n    ) -&gt; Collection:\n\"\"\"Returns a list of nodes that are contained in the links.\n\n        Args:\n            links_df: Links which to return node list for\n        \"\"\"\n        if len(links_df) &lt; 25:\n            WranglerLogger.debug(\n                f\"Links:\\n{links_df[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE]}\"\n            )\n        nodes_list = list(\n            set(\n                pd.concat(\n                    [links_df[c] for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE]\n                ).tolist()\n            )\n        )\n        if len(nodes_list) &lt; 25:\n            WranglerLogger.debug(f\"_node_list:\\n{nodes_list}\")\n        return nodes_list\n\n    @staticmethod\n    def links_with_nodes(\n        links_df: pd.DataFrame, node_id_list: list\n    ) -&gt; gpd.GeoDataFrame:\n\"\"\"Returns a links geodataframe which start or end at the nodes in the list.\n\n        Args:\n            links_df: dataframe of links to search for nodes in\n            node_id_list (list): List of nodes to find links for.  Nodes should be identified\n                by the foreign key - the one that is referenced in LINK_FOREIGN_KEY.\n        \"\"\"\n        # If nodes are equal to all the nodes in the links, return all the links\n        _nodes_in_links = RoadwayNetwork.nodes_in_links(links_df)\n        WranglerLogger.debug(\n            f\"# Nodes: {len(node_id_list)}\\nNodes in links:{len(_nodes_in_links)}\"\n        )\n        if len(set(node_id_list) - set(_nodes_in_links)) == 0:\n            return links_df\n\n        WranglerLogger.debug(f\"Finding links assocated with {len(node_id_list)} nodes.\")\n        if len(node_id_list) &lt; 25:\n            WranglerLogger.debug(f\"node_id_list: {node_id_list}\")\n\n        _selected_links_df = links_df[\n            links_df.isin(\n                {c: node_id_list for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE}\n            )\n        ]\n        WranglerLogger.debug(\n            f\"Temp Selected {len(_selected_links_df)} associated with {len(node_id_list)} nodes.\"\n        )\n\"\"\"\n        _query_parts = [\n            f\"{prop} == {str(n)}\"\n            for prop in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n            for n in node_id_list\n        ]\n\n        _query = \" or \".join(_query_parts)\n        _selected_links_df = links_df.query(_query, engine=\"python\")\n        \"\"\"\n        WranglerLogger.debug(\n            f\"Selected {len(_selected_links_df)} associated with {len(node_id_list)} nodes.\"\n        )\n\n        return _selected_links_df\n\n    def _update_node_geometry_in_links_shapes(\n        self,\n        updated_nodes_df: gpd.GeoDataFrame,\n    ) -&gt; None:\n\"\"\"Updates the locationReferences &amp; geometry for given links &amp; shapes for a given node df\n\n        Should be called by any function that changes a node location.\n\n        NOTES:\n         - For shapes, this will mutate the geometry of a shape in place for the start and end node\n            ...but not the nodes in-between.  Something to consider...\n\n        Args:\n            updated_nodes_df: gdf of nodes with updated geometry.\n        \"\"\"\n        _node_ids = updated_nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].tolist()\n        updated_links_df = copy.deepcopy(\n            RoadwayNetwork.links_with_nodes(self.links_df, _node_ids)\n        )\n\n        _shape_ids = updated_links_df[RoadwayNetwork.LINK_FOREIGN_KEY_TO_SHAPE].tolist()\n        updated_shapes_df = copy.deepcopy(\n            self.shapes_df.loc[\n                self.shapes_df[RoadwayNetwork.UNIQUE_SHAPE_KEY].isin(_shape_ids)\n            ]\n        )\n\n        updated_links_df[\"locationReferences\"] = self._create_link_locationreferences(\n            updated_links_df\n        )\n        updated_links_df[\"geometry\"] = updated_links_df[\"locationReferences\"].apply(\n            line_string_from_location_references,\n        )\n\n        updated_shapes_df[\"geometry\"] = self._update_existing_shape_geometry_from_nodes(\n            updated_shapes_df, updated_links_df\n        )\n\n        self.links_df.update(\n            updated_links_df[\n                [RoadwayNetwork.UNIQUE_LINK_KEY, \"geometry\", \"locationReferences\"]\n            ]\n        )\n        self.shapes_df.update(\n            updated_shapes_df[[RoadwayNetwork.UNIQUE_SHAPE_KEY, \"geometry\"]]\n        )\n\n    def _create_link_locationreferences(self, links_df: pd.DataFrame) -&gt; pd.Series:\n        locationreferences_s = links_df.apply(\n            lambda x: location_reference_from_nodes(\n                [\n                    self.nodes_df[\n                        self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK]\n                        == x[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE[0]]\n                    ].squeeze(),\n                    self.nodes_df[\n                        self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK]\n                        == x[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE[1]]\n                    ].squeeze(),\n                ]\n            ),\n            axis=1,\n        )\n        return locationreferences_s\n\n    def _add_link_geometry_from_nodes(self, links_df: pd.DataFrame) -&gt; gpd.GeoDataFrame:\n        links_df[\"locationReferences\"] = self._create_link_locationreferences(links_df)\n        links_df[\"geometry\"] = links_df[\"locationReferences\"].apply(\n            line_string_from_location_references,\n        )\n        links_df = gpd.GeoDataFrame(links_df)\n        return links_df\n\n    def _update_existing_shape_geometry_from_nodes(\n        self, updated_shapes_df, updated_links_df\n    ) -&gt; gpd.GeoSeries:\n        # WranglerLogger.debug(f\"updated_shapes_df:\\n {updated_shapes_df}\")\n        # update the first and last coordinates for the shape\n\n        _df = updated_shapes_df[[RoadwayNetwork.UNIQUE_SHAPE_KEY, \"geometry\"]].merge(\n            updated_links_df[[RoadwayNetwork.LINK_FOREIGN_KEY_TO_SHAPE, \"geometry\"]],\n            left_on=RoadwayNetwork.UNIQUE_SHAPE_KEY,\n            right_on=RoadwayNetwork.LINK_FOREIGN_KEY_TO_SHAPE,\n            suffixes=[\"_old_shape\", \"_link\"],\n            how=\"left\",\n        )\n\n        for position in [0, -1]:\n            _df[\"geometry\"] = _df.apply(\n                lambda x: update_points_in_linestring(\n                    x[\"geometry_old_shape\"],\n                    _df[\"geometry_link\"][0].coords[position],\n                    position,\n                ),\n                axis=1,\n            )\n        return _df[\"geometry\"]\n\n    def _create_new_link_geometry(self, new_links_df: pd.DataFrame) -&gt; gpd.GeoDataFrame:\n        new_links_df = self._add_link_geometry_from_nodes(new_links_df)\n        new_links_df[RoadwayNetwork.UNIQUE_SHAPE_KEY] = new_links_df[\"geometry\"].apply(\n            create_unique_shape_id\n        )\n        return new_links_df\n\n    @staticmethod\n    def _create_new_shapes_from_links(links_df: gpd.GeoDataFrame) -&gt; gpd.GeoDataFrame:\n        new_shapes_df = copy.deepcopy(\n            links_df[[RoadwayNetwork.UNIQUE_SHAPE_KEY, \"geometry\"]]\n        )\n        return new_shapes_df\n\n    def apply_python_calculation(self, pycode: str) -&gt; \"RoadwayNetwork\":\n\"\"\"\n        Changes roadway network object by executing pycode.\n\n        Args:\n            net: network to manipulate\n            pycode: python code which changes values in the roadway network object\n        \"\"\"\n        exec(pycode)\n        return self\n\n    def _add_property(self, df: pd.DataFrame, property_dict: dict) -&gt; pd.DataFrame:\n\"\"\"\n        Adds a property to a dataframe. Infers type from the property_dict \"set\" value.\n\n        Args:\n            df: dataframe to add property to\n            property_dict: dictionary of property to add with \"set\" value.\n\n        Returns:\n            pd.DataFrame: dataframe with property added filled with NaN.\n        \"\"\"\n        WranglerLogger.info(f\"Adding property: {property_dict['property']}\")\n        df[property_dict[\"property\"]] = np.nan\n        return df\n\n    def _update_property(self, existing_facilities_df: pd.DataFrame, property: dict):\n\"\"\"_summary_\n\n        Args:\n            existing_facilities_df: selected existing facility df\n            property (dict): project property update\n        \"\"\"\n        # WranglerLogger.debug(f\"property:\\n{property}\")\n        # WranglerLogger.debug(f\"existing_facilities_df:\\n{existing_facilities_df}\")\n        if \"existing\" in property:\n            if (\n                not existing_facilities_df[property[\"property\"]]\n                .eq(property[\"existing\"])\n                .all()\n            ):\n                WranglerLogger.warning(\n                    \"Existing value defined for {} in project card does \"\n                    \"not match the value in the roadway network for the \"\n                    \"selected links\".format(property[\"property\"])\n                )\n\n        if \"set\" in property:\n            _updated_series = pd.Series(\n                property[\"set\"],\n                name=property[\"property\"],\n                index=existing_facilities_df.index,\n            )\n\n        elif \"change\" in property:\n            _updated_series = (\n                existing_facilities_df[property[\"property\"]] + property[\"change\"]\n            )\n        else:\n            WranglerLogger.debug(f\"Property: \\n {property}\")\n            raise ValueError(\n                f\"No 'set' or 'change' specified for property {property['property']} \\\n                    in Roadway Network Change project card\"\n            )\n        return _updated_series\n\n    def apply_roadway_feature_change(\n        self,\n        df_idx: list,\n        properties: dict,\n        geometry_type=\"links\",\n    ) -&gt; \"RoadwayNetwork\":\n\"\"\"\n        Changes the roadway attributes for the selected features based on the\n        project card information passed\n\n        Args:\n            df_idx : list\n                lndices of all links or nodes to apply change to\n            properties : list of dictionarys\n                roadway properties to change\n            geometry_type: either 'links' or 'nodes'. Defaults to 'link'\n        \"\"\"\n        if geometry_type == \"links\":\n            self._apply_links_feature_change(df_idx, properties)\n        elif geometry_type == \"nodes\":\n            self._apply_nodes_feature_change(df_idx, properties)\n        else:\n            raise ValueError(\"geometry_type must be either 'links' or 'nodes'\")\n\n        return self\n\n    def _apply_nodes_feature_change(\n        self,\n        node_idx: list,\n        properties: dict,\n    ) -&gt; \"RoadwayNetwork\":\n\"\"\"\n        Changes the roadway attributes for the selected nodes based on the\n        project card information passed\n\n        Args:\n            df_idx : list of indices of all links or nodes to apply change to\n            properties : list of dictionarys\n                roadway properties to change\n        \"\"\"\n        WranglerLogger.debug(\"Updating Nodes\")\n\n        self.validate_properties(self.nodes_df, properties)\n        for p in properties:\n\n            if not p[\"property\"] in self.nodes_df.columns:\n                _df = self._add_property(self.nodes_df, p)\n\n            _updated_nodes_df = self._update_property(self.nodes_df.loc[node_idx], p)\n            self.nodes_df.update(_updated_nodes_df)\n\n        _property_names = [p[\"property\"] for p in properties]\n\n        WranglerLogger.info(\n            f\"Updated following node properties: \\\n{','.join(_property_names)}\"\n        )\n\n        if [p for p in _property_names if p in RoadwayNetwork.GEOMETRY_PROPERTIES]:\n            self.update_node_geometry(node_idx)\n            WranglerLogger.debug(\"Updated node geometry and associated links/shapes.\")\n        return self.nodes_df\n\n    def _apply_links_feature_change(\n        self,\n        link_idx: list,\n        properties: dict,\n    ) -&gt; \"RoadwayNetwork\":\n\"\"\"\n        Changes the roadway attributes for the selected links based on the\n        project card information passed\n\n        Args:\n            link_idx : list od indices of all links to apply change to\n            properties : list of dictionarys\n                roadway properties to change\n        \"\"\"\n        WranglerLogger.debug(\"Updating Links.\")\n\n        self.validate_properties(self.links_df, properties)\n        for p in properties:\n\n            if not p[\"property\"] in self.links_df.columns:\n                self.links_df = self._add_property(self.links_df, p)\n\n            _updated_links_df = self._update_property(self.links_df.loc[link_idx], p)\n            self.links_df.update(_updated_links_df)\n\n        WranglerLogger.info(\n            f\"Updated following link properties: \\\n{','.join([p['property'] for p in properties])}\"\n        )\n\n    def apply_managed_lane_feature_change(\n        self,\n        link_idx: list,\n        properties: dict,\n    ) -&gt; \"RoadwayNetwork\":\n\"\"\"\n        Apply the managed lane feature changes to the roadway network\n\n        Args:\n            link_idx : list of lndices of all links to apply change to\n            properties : list of dictionarys roadway properties to change\n\n        .. todo:: decide on connectors info when they are more specific in project card\n        \"\"\"\n\n        # add ML flag to relevant links\n        if \"managed\" in self.links_df.columns:\n            self.links_df.loc[link_idx, \"managed\"] = 1\n        else:\n            self.links_df[\"managed\"] = 0\n            self.links_df.loc[link_idx, \"managed\"] = 1\n\n        for p in properties:\n            attribute = p[\"property\"]\n            attr_value = \"\"\n\n            for idx in link_idx:\n                if \"group\" in p.keys():\n                    attr_value = {}\n\n                    if \"set\" in p.keys():\n                        attr_value[\"default\"] = p[\"set\"]\n                    elif \"change\" in p.keys():\n                        attr_value[\"default\"] = (\n                            self.links_df.at[idx, attribute] + p[\"change\"]\n                        )\n\n                    attr_value[\"timeofday\"] = []\n\n                    for g in p[\"group\"]:\n                        category = g[\"category\"]\n                        for tod in g[\"timeofday\"]:\n                            if \"set\" in tod.keys():\n                                attr_value[\"timeofday\"].append(\n                                    {\n                                        \"category\": category,\n                                        \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                        \"value\": tod[\"set\"],\n                                    }\n                                )\n                            elif \"change\" in tod.keys():\n                                attr_value[\"timeofday\"].append(\n                                    {\n                                        \"category\": category,\n                                        \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                        \"value\": self.links_df.at[idx, attribute]\n                                        + tod[\"change\"],\n                                    }\n                                )\n\n                elif \"timeofday\" in p.keys():\n                    attr_value = {}\n\n                    if \"set\" in p.keys():\n                        attr_value[\"default\"] = p[\"set\"]\n                    elif \"change\" in p.keys():\n                        attr_value[\"default\"] = (\n                            self.links_df.at[idx, attribute] + p[\"change\"]\n                        )\n\n                    attr_value[\"timeofday\"] = []\n\n                    for tod in p[\"timeofday\"]:\n                        if \"set\" in tod.keys():\n                            attr_value[\"timeofday\"].append(\n                                {\n                                    \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                    \"value\": tod[\"set\"],\n                                }\n                            )\n                        elif \"change\" in tod.keys():\n                            attr_value[\"timeofday\"].append(\n                                {\n                                    \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                    \"value\": self.links_df.at[idx, attribute]\n                                    + tod[\"change\"],\n                                }\n                            )\n                elif \"set\" in p.keys():\n                    attr_value = p[\"set\"]\n\n                elif \"change\" in p.keys():\n                    attr_value = self.links_df.at[idx, attribute] + p[\"change\"]\n\n                if attribute in self.links_df.columns and not isinstance(\n                    attr_value, numbers.Number\n                ):\n                    # if the attribute already exists\n                    # and the attr value we are trying to set is not numeric\n                    # then change the attribute type to object\n                    self.links_df[attribute] = self.links_df[attribute].astype(object)\n\n                if attribute not in self.links_df.columns:\n                    # if it is a new attribute then initialize with NaN values\n                    self.links_df[attribute] = \"NaN\"\n\n                self.links_df.at[idx, attribute] = attr_value\n\n        WranglerLogger.debug(f\"{len(self.nodes_df)} Nodes in Network\")\n\n        return self\n\n    def _create_links(self, new_links: Collection[dict] = []):\n\n        new_links_df = pd.DataFrame(new_links)\n\n        _idx_c = RoadwayNetwork.UNIQUE_LINK_KEY + \"_idx\"\n        new_links_df[_idx_c] = new_links_df[RoadwayNetwork.UNIQUE_LINK_KEY]\n        new_links_df.set_index(_idx_c, inplace=True)\n        new_links_df = RoadwayNetwork.coerce_types(new_links_df)\n\n        new_links_df = self._create_new_link_geometry(new_links_df)\n\n        WranglerLogger.debug(\n            f\"New Links:\\n{new_links_df[[RoadwayNetwork.UNIQUE_LINK_KEY,'name']]}\"\n        )\n        assert self.new_links_valid(new_links_df)\n        return new_links_df\n\n    def _create_nodes(self, new_nodes: Collection[dict] = []):\n\n        new_nodes_df = pd.DataFrame(new_nodes)\n\n        _idx_c = RoadwayNetwork.UNIQUE_NODE_KEY + \"_idx\"\n        new_nodes_df[_idx_c] = new_nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY]\n        new_nodes_df.set_index(_idx_c, inplace=True)\n        new_nodes_df = RoadwayNetwork.coerce_types(new_nodes_df)\n\n        new_nodes_df[\"geometry\"] = new_nodes_df.apply(\n            lambda x: point_from_xy(\n                x[\"X\"],\n                x[\"Y\"],\n                xy_crs=RoadwayNetwork.CRS,\n                point_crs=RoadwayNetwork.CRS,\n            ),\n            axis=1,\n        )\n\n        new_nodes_df = gpd.GeoDataFrame(new_nodes_df)\n        WranglerLogger.debug(f\"New Nodes:\\n{new_nodes_df}\")\n\n        assert self.new_nodes_valid(new_nodes_df)\n        return new_nodes_df\n\n    def add_new_roadway_feature_change(\n        self, add_links: Collection[dict] = [], add_nodes: Collection[dict] = []\n    ) -&gt; None:\n\"\"\"\n        Add the new roadway features defined in the project card.\n\n        New shapes are also added for the new roadway links.\n\n        New nodes are added first so that links can refer to any added nodes.\n\n        args:\n            add_links: list of dictionaries\n            add_nodes: list of dictionaries\n\n        returns: updated network with new links and nodes and associated geometries\n\n        .. todo:: validate links and nodes dictionary\n        \"\"\"\n        WranglerLogger.debug(\n            f\"Adding New Roadway Features:\\n-Links:\\n{add_links}\\n-Nodes:\\n{add_nodes}\"\n        )\n        if add_nodes:\n            _new_nodes_df = self._create_nodes(add_nodes)\n            self.nodes_df = pd.concat([self.nodes_df, _new_nodes_df])\n\n        if add_links:\n            _new_links_df = self._create_links(add_links)\n            self.links_df = pd.concat([self.links_df, _new_links_df])\n\n            _new_shapes_df = RoadwayNetwork._create_new_shapes_from_links(_new_links_df)\n            self.shapes_df = pd.concat([self.shapes_df, _new_shapes_df])\n        return self\n\n    def new_nodes_valid(self, new_nodes_df: pd.DataFrame) -&gt; bool:\n\n        # Check to see if same node is already in the network\n        _existing_nodes = new_nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].apply(\n            self.has_node\n        )\n        if _existing_nodes.any():\n            msg = f\"Node already exists between nodes:\\n {new_nodes_df[_existing_nodes,RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK]}.\"\n            raise ValueError(msg)\n\n        # Check to see if there are missing required columns\n        _missing_cols = [\n            c\n            for c in RoadwayNetwork.MIN_NODE_REQUIRED_PROPS_DEFAULT\n            if c not in new_nodes_df.columns\n        ]\n        if _missing_cols:\n            msg = f\"Missing required link properties:{_missing_cols}\"\n            raise ValueError(msg)\n\n        # Check to see if there are missing required values\n        _missing_values = new_nodes_df[\n            RoadwayNetwork.MIN_NODE_REQUIRED_PROPS_DEFAULT\n        ].isna()\n        if _missing_values.any().any():\n            msg = f\"Missing values for required node properties:\\n{new_nodes_df.loc[_missing_values]}\"\n            WranglerLogger.Warning(msg)\n\n        return True\n\n    def new_links_valid(self, new_links_df: pd.DataFrame) -&gt; bool:\n\"\"\"Assesses if a set of links are valid for adding to self.links_df.\n\n        Will produce a ValueError if new_links_df:\n        1. A-B combinations are not unique within new_links_df\n        2. UNIQUE_LINK_KEY is not unique within new_links_df\n        3. A-B combinations overlap with an existing A-B link in self.links_df\n        4. UNIQUE_LINK_KEY overlaps with an existing UNIQUE_LINK_ID in self.links_df\n        5. A and B nodes are not in self.nodes_df\n        6. Doesn't contain columns for MIN_LINK_REQUIRED_PROPS_DEFAULT\n\n        Will produce a warning if there are NA values for any MIN_LINK_REQUIRED_PROPS_DEFAULT\n\n        Args:\n            new_links_df: dataframe of links being considered for addition to self.links_df\n\n        Returns:\n            bool: Returns a True if passes various validation tests.\n        \"\"\"\n\n        # A-B combinations are unique within new_links_df\n        _new_fk_id = pd.Series(\n            zip(*[new_links_df[c] for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE])\n        )\n        if not _new_fk_id.is_unique:\n            msg = f\"Duplicate ABs in new links.\"\n            raise ValueError(msg)\n\n        # UNIQUE_LINK_ID is unique within new_links_df\n        if not new_links_df[RoadwayNetwork.UNIQUE_LINK_KEY].is_unique:\n            msg = f\"Duplicate link IDs in new links.\"\n            raise ValueError(msg)\n\n        # Doesn't overlap with an existing A-B link in self.links_df\n        _existing_links_ab = _new_fk_id.apply(self.has_link)\n        if _existing_links_ab.any():\n            msg = f\"Link already exists between nodes:\\n {_new_fk_id[_existing_links_ab]}.\"\n            raise ValueError(msg)\n\n        # Doesn't overlap with an existing UNIQUE_LINK_ID in self.links_df\n        _ids = pd.concat(\n            [\n                self.links_df[RoadwayNetwork.UNIQUE_LINK_KEY],\n                new_links_df[RoadwayNetwork.UNIQUE_LINK_KEY],\n            ]\n        )\n        if not _ids.is_unique:\n            msg = f\"Link ID already exists:\\n{_ids.loc[_ids.duplicated()]}.\"\n            raise ValueError(msg)\n\n        # A and B nodes are in self.nodes_df\n        for fk_prop in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE:\n            _has_node = new_links_df[fk_prop].apply(self.has_node)\n            if not _has_node.all():\n                if len(self.nodes) &lt; 25:\n                    WranglerLogger.debug(f\"self.nodes_df:\\n{self.nodes_df}\")\n                msg = f\"New link specifies non existant node {fk_prop} = {new_links_df.loc[_has_node,fk_prop]}.\"\n                raise ValueError(msg)\n\n        # Check to see if there are missing required columns\n        _missing_cols = [\n            c\n            for c in RoadwayNetwork.MIN_LINK_REQUIRED_PROPS_DEFAULT\n            if c not in new_links_df.columns\n        ]\n        if _missing_cols:\n            msg = f\"Missing required link properties:{_missing_cols}\"\n            raise ValueError(msg)\n\n        # Check to see if there are missing required values\n        _missing_values = new_links_df[\n            RoadwayNetwork.MIN_LINK_REQUIRED_PROPS_DEFAULT\n        ].isna()\n        if _missing_values.any().any():\n            msg = f\"Missing values for required link properties:\\n{new_links_df.loc[_missing_values]}\"\n            WranglerLogger.Warning(msg)\n\n        return True\n\n    def has_node(self, unique_node_id) -&gt; bool:\n\"\"\"Queries if network has node based on RoadwayNetwork.UNIQUE_NODE_KEY.\n\n        Args:\n            unique_node_id (_type_): value of RoadwayNetwork.UNIQUE_NODE_KEY\n        \"\"\"\n\n        has_node = (\n            self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY].isin([unique_node_id]).any()\n        )\n\n        return has_node\n\n    def has_link(self, link_key_values: tuple) -&gt; bool:\n\"\"\"Returns true if network has link based values corresponding with LINK_FOREIGN_KEY_TO_NODE properties.\n\n        Args:\n            link_key_values: Tuple of values corresponding with RoadwayNetwork.LINK_FOREIGN_KEY_TO_ ODE properties.\n                If LINK_FOREIGN_KEY_TO_NODE is (\"A\",\"B\"), then (1,2) references the link of A=1 and B=2.\n        \"\"\"\n        _query_parts = [\n            f\"{k} == {str(v)}\"\n            for k, v in zip(RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE, link_key_values)\n        ]\n        _query = \" and \".join(_query_parts)\n        _links = self.links_df.query(_query, engine=\"python\")\n\n        return bool(len(_links))\n\n    def _shapes_without_links(self) -&gt; pd.Series:\n\"\"\"Returns shape ids that don't have associated links.\"\"\"\n\n        _ids_in_shapes = self.links_df[RoadwayNetwork.UNIQUE_SHAPE_KEY]\n        _ids_in_links = self.links_df[RoadwayNetwork.LINK_FOREIGN_KEY_TO_SHAPE]\n\n        shapes_missing_links = _ids_in_shapes[~_ids_in_shapes.isin(_ids_in_links)]\n        return shapes_missing_links\n\n    def delete_links(self, del_links, dict, ignore_missing=True) -&gt; None:\n\"\"\"\n        Delete the roadway links based on del_links dictionary selecting links by properties.\n\n        Also deletes shapes which no longer have links associated with them.\n\n        Args:\n            del_links: Dictionary identified shapes to delete by properties.  Links will be selected\n                if *any* of the properties are equal to *any* of the values.\n            ignore_missing: If True, will only warn if try to delete a links that isn't in network.\n                If False, it will fail on missing links. Defaults to True.\n        \"\"\"\n        # if RoadwayNetwork.UNIQUE_LINK_ID is used to select, flag links that weren't in network.\n        if RoadwayNetwork.UNIQUE_LINK_KEY in del_links:\n            _del_link_ids = pd.Series(del_links[RoadwayNetwork.UNIQUE_LINK_KEY])\n            _missing_links = _del_link_ids[\n                ~_del_link_ids.isin(self.links_df[RoadwayNetwork.UNIQUE_LINK_KEY])\n            ]\n            msg = f\"Following links cannot be deleted because they are not in the network: {_missing_links}\"\n            if len(_missing_links) and ignore_missing:\n                WranglerLogger.warning(msg)\n            elif len(_missing_links):\n                raise ValueError(msg)\n\n        _del_links_mask = self.links_df.isin(del_links).any(axis=1)\n        if not _del_links_mask.any():\n            WranglerLogger.warning(\"No links found matching criteria to delete.\")\n            return\n        WranglerLogger.debug(\n            f\"Deleting following links:\\n{self.links_df.loc[_del_links_mask][['A','B','model_link_id']]}\"\n        )\n        self.links_df = self.links_df.loc[~_del_links_mask]\n\n        # Delete shapes which no longer have links associated with them\n        _shapes_without_links = self._shapes_without_links()\n        if len(_shapes_without_links):\n            WranglerLogger.debug(f\"Shapes without links:\\n {_shapes_without_links}\")\n            self.shapes_df = self.shapes_df.loc[~_shapes_without_links]\n            WranglerLogger.debug(f\"self.shapes_df reduced to:\\n {self.shapes_df}\")\n\n    def delete_nodes(self, del_nodes: dict, ignore_missing: bool = True) -&gt; None:\n\"\"\"\n        Delete the roadway nodes based on del_nodes dictionary selecting nodes by properties.\n\n        Will fail if try to delete node that is currently being used by a link.\n\n        Args:\n            del_nodes : Dictionary identified nodes to delete by properties.  Nodes will be selected\n                if *any* of the properties are equal to *any* of the values.\n            ignore_missing: If True, will only warn if try to delete a node that isn't in network.\n                If False, it will fail on missing nodes. Defaults to True.\n        \"\"\"\n        _del_nodes_mask = self.nodes_df.isin(del_nodes).any(axis=1)\n        _del_nodes_df = self.nodes_df.loc[_del_nodes_mask]\n\n        if not _del_nodes_mask.any():\n            WranglerLogger.warning(\"No nodes found matching criteria to delete.\")\n            return\n\n        WranglerLogger.debug(f\"Deleting Nodes:\\n{_del_nodes_df}\")\n        # Check if node used in an existing link\n        _links_with_nodes = RoadwayNetwork.links_with_nodes(\n            self.links_df,\n            _del_nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].tolist(),\n        )\n        if len(_links_with_nodes):\n            WranglerLogger.error(\n                f\"Node deletion failed because being used in following links:\\n{_links_with_nodes[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE]}\"\n            )\n            raise ValueError\n\n        # Check if node is in network\n        if RoadwayNetwork.UNIQUE_NODE_KEY in del_nodes:\n            _del_node_ids = pd.Series(del_nodes[RoadwayNetwork.UNIQUE_NODE_KEY])\n            _missing_nodes = _del_node_ids[\n                ~_del_node_ids.isin(self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY])\n            ]\n            msg = f\"Following nodes cannot be deleted because they are not in the network: {_missing_nodes}\"\n            if len(_missing_nodes) and ignore_missing:\n                WranglerLogger.warning(msg)\n            elif len(_missing_nodes):\n                raise ValueError(msg)\n        self.nodes_df = self.nodes_df.loc[~_del_nodes_mask]\n\n    def delete_roadway_feature_change(\n        self,\n        del_links: dict = None,\n        del_nodes: dict = None,\n        ignore_missing=True,\n    ) -&gt; \"RoadwayNetwork\":\n\"\"\"\n        Delete the roadway links or nodes defined in the project card.\n\n        Corresponding shapes to the deleted links are also deleted if they are not used elsewhere.\n\n        Args:\n            del_links : dictionary of identified links to delete\n            del_nodes : dictionary of identified nodes to delete\n            ignore_missing: bool\n                If True, will only warn about links/nodes that are missing from\n                network but specified to \"delete\" in project card\n                If False, will fail.\n        \"\"\"\n\n        WranglerLogger.debug(\n            f\"Deleting Roadway Features:\\n-Links:\\n{del_links}\\n-Nodes:\\n{del_nodes}\"\n        )\n\n        if del_links:\n            self.delete_links(del_links, ignore_missing)\n\n        if del_nodes:\n            self.delete_nodes(del_nodes, ignore_missing)\n\n        return self\n\n    def get_property_by_time_period_and_group(\n        self, property, time_period=None, category=None\n    ):\n\"\"\"\n        Return a series for the properties with a specific group or time period.\n\n        args\n        ------\n        property: str\n          the variable that you want from network\n        time_period: list(str)\n          the time period that you are querying for\n          i.e. ['16:00', '19:00']\n        category: str or list(str)(Optional)\n          the group category\n          i.e. \"sov\"\n\n          or\n\n          list of group categories in order of search, i.e.\n          [\"hov3\",\"hov2\"]\n\n        returns\n        --------\n        pandas series\n        \"\"\"\n\n        def _get_property(\n            v,\n            time_spans=None,\n            category=None,\n            return_partial_match: bool = False,\n            partial_match_minutes: int = 60,\n        ):\n\"\"\"\n\n            .. todo:: return the time period with the largest overlap\n\n            \"\"\"\n\n            if category and not time_spans:\n                WranglerLogger.error(\n                    \"\\nShouldn't have a category group without time spans\"\n                )\n                raise ValueError(\"Shouldn't have a category group without time spans\")\n\n            # simple case\n            if type(v) in (int, float, str):\n                return v\n\n            if not category:\n                category = [\"default\"]\n            elif isinstance(category, str):\n                category = [category]\n            search_cats = [c.lower() for c in category]\n\n            # if no time or group specified, but it is a complex link situation\n            if not time_spans:\n                if \"default\" in v.keys():\n                    return v[\"default\"]\n                else:\n                    WranglerLogger.debug(f\"variable: {v}\")\n                    msg = f\"Variable {v} is more complex in network than query\"\n                    WranglerLogger.error(msg)\n                    raise ValueError(msg)\n\n            if v.get(\"timeofday\"):\n                categories = []\n                for tg in v[\"timeofday\"]:\n                    if (\n                        (time_spans[0] &gt;= tg[\"time\"][0])\n                        and (time_spans[1] &lt;= tg[\"time\"][1])\n                        and (time_spans[0] &lt;= time_spans[1])\n                    ):\n                        if tg.get(\"category\"):\n                            categories += tg[\"category\"]\n                            for c in search_cats:\n                                print(\"CAT:\", c, tg[\"category\"])\n                                if c in tg[\"category\"]:\n                                    # print(\"Var:\", v)\n                                    # print(\n                                    #    \"RETURNING:\", time_spans, category, tg[\"value\"]\n                                    # )\n                                    return tg[\"value\"]\n                        else:\n                            # print(\"Var:\", v)\n                            # print(\"RETURNING:\", time_spans, category, tg[\"value\"])\n                            return tg[\"value\"]\n\n                    if (\n                        (time_spans[0] &gt;= tg[\"time\"][0])\n                        and (time_spans[1] &lt;= tg[\"time\"][1])\n                        and (time_spans[0] &gt; time_spans[1])\n                        and (tg[\"time\"][0] &gt; tg[\"time\"][1])\n                    ):\n                        if tg.get(\"category\"):\n                            categories += tg[\"category\"]\n                            for c in search_cats:\n                                print(\"CAT:\", c, tg[\"category\"])\n                                if c in tg[\"category\"]:\n                                    # print(\"Var:\", v)\n                                    # print(\n                                    #    \"RETURNING:\", time_spans, category, tg[\"value\"]\n                                    # )\n                                    return tg[\"value\"]\n                        else:\n                            # print(\"Var:\", v)\n                            # print(\"RETURNING:\", time_spans, category, tg[\"value\"])\n                            return tg[\"value\"]\n\n                    # if there isn't a fully matched time period, see if there is an overlapping\n                    # one right now just return the first overlapping ones\n                    # TODO return the time period with the largest overlap\n\n                    if (\n                        (time_spans[0] &gt;= tg[\"time\"][0])\n                        and (time_spans[0] &lt;= tg[\"time\"][1])\n                    ) or (\n                        (time_spans[1] &gt;= tg[\"time\"][0])\n                        and (time_spans[1] &lt;= tg[\"time\"][1])\n                    ):\n                        overlap_minutes = max(\n                            0,\n                            min(tg[\"time\"][1], time_spans[1])\n                            - max(time_spans[0], tg[\"time\"][0]),\n                        )\n                        # print(\"OLM\",overlap_minutes)\n                        if not return_partial_match and overlap_minutes &gt; 0:\n                            WranglerLogger.debug(\n                                f\"Couldn't find time period consistent with {time_spans}, but \\\n                                    found a partial match: {tg['time']}. Consider allowing \\\n                                    partial matches using 'return_partial_match' keyword or \\\n                                    updating query.\"\n                            )\n                        elif (\n                            overlap_minutes &lt; partial_match_minutes\n                            and overlap_minutes &gt; 0\n                        ):\n                            WranglerLogger.debug(\n                                f\"Time period: {time_spans} overlapped less than the minimum number \\\n                                of minutes ({overlap_minutes}&lt;{partial_match_minutes}) to be \\\n                                considered a match with time period in network: {tg['time']}.\"\n                            )\n                        elif overlap_minutes &gt; 0:\n                            WranglerLogger.debug(\n                                f\"Returning a partial time period match. Time period: {time_spans}\\\n                                overlapped the minimum number of minutes ({overlap_minutes}&gt;=\\\n{partial_match_minutes}) to be considered a match with time period\\\n                                 in network: {tg['time']}.\"\n                            )\n                            if tg.get(\"category\"):\n                                categories += tg[\"category\"]\n                                for c in search_cats:\n                                    print(\"CAT:\", c, tg[\"category\"])\n                                    if c in tg[\"category\"]:\n                                        # print(\"Var:\", v)\n                                        # print(\n                                        #    \"RETURNING:\",\n                                        #    time_spans,\n                                        #    category,\n                                        #    tg[\"value\"],\n                                        # )\n                                        return tg[\"value\"]\n                            else:\n                                # print(\"Var:\", v)\n                                # print(\"RETURNING:\", time_spans, category, tg[\"value\"])\n                                return tg[\"value\"]\n\n\"\"\"\n                WranglerLogger.debug(\n                    \"\\nCouldn't find time period for {}, returning default\".format(\n                        str(time_spans)\n                    )\n                )\n                \"\"\"\n                if \"default\" in v.keys():\n                    # print(\"Var:\", v)\n                    # print(\"RETURNING:\", time_spans, v[\"default\"])\n                    return v[\"default\"]\n                else:\n                    # print(\"Var:\", v)\n                    WranglerLogger.error(\n                        \"\\nCan't find default; must specify a category in {}\".format(\n                            str(categories)\n                        )\n                    )\n                    raise ValueError(\n                        \"Can't find default, must specify a category in: {}\".format(\n                            str(categories)\n                        )\n                    )\n\n        time_spans = parse_time_spans_to_secs(time_period)\n\n        return self.links_df[property].apply(\n            _get_property, time_spans=time_spans, category=category\n        )\n\n    def _nodes_from_link(\n        self, links_df: gpd.GeoDataFrame, link_pos: int, node_key_field: str\n    ) -&gt; gpd.GeoDataFrame:\n\"\"\"Creates a basic list of node entries from links, their geometry, and a position.\n\n        TODO: Does not currently fill in additional values used in nodes.\n\n        Args:\n            links_df (gpd.GeoDataFrame): subset of self.links_df or similar which needs nodes created\n            link_pos (int): Position within geometry collection to use for geometry\n            node_key_field (str): field name to use for generating index and node key\n\n        Returns:\n            gpd.GeoDataFrame: _description_\n        \"\"\"\n\n        nodes_df = copy.deepcopy(\n            links_df[[node_key_field, \"geometry\"]].drop_duplicates()\n        )\n        # WranglerLogger.debug(f\"ct1: nodes_df:\\n{nodes_df}\")\n        nodes_df = nodes_df.rename(\n            columns={node_key_field: RoadwayNetwork.UNIQUE_NODE_KEY}\n        )\n        # WranglerLogger.debug(f\"ct2: nodes_df:\\n{nodes_df}\")\n        nodes_df[\"geometry\"] = nodes_df[\"geometry\"].apply(\n            get_point_geometry_from_linestring, pos=link_pos\n        )\n        nodes_df[\"X\"] = nodes_df.geometry.x\n        nodes_df[\"Y\"] = nodes_df.geometry.y\n        nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY + \"_idx\"] = nodes_df[\n            RoadwayNetwork.UNIQUE_NODE_KEY\n        ]\n        nodes_df.set_index(RoadwayNetwork.UNIQUE_NODE_KEY + \"_idx\", inplace=True)\n        # WranglerLogger.debug(f\"ct3: nodes_df:\\n{nodes_df}\")\n        return nodes_df\n\n    @staticmethod\n    def get_modal_links_nodes(\n        links_df: DataFrame, nodes_df: DataFrame, modes: list[str] = None\n    ) -&gt; tuple(DataFrame, DataFrame):\n\"\"\"Returns nodes and link dataframes for specific mode.\n\n        Args:\n            links_df: DataFrame of standard network links\n            nodes_df: DataFrame of standard network nodes\n            modes: list of the modes of the network to be kept, must be in\n                `drive`,`transit`,`rail`,`bus`,`walk`, `bike`.\n                For example, if bike and walk are selected, both bike and walk links will be kept.\n\n        Returns: tuple of DataFrames for links, nodes filtered by mode\n\n        .. todo:: Right now we don't filter the nodes because transit-only\n        links with walk access are not marked as having walk access\n        Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145\n        modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1]\n        \"\"\"\n        for mode in modes:\n            if mode not in RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys():\n                msg = \"mode value should be one of {}, got {}\".format(\n                    list(RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys()),\n                    mode,\n                )\n                WranglerLogger.error(msg)\n                raise ValueError(msg)\n\n        mode_link_variables = list(\n            set(\n                [\n                    mode\n                    for mode in modes\n                    for mode in RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES[mode]\n                ]\n            )\n        )\n        mode_node_variables = list(\n            set(\n                [\n                    mode\n                    for mode in modes\n                    for mode in RoadwayNetwork.MODES_TO_NETWORK_NODE_VARIABLES[mode]\n                ]\n            )\n        )\n\n        if not set(mode_link_variables).issubset(set(links_df.columns)):\n            msg = f\"\"\"{set(mode_link_variables) - set(links_df.columns)} not in provided links_df \\\n                list of columns. Available columns are:\n{links_df.columns}\"\"\"\n            WranglerLogger.error(msg)\n\n        if not set(mode_node_variables).issubset(set(nodes_df.columns)):\n            msg = f\"\"\"{set(mode_node_variables) - set(nodes_df.columns)} not in provided nodes_df \\\n                list of columns. Available columns are:\n{nodes_df.columns}\"\"\"\n            WranglerLogger.error(msg)\n\n        modal_links_df = links_df.loc[links_df[mode_link_variables].any(axis=1)]\n\n        # TODO right now we don't filter the nodes because transit-only\n        # links with walk access are not marked as having walk access\n        # Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145\n        # modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1]\n        modal_nodes_df = nodes_df\n\n        return modal_links_df, modal_nodes_df\n\n    @staticmethod\n    def get_modal_graph(links_df: DataFrame, nodes_df: DataFrame, mode: str = None):\n\"\"\"Determines if the network graph is \"strongly\" connected\n        A graph is strongly connected if each vertex is reachable from every other vertex.\n\n        Args:\n            links_df: DataFrame of standard network links\n            nodes_df: DataFrame of standard network nodes\n            mode: mode of the network, one of `drive`,`transit`,\n                `walk`, `bike`\n\n        Returns: networkx: osmnx: DiGraph  of network\n        \"\"\"\n        if mode not in RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys():\n            msg = \"mode value should be one of {}.\".format(\n                list(RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys())\n            )\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n\n        _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n            links_df,\n            nodes_df,\n            modes=[mode],\n        )\n        G = RoadwayNetwork.ox_graph(_nodes_df, _links_df)\n\n        return G\n\n    def is_network_connected(\n        self, mode: str = None, links_df: DataFrame = None, nodes_df: DataFrame = None\n    ):\n\"\"\"\n        Determines if the network graph is \"strongly\" connected\n        A graph is strongly connected if each vertex is reachable from every other vertex.\n\n        Args:\n            mode:  mode of the network, one of `drive`,`transit`,\n                `walk`, `bike`\n            links_df: DataFrame of standard network links\n            nodes_df: DataFrame of standard network nodes\n\n        Returns: boolean\n\n        .. todo:: Consider caching graphs if they take a long time.\n        \"\"\"\n\n        _nodes_df = nodes_df if nodes_df else self.nodes_df\n        _links_df = links_df if links_df else self.links_df\n\n        if mode:\n            _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n                _links_df,\n                _nodes_df,\n                modes=[mode],\n            )\n        else:\n            WranglerLogger.info(\n                \"Assessing connectivity without a mode\\\n                specified. This may have limited value in interpretation.\\\n                To add mode specificity, add the keyword `mode =` to calling\\\n                this method\"\n            )\n\n        # TODO: consider caching graphs if they start to take forever\n        #      and we are calling them more than once.\n        G = RoadwayNetwork.ox_graph(_nodes_df, _links_df)\n        is_connected = nx.is_strongly_connected(G)\n\n        return is_connected\n\n    @staticmethod\n    def add_incident_link_data_to_nodes(\n        links_df: DataFrame = None,\n        nodes_df: DataFrame = None,\n        link_variables: list = [],\n    ) -&gt; DataFrame:\n\"\"\"\n        Add data from links going to/from nodes to node.\n\n        Args:\n            links_df: if specified, will assess connectivity of this\n                links list rather than self.links_df\n            nodes_df: if specified, will assess connectivity of this\n                nodes list rather than self.nodes_df\n            link_variables: list of columns in links dataframe to add to incident nodes\n\n        Returns:\n            nodes DataFrame with link data where length is N*number of links going in/out\n        \"\"\"\n        WranglerLogger.debug(\"Adding following link data to nodes: \".format())\n\n        _link_vals_to_nodes = [x for x in link_variables if x in links_df.columns]\n        if link_variables not in _link_vals_to_nodes:\n            WranglerLogger.warning(\n                \"Following columns not in links_df and wont be added to nodes: {} \".format(\n                    list(set(link_variables) - set(_link_vals_to_nodes))\n                )\n            )\n\n        _nodes_from_links_A = nodes_df.merge(\n            links_df[[\"A\"] + _link_vals_to_nodes],\n            how=\"outer\",\n            left_on=RoadwayNetwork.UNIQUE_NODE_KEY,\n            right_on=\"A\",\n        )\n        _nodes_from_links_B = nodes_df.merge(\n            links_df[[\"B\"] + _link_vals_to_nodes],\n            how=\"outer\",\n            left_on=RoadwayNetwork.UNIQUE_NODE_KEY,\n            right_on=\"B\",\n        )\n        _nodes_from_links_ab = pd.concat([_nodes_from_links_A, _nodes_from_links_B])\n\n        return _nodes_from_links_ab\n\n    def identify_segment_endpoints(\n        self,\n        mode: str = \"\",\n        links_df: DataFrame = None,\n        nodes_df: DataFrame = None,\n        min_connecting_links: int = 10,\n        min_distance: float = None,\n        max_link_deviation: int = 2,\n    ):\n\"\"\"\n\n        Args:\n            mode:  list of modes of the network, one of `drive`,`transit`,\n                `walk`, `bike`\n            links_df: if specified, will assess connectivity of this\n                links list rather than self.links_df\n            nodes_df: if specified, will assess connectivity of this\n                nodes list rather than self.nodes_df\n\n        \"\"\"\n        SEGMENT_IDENTIFIERS = [\"name\", \"ref\"]\n\n        NAME_PER_NODE = 4\n        REF_PER_NODE = 2\n\n        _nodes_df = nodes_df if nodes_df else self.nodes_df\n        _links_df = links_df if links_df else self.links_df\n\n        if mode:\n            _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n                _links_df,\n                _nodes_df,\n                modes=[mode],\n            )\n        else:\n            WranglerLogger.warning(\n                \"Assessing connectivity without a mode\\\n                specified. This may have limited value in interpretation.\\\n                To add mode specificity, add the keyword `mode =` to calling\\\n                this method\"\n            )\n\n        _nodes_df = RoadwayNetwork.add_incident_link_data_to_nodes(\n            links_df=_links_df,\n            nodes_df=_nodes_df,\n            link_variables=SEGMENT_IDENTIFIERS + [\"distance\"],\n        )\n        WranglerLogger.debug(\"Node/Link table elements: {}\".format(len(_nodes_df)))\n\n        # Screen out segments that have blank name AND refs\n        _nodes_df = _nodes_df.replace(r\"^\\s*$\", np.nan, regex=True).dropna(\n            subset=[\"name\", \"ref\"]\n        )\n\n        WranglerLogger.debug(\n            \"Node/Link table elements after dropping empty name AND ref : {}\".format(\n                len(_nodes_df)\n            )\n        )\n\n        # Screen out segments that aren't likely to be long enough\n        # Minus 1 in case ref or name is missing on an intermediate link\n        _min_ref_in_table = REF_PER_NODE * (min_connecting_links - max_link_deviation)\n        _min_name_in_table = NAME_PER_NODE * (min_connecting_links - max_link_deviation)\n\n        _nodes_df[\"ref_freq\"] = _nodes_df[\"ref\"].map(_nodes_df[\"ref\"].value_counts())\n        _nodes_df[\"name_freq\"] = _nodes_df[\"name\"].map(_nodes_df[\"name\"].value_counts())\n\n        _nodes_df = _nodes_df.loc[\n            (_nodes_df[\"ref_freq\"] &gt;= _min_ref_in_table)\n            &amp; (_nodes_df[\"name_freq\"] &gt;= _min_name_in_table)\n        ]\n\n        WranglerLogger.debug(\n            \"Node/Link table has n = {} after screening segments for min length:\\n{}\".format(\n                len(_nodes_df),\n                _nodes_df[\n                    [\n                        RoadwayNetwork.UNIQUE_NODE_KEY,\n                        \"name\",\n                        \"ref\",\n                        \"distance\",\n                        \"ref_freq\",\n                        \"name_freq\",\n                    ]\n                ],\n            )\n        )\n        # ----------------------------------------\n        # Find nodes that are likely endpoints\n        # ----------------------------------------\n\n        # - Likely have one incident link and one outgoing link\n        _max_ref_endpoints = REF_PER_NODE / 2\n        _max_name_endpoints = NAME_PER_NODE / 2\n        # - Attach frequency  of node/ref\n        _nodes_df = _nodes_df.merge(\n            _nodes_df.groupby(by=[RoadwayNetwork.UNIQUE_NODE_KEY, \"ref\"])\n            .size()\n            .rename(\"ref_N_freq\"),\n            on=[RoadwayNetwork.UNIQUE_NODE_KEY, \"ref\"],\n        )\n        # WranglerLogger.debug(\"_ref_count+_nodes:\\n{}\".format(_nodes_df[[\"model_node_id\",\"ref\",\"name\",\"ref_N_freq\"]]))\n        # - Attach frequency  of node/name\n        _nodes_df = _nodes_df.merge(\n            _nodes_df.groupby(by=[RoadwayNetwork.UNIQUE_NODE_KEY, \"name\"])\n            .size()\n            .rename(\"name_N_freq\"),\n            on=[RoadwayNetwork.UNIQUE_NODE_KEY, \"name\"],\n        )\n        # WranglerLogger.debug(\"_name_count+_nodes:\\n{}\".format(_nodes_df[[\"model_node_id\",\"ref\",\"name\",\"name_N_freq\"]]))\n\n        WranglerLogger.debug(\n            \"Possible segment endpoints:\\n{}\".format(\n                _nodes_df[\n                    [\n                        RoadwayNetwork.UNIQUE_NODE_KEY,\n                        \"name\",\n                        \"ref\",\n                        \"distance\",\n                        \"ref_N_freq\",\n                        \"name_N_freq\",\n                    ]\n                ]\n            )\n        )\n        # - Filter possible endpoint list based on node/name node/ref frequency\n        _nodes_df = _nodes_df.loc[\n            (_nodes_df[\"ref_N_freq\"] &lt;= _max_ref_endpoints)\n            | (_nodes_df[\"name_N_freq\"] &lt;= _max_name_endpoints)\n        ]\n        WranglerLogger.debug(\n            \"{} Likely segment endpoints with req_ref&lt;= {} or freq_name&lt;={} \\n{}\".format(\n                len(_nodes_df),\n                _max_ref_endpoints,\n                _max_name_endpoints,\n                _nodes_df[\n                    [\n                        RoadwayNetwork.UNIQUE_NODE_KEY,\n                        \"name\",\n                        \"ref\",\n                        \"ref_N_freq\",\n                        \"name_N_freq\",\n                    ]\n                ],\n            )\n        )\n        # ----------------------------------------\n        # Assign a segment id\n        # ----------------------------------------\n        _nodes_df[\"segment_id\"], _segments = pd.factorize(\n            _nodes_df.name + _nodes_df.ref\n        )\n        WranglerLogger.debug(\"{} Segments:\\n{}\".format(len(_segments), _segments))\n\n        # ----------------------------------------\n        # Drop segments without at least two nodes\n        # ----------------------------------------\n\n        # https://stackoverflow.com/questions/13446480/python-pandas-remove-entries-based-on-the-number-of-occurrences\n        _nodes_df = _nodes_df[\n            _nodes_df.groupby([\"segment_id\", RoadwayNetwork.UNIQUE_NODE_KEY])[\n                RoadwayNetwork.UNIQUE_NODE_KEY\n            ].transform(len)\n            &gt; 1\n        ]\n\n        WranglerLogger.debug(\n            \"{} Segments with at least nodes:\\n{}\".format(\n                len(_nodes_df),\n                _nodes_df[\n                    [RoadwayNetwork.UNIQUE_NODE_KEY, \"name\", \"ref\", \"segment_id\"]\n                ],\n            )\n        )\n\n        # ----------------------------------------\n        # For segments with more than two nodes, find farthest apart pairs\n        # ----------------------------------------\n\n        def _max_segment_distance(row):\n            _segment_nodes = _nodes_df.loc[_nodes_df[\"segment_id\"] == row[\"segment_id\"]]\n            dist = _segment_nodes.geometry.distance(row.geometry)\n            return max(dist.dropna())\n\n        _nodes_df[\"seg_distance\"] = _nodes_df.apply(_max_segment_distance, axis=1)\n        _nodes_df = _nodes_df.merge(\n            _nodes_df.groupby(\"segment_id\")\n            .seg_distance.agg(max)\n            .rename(\"max_seg_distance\"),\n            on=\"segment_id\",\n        )\n\n        _nodes_df = _nodes_df.loc[\n            (_nodes_df[\"max_seg_distance\"] == _nodes_df[\"seg_distance\"])\n            &amp; (_nodes_df[\"seg_distance\"] &gt; 0)\n        ].drop_duplicates(subset=[RoadwayNetwork.UNIQUE_NODE_KEY, \"segment_id\"])\n\n        # ----------------------------------------\n        # Reassign segment id for final segments\n        # ----------------------------------------\n        _nodes_df[\"segment_id\"], _segments = pd.factorize(\n            _nodes_df.name + _nodes_df.ref\n        )\n\n        WranglerLogger.debug(\n            \"{} Segments:\\n{}\".format(\n                len(_segments),\n                _nodes_df[\n                    [\n                        RoadwayNetwork.UNIQUE_NODE_KEY,\n                        \"name\",\n                        \"ref\",\n                        \"segment_id\",\n                        \"seg_distance\",\n                    ]\n                ],\n            )\n        )\n\n        return _nodes_df[\n            [\"segment_id\", RoadwayNetwork.UNIQUE_NODE_KEY, \"geometry\", \"name\", \"ref\"]\n        ]\n\n    def identify_segment(\n        self,\n        O_id,\n        D_id,\n        selection_dict: dict = {},\n        mode=None,\n        nodes_df=None,\n        links_df=None,\n    ):\n\"\"\"\n        Args:\n            endpoints: list of length of two unique keys of nodes making up endpoints of segment\n            selection_dict: dictionary of link variables to select candidate links from, otherwise\n                will create a graph of ALL links which will be both a RAM hog and could result in\n                odd shortest paths.\n            segment_variables: list of variables to keep\n        \"\"\"\n        _nodes_df = nodes_df if nodes_df else self.nodes_df\n        _links_df = links_df if links_df else self.links_df\n\n        if mode:\n            _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n                _links_df,\n                _nodes_df,\n                modes=[mode],\n            )\n        else:\n            WranglerLogger.warning(\n                \"Assessing connectivity without a mode\\\n                specified. This may have limited value in interpretation.\\\n                To add mode specificity, add the keyword `mode =` to calling\\\n                this method\"\n            )\n\n        if selection_dict:\n            _query = \" or \".join(\n                [f\"{k} == {repr(v)}\" for k, v in selection_dict.items()]\n            )\n            _candidate_links = _links_df.query(_query)\n            WranglerLogger.debug(\n                \"Found {} candidate links from {} total links using following query:\\n{}\".format(\n                    len(_candidate_links), len(_links_df), _query\n                )\n            )\n        else:\n            _candidate_links = _links_df\n\n            WranglerLogger.warning(\n                \"Not pre-selecting links using selection_dict can use up a lot of RAM and \\\n                    also result in odd segment paths.\"\n            )\n\n        WranglerLogger.debug(\n            \"_candidate links for segment: \\n{}\".format(\n                _candidate_links[[\"u\", \"v\", \"A\", \"B\", \"name\", \"ref\"]]\n            )\n        )\n\n        try:\n            (G, candidate_links, sp_route, sp_links) = self.path_search(\n                _candidate_links, O_id, D_id\n            )\n        except NoPathFound:\n            msg = \"Route not found from {} to {} using selection candidates {}\".format(\n                O_id, D_id, selection_dict\n            )\n            WranglerLogger.warning(msg)\n            sp_links = pd.DataFrame()\n\n        return sp_links\n\n    def assess_connectivity(\n        self,\n        mode: str = \"\",\n        ignore_end_nodes: bool = True,\n        links_df: DataFrame = None,\n        nodes_df: DataFrame = None,\n    ):\n\"\"\"Returns a network graph and list of disconnected subgraphs\n        as described by a list of their member nodes.\n\n        Args:\n            mode:  list of modes of the network, one of `drive`,`transit`,\n                `walk`, `bike`\n            ignore_end_nodes: if True, ignores stray singleton nodes\n            links_df: if specified, will assess connectivity of this\n                links list rather than self.links_df\n            nodes_df: if specified, will assess connectivity of this\n                nodes list rather than self.nodes_df\n\n        Returns: Tuple of\n            Network Graph (osmnx flavored networkX DiGraph)\n            List of disconnected subgraphs described by the list of their\n                member nodes (as described by their `model_node_id`)\n        \"\"\"\n        _nodes_df = nodes_df if nodes_df else self.nodes_df\n        _links_df = links_df if links_df else self.links_df\n\n        if mode:\n            _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n                _links_df,\n                _nodes_df,\n                modes=[mode],\n            )\n        else:\n            WranglerLogger.warning(\n                \"Assessing connectivity without a mode\\\n                specified. This may have limited value in interpretation.\\\n                To add mode specificity, add the keyword `mode =` to calling\\\n                this method\"\n            )\n\n        G = RoadwayNetwork.ox_graph(_nodes_df, _links_df)\n\n        sub_graph_nodes = [\n            list(s)\n            for s in sorted(nx.strongly_connected_components(G), key=len, reverse=True)\n        ]\n\n        # sorted on decreasing length, dropping the main sub-graph\n        disconnected_sub_graph_nodes = sub_graph_nodes[1:]\n\n        # dropping the sub-graphs with only 1 node\n        if ignore_end_nodes:\n            disconnected_sub_graph_nodes = [\n                list(s) for s in disconnected_sub_graph_nodes if len(s) &gt; 1\n            ]\n\n        WranglerLogger.info(\n            \"{} for disconnected networks for mode = {}:\\n{}\".format(\n                RoadwayNetwork.UNIQUE_NODE_KEY,\n                mode,\n                \"\\n\".join(list(map(str, disconnected_sub_graph_nodes))),\n            )\n        )\n        return G, disconnected_sub_graph_nodes\n\n    @staticmethod\n    def network_connection_plot(G, disconnected_subgraph_nodes: list):\n\"\"\"Plot a graph to check for network connection.\n\n        Args:\n            G: OSMNX flavored networkX graph.\n            disconnected_subgraph_nodes: List of disconnected subgraphs described by the list\n                of their member nodes (as described by their `model_node_id`).\n\n        returns: fig, ax : tuple\n        \"\"\"\n\n        colors = []\n        for i in range(len(disconnected_subgraph_nodes)):\n            colors.append(\"#%06X\" % randint(0, 0xFFFFFF))\n\n        fig, ax = ox.plot_graph(\n            G,\n            figsize=(16, 16),\n            show=False,\n            close=True,\n            edge_color=\"black\",\n            edge_alpha=0.1,\n            node_color=\"black\",\n            node_alpha=0.5,\n            node_size=10,\n        )\n        i = 0\n        for nodes in disconnected_subgraph_nodes:\n            for n in nodes:\n                size = 100\n                ax.scatter(G.nodes[n][\"X\"], G.nodes[n][\"Y\"], c=colors[i], s=size)\n            i = i + 1\n\n        return fig, ax\n\n    def selection_map(\n        self,\n        selected_link_idx: list,\n        A: Optional[Any] = None,\n        B: Optional[Any] = None,\n        candidate_link_idx: Optional[List] = [],\n    ):\n\"\"\"\n        Shows which links are selected for roadway property change or parallel\n        managed lanes category of roadway projects.\n\n        Args:\n            selected_links_idx: list of selected link indices\n            candidate_links_idx: optional list of candidate link indices to also include in map\n            A: optional foreign key of starting node of a route selection\n            B: optional foreign key of ending node of a route selection\n        \"\"\"\n        WranglerLogger.debug(\n            \"Selected Links: {}\\nCandidate Links: {}\\n\".format(\n                selected_link_idx, candidate_link_idx\n            )\n        )\n\n        graph_link_idx = list(set(selected_link_idx + candidate_link_idx))\n        graph_links = self.links_df.loc[graph_link_idx]\n\n        node_list_foreign_keys = list(\n            set(\n                [\n                    i\n                    for fk in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n                    for i in list(graph_links[fk])\n                ]\n            )\n        )\n\n        graph_nodes = self.nodes_df.loc[node_list_foreign_keys]\n\n        G = RoadwayNetwork.ox_graph(graph_nodes, graph_links)\n\n        # base map plot with whole graph\n        m = ox.plot_graph_folium(\n            G, edge_color=None, tiles=\"cartodbpositron\", width=\"300px\", height=\"250px\"\n        )\n\n        # plot selection\n        selected_links = self.links_df.loc[selected_link_idx]\n\n        for _, row in selected_links.iterrows():\n            pl = ox.folium._make_folium_polyline(\n                geom=row[\"geometry\"],\n                edge=row,\n                edge_color=\"blue\",\n                edge_width=5,\n                edge_opacity=0.8,\n            )\n            pl.add_to(m)\n\n        # if have A and B node add them to base map\n        def _folium_node(node_row, color=\"white\", icon=\"\"):\n            node_marker = folium.Marker(\n                location=[node_row[\"Y\"], node_row[\"X\"]],\n                icon=folium.Icon(icon=icon, color=color),\n            )\n            return node_marker\n\n        if A:\n            msg = f\"A: {A}\\n{self.nodes_df[self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY] == A]}\"\n            # WranglerLogger.debug(msg)\n            _folium_node(\n                self.nodes_df[self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY] == A],\n                color=\"green\",\n                icon=\"play\",\n            ).add_to(m)\n\n        if B:\n            _folium_node(\n                self.nodes_df[self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY] == B],\n                color=\"red\",\n                icon=\"star\",\n            ).add_to(m)\n\n        return m\n\n    def deletion_map(self, links: dict, nodes: dict):\n\"\"\"\n        Shows which links and nodes are deleted from the roadway network\n        \"\"\"\n\n        if links is not None:\n            for key, val in links.items():\n                deleted_links = self.links_df[self.links_df[key].isin(val)]\n\n                node_list_foreign_keys = list(\n                    set(\n                        [\n                            i\n                            for fk in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n                            for i in list(deleted_links[fk])\n                        ]\n                    )\n                )\n                candidate_nodes = self.nodes_df.loc[node_list_foreign_keys]\n        else:\n            deleted_links = None\n\n        if nodes is not None:\n            for key, val in nodes.items():\n                deleted_nodes = self.nodes_df[self.nodes_df[key].isin(val)]\n        else:\n            deleted_nodes = None\n\n        G = RoadwayNetwork.ox_graph(candidate_nodes, deleted_links)\n\n        m = ox.plot_graph_folium(G, edge_color=\"red\", tiles=\"cartodbpositron\")\n\n        def _folium_node(node, color=\"white\", icon=\"\"):\n            node_circle = folium.Circle(\n                location=[node[\"Y\"], node[\"X\"]],\n                radius=2,\n                fill=True,\n                color=color,\n                fill_opacity=0.8,\n            )\n            return node_circle\n\n        if deleted_nodes is not None:\n            for _, row in deleted_nodes.iterrows():\n                _folium_node(row, color=\"red\").add_to(m)\n\n        return m\n\n    def addition_map(self, links: dict, nodes: dict):\n\"\"\"\n        Shows which links and nodes are added to the roadway network\n        \"\"\"\n\n        if links is not None:\n            link_ids = []\n            for link in links:\n                link_ids.append(link.get(RoadwayNetwork.UNIQUE_LINK_KEY))\n\n            added_links = self.links_df[\n                self.links_df[RoadwayNetwork.UNIQUE_LINK_KEY].isin(link_ids)\n            ]\n            node_list_foreign_keys = list(\n                set(\n                    [\n                        i\n                        for fk in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n                        for i in list(added_links[fk])\n                    ]\n                )\n            )\n            try:\n                candidate_nodes = self.nodes_df.loc[node_list_foreign_keys]\n            except:\n                return None\n\n        if nodes is not None:\n            node_ids = []\n            for node in nodes:\n                node_ids.append(node.get(RoadwayNetwork.UNIQUE_NODE_KEY))\n\n            added_nodes = self.nodes_df[\n                self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY].isin(node_ids)\n            ]\n        else:\n            added_nodes = None\n\n        G = RoadwayNetwork.ox_graph(candidate_nodes, added_links)\n\n        m = ox.plot_graph_folium(G, edge_color=\"green\", tiles=\"cartodbpositron\")\n\n        def _folium_node(node, color=\"white\", icon=\"\"):\n            node_circle = folium.Circle(\n                location=[node[\"Y\"], node[\"X\"]],\n                radius=2,\n                fill=True,\n                color=color,\n                fill_opacity=0.8,\n            )\n            return node_circle\n\n        if added_nodes is not None:\n            for _, row in added_nodes.iterrows():\n                _folium_node(row, color=\"green\").add_to(m)\n\n        return m\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.__init__","title":"<code>__init__(nodes, links, shapes)</code>","text":"<p>Constructor</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def __init__(self, nodes: GeoDataFrame, links: GeoDataFrame, shapes: GeoDataFrame):\n\"\"\"\n    Constructor\n    \"\"\"\n\n    if not RoadwayNetwork.validate_object_types(nodes, links, shapes):\n        sys.exit(\"RoadwayNetwork: Invalid constructor data type\")\n\n    self.nodes_df = nodes\n    self.links_df = links\n    self.shapes_df = shapes\n\n    # Model network\n    self.m_nodes_df = None\n    self.m_links_df = None\n    self.m_shapes_df = None\n\n    self.link_file = None\n    self.node_file = None\n    self.shape_file = None\n\n    # Add non-required fields if they aren't there.\n    # for field, default_value in RoadwayNetwork.OPTIONAL_FIELDS:\n    #    if field not in self.links_df.columns:\n    #        self.links_df[field] = default_value\n    if not self.validate_uniqueness():\n        raise ValueError(\"IDs in network not unique\")\n    self.selections = {}\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.add_incident_link_data_to_nodes","title":"<code>add_incident_link_data_to_nodes(links_df=None, nodes_df=None, link_variables=[])</code>  <code>staticmethod</code>","text":"<p>Add data from links going to/from nodes to node.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>DataFrame</code> <p>if specified, will assess connectivity of this links list rather than self.links_df</p> <code>None</code> <code>nodes_df</code> <code>DataFrame</code> <p>if specified, will assess connectivity of this nodes list rather than self.nodes_df</p> <code>None</code> <code>link_variables</code> <code>list</code> <p>list of columns in links dataframe to add to incident nodes</p> <code>[]</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>nodes DataFrame with link data where length is N*number of links going in/out</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef add_incident_link_data_to_nodes(\n    links_df: DataFrame = None,\n    nodes_df: DataFrame = None,\n    link_variables: list = [],\n) -&gt; DataFrame:\n\"\"\"\n    Add data from links going to/from nodes to node.\n\n    Args:\n        links_df: if specified, will assess connectivity of this\n            links list rather than self.links_df\n        nodes_df: if specified, will assess connectivity of this\n            nodes list rather than self.nodes_df\n        link_variables: list of columns in links dataframe to add to incident nodes\n\n    Returns:\n        nodes DataFrame with link data where length is N*number of links going in/out\n    \"\"\"\n    WranglerLogger.debug(\"Adding following link data to nodes: \".format())\n\n    _link_vals_to_nodes = [x for x in link_variables if x in links_df.columns]\n    if link_variables not in _link_vals_to_nodes:\n        WranglerLogger.warning(\n            \"Following columns not in links_df and wont be added to nodes: {} \".format(\n                list(set(link_variables) - set(_link_vals_to_nodes))\n            )\n        )\n\n    _nodes_from_links_A = nodes_df.merge(\n        links_df[[\"A\"] + _link_vals_to_nodes],\n        how=\"outer\",\n        left_on=RoadwayNetwork.UNIQUE_NODE_KEY,\n        right_on=\"A\",\n    )\n    _nodes_from_links_B = nodes_df.merge(\n        links_df[[\"B\"] + _link_vals_to_nodes],\n        how=\"outer\",\n        left_on=RoadwayNetwork.UNIQUE_NODE_KEY,\n        right_on=\"B\",\n    )\n    _nodes_from_links_ab = pd.concat([_nodes_from_links_A, _nodes_from_links_B])\n\n    return _nodes_from_links_ab\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.add_new_roadway_feature_change","title":"<code>add_new_roadway_feature_change(add_links=[], add_nodes=[])</code>","text":"<p>Add the new roadway features defined in the project card.</p> <p>New shapes are also added for the new roadway links.</p> <p>New nodes are added first so that links can refer to any added nodes.</p> <p>Parameters:</p> Name Type Description Default <code>add_links</code> <code>Collection[dict]</code> <p>list of dictionaries</p> <code>[]</code> <code>add_nodes</code> <code>Collection[dict]</code> <p>list of dictionaries</p> <code>[]</code> <p>.. todo:: validate links and nodes dictionary</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def add_new_roadway_feature_change(\n    self, add_links: Collection[dict] = [], add_nodes: Collection[dict] = []\n) -&gt; None:\n\"\"\"\n    Add the new roadway features defined in the project card.\n\n    New shapes are also added for the new roadway links.\n\n    New nodes are added first so that links can refer to any added nodes.\n\n    args:\n        add_links: list of dictionaries\n        add_nodes: list of dictionaries\n\n    returns: updated network with new links and nodes and associated geometries\n\n    .. todo:: validate links and nodes dictionary\n    \"\"\"\n    WranglerLogger.debug(\n        f\"Adding New Roadway Features:\\n-Links:\\n{add_links}\\n-Nodes:\\n{add_nodes}\"\n    )\n    if add_nodes:\n        _new_nodes_df = self._create_nodes(add_nodes)\n        self.nodes_df = pd.concat([self.nodes_df, _new_nodes_df])\n\n    if add_links:\n        _new_links_df = self._create_links(add_links)\n        self.links_df = pd.concat([self.links_df, _new_links_df])\n\n        _new_shapes_df = RoadwayNetwork._create_new_shapes_from_links(_new_links_df)\n        self.shapes_df = pd.concat([self.shapes_df, _new_shapes_df])\n    return self\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.addition_map","title":"<code>addition_map(links, nodes)</code>","text":"<p>Shows which links and nodes are added to the roadway network</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def addition_map(self, links: dict, nodes: dict):\n\"\"\"\n    Shows which links and nodes are added to the roadway network\n    \"\"\"\n\n    if links is not None:\n        link_ids = []\n        for link in links:\n            link_ids.append(link.get(RoadwayNetwork.UNIQUE_LINK_KEY))\n\n        added_links = self.links_df[\n            self.links_df[RoadwayNetwork.UNIQUE_LINK_KEY].isin(link_ids)\n        ]\n        node_list_foreign_keys = list(\n            set(\n                [\n                    i\n                    for fk in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n                    for i in list(added_links[fk])\n                ]\n            )\n        )\n        try:\n            candidate_nodes = self.nodes_df.loc[node_list_foreign_keys]\n        except:\n            return None\n\n    if nodes is not None:\n        node_ids = []\n        for node in nodes:\n            node_ids.append(node.get(RoadwayNetwork.UNIQUE_NODE_KEY))\n\n        added_nodes = self.nodes_df[\n            self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY].isin(node_ids)\n        ]\n    else:\n        added_nodes = None\n\n    G = RoadwayNetwork.ox_graph(candidate_nodes, added_links)\n\n    m = ox.plot_graph_folium(G, edge_color=\"green\", tiles=\"cartodbpositron\")\n\n    def _folium_node(node, color=\"white\", icon=\"\"):\n        node_circle = folium.Circle(\n            location=[node[\"Y\"], node[\"X\"]],\n            radius=2,\n            fill=True,\n            color=color,\n            fill_opacity=0.8,\n        )\n        return node_circle\n\n    if added_nodes is not None:\n        for _, row in added_nodes.iterrows():\n            _folium_node(row, color=\"green\").add_to(m)\n\n    return m\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply","title":"<code>apply(project_card_dictionary, _subproject=False)</code>","text":"<p>Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>project_card_dictionary</code> <code>dict</code> <p>a dictionary of the project card object</p> required <code>_subproject</code> <code>bool</code> <p>boolean indicating if this is a subproject under a \u201cchanges\u201d heading. Defaults to False. Will be set to true with code when necessary.</p> <code>False</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def apply(\n    self, project_card_dictionary: dict, _subproject: bool = False\n) -&gt; \"RoadwayNetwork\":\n\"\"\"\n    Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n    Args:\n        project_card_dictionary: a dictionary of the project card object\n        _subproject: boolean indicating if this is a subproject under a \"changes\" heading.\n            Defaults to False. Will be set to true with code when necessary.\n\n    \"\"\"\n    if not _subproject:\n        WranglerLogger.info(\n            \"Applying Project to Roadway Network: {}\".format(\n                project_card_dictionary[\"project\"]\n            )\n        )\n\n    if project_card_dictionary.get(\"changes\"):\n        for project_dictionary in project_card_dictionary[\"changes\"]:\n            return self.apply(project_dictionary, _subproject=True)\n    else:\n        project_dictionary = project_card_dictionary\n\n    _facility = project_dictionary.get(\"facility\")\n    _category = project_dictionary.get(\"category\").lower()\n\n    if _facility:\n        WranglerLogger.info(f\"Selecting Facility: {_facility}\")\n\n        _geometry_type = list({\"links\", \"nodes\"}.intersection(set(_facility)))\n        assert (\n            len(_geometry_type) == 1\n        ), \"Facility must have exactly one of 'links' or 'nodes'\"\n        _geometry_type = _geometry_type[0]\n\n        _df_idx = self.select_roadway_features(_facility)\n\n    if _category == \"roadway property change\":\n        return self.apply_roadway_feature_change(\n            _df_idx,\n            project_dictionary[\"properties\"],\n            geometry_type=_geometry_type,\n        )\n    elif _category == \"parallel managed lanes\":\n        return self.apply_managed_lane_feature_change(\n            _df_idx,\n            project_dictionary[\"properties\"],\n        )\n    elif _category == \"add new roadway\":\n        return self.add_new_roadway_feature_change(\n            project_dictionary.get(\"links\", []),\n            project_dictionary.get(\"nodes\", []),\n        )\n    elif _category == \"roadway deletion\":\n        return self.delete_roadway_feature_change(\n            project_dictionary.get(\"links\", []),\n            project_dictionary.get(\"nodes\", []),\n        )\n    elif _category == \"calculated roadway\":\n        return self.apply_python_calculation(\n            project_dictionary[\"pycode\"],\n        )\n    else:\n        raise (ValueError(f\"Invalid Project Card Category: {_category}\"))\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply_managed_lane_feature_change","title":"<code>apply_managed_lane_feature_change(link_idx, properties)</code>","text":"<p>Apply the managed lane feature changes to the roadway network</p> <p>Parameters:</p> Name Type Description Default <code>link_idx</code> <p>list of lndices of all links to apply change to</p> required <code>properties</code> <p>list of dictionarys roadway properties to change</p> required <p>.. todo:: decide on connectors info when they are more specific in project card</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def apply_managed_lane_feature_change(\n    self,\n    link_idx: list,\n    properties: dict,\n) -&gt; \"RoadwayNetwork\":\n\"\"\"\n    Apply the managed lane feature changes to the roadway network\n\n    Args:\n        link_idx : list of lndices of all links to apply change to\n        properties : list of dictionarys roadway properties to change\n\n    .. todo:: decide on connectors info when they are more specific in project card\n    \"\"\"\n\n    # add ML flag to relevant links\n    if \"managed\" in self.links_df.columns:\n        self.links_df.loc[link_idx, \"managed\"] = 1\n    else:\n        self.links_df[\"managed\"] = 0\n        self.links_df.loc[link_idx, \"managed\"] = 1\n\n    for p in properties:\n        attribute = p[\"property\"]\n        attr_value = \"\"\n\n        for idx in link_idx:\n            if \"group\" in p.keys():\n                attr_value = {}\n\n                if \"set\" in p.keys():\n                    attr_value[\"default\"] = p[\"set\"]\n                elif \"change\" in p.keys():\n                    attr_value[\"default\"] = (\n                        self.links_df.at[idx, attribute] + p[\"change\"]\n                    )\n\n                attr_value[\"timeofday\"] = []\n\n                for g in p[\"group\"]:\n                    category = g[\"category\"]\n                    for tod in g[\"timeofday\"]:\n                        if \"set\" in tod.keys():\n                            attr_value[\"timeofday\"].append(\n                                {\n                                    \"category\": category,\n                                    \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                    \"value\": tod[\"set\"],\n                                }\n                            )\n                        elif \"change\" in tod.keys():\n                            attr_value[\"timeofday\"].append(\n                                {\n                                    \"category\": category,\n                                    \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                    \"value\": self.links_df.at[idx, attribute]\n                                    + tod[\"change\"],\n                                }\n                            )\n\n            elif \"timeofday\" in p.keys():\n                attr_value = {}\n\n                if \"set\" in p.keys():\n                    attr_value[\"default\"] = p[\"set\"]\n                elif \"change\" in p.keys():\n                    attr_value[\"default\"] = (\n                        self.links_df.at[idx, attribute] + p[\"change\"]\n                    )\n\n                attr_value[\"timeofday\"] = []\n\n                for tod in p[\"timeofday\"]:\n                    if \"set\" in tod.keys():\n                        attr_value[\"timeofday\"].append(\n                            {\n                                \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                \"value\": tod[\"set\"],\n                            }\n                        )\n                    elif \"change\" in tod.keys():\n                        attr_value[\"timeofday\"].append(\n                            {\n                                \"time\": parse_time_spans_to_secs(tod[\"time\"]),\n                                \"value\": self.links_df.at[idx, attribute]\n                                + tod[\"change\"],\n                            }\n                        )\n            elif \"set\" in p.keys():\n                attr_value = p[\"set\"]\n\n            elif \"change\" in p.keys():\n                attr_value = self.links_df.at[idx, attribute] + p[\"change\"]\n\n            if attribute in self.links_df.columns and not isinstance(\n                attr_value, numbers.Number\n            ):\n                # if the attribute already exists\n                # and the attr value we are trying to set is not numeric\n                # then change the attribute type to object\n                self.links_df[attribute] = self.links_df[attribute].astype(object)\n\n            if attribute not in self.links_df.columns:\n                # if it is a new attribute then initialize with NaN values\n                self.links_df[attribute] = \"NaN\"\n\n            self.links_df.at[idx, attribute] = attr_value\n\n    WranglerLogger.debug(f\"{len(self.nodes_df)} Nodes in Network\")\n\n    return self\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply_python_calculation","title":"<code>apply_python_calculation(pycode)</code>","text":"<p>Changes roadway network object by executing pycode.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <p>network to manipulate</p> required <code>pycode</code> <code>str</code> <p>python code which changes values in the roadway network object</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def apply_python_calculation(self, pycode: str) -&gt; \"RoadwayNetwork\":\n\"\"\"\n    Changes roadway network object by executing pycode.\n\n    Args:\n        net: network to manipulate\n        pycode: python code which changes values in the roadway network object\n    \"\"\"\n    exec(pycode)\n    return self\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply_roadway_feature_change","title":"<code>apply_roadway_feature_change(df_idx, properties, geometry_type='links')</code>","text":"<p>Changes the roadway attributes for the selected features based on the project card information passed</p> <p>Parameters:</p> Name Type Description Default <code>df_idx</code> <p>list lndices of all links or nodes to apply change to</p> required <code>properties</code> <p>list of dictionarys roadway properties to change</p> required <code>geometry_type</code> <p>either \u2018links\u2019 or \u2018nodes\u2019. Defaults to \u2018link\u2019</p> <code>'links'</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def apply_roadway_feature_change(\n    self,\n    df_idx: list,\n    properties: dict,\n    geometry_type=\"links\",\n) -&gt; \"RoadwayNetwork\":\n\"\"\"\n    Changes the roadway attributes for the selected features based on the\n    project card information passed\n\n    Args:\n        df_idx : list\n            lndices of all links or nodes to apply change to\n        properties : list of dictionarys\n            roadway properties to change\n        geometry_type: either 'links' or 'nodes'. Defaults to 'link'\n    \"\"\"\n    if geometry_type == \"links\":\n        self._apply_links_feature_change(df_idx, properties)\n    elif geometry_type == \"nodes\":\n        self._apply_nodes_feature_change(df_idx, properties)\n    else:\n        raise ValueError(\"geometry_type must be either 'links' or 'nodes'\")\n\n    return self\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.assess_connectivity","title":"<code>assess_connectivity(mode='', ignore_end_nodes=True, links_df=None, nodes_df=None)</code>","text":"<p>Returns a network graph and list of disconnected subgraphs as described by a list of their member nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>list of modes of the network, one of <code>drive</code>,<code>transit</code>, <code>walk</code>, <code>bike</code></p> <code>''</code> <code>ignore_end_nodes</code> <code>bool</code> <p>if True, ignores stray singleton nodes</p> <code>True</code> <code>links_df</code> <code>DataFrame</code> <p>if specified, will assess connectivity of this links list rather than self.links_df</p> <code>None</code> <code>nodes_df</code> <code>DataFrame</code> <p>if specified, will assess connectivity of this nodes list rather than self.nodes_df</p> <code>None</code> <p>Tuple of</p> Type Description <p>Network Graph (osmnx flavored networkX DiGraph)</p> <p>List of disconnected subgraphs described by the list of their member nodes (as described by their <code>model_node_id</code>)</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def assess_connectivity(\n    self,\n    mode: str = \"\",\n    ignore_end_nodes: bool = True,\n    links_df: DataFrame = None,\n    nodes_df: DataFrame = None,\n):\n\"\"\"Returns a network graph and list of disconnected subgraphs\n    as described by a list of their member nodes.\n\n    Args:\n        mode:  list of modes of the network, one of `drive`,`transit`,\n            `walk`, `bike`\n        ignore_end_nodes: if True, ignores stray singleton nodes\n        links_df: if specified, will assess connectivity of this\n            links list rather than self.links_df\n        nodes_df: if specified, will assess connectivity of this\n            nodes list rather than self.nodes_df\n\n    Returns: Tuple of\n        Network Graph (osmnx flavored networkX DiGraph)\n        List of disconnected subgraphs described by the list of their\n            member nodes (as described by their `model_node_id`)\n    \"\"\"\n    _nodes_df = nodes_df if nodes_df else self.nodes_df\n    _links_df = links_df if links_df else self.links_df\n\n    if mode:\n        _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n            _links_df,\n            _nodes_df,\n            modes=[mode],\n        )\n    else:\n        WranglerLogger.warning(\n            \"Assessing connectivity without a mode\\\n            specified. This may have limited value in interpretation.\\\n            To add mode specificity, add the keyword `mode =` to calling\\\n            this method\"\n        )\n\n    G = RoadwayNetwork.ox_graph(_nodes_df, _links_df)\n\n    sub_graph_nodes = [\n        list(s)\n        for s in sorted(nx.strongly_connected_components(G), key=len, reverse=True)\n    ]\n\n    # sorted on decreasing length, dropping the main sub-graph\n    disconnected_sub_graph_nodes = sub_graph_nodes[1:]\n\n    # dropping the sub-graphs with only 1 node\n    if ignore_end_nodes:\n        disconnected_sub_graph_nodes = [\n            list(s) for s in disconnected_sub_graph_nodes if len(s) &gt; 1\n        ]\n\n    WranglerLogger.info(\n        \"{} for disconnected networks for mode = {}:\\n{}\".format(\n            RoadwayNetwork.UNIQUE_NODE_KEY,\n            mode,\n            \"\\n\".join(list(map(str, disconnected_sub_graph_nodes))),\n        )\n    )\n    return G, disconnected_sub_graph_nodes\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.build_selection_key","title":"<code>build_selection_key(selection_dict)</code>","text":"<p>Selections are stored by a hash of the selection dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dictonary</code> <p>Selection Dictionary</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def build_selection_key(self, selection_dict: dict) -&gt; tuple:\n\"\"\"\n    Selections are stored by a hash of the selection dictionary.\n\n    Args:\n        selection_dictonary: Selection Dictionary\n\n    Returns: Hex code for hash\n\n    \"\"\"\n\n    return hashlib.md5(b\"selection_dict\").hexdigest()\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.coerce_types","title":"<code>coerce_types(df, cols=None)</code>  <code>classmethod</code>","text":"<p>Coerces types to bool, str and int which might default to other types based on values.</p> <p>Uses BOOL_PROPERTIES, INT_PROPERTIES and STR_PROPERTIES.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Dataframe to coerce type of</p> required <code>cols</code> <code>Collection[str]</code> <p>optional list of fields to check and coerce. Defaults to all fields.</p> <code>None</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>pd.DataFrame: Dataframe with types coerced</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@classmethod\ndef coerce_types(\n    cls, df: pd.DataFrame, cols: Collection[str] = None\n) -&gt; pd.DataFrame:\n\"\"\"Coerces types to bool, str and int which might default to other types based on values.\n\n    Uses BOOL_PROPERTIES, INT_PROPERTIES and STR_PROPERTIES.\n\n    Args:\n        df: Dataframe to coerce type of\n        cols: optional list of fields to check and coerce. Defaults to all fields.\n\n    Returns:\n        pd.DataFrame: Dataframe with types coerced\n    \"\"\"\n    if cols is None:\n        cols = df.columns\n\n    for c in list(set(cls.BOOL_PROPERTIES) &amp; set(cols)):\n        df[c] = df[c].astype(bool)\n\n    for c in list(set(cls.STR_PROPERTIES) &amp; set(cols)):\n        df[c] = df[c].astype(str)\n\n    for c in list(set(cls.INT_PROPERTIES) &amp; set(cols)):\n        df[c] = df[c].astype(int)\n\n    return df\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.delete_links","title":"<code>delete_links(del_links, dict, ignore_missing=True)</code>","text":"<p>Delete the roadway links based on del_links dictionary selecting links by properties.</p> <p>Also deletes shapes which no longer have links associated with them.</p> <p>Parameters:</p> Name Type Description Default <code>del_links</code> <p>Dictionary identified shapes to delete by properties.  Links will be selected if any of the properties are equal to any of the values.</p> required <code>ignore_missing</code> <p>If True, will only warn if try to delete a links that isn\u2019t in network. If False, it will fail on missing links. Defaults to True.</p> <code>True</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def delete_links(self, del_links, dict, ignore_missing=True) -&gt; None:\n\"\"\"\n    Delete the roadway links based on del_links dictionary selecting links by properties.\n\n    Also deletes shapes which no longer have links associated with them.\n\n    Args:\n        del_links: Dictionary identified shapes to delete by properties.  Links will be selected\n            if *any* of the properties are equal to *any* of the values.\n        ignore_missing: If True, will only warn if try to delete a links that isn't in network.\n            If False, it will fail on missing links. Defaults to True.\n    \"\"\"\n    # if RoadwayNetwork.UNIQUE_LINK_ID is used to select, flag links that weren't in network.\n    if RoadwayNetwork.UNIQUE_LINK_KEY in del_links:\n        _del_link_ids = pd.Series(del_links[RoadwayNetwork.UNIQUE_LINK_KEY])\n        _missing_links = _del_link_ids[\n            ~_del_link_ids.isin(self.links_df[RoadwayNetwork.UNIQUE_LINK_KEY])\n        ]\n        msg = f\"Following links cannot be deleted because they are not in the network: {_missing_links}\"\n        if len(_missing_links) and ignore_missing:\n            WranglerLogger.warning(msg)\n        elif len(_missing_links):\n            raise ValueError(msg)\n\n    _del_links_mask = self.links_df.isin(del_links).any(axis=1)\n    if not _del_links_mask.any():\n        WranglerLogger.warning(\"No links found matching criteria to delete.\")\n        return\n    WranglerLogger.debug(\n        f\"Deleting following links:\\n{self.links_df.loc[_del_links_mask][['A','B','model_link_id']]}\"\n    )\n    self.links_df = self.links_df.loc[~_del_links_mask]\n\n    # Delete shapes which no longer have links associated with them\n    _shapes_without_links = self._shapes_without_links()\n    if len(_shapes_without_links):\n        WranglerLogger.debug(f\"Shapes without links:\\n {_shapes_without_links}\")\n        self.shapes_df = self.shapes_df.loc[~_shapes_without_links]\n        WranglerLogger.debug(f\"self.shapes_df reduced to:\\n {self.shapes_df}\")\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.delete_nodes","title":"<code>delete_nodes(del_nodes, ignore_missing=True)</code>","text":"<p>Delete the roadway nodes based on del_nodes dictionary selecting nodes by properties.</p> <p>Will fail if try to delete node that is currently being used by a link.</p> <p>Parameters:</p> Name Type Description Default <code>del_nodes</code> <p>Dictionary identified nodes to delete by properties.  Nodes will be selected if any of the properties are equal to any of the values.</p> required <code>ignore_missing</code> <code>bool</code> <p>If True, will only warn if try to delete a node that isn\u2019t in network. If False, it will fail on missing nodes. Defaults to True.</p> <code>True</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def delete_nodes(self, del_nodes: dict, ignore_missing: bool = True) -&gt; None:\n\"\"\"\n    Delete the roadway nodes based on del_nodes dictionary selecting nodes by properties.\n\n    Will fail if try to delete node that is currently being used by a link.\n\n    Args:\n        del_nodes : Dictionary identified nodes to delete by properties.  Nodes will be selected\n            if *any* of the properties are equal to *any* of the values.\n        ignore_missing: If True, will only warn if try to delete a node that isn't in network.\n            If False, it will fail on missing nodes. Defaults to True.\n    \"\"\"\n    _del_nodes_mask = self.nodes_df.isin(del_nodes).any(axis=1)\n    _del_nodes_df = self.nodes_df.loc[_del_nodes_mask]\n\n    if not _del_nodes_mask.any():\n        WranglerLogger.warning(\"No nodes found matching criteria to delete.\")\n        return\n\n    WranglerLogger.debug(f\"Deleting Nodes:\\n{_del_nodes_df}\")\n    # Check if node used in an existing link\n    _links_with_nodes = RoadwayNetwork.links_with_nodes(\n        self.links_df,\n        _del_nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].tolist(),\n    )\n    if len(_links_with_nodes):\n        WranglerLogger.error(\n            f\"Node deletion failed because being used in following links:\\n{_links_with_nodes[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE]}\"\n        )\n        raise ValueError\n\n    # Check if node is in network\n    if RoadwayNetwork.UNIQUE_NODE_KEY in del_nodes:\n        _del_node_ids = pd.Series(del_nodes[RoadwayNetwork.UNIQUE_NODE_KEY])\n        _missing_nodes = _del_node_ids[\n            ~_del_node_ids.isin(self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY])\n        ]\n        msg = f\"Following nodes cannot be deleted because they are not in the network: {_missing_nodes}\"\n        if len(_missing_nodes) and ignore_missing:\n            WranglerLogger.warning(msg)\n        elif len(_missing_nodes):\n            raise ValueError(msg)\n    self.nodes_df = self.nodes_df.loc[~_del_nodes_mask]\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.delete_roadway_feature_change","title":"<code>delete_roadway_feature_change(del_links=None, del_nodes=None, ignore_missing=True)</code>","text":"<p>Delete the roadway links or nodes defined in the project card.</p> <p>Corresponding shapes to the deleted links are also deleted if they are not used elsewhere.</p> <p>Parameters:</p> Name Type Description Default <code>del_links</code> <p>dictionary of identified links to delete</p> <code>None</code> <code>del_nodes</code> <p>dictionary of identified nodes to delete</p> <code>None</code> <code>ignore_missing</code> <p>bool If True, will only warn about links/nodes that are missing from network but specified to \u201cdelete\u201d in project card If False, will fail.</p> <code>True</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def delete_roadway_feature_change(\n    self,\n    del_links: dict = None,\n    del_nodes: dict = None,\n    ignore_missing=True,\n) -&gt; \"RoadwayNetwork\":\n\"\"\"\n    Delete the roadway links or nodes defined in the project card.\n\n    Corresponding shapes to the deleted links are also deleted if they are not used elsewhere.\n\n    Args:\n        del_links : dictionary of identified links to delete\n        del_nodes : dictionary of identified nodes to delete\n        ignore_missing: bool\n            If True, will only warn about links/nodes that are missing from\n            network but specified to \"delete\" in project card\n            If False, will fail.\n    \"\"\"\n\n    WranglerLogger.debug(\n        f\"Deleting Roadway Features:\\n-Links:\\n{del_links}\\n-Nodes:\\n{del_nodes}\"\n    )\n\n    if del_links:\n        self.delete_links(del_links, ignore_missing)\n\n    if del_nodes:\n        self.delete_nodes(del_nodes, ignore_missing)\n\n    return self\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.deletion_map","title":"<code>deletion_map(links, nodes)</code>","text":"<p>Shows which links and nodes are deleted from the roadway network</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def deletion_map(self, links: dict, nodes: dict):\n\"\"\"\n    Shows which links and nodes are deleted from the roadway network\n    \"\"\"\n\n    if links is not None:\n        for key, val in links.items():\n            deleted_links = self.links_df[self.links_df[key].isin(val)]\n\n            node_list_foreign_keys = list(\n                set(\n                    [\n                        i\n                        for fk in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n                        for i in list(deleted_links[fk])\n                    ]\n                )\n            )\n            candidate_nodes = self.nodes_df.loc[node_list_foreign_keys]\n    else:\n        deleted_links = None\n\n    if nodes is not None:\n        for key, val in nodes.items():\n            deleted_nodes = self.nodes_df[self.nodes_df[key].isin(val)]\n    else:\n        deleted_nodes = None\n\n    G = RoadwayNetwork.ox_graph(candidate_nodes, deleted_links)\n\n    m = ox.plot_graph_folium(G, edge_color=\"red\", tiles=\"cartodbpositron\")\n\n    def _folium_node(node, color=\"white\", icon=\"\"):\n        node_circle = folium.Circle(\n            location=[node[\"Y\"], node[\"X\"]],\n            radius=2,\n            fill=True,\n            color=color,\n            fill_opacity=0.8,\n        )\n        return node_circle\n\n    if deleted_nodes is not None:\n        for _, row in deleted_nodes.iterrows():\n            _folium_node(row, color=\"red\").add_to(m)\n\n    return m\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_modal_graph","title":"<code>get_modal_graph(links_df, nodes_df, mode=None)</code>  <code>staticmethod</code>","text":"<p>Determines if the network graph is \u201cstrongly\u201d connected A graph is strongly connected if each vertex is reachable from every other vertex.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>DataFrame</code> <p>DataFrame of standard network links</p> required <code>nodes_df</code> <code>DataFrame</code> <p>DataFrame of standard network nodes</p> required <code>mode</code> <code>str</code> <p>mode of the network, one of <code>drive</code>,<code>transit</code>, <code>walk</code>, <code>bike</code></p> <code>None</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef get_modal_graph(links_df: DataFrame, nodes_df: DataFrame, mode: str = None):\n\"\"\"Determines if the network graph is \"strongly\" connected\n    A graph is strongly connected if each vertex is reachable from every other vertex.\n\n    Args:\n        links_df: DataFrame of standard network links\n        nodes_df: DataFrame of standard network nodes\n        mode: mode of the network, one of `drive`,`transit`,\n            `walk`, `bike`\n\n    Returns: networkx: osmnx: DiGraph  of network\n    \"\"\"\n    if mode not in RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys():\n        msg = \"mode value should be one of {}.\".format(\n            list(RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys())\n        )\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n\n    _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n        links_df,\n        nodes_df,\n        modes=[mode],\n    )\n    G = RoadwayNetwork.ox_graph(_nodes_df, _links_df)\n\n    return G\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_modal_links_nodes","title":"<code>get_modal_links_nodes(links_df, nodes_df, modes=None)</code>  <code>staticmethod</code>","text":"<p>Returns nodes and link dataframes for specific mode.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>DataFrame</code> <p>DataFrame of standard network links</p> required <code>nodes_df</code> <code>DataFrame</code> <p>DataFrame of standard network nodes</p> required <code>modes</code> <code>list[str]</code> <p>list of the modes of the network to be kept, must be in <code>drive</code>,<code>transit</code>,<code>rail</code>,<code>bus</code>,<code>walk</code>, <code>bike</code>. For example, if bike and walk are selected, both bike and walk links will be kept.</p> <code>None</code> <p>.. todo:: Right now we don\u2019t filter the nodes because transit-only links with walk access are not marked as having walk access Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1]</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef get_modal_links_nodes(\n    links_df: DataFrame, nodes_df: DataFrame, modes: list[str] = None\n) -&gt; tuple(DataFrame, DataFrame):\n\"\"\"Returns nodes and link dataframes for specific mode.\n\n    Args:\n        links_df: DataFrame of standard network links\n        nodes_df: DataFrame of standard network nodes\n        modes: list of the modes of the network to be kept, must be in\n            `drive`,`transit`,`rail`,`bus`,`walk`, `bike`.\n            For example, if bike and walk are selected, both bike and walk links will be kept.\n\n    Returns: tuple of DataFrames for links, nodes filtered by mode\n\n    .. todo:: Right now we don't filter the nodes because transit-only\n    links with walk access are not marked as having walk access\n    Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145\n    modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1]\n    \"\"\"\n    for mode in modes:\n        if mode not in RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys():\n            msg = \"mode value should be one of {}, got {}\".format(\n                list(RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES.keys()),\n                mode,\n            )\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n\n    mode_link_variables = list(\n        set(\n            [\n                mode\n                for mode in modes\n                for mode in RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES[mode]\n            ]\n        )\n    )\n    mode_node_variables = list(\n        set(\n            [\n                mode\n                for mode in modes\n                for mode in RoadwayNetwork.MODES_TO_NETWORK_NODE_VARIABLES[mode]\n            ]\n        )\n    )\n\n    if not set(mode_link_variables).issubset(set(links_df.columns)):\n        msg = f\"\"\"{set(mode_link_variables) - set(links_df.columns)} not in provided links_df \\\n            list of columns. Available columns are:\n{links_df.columns}\"\"\"\n        WranglerLogger.error(msg)\n\n    if not set(mode_node_variables).issubset(set(nodes_df.columns)):\n        msg = f\"\"\"{set(mode_node_variables) - set(nodes_df.columns)} not in provided nodes_df \\\n            list of columns. Available columns are:\n{nodes_df.columns}\"\"\"\n        WranglerLogger.error(msg)\n\n    modal_links_df = links_df.loc[links_df[mode_link_variables].any(axis=1)]\n\n    # TODO right now we don't filter the nodes because transit-only\n    # links with walk access are not marked as having walk access\n    # Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145\n    # modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1]\n    modal_nodes_df = nodes_df\n\n    return modal_links_df, modal_nodes_df\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_property_by_time_period_and_group","title":"<code>get_property_by_time_period_and_group(property, time_period=None, category=None)</code>","text":"<p>Return a series for the properties with a specific group or time period.</p>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_property_by_time_period_and_group--args","title":"args","text":"str <p>the variable that you want from network</p> list(str) <p>the time period that you are querying for i.e. [\u201816:00\u2019, \u201819:00\u2019]</p> str or list(str)(Optional) <p>the group category i.e. \u201csov\u201d</p> <p>or</p> <p>list of group categories in order of search, i.e. [\u201chov3\u201d,\u201dhov2\u201d]</p>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_property_by_time_period_and_group--returns","title":"returns","text":"<p>pandas series</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def get_property_by_time_period_and_group(\n    self, property, time_period=None, category=None\n):\n\"\"\"\n    Return a series for the properties with a specific group or time period.\n\n    args\n    ------\n    property: str\n      the variable that you want from network\n    time_period: list(str)\n      the time period that you are querying for\n      i.e. ['16:00', '19:00']\n    category: str or list(str)(Optional)\n      the group category\n      i.e. \"sov\"\n\n      or\n\n      list of group categories in order of search, i.e.\n      [\"hov3\",\"hov2\"]\n\n    returns\n    --------\n    pandas series\n    \"\"\"\n\n    def _get_property(\n        v,\n        time_spans=None,\n        category=None,\n        return_partial_match: bool = False,\n        partial_match_minutes: int = 60,\n    ):\n\"\"\"\n\n        .. todo:: return the time period with the largest overlap\n\n        \"\"\"\n\n        if category and not time_spans:\n            WranglerLogger.error(\n                \"\\nShouldn't have a category group without time spans\"\n            )\n            raise ValueError(\"Shouldn't have a category group without time spans\")\n\n        # simple case\n        if type(v) in (int, float, str):\n            return v\n\n        if not category:\n            category = [\"default\"]\n        elif isinstance(category, str):\n            category = [category]\n        search_cats = [c.lower() for c in category]\n\n        # if no time or group specified, but it is a complex link situation\n        if not time_spans:\n            if \"default\" in v.keys():\n                return v[\"default\"]\n            else:\n                WranglerLogger.debug(f\"variable: {v}\")\n                msg = f\"Variable {v} is more complex in network than query\"\n                WranglerLogger.error(msg)\n                raise ValueError(msg)\n\n        if v.get(\"timeofday\"):\n            categories = []\n            for tg in v[\"timeofday\"]:\n                if (\n                    (time_spans[0] &gt;= tg[\"time\"][0])\n                    and (time_spans[1] &lt;= tg[\"time\"][1])\n                    and (time_spans[0] &lt;= time_spans[1])\n                ):\n                    if tg.get(\"category\"):\n                        categories += tg[\"category\"]\n                        for c in search_cats:\n                            print(\"CAT:\", c, tg[\"category\"])\n                            if c in tg[\"category\"]:\n                                # print(\"Var:\", v)\n                                # print(\n                                #    \"RETURNING:\", time_spans, category, tg[\"value\"]\n                                # )\n                                return tg[\"value\"]\n                    else:\n                        # print(\"Var:\", v)\n                        # print(\"RETURNING:\", time_spans, category, tg[\"value\"])\n                        return tg[\"value\"]\n\n                if (\n                    (time_spans[0] &gt;= tg[\"time\"][0])\n                    and (time_spans[1] &lt;= tg[\"time\"][1])\n                    and (time_spans[0] &gt; time_spans[1])\n                    and (tg[\"time\"][0] &gt; tg[\"time\"][1])\n                ):\n                    if tg.get(\"category\"):\n                        categories += tg[\"category\"]\n                        for c in search_cats:\n                            print(\"CAT:\", c, tg[\"category\"])\n                            if c in tg[\"category\"]:\n                                # print(\"Var:\", v)\n                                # print(\n                                #    \"RETURNING:\", time_spans, category, tg[\"value\"]\n                                # )\n                                return tg[\"value\"]\n                    else:\n                        # print(\"Var:\", v)\n                        # print(\"RETURNING:\", time_spans, category, tg[\"value\"])\n                        return tg[\"value\"]\n\n                # if there isn't a fully matched time period, see if there is an overlapping\n                # one right now just return the first overlapping ones\n                # TODO return the time period with the largest overlap\n\n                if (\n                    (time_spans[0] &gt;= tg[\"time\"][0])\n                    and (time_spans[0] &lt;= tg[\"time\"][1])\n                ) or (\n                    (time_spans[1] &gt;= tg[\"time\"][0])\n                    and (time_spans[1] &lt;= tg[\"time\"][1])\n                ):\n                    overlap_minutes = max(\n                        0,\n                        min(tg[\"time\"][1], time_spans[1])\n                        - max(time_spans[0], tg[\"time\"][0]),\n                    )\n                    # print(\"OLM\",overlap_minutes)\n                    if not return_partial_match and overlap_minutes &gt; 0:\n                        WranglerLogger.debug(\n                            f\"Couldn't find time period consistent with {time_spans}, but \\\n                                found a partial match: {tg['time']}. Consider allowing \\\n                                partial matches using 'return_partial_match' keyword or \\\n                                updating query.\"\n                        )\n                    elif (\n                        overlap_minutes &lt; partial_match_minutes\n                        and overlap_minutes &gt; 0\n                    ):\n                        WranglerLogger.debug(\n                            f\"Time period: {time_spans} overlapped less than the minimum number \\\n                            of minutes ({overlap_minutes}&lt;{partial_match_minutes}) to be \\\n                            considered a match with time period in network: {tg['time']}.\"\n                        )\n                    elif overlap_minutes &gt; 0:\n                        WranglerLogger.debug(\n                            f\"Returning a partial time period match. Time period: {time_spans}\\\n                            overlapped the minimum number of minutes ({overlap_minutes}&gt;=\\\n{partial_match_minutes}) to be considered a match with time period\\\n                             in network: {tg['time']}.\"\n                        )\n                        if tg.get(\"category\"):\n                            categories += tg[\"category\"]\n                            for c in search_cats:\n                                print(\"CAT:\", c, tg[\"category\"])\n                                if c in tg[\"category\"]:\n                                    # print(\"Var:\", v)\n                                    # print(\n                                    #    \"RETURNING:\",\n                                    #    time_spans,\n                                    #    category,\n                                    #    tg[\"value\"],\n                                    # )\n                                    return tg[\"value\"]\n                        else:\n                            # print(\"Var:\", v)\n                            # print(\"RETURNING:\", time_spans, category, tg[\"value\"])\n                            return tg[\"value\"]\n\n\"\"\"\n            WranglerLogger.debug(\n                \"\\nCouldn't find time period for {}, returning default\".format(\n                    str(time_spans)\n                )\n            )\n            \"\"\"\n            if \"default\" in v.keys():\n                # print(\"Var:\", v)\n                # print(\"RETURNING:\", time_spans, v[\"default\"])\n                return v[\"default\"]\n            else:\n                # print(\"Var:\", v)\n                WranglerLogger.error(\n                    \"\\nCan't find default; must specify a category in {}\".format(\n                        str(categories)\n                    )\n                )\n                raise ValueError(\n                    \"Can't find default, must specify a category in: {}\".format(\n                        str(categories)\n                    )\n                )\n\n    time_spans = parse_time_spans_to_secs(time_period)\n\n    return self.links_df[property].apply(\n        _get_property, time_spans=time_spans, category=category\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.has_link","title":"<code>has_link(link_key_values)</code>","text":"<p>Returns true if network has link based values corresponding with LINK_FOREIGN_KEY_TO_NODE properties.</p> <p>Parameters:</p> Name Type Description Default <code>link_key_values</code> <code>tuple</code> <p>Tuple of values corresponding with RoadwayNetwork.LINK_FOREIGN_KEY_TO_ ODE properties. If LINK_FOREIGN_KEY_TO_NODE is (\u201cA\u201d,\u201dB\u201d), then (1,2) references the link of A=1 and B=2.</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def has_link(self, link_key_values: tuple) -&gt; bool:\n\"\"\"Returns true if network has link based values corresponding with LINK_FOREIGN_KEY_TO_NODE properties.\n\n    Args:\n        link_key_values: Tuple of values corresponding with RoadwayNetwork.LINK_FOREIGN_KEY_TO_ ODE properties.\n            If LINK_FOREIGN_KEY_TO_NODE is (\"A\",\"B\"), then (1,2) references the link of A=1 and B=2.\n    \"\"\"\n    _query_parts = [\n        f\"{k} == {str(v)}\"\n        for k, v in zip(RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE, link_key_values)\n    ]\n    _query = \" and \".join(_query_parts)\n    _links = self.links_df.query(_query, engine=\"python\")\n\n    return bool(len(_links))\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.has_node","title":"<code>has_node(unique_node_id)</code>","text":"<p>Queries if network has node based on RoadwayNetwork.UNIQUE_NODE_KEY.</p> <p>Parameters:</p> Name Type Description Default <code>unique_node_id</code> <code>_type_</code> <p>value of RoadwayNetwork.UNIQUE_NODE_KEY</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def has_node(self, unique_node_id) -&gt; bool:\n\"\"\"Queries if network has node based on RoadwayNetwork.UNIQUE_NODE_KEY.\n\n    Args:\n        unique_node_id (_type_): value of RoadwayNetwork.UNIQUE_NODE_KEY\n    \"\"\"\n\n    has_node = (\n        self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY].isin([unique_node_id]).any()\n    )\n\n    return has_node\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.identify_segment","title":"<code>identify_segment(O_id, D_id, selection_dict={}, mode=None, nodes_df=None, links_df=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>endpoints</code> <p>list of length of two unique keys of nodes making up endpoints of segment</p> required <code>selection_dict</code> <code>dict</code> <p>dictionary of link variables to select candidate links from, otherwise will create a graph of ALL links which will be both a RAM hog and could result in odd shortest paths.</p> <code>{}</code> <code>segment_variables</code> <p>list of variables to keep</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def identify_segment(\n    self,\n    O_id,\n    D_id,\n    selection_dict: dict = {},\n    mode=None,\n    nodes_df=None,\n    links_df=None,\n):\n\"\"\"\n    Args:\n        endpoints: list of length of two unique keys of nodes making up endpoints of segment\n        selection_dict: dictionary of link variables to select candidate links from, otherwise\n            will create a graph of ALL links which will be both a RAM hog and could result in\n            odd shortest paths.\n        segment_variables: list of variables to keep\n    \"\"\"\n    _nodes_df = nodes_df if nodes_df else self.nodes_df\n    _links_df = links_df if links_df else self.links_df\n\n    if mode:\n        _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n            _links_df,\n            _nodes_df,\n            modes=[mode],\n        )\n    else:\n        WranglerLogger.warning(\n            \"Assessing connectivity without a mode\\\n            specified. This may have limited value in interpretation.\\\n            To add mode specificity, add the keyword `mode =` to calling\\\n            this method\"\n        )\n\n    if selection_dict:\n        _query = \" or \".join(\n            [f\"{k} == {repr(v)}\" for k, v in selection_dict.items()]\n        )\n        _candidate_links = _links_df.query(_query)\n        WranglerLogger.debug(\n            \"Found {} candidate links from {} total links using following query:\\n{}\".format(\n                len(_candidate_links), len(_links_df), _query\n            )\n        )\n    else:\n        _candidate_links = _links_df\n\n        WranglerLogger.warning(\n            \"Not pre-selecting links using selection_dict can use up a lot of RAM and \\\n                also result in odd segment paths.\"\n        )\n\n    WranglerLogger.debug(\n        \"_candidate links for segment: \\n{}\".format(\n            _candidate_links[[\"u\", \"v\", \"A\", \"B\", \"name\", \"ref\"]]\n        )\n    )\n\n    try:\n        (G, candidate_links, sp_route, sp_links) = self.path_search(\n            _candidate_links, O_id, D_id\n        )\n    except NoPathFound:\n        msg = \"Route not found from {} to {} using selection candidates {}\".format(\n            O_id, D_id, selection_dict\n        )\n        WranglerLogger.warning(msg)\n        sp_links = pd.DataFrame()\n\n    return sp_links\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.identify_segment_endpoints","title":"<code>identify_segment_endpoints(mode='', links_df=None, nodes_df=None, min_connecting_links=10, min_distance=None, max_link_deviation=2)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>list of modes of the network, one of <code>drive</code>,<code>transit</code>, <code>walk</code>, <code>bike</code></p> <code>''</code> <code>links_df</code> <code>DataFrame</code> <p>if specified, will assess connectivity of this links list rather than self.links_df</p> <code>None</code> <code>nodes_df</code> <code>DataFrame</code> <p>if specified, will assess connectivity of this nodes list rather than self.nodes_df</p> <code>None</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def identify_segment_endpoints(\n    self,\n    mode: str = \"\",\n    links_df: DataFrame = None,\n    nodes_df: DataFrame = None,\n    min_connecting_links: int = 10,\n    min_distance: float = None,\n    max_link_deviation: int = 2,\n):\n\"\"\"\n\n    Args:\n        mode:  list of modes of the network, one of `drive`,`transit`,\n            `walk`, `bike`\n        links_df: if specified, will assess connectivity of this\n            links list rather than self.links_df\n        nodes_df: if specified, will assess connectivity of this\n            nodes list rather than self.nodes_df\n\n    \"\"\"\n    SEGMENT_IDENTIFIERS = [\"name\", \"ref\"]\n\n    NAME_PER_NODE = 4\n    REF_PER_NODE = 2\n\n    _nodes_df = nodes_df if nodes_df else self.nodes_df\n    _links_df = links_df if links_df else self.links_df\n\n    if mode:\n        _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n            _links_df,\n            _nodes_df,\n            modes=[mode],\n        )\n    else:\n        WranglerLogger.warning(\n            \"Assessing connectivity without a mode\\\n            specified. This may have limited value in interpretation.\\\n            To add mode specificity, add the keyword `mode =` to calling\\\n            this method\"\n        )\n\n    _nodes_df = RoadwayNetwork.add_incident_link_data_to_nodes(\n        links_df=_links_df,\n        nodes_df=_nodes_df,\n        link_variables=SEGMENT_IDENTIFIERS + [\"distance\"],\n    )\n    WranglerLogger.debug(\"Node/Link table elements: {}\".format(len(_nodes_df)))\n\n    # Screen out segments that have blank name AND refs\n    _nodes_df = _nodes_df.replace(r\"^\\s*$\", np.nan, regex=True).dropna(\n        subset=[\"name\", \"ref\"]\n    )\n\n    WranglerLogger.debug(\n        \"Node/Link table elements after dropping empty name AND ref : {}\".format(\n            len(_nodes_df)\n        )\n    )\n\n    # Screen out segments that aren't likely to be long enough\n    # Minus 1 in case ref or name is missing on an intermediate link\n    _min_ref_in_table = REF_PER_NODE * (min_connecting_links - max_link_deviation)\n    _min_name_in_table = NAME_PER_NODE * (min_connecting_links - max_link_deviation)\n\n    _nodes_df[\"ref_freq\"] = _nodes_df[\"ref\"].map(_nodes_df[\"ref\"].value_counts())\n    _nodes_df[\"name_freq\"] = _nodes_df[\"name\"].map(_nodes_df[\"name\"].value_counts())\n\n    _nodes_df = _nodes_df.loc[\n        (_nodes_df[\"ref_freq\"] &gt;= _min_ref_in_table)\n        &amp; (_nodes_df[\"name_freq\"] &gt;= _min_name_in_table)\n    ]\n\n    WranglerLogger.debug(\n        \"Node/Link table has n = {} after screening segments for min length:\\n{}\".format(\n            len(_nodes_df),\n            _nodes_df[\n                [\n                    RoadwayNetwork.UNIQUE_NODE_KEY,\n                    \"name\",\n                    \"ref\",\n                    \"distance\",\n                    \"ref_freq\",\n                    \"name_freq\",\n                ]\n            ],\n        )\n    )\n    # ----------------------------------------\n    # Find nodes that are likely endpoints\n    # ----------------------------------------\n\n    # - Likely have one incident link and one outgoing link\n    _max_ref_endpoints = REF_PER_NODE / 2\n    _max_name_endpoints = NAME_PER_NODE / 2\n    # - Attach frequency  of node/ref\n    _nodes_df = _nodes_df.merge(\n        _nodes_df.groupby(by=[RoadwayNetwork.UNIQUE_NODE_KEY, \"ref\"])\n        .size()\n        .rename(\"ref_N_freq\"),\n        on=[RoadwayNetwork.UNIQUE_NODE_KEY, \"ref\"],\n    )\n    # WranglerLogger.debug(\"_ref_count+_nodes:\\n{}\".format(_nodes_df[[\"model_node_id\",\"ref\",\"name\",\"ref_N_freq\"]]))\n    # - Attach frequency  of node/name\n    _nodes_df = _nodes_df.merge(\n        _nodes_df.groupby(by=[RoadwayNetwork.UNIQUE_NODE_KEY, \"name\"])\n        .size()\n        .rename(\"name_N_freq\"),\n        on=[RoadwayNetwork.UNIQUE_NODE_KEY, \"name\"],\n    )\n    # WranglerLogger.debug(\"_name_count+_nodes:\\n{}\".format(_nodes_df[[\"model_node_id\",\"ref\",\"name\",\"name_N_freq\"]]))\n\n    WranglerLogger.debug(\n        \"Possible segment endpoints:\\n{}\".format(\n            _nodes_df[\n                [\n                    RoadwayNetwork.UNIQUE_NODE_KEY,\n                    \"name\",\n                    \"ref\",\n                    \"distance\",\n                    \"ref_N_freq\",\n                    \"name_N_freq\",\n                ]\n            ]\n        )\n    )\n    # - Filter possible endpoint list based on node/name node/ref frequency\n    _nodes_df = _nodes_df.loc[\n        (_nodes_df[\"ref_N_freq\"] &lt;= _max_ref_endpoints)\n        | (_nodes_df[\"name_N_freq\"] &lt;= _max_name_endpoints)\n    ]\n    WranglerLogger.debug(\n        \"{} Likely segment endpoints with req_ref&lt;= {} or freq_name&lt;={} \\n{}\".format(\n            len(_nodes_df),\n            _max_ref_endpoints,\n            _max_name_endpoints,\n            _nodes_df[\n                [\n                    RoadwayNetwork.UNIQUE_NODE_KEY,\n                    \"name\",\n                    \"ref\",\n                    \"ref_N_freq\",\n                    \"name_N_freq\",\n                ]\n            ],\n        )\n    )\n    # ----------------------------------------\n    # Assign a segment id\n    # ----------------------------------------\n    _nodes_df[\"segment_id\"], _segments = pd.factorize(\n        _nodes_df.name + _nodes_df.ref\n    )\n    WranglerLogger.debug(\"{} Segments:\\n{}\".format(len(_segments), _segments))\n\n    # ----------------------------------------\n    # Drop segments without at least two nodes\n    # ----------------------------------------\n\n    # https://stackoverflow.com/questions/13446480/python-pandas-remove-entries-based-on-the-number-of-occurrences\n    _nodes_df = _nodes_df[\n        _nodes_df.groupby([\"segment_id\", RoadwayNetwork.UNIQUE_NODE_KEY])[\n            RoadwayNetwork.UNIQUE_NODE_KEY\n        ].transform(len)\n        &gt; 1\n    ]\n\n    WranglerLogger.debug(\n        \"{} Segments with at least nodes:\\n{}\".format(\n            len(_nodes_df),\n            _nodes_df[\n                [RoadwayNetwork.UNIQUE_NODE_KEY, \"name\", \"ref\", \"segment_id\"]\n            ],\n        )\n    )\n\n    # ----------------------------------------\n    # For segments with more than two nodes, find farthest apart pairs\n    # ----------------------------------------\n\n    def _max_segment_distance(row):\n        _segment_nodes = _nodes_df.loc[_nodes_df[\"segment_id\"] == row[\"segment_id\"]]\n        dist = _segment_nodes.geometry.distance(row.geometry)\n        return max(dist.dropna())\n\n    _nodes_df[\"seg_distance\"] = _nodes_df.apply(_max_segment_distance, axis=1)\n    _nodes_df = _nodes_df.merge(\n        _nodes_df.groupby(\"segment_id\")\n        .seg_distance.agg(max)\n        .rename(\"max_seg_distance\"),\n        on=\"segment_id\",\n    )\n\n    _nodes_df = _nodes_df.loc[\n        (_nodes_df[\"max_seg_distance\"] == _nodes_df[\"seg_distance\"])\n        &amp; (_nodes_df[\"seg_distance\"] &gt; 0)\n    ].drop_duplicates(subset=[RoadwayNetwork.UNIQUE_NODE_KEY, \"segment_id\"])\n\n    # ----------------------------------------\n    # Reassign segment id for final segments\n    # ----------------------------------------\n    _nodes_df[\"segment_id\"], _segments = pd.factorize(\n        _nodes_df.name + _nodes_df.ref\n    )\n\n    WranglerLogger.debug(\n        \"{} Segments:\\n{}\".format(\n            len(_segments),\n            _nodes_df[\n                [\n                    RoadwayNetwork.UNIQUE_NODE_KEY,\n                    \"name\",\n                    \"ref\",\n                    \"segment_id\",\n                    \"seg_distance\",\n                ]\n            ],\n        )\n    )\n\n    return _nodes_df[\n        [\"segment_id\", RoadwayNetwork.UNIQUE_NODE_KEY, \"geometry\", \"name\", \"ref\"]\n    ]\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.is_network_connected","title":"<code>is_network_connected(mode=None, links_df=None, nodes_df=None)</code>","text":"<p>Determines if the network graph is \u201cstrongly\u201d connected A graph is strongly connected if each vertex is reachable from every other vertex.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>mode of the network, one of <code>drive</code>,<code>transit</code>, <code>walk</code>, <code>bike</code></p> <code>None</code> <code>links_df</code> <code>DataFrame</code> <p>DataFrame of standard network links</p> <code>None</code> <code>nodes_df</code> <code>DataFrame</code> <p>DataFrame of standard network nodes</p> <code>None</code> <p>.. todo:: Consider caching graphs if they take a long time.</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def is_network_connected(\n    self, mode: str = None, links_df: DataFrame = None, nodes_df: DataFrame = None\n):\n\"\"\"\n    Determines if the network graph is \"strongly\" connected\n    A graph is strongly connected if each vertex is reachable from every other vertex.\n\n    Args:\n        mode:  mode of the network, one of `drive`,`transit`,\n            `walk`, `bike`\n        links_df: DataFrame of standard network links\n        nodes_df: DataFrame of standard network nodes\n\n    Returns: boolean\n\n    .. todo:: Consider caching graphs if they take a long time.\n    \"\"\"\n\n    _nodes_df = nodes_df if nodes_df else self.nodes_df\n    _links_df = links_df if links_df else self.links_df\n\n    if mode:\n        _links_df, _nodes_df = RoadwayNetwork.get_modal_links_nodes(\n            _links_df,\n            _nodes_df,\n            modes=[mode],\n        )\n    else:\n        WranglerLogger.info(\n            \"Assessing connectivity without a mode\\\n            specified. This may have limited value in interpretation.\\\n            To add mode specificity, add the keyword `mode =` to calling\\\n            this method\"\n        )\n\n    # TODO: consider caching graphs if they start to take forever\n    #      and we are calling them more than once.\n    G = RoadwayNetwork.ox_graph(_nodes_df, _links_df)\n    is_connected = nx.is_strongly_connected(G)\n\n    return is_connected\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.links_with_nodes","title":"<code>links_with_nodes(links_df, node_id_list)</code>  <code>staticmethod</code>","text":"<p>Returns a links geodataframe which start or end at the nodes in the list.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>pd.DataFrame</code> <p>dataframe of links to search for nodes in</p> required <code>node_id_list</code> <code>list</code> <p>List of nodes to find links for.  Nodes should be identified by the foreign key - the one that is referenced in LINK_FOREIGN_KEY.</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef links_with_nodes(\n    links_df: pd.DataFrame, node_id_list: list\n) -&gt; gpd.GeoDataFrame:\n\"\"\"Returns a links geodataframe which start or end at the nodes in the list.\n\n    Args:\n        links_df: dataframe of links to search for nodes in\n        node_id_list (list): List of nodes to find links for.  Nodes should be identified\n            by the foreign key - the one that is referenced in LINK_FOREIGN_KEY.\n    \"\"\"\n    # If nodes are equal to all the nodes in the links, return all the links\n    _nodes_in_links = RoadwayNetwork.nodes_in_links(links_df)\n    WranglerLogger.debug(\n        f\"# Nodes: {len(node_id_list)}\\nNodes in links:{len(_nodes_in_links)}\"\n    )\n    if len(set(node_id_list) - set(_nodes_in_links)) == 0:\n        return links_df\n\n    WranglerLogger.debug(f\"Finding links assocated with {len(node_id_list)} nodes.\")\n    if len(node_id_list) &lt; 25:\n        WranglerLogger.debug(f\"node_id_list: {node_id_list}\")\n\n    _selected_links_df = links_df[\n        links_df.isin(\n            {c: node_id_list for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE}\n        )\n    ]\n    WranglerLogger.debug(\n        f\"Temp Selected {len(_selected_links_df)} associated with {len(node_id_list)} nodes.\"\n    )\n\"\"\"\n    _query_parts = [\n        f\"{prop} == {str(n)}\"\n        for prop in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n        for n in node_id_list\n    ]\n\n    _query = \" or \".join(_query_parts)\n    _selected_links_df = links_df.query(_query, engine=\"python\")\n    \"\"\"\n    WranglerLogger.debug(\n        f\"Selected {len(_selected_links_df)} associated with {len(node_id_list)} nodes.\"\n    )\n\n    return _selected_links_df\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.network_connection_plot","title":"<code>network_connection_plot(G, disconnected_subgraph_nodes)</code>  <code>staticmethod</code>","text":"<p>Plot a graph to check for network connection.</p> <p>Parameters:</p> Name Type Description Default <code>G</code> <p>OSMNX flavored networkX graph.</p> required <code>disconnected_subgraph_nodes</code> <code>list</code> <p>List of disconnected subgraphs described by the list of their member nodes (as described by their <code>model_node_id</code>).</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef network_connection_plot(G, disconnected_subgraph_nodes: list):\n\"\"\"Plot a graph to check for network connection.\n\n    Args:\n        G: OSMNX flavored networkX graph.\n        disconnected_subgraph_nodes: List of disconnected subgraphs described by the list\n            of their member nodes (as described by their `model_node_id`).\n\n    returns: fig, ax : tuple\n    \"\"\"\n\n    colors = []\n    for i in range(len(disconnected_subgraph_nodes)):\n        colors.append(\"#%06X\" % randint(0, 0xFFFFFF))\n\n    fig, ax = ox.plot_graph(\n        G,\n        figsize=(16, 16),\n        show=False,\n        close=True,\n        edge_color=\"black\",\n        edge_alpha=0.1,\n        node_color=\"black\",\n        node_alpha=0.5,\n        node_size=10,\n    )\n    i = 0\n    for nodes in disconnected_subgraph_nodes:\n        for n in nodes:\n            size = 100\n            ax.scatter(G.nodes[n][\"X\"], G.nodes[n][\"Y\"], c=colors[i], s=size)\n        i = i + 1\n\n    return fig, ax\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.new_links_valid","title":"<code>new_links_valid(new_links_df)</code>","text":"<p>Assesses if a set of links are valid for adding to self.links_df.</p> <p>Will produce a ValueError if new_links_df: 1. A-B combinations are not unique within new_links_df 2. UNIQUE_LINK_KEY is not unique within new_links_df 3. A-B combinations overlap with an existing A-B link in self.links_df 4. UNIQUE_LINK_KEY overlaps with an existing UNIQUE_LINK_ID in self.links_df 5. A and B nodes are not in self.nodes_df 6. Doesn\u2019t contain columns for MIN_LINK_REQUIRED_PROPS_DEFAULT</p> <p>Will produce a warning if there are NA values for any MIN_LINK_REQUIRED_PROPS_DEFAULT</p> <p>Parameters:</p> Name Type Description Default <code>new_links_df</code> <code>pd.DataFrame</code> <p>dataframe of links being considered for addition to self.links_df</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Returns a True if passes various validation tests.</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def new_links_valid(self, new_links_df: pd.DataFrame) -&gt; bool:\n\"\"\"Assesses if a set of links are valid for adding to self.links_df.\n\n    Will produce a ValueError if new_links_df:\n    1. A-B combinations are not unique within new_links_df\n    2. UNIQUE_LINK_KEY is not unique within new_links_df\n    3. A-B combinations overlap with an existing A-B link in self.links_df\n    4. UNIQUE_LINK_KEY overlaps with an existing UNIQUE_LINK_ID in self.links_df\n    5. A and B nodes are not in self.nodes_df\n    6. Doesn't contain columns for MIN_LINK_REQUIRED_PROPS_DEFAULT\n\n    Will produce a warning if there are NA values for any MIN_LINK_REQUIRED_PROPS_DEFAULT\n\n    Args:\n        new_links_df: dataframe of links being considered for addition to self.links_df\n\n    Returns:\n        bool: Returns a True if passes various validation tests.\n    \"\"\"\n\n    # A-B combinations are unique within new_links_df\n    _new_fk_id = pd.Series(\n        zip(*[new_links_df[c] for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE])\n    )\n    if not _new_fk_id.is_unique:\n        msg = f\"Duplicate ABs in new links.\"\n        raise ValueError(msg)\n\n    # UNIQUE_LINK_ID is unique within new_links_df\n    if not new_links_df[RoadwayNetwork.UNIQUE_LINK_KEY].is_unique:\n        msg = f\"Duplicate link IDs in new links.\"\n        raise ValueError(msg)\n\n    # Doesn't overlap with an existing A-B link in self.links_df\n    _existing_links_ab = _new_fk_id.apply(self.has_link)\n    if _existing_links_ab.any():\n        msg = f\"Link already exists between nodes:\\n {_new_fk_id[_existing_links_ab]}.\"\n        raise ValueError(msg)\n\n    # Doesn't overlap with an existing UNIQUE_LINK_ID in self.links_df\n    _ids = pd.concat(\n        [\n            self.links_df[RoadwayNetwork.UNIQUE_LINK_KEY],\n            new_links_df[RoadwayNetwork.UNIQUE_LINK_KEY],\n        ]\n    )\n    if not _ids.is_unique:\n        msg = f\"Link ID already exists:\\n{_ids.loc[_ids.duplicated()]}.\"\n        raise ValueError(msg)\n\n    # A and B nodes are in self.nodes_df\n    for fk_prop in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE:\n        _has_node = new_links_df[fk_prop].apply(self.has_node)\n        if not _has_node.all():\n            if len(self.nodes) &lt; 25:\n                WranglerLogger.debug(f\"self.nodes_df:\\n{self.nodes_df}\")\n            msg = f\"New link specifies non existant node {fk_prop} = {new_links_df.loc[_has_node,fk_prop]}.\"\n            raise ValueError(msg)\n\n    # Check to see if there are missing required columns\n    _missing_cols = [\n        c\n        for c in RoadwayNetwork.MIN_LINK_REQUIRED_PROPS_DEFAULT\n        if c not in new_links_df.columns\n    ]\n    if _missing_cols:\n        msg = f\"Missing required link properties:{_missing_cols}\"\n        raise ValueError(msg)\n\n    # Check to see if there are missing required values\n    _missing_values = new_links_df[\n        RoadwayNetwork.MIN_LINK_REQUIRED_PROPS_DEFAULT\n    ].isna()\n    if _missing_values.any().any():\n        msg = f\"Missing values for required link properties:\\n{new_links_df.loc[_missing_values]}\"\n        WranglerLogger.Warning(msg)\n\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.nodes_in_links","title":"<code>nodes_in_links(links_df)</code>  <code>staticmethod</code>","text":"<p>Returns a list of nodes that are contained in the links.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>pd.DataFrame</code> <p>Links which to return node list for</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef nodes_in_links(\n    links_df: pd.DataFrame,\n) -&gt; Collection:\n\"\"\"Returns a list of nodes that are contained in the links.\n\n    Args:\n        links_df: Links which to return node list for\n    \"\"\"\n    if len(links_df) &lt; 25:\n        WranglerLogger.debug(\n            f\"Links:\\n{links_df[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE]}\"\n        )\n    nodes_list = list(\n        set(\n            pd.concat(\n                [links_df[c] for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE]\n            ).tolist()\n        )\n    )\n    if len(nodes_list) &lt; 25:\n        WranglerLogger.debug(f\"_node_list:\\n{nodes_list}\")\n    return nodes_list\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.orig_dest_nodes_foreign_key","title":"<code>orig_dest_nodes_foreign_key(selection, node_foreign_key='')</code>","text":"<p>Returns the foreign key id (whatever is used in the u and v variables in the links file) for the AB nodes as a tuple.</p> <p>Parameters:</p> Name Type Description Default <code>selection</code> <p>selection dictionary with A and B keys</p> required <code>node_foreign_key</code> <code>str</code> <p>variable name for whatever is used by the u and v variable</p> <code>''</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def orig_dest_nodes_foreign_key(\n    self, selection: dict, node_foreign_key: str = \"\"\n) -&gt; tuple:\n\"\"\"\n    Returns the foreign key id (whatever is used in the u and v\n    variables in the links file) for the AB nodes as a tuple.\n\n    Args:\n        selection : selection dictionary with A and B keys\n        node_foreign_key: variable name for whatever is used by the u and v variable\n        in the links_df file.  If nothing is specified, assume whatever\n        default is (usually osm_node_id)\n\n    Returns: tuple of (A_id, B_id)\n    \"\"\"\n\n    if not node_foreign_key:\n        node_foreign_key = RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK\n    if len(selection[\"A\"]) &gt; 1:\n        raise (\"Selection A node dictionary should be of length 1\")\n    if len(selection[\"B\"]) &gt; 1:\n        raise (\"Selection B node dictionary should be of length 1\")\n\n    A_node_key, A_id = next(iter(selection[\"A\"].items()))\n    B_node_key, B_id = next(iter(selection[\"B\"].items()))\n\n    if A_node_key != node_foreign_key:\n        A_id = self.nodes_df[self.nodes_df[A_node_key] == A_id][\n            node_foreign_key\n        ].values[0]\n    if B_node_key != node_foreign_key:\n        B_id = self.nodes_df[self.nodes_df[B_node_key] == B_id][\n            node_foreign_key\n        ].values[0]\n\n    return (A_id, B_id)\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.ox_graph","title":"<code>ox_graph(nodes_df, links_df)</code>  <code>staticmethod</code>","text":"<p>create an osmnx-flavored network graph</p> <p>osmnx doesn\u2019t like values that are arrays, so remove the variables that have arrays.  osmnx also requires that certain variables be filled in, so do that too.</p> <p>Parameters:</p> Name Type Description Default <code>nodes_df</code> <p>GeoDataFrame of nodes</p> required <code>links_df</code> <p>GeoDataFrame of links</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef ox_graph(nodes_df: GeoDataFrame, links_df: GeoDataFrame):\n\"\"\"\n    create an osmnx-flavored network graph\n\n    osmnx doesn't like values that are arrays, so remove the variables\n    that have arrays.  osmnx also requires that certain variables\n    be filled in, so do that too.\n\n    Args:\n        nodes_df : GeoDataFrame of nodes\n        links_df : GeoDataFrame of links\n\n    Returns: a networkx multidigraph\n    \"\"\"\n    WranglerLogger.debug(\"starting ox_graph()\")\n\n    if \"inboundReferenceIds\" in nodes_df.columns:\n        graph_nodes = nodes_df.copy().drop(\n            [\"inboundReferenceIds\", \"outboundReferenceIds\"], axis=1\n        )\n    else:\n        graph_nodes = nodes_df.copy()\n\n    graph_nodes.gdf_name = \"network_nodes\"\n    WranglerLogger.debug(\"GRAPH NODES: {}\".format(graph_nodes.columns))\n    graph_nodes[\"id\"] = graph_nodes[RoadwayNetwork.UNIQUE_NODE_KEY]\n\n    graph_nodes[\"x\"] = graph_nodes[\"X\"]\n    graph_nodes[\"y\"] = graph_nodes[\"Y\"]\n\n    if \"osm_link_id\" in links_df.columns:\n        graph_links = links_df.copy().drop(\n            [\"osm_link_id\", \"locationReferences\"], axis=1\n        )\n    else:\n        graph_links = links_df.copy().drop([\"locationReferences\"], axis=1)\n\n    # have to change this over into u,v b/c this is what osm-nx is expecting\n    graph_links[\"u\"] = graph_links[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE[0]]\n    graph_links[\"v\"] = graph_links[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE[1]]\n    graph_links[\"key\"] = graph_links[RoadwayNetwork.UNIQUE_LINK_KEY]\n\n    # Per osmnx u,v,key should be a multi-index;\n    #     https://osmnx.readthedocs.io/en/stable/osmnx.html#osmnx.utils_graph.graph_from_gdfs\n    # However - if the index is set before hand in osmnx version &lt;1.0 then it fails\n    #     on the set_index line *within* osmnx.utils_graph.graph_from_gdfs():\n    #           `for (u, v, k), row in gdf_edges.set_index([\"u\", \"v\", \"key\"]).iterrows():`\n\n    if int(ox.__version__.split(\".\")[0]) &gt;= 1:\n        graph_links = graph_links.set_index(keys=[\"u\", \"v\", \"key\"], drop=True)\n\n    WranglerLogger.debug(\"starting ox.gdfs_to_graph()\")\n    try:\n        G = ox.graph_from_gdfs(graph_nodes, graph_links)\n\n    except AttributeError as attr_error:\n        if (\n            attr_error.args[0]\n            == \"module 'osmnx' has no attribute 'graph_from_gdfs'\"\n        ):\n            # This is the only exception for which we have a workaround\n            # Does this still work given the u,v,key multi-indexing?\n            #\n            WranglerLogger.warn(\n                \"Please upgrade your OSMNX package. For now, using deprecated\\\n                     osmnx.gdfs_to_graph because osmnx.graph_from_gdfs not found\"\n            )\n            G = ox.gdfs_to_graph(graph_nodes, graph_links)\n        else:\n            # for other AttributeErrors, raise further\n            raise attr_error\n    except Exception as e:\n        # for other Exceptions, raise further\n        raise e\n\n    WranglerLogger.debug(\"finished ox.gdfs_to_graph()\")\n    return G\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.path_search","title":"<code>path_search(candidate_links_df, O_id, D_id, weight_column='i', weight_factor=1.0)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>candidate_links</code> <p>selection of links geodataframe with links likely to be part of path</p> required <code>O_id</code> <p>origin node foreigh key ID</p> required <code>D_id</code> <p>destination node foreigh key ID</p> required <code>weight_column</code> <code>str</code> <p>column to use for weight of shortest path. Defaults to \u201ci\u201d (iteration)</p> <code>'i'</code> <code>weight_factor</code> <code>float</code> <p>optional weight to multiply the weight column by when finding the shortest path</p> <code>1.0</code> <p>Returns</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def path_search(\n    self,\n    candidate_links_df: gpd.GeoDataFrame,\n    O_id,\n    D_id,\n    weight_column: str = \"i\",\n    weight_factor: float = 1.0,\n):\n\"\"\"\n\n    Args:\n        candidate_links: selection of links geodataframe with links likely to be part of path\n        O_id: origin node foreigh key ID\n        D_id: destination node foreigh key ID\n        weight_column: column to use for weight of shortest path. Defaults to \"i\" (iteration)\n        weight_factor: optional weight to multiply the weight column by when finding\n            the shortest path\n\n    Returns\n\n    \"\"\"\n\n    def _add_breadth(\n        _candidate_links_df: gpd.GeoDataFrame,\n        _nodes_df: gpd.GeoDataFrame,\n        _links_df: gpd.GeoDataFrame,\n        i: int = None,\n    ):\n\"\"\"\n        Add outbound and inbound reference IDs to candidate links\n        from existing nodes\n\n        Args:\n            _candidate_links_df : df with the links from the previous iteration\n            _nodes_df : df of all nodes in the full network\n            _links_df : df of all links in the full network\n            i : iteration of adding breadth\n\n        Returns:\n            candidate_links : GeoDataFrame\n                updated df with one more degree of added breadth\n\n            node_list_foreign_keys : list of foreign key ids for nodes in the updated\n                candidate links to test if the A and B nodes are in there.\n        \"\"\"\n        WranglerLogger.debug(\"-Adding Breadth-\")\n\n        if not i:\n            WranglerLogger.warning(\"i not specified in _add_breadth, using 1\")\n            i = 1\n\n        _candidate_nodes_df = _nodes_df.loc[\n            RoadwayNetwork._get_fk_nodes(_candidate_links_df)\n        ]\n        WranglerLogger.debug(\"Candidate Nodes: {}\".format(len(_candidate_nodes_df)))\n\n        # Identify links to add based on outbound and inbound links from nodes\n        _links_shstRefId_to_add = list(\n            set(\n                sum(_candidate_nodes_df[\"outboundReferenceIds\"].tolist(), [])\n                + sum(_candidate_nodes_df[\"inboundReferenceIds\"].tolist(), [])\n            )\n            - set(_candidate_links_df[\"shstReferenceId\"].tolist())\n            - set([\"\"])\n        )\n        _links_to_add_df = _links_df[\n            _links_df.shstReferenceId.isin(_links_shstRefId_to_add)\n        ]\n\n        WranglerLogger.debug(\"Adding {} links.\".format(_links_to_add_df.shape[0]))\n\n        # Add information about what iteration the link was added in\n        _links_df[_links_df.model_link_id.isin(_links_shstRefId_to_add)][\"i\"] = i\n\n        # Append links and update node list\n        _candidate_links_df = pd.concat([_candidate_links_df, _links_to_add_df])\n        _node_list_foreign_keys = RoadwayNetwork._get_fk_nodes(_candidate_links_df)\n\n        return _candidate_links_df, _node_list_foreign_keys\n\n    # -----------------------------------\n    # Set search breadth to zero + set max\n    # -----------------------------------\n    i = 0\n    max_i = RoadwayNetwork.SEARCH_BREADTH\n    # -----------------------------------\n    # Add links to the graph until\n    #   (i) the A and B nodes are in the\n    #       foreign key list\n    #          - OR -\n    #   (ii) reach maximum search breadth\n    # -----------------------------------\n    node_list_foreign_keys = RoadwayNetwork._get_fk_nodes(candidate_links_df)\n    WranglerLogger.debug(\"Initial set of nodes: {}\".format(node_list_foreign_keys))\n    while (\n        O_id not in node_list_foreign_keys or D_id not in node_list_foreign_keys\n    ) and i &lt;= max_i:\n        WranglerLogger.debug(\n            \"Adding breadth - i: {}, Max i: {}] - {} and {} not found in node list.\".format(\n                i, max_i, O_id, D_id\n            )\n        )\n        i += 1\n        candidate_links_df, node_list_foreign_keys = _add_breadth(\n            candidate_links_df, self.nodes_df, self.links_df, i=i\n        )\n    # -----------------------------------\n    #  Once have A and B in graph,\n    #  Try calculating shortest path\n    # -----------------------------------\n    WranglerLogger.debug(\"calculating shortest path from graph\")\n    (\n        sp_found,\n        graph,\n        candidate_links_df,\n        shortest_path_route,\n        shortest_path_links,\n    ) = self.shortest_path(candidate_links_df, O_id, D_id)\n    if sp_found:\n        return graph, candidate_links_df, shortest_path_route, shortest_path_links\n\n    if not sp_found:\n        WranglerLogger.debug(\n            \"No shortest path found with breadth of {i}, trying greater breadth until SP \\\n                found or max breadth {max_i} reached.\"\n        )\n    while not sp_found and i &lt;= RoadwayNetwork.MAX_SEARCH_BREADTH:\n        WranglerLogger.debug(\n            \"Adding breadth, with shortest path iteration. i: {} Max i: {}\".format(\n                i, max_i\n            )\n        )\n        i += 1\n        candidate_links_df, node_list_foreign_keys = _add_breadth(\n            candidate_links_df, self.nodes_df, self.links_df, i=i\n        )\n        (\n            sp_found,\n            graph,\n            candidate_links_df,\n            route,\n            shortest_path_links,\n        ) = self.shortest_path(candidate_links_df, O_id, D_id)\n\n    if sp_found:\n        return graph, candidate_links_df, route, shortest_path_links\n\n    if not sp_found:\n        msg = \"Couldn't find path from {} to {} after adding {} links in breadth\".format(\n            O_id, D_id, i\n        )\n        WranglerLogger.error(msg)\n        raise NoPathFound(msg)\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.read","title":"<code>read(link_file, node_file, shape_file, fast=True)</code>  <code>staticmethod</code>","text":"<p>Reads a network from the roadway network standard Validates that it conforms to the schema</p> <p>Parameters:</p> Name Type Description Default <code>link_file</code> <code>str</code> <p>full path to the link file</p> required <code>node_file</code> <code>str</code> <p>full path to the node file</p> required <code>shape_file</code> <code>str</code> <p>full path to the shape file</p> required <code>fast</code> <code>bool</code> <p>boolean that will skip validation to speed up read time</p> <code>True</code> <p>.. todo:: Turn off fast=True as default</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef read(\n    link_file: str, node_file: str, shape_file: str, fast: bool = True\n) -&gt; RoadwayNetwork:\n\"\"\"\n    Reads a network from the roadway network standard\n    Validates that it conforms to the schema\n\n    args:\n        link_file: full path to the link file\n        node_file: full path to the node file\n        shape_file: full path to the shape file\n        fast: boolean that will skip validation to speed up read time\n\n    Returns: a RoadwayNetwork instance\n\n    .. todo:: Turn off fast=True as default\n    \"\"\"\n\n    for fn in (link_file, node_file, shape_file):\n\n        if not os.path.exists(fn):\n            msg = f\"Specified file doesn't exist at: {fn}\"\n            WranglerLogger.error(msg)\n            raise ValueError(msg)\n\n    if not fast:\n        if not (\n            RoadwayNetwork.validate_node_schema(node_file)\n            and RoadwayNetwork.validate_link_schema(link_file)\n            and RoadwayNetwork.validate_shape_schema(shape_file)\n        ):\n            sys.exit(\"RoadwayNetwork: Data doesn't conform to schema\")\n\n    links_df = RoadwayNetwork.read_links(link_file)\n    nodes_df = RoadwayNetwork.read_nodes(node_file)\n    shapes_df = RoadwayNetwork.read_shapes(shape_file)\n\n    roadway_network = RoadwayNetwork(\n        nodes=nodes_df, links=links_df, shapes=shapes_df\n    )\n\n    roadway_network.link_file = link_file\n    roadway_network.node_file = node_file\n    roadway_network.shape_file = shape_file\n\n    return roadway_network\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.read_links","title":"<code>read_links(filename)</code>  <code>classmethod</code>","text":"<p>Reads links and returns a geodataframe of links.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>file to read links in from.</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@classmethod\ndef read_links(cls, filename: str) -&gt; gpd.GeoDataFrame:\n\"\"\"Reads links and returns a geodataframe of links.\n\n    Args:\n        filename (str): file to read links in from.\n    \"\"\"\n    WranglerLogger.info(f\"Reading links from {filename}.\")\n    with open(filename) as f:\n        link_json = json.load(f)\n    WranglerLogger.debug(\"Read link file.\")\n    link_properties = pd.DataFrame(link_json)\n    link_geometries = [\n        line_string_from_location_references(g[\"locationReferences\"])\n        for g in link_json\n    ]\n    links_df = gpd.GeoDataFrame(link_properties, geometry=link_geometries)\n    links_df.crs = RoadwayNetwork.CRS\n    links_df.gdf_name = \"network_links\"\n\n    links_df = RoadwayNetwork.coerce_types(links_df)\n\n    links_df[RoadwayNetwork.UNIQUE_LINK_KEY + \"_idx\"] = links_df[\n        RoadwayNetwork.UNIQUE_LINK_KEY\n    ]\n    links_df.set_index(RoadwayNetwork.UNIQUE_LINK_KEY + \"_idx\", inplace=True)\n\n    WranglerLogger.info(f\"Read {len(links_df)} links.\")\n    return links_df\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.read_nodes","title":"<code>read_nodes(filename)</code>  <code>classmethod</code>","text":"<p>Reads nodes and returns a geodataframe of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>file to read nodes in from.</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@classmethod\ndef read_nodes(cls, filename: str) -&gt; gpd.GeoDataFrame:\n\"\"\"Reads nodes and returns a geodataframe of nodes.\n\n    Args:\n        filename (str): file to read nodes in from.\n    \"\"\"\n    # geopandas uses fiona OGR drivers, which doesn't let you have\n    # a list as a property type. Therefore, must read in node_properties\n    # separately in a vanilla dataframe and then convert to geopandas\n    WranglerLogger.info(f\"Reading nodes from {filename}.\")\n    with open(filename) as f:\n        node_geojson = json.load(f)\n    WranglerLogger.debug(\"Read nodes file.\")\n    node_properties = pd.DataFrame(\n        [g[\"properties\"] for g in node_geojson[\"features\"]]\n    )\n    node_geometries = [\n        Point(g[\"geometry\"][\"coordinates\"]) for g in node_geojson[\"features\"]\n    ]\n\n    nodes_df = gpd.GeoDataFrame(node_properties, geometry=node_geometries)\n\n    nodes_df.gdf_name = \"network_nodes\"\n\n    # set a copy of the  foreign key to be the index so that the\n    # variable itself remains queryiable\n    ## TODO this should be more elegant\n    nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY + \"_idx\"] = nodes_df[\n        RoadwayNetwork.UNIQUE_NODE_KEY\n    ]\n    nodes_df.set_index(cls.UNIQUE_NODE_KEY + \"_idx\", inplace=True)\n\n    nodes_df.crs = RoadwayNetwork.CRS\n    nodes_df[\"X\"] = nodes_df[\"geometry\"].apply(lambda g: g.x)\n    nodes_df[\"Y\"] = nodes_df[\"geometry\"].apply(lambda g: g.y)\n\n    nodes_df = RoadwayNetwork.coerce_types(nodes_df)\n    WranglerLogger.info(f\"Read {len(nodes_df)} nodes.\")\n    return nodes_df\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.read_shapes","title":"<code>read_shapes(filename)</code>  <code>classmethod</code>","text":"<p>Reads shapes and returns a geodataframe of shapes.</p> <p>Also: - drops records without geometry or id - sets CRS to RoadwayNetwork.CRS</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>file to read shapes in from.</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@classmethod\ndef read_shapes(cls, filename: str) -&gt; gpd.GeoDataFrame:\n\"\"\"Reads shapes and returns a geodataframe of shapes.\n\n    Also:\n    - drops records without geometry or id\n    - sets CRS to RoadwayNetwork.CRS\n\n    Args:\n        filename (str): file to read shapes in from.\n    \"\"\"\n    WranglerLogger.info(f\"Reading shapes from {filename}.\")\n    shapes_df = gpd.read_file(filename)\n    shapes_df.gdf_name = \"network_shapes\"\n    WranglerLogger.debug(\"Read shapes file.\")\n    shapes_df.dropna(subset=[\"geometry\", \"id\"], inplace=True)\n    shapes_df.crs = cls.CRS\n    WranglerLogger.info(f\"Read {len(shapes_df)} shapes.\")\n    return shapes_df\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.roadway_net_to_gdf","title":"<code>roadway_net_to_gdf(roadway_net)</code>  <code>staticmethod</code>","text":"<p>Turn the roadway network into a GeoDataFrame</p> <p>Parameters:</p> Name Type Description Default <code>roadway_net</code> <code>RoadwayNetwork</code> <p>the roadway network to export</p> required <p>.. todo:: Make this much more sophisticated, for example attach link info to shapes</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef roadway_net_to_gdf(roadway_net: RoadwayNetwork) -&gt; gpd.GeoDataFrame:\n\"\"\"\n    Turn the roadway network into a GeoDataFrame\n    args:\n        roadway_net: the roadway network to export\n\n    returns: shapes dataframe\n\n    .. todo:: Make this much more sophisticated, for example attach link info to shapes\n    \"\"\"\n    return roadway_net.shapes_df\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.select_node_features","title":"<code>select_node_features(selection, sel_key)</code>","text":"<p>Select Node Features.</p> <p>Parameters:</p> Name Type Description Default <code>selection</code> <code>dict</code> <p>selection dictionary from project card.</p> required <code>sel_key</code> <code>str</code> <p>key to store selection in self.selections under.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of indices for selected nodes in self.nodes_df</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def select_node_features(\n    self,\n    selection: dict,\n    sel_key: str,\n) -&gt; list:\n\"\"\"Select Node Features.\n\n    Args:\n        selection (dict): selection dictionary from project card.\n        sel_key (str): key to store selection in self.selections under.\n\n    Returns:\n        List of indices for selected nodes in self.nodes_df\n    \"\"\"\n    WranglerLogger.debug(\"Selecting nodes.\")\n    if selection.get(\"nodes\") == \"all\":\n        return self.nodes_df.index.tolist()\n\n    sel_query = ProjectCard.build_selection_query(\n        selection=selection,\n        type=\"nodes\",\n        unique_ids=RoadwayNetwork.UNIQUE_NODE_IDENTIFIERS,\n    )\n    WranglerLogger.debug(\"Selecting node features:\\n{}\".format(sel_query))\n\n    self.selections[sel_key][\"selected_nodes\"] = self.nodes_df.query(\n        sel_query, engine=\"python\"\n    )\n\n    if len(self.selections[sel_key][\"selected_nodes\"]) &gt; 0:\n        self.selections[sel_key][\"selection_found\"] = True\n    else:\n        raise ValueError(f\"No nodes found for selection: {selection}\")\n\n    return self.selections[sel_key][\"selected_nodes\"].index.tolist()\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.select_roadway_features","title":"<code>select_roadway_features(selection, search_mode='drive', force_search=False)</code>","text":"<p>Selects roadway features that satisfy selection criteria</p> Example usage <p>net.select_roadway_features(   selection = [ {     #   a match condition for the from node using osm,     #   shared streets, or model node number     \u2018from\u2019: {\u2018osm_model_link_id\u2019: \u20181234\u2019},     #   a match for the to-node..     \u2018to\u2019: {\u2018shstid\u2019: \u20184321\u2019},     #   a regex or match for facility condition     #   could be # of lanes, facility type, etc.     \u2018facility\u2019: {\u2018name\u2019:\u2019Main St\u2019},     }, \u2026 ])</p> <p>Parameters:</p> Name Type Description Default <code>selection</code> <p>dictionary with keys for:  A - from node  B - to node  link - which includes at least a variable for <code>name</code> or \u2018all\u2019 if all selected</p> required <code>search_mode</code> <p>will be overridden if \u2018link\u2019:\u2019all\u2019</p> <code>'drive'</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def select_roadway_features(\n    self, selection: dict, search_mode=\"drive\", force_search=False\n) -&gt; list:\n\"\"\"\n    Selects roadway features that satisfy selection criteria\n\n    Example usage:\n        net.select_roadway_features(\n          selection = [ {\n            #   a match condition for the from node using osm,\n            #   shared streets, or model node number\n            'from': {'osm_model_link_id': '1234'},\n            #   a match for the to-node..\n            'to': {'shstid': '4321'},\n            #   a regex or match for facility condition\n            #   could be # of lanes, facility type, etc.\n            'facility': {'name':'Main St'},\n            }, ... ])\n\n    Args:\n        selection : dictionary with keys for:\n             A - from node\n             B - to node\n             link - which includes at least a variable for `name` or 'all' if all selected\n        search_mode: will be overridden if 'link':'all'\n\n    Returns: a list of indices for the selected links or nodes\n    \"\"\"\n    WranglerLogger.debug(\"validating selection\")\n    self.validate_selection(selection)\n\n    # create a unique key for the selection so that we can cache it\n    sel_key = self.build_selection_key(selection)\n    WranglerLogger.debug(\"Selection Key: {}\".format(sel_key))\n\n    self.selections[sel_key] = {\"selection_found\": False}\n\n    if \"links\" in selection:\n        return self.select_roadway_link_features(\n            selection,\n            sel_key,\n            force_search=force_search,\n            search_mode=search_mode,\n        )\n    if \"nodes\" in selection:\n        return self.select_node_features(\n            selection,\n            sel_key,\n        )\n\n    raise ValueError(\"Invalid selection type. Must be either 'links' or 'nodes'.\")\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.select_roadway_link_features","title":"<code>select_roadway_link_features(selection, sel_key, force_search=False, search_mode='drive')</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>selection</code> <code>dict</code> <p>description</p> required <code>sel_key</code> <code>str</code> <p>selection key hash to store selection in</p> required <code>force_search</code> <code>bool</code> <p>description. Defaults to False.</p> <code>False</code> <code>search_mode</code> <code>str</code> <p>description. Defaults to \u201cdrive\u201d.</p> <code>'drive'</code> <p>Returns:</p> Type Description <code>list</code> <p>List of indices for selected links in self.links_df</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def select_roadway_link_features(\n    self,\n    selection: dict,\n    sel_key: str,\n    force_search: bool = False,\n    search_mode=\"drive\",\n) -&gt; list:\n\"\"\"_summary_\n\n    Args:\n        selection (dict): _description_\n        sel_key: selection key hash to store selection in\n        force_search (bool, optional): _description_. Defaults to False.\n        search_mode (str, optional): _description_. Defaults to \"drive\".\n\n    Returns:\n        List of indices for selected links in self.links_df\n    \"\"\"\n    WranglerLogger.debug(\"Selecting links.\")\n    if selection.get(\"links\") == \"all\":\n        return self.links_df.index.tolist()\n\n    # if this selection has been found before, return the previously selected links\n    if (\n        self.selections.get(sel_key, {}).get(\"selection_found\", None)\n        and not force_search\n    ):\n        return self.selections[sel_key][\"selected_links\"].index.tolist()\n\n    unique_model_link_identifer_in_selection = (\n        RoadwayNetwork.selection_has_unique_link_id(selection)\n    )\n    if not unique_model_link_identifer_in_selection:\n        A_id, B_id = self.orig_dest_nodes_foreign_key(selection)\n    # identify candidate links which match the initial query\n    # assign them as iteration = 0\n    # subsequent iterations that didn't match the query will be\n    # assigned a heigher weight in the shortest path\n    WranglerLogger.debug(\"Building selection query\")\n    # build a selection query based on the selection dictionary\n\n    sel_query = ProjectCard.build_selection_query(\n        selection=selection,\n        type=\"links\",\n        unique_ids=RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS,\n        mode=RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES[search_mode],\n    )\n    WranglerLogger.debug(\"Selecting link features:\\n{}\".format(sel_query))\n\n    self.selections[sel_key][\"candidate_links\"] = self.links_df.query(\n        sel_query, engine=\"python\"\n    )\n    WranglerLogger.debug(\"Completed query\")\n    candidate_links = self.selections[sel_key][\n        \"candidate_links\"\n    ]  # b/c too long to keep that way\n\n    candidate_links[\"i\"] = 0\n\n    if len(candidate_links.index) == 0 and unique_model_link_identifer_in_selection:\n        msg = \"No links found based on unique link identifiers.\\nSelection Failed.\"\n        WranglerLogger.error(msg)\n        raise Exception(msg)\n\n    if len(candidate_links.index) == 0:\n        WranglerLogger.debug(\n            \"No candidate links in initial search.\\nRetrying query using 'ref' instead of \\\n                'name'\"\n        )\n        # if the query doesn't come back with something from 'name'\n        # try it again with 'ref' instead\n        selection_has_name_key = any(\"name\" in d for d in selection[\"links\"])\n\n        if not selection_has_name_key:\n            msg = \"Not able to complete search using 'ref' instead of 'name' because 'name' \\\n                not in search.\"\n            WranglerLogger.error(msg)\n            raise Exception(msg)\n\n        if \"ref\" not in self.links_df.columns:\n            msg = \"Not able to complete search using 'ref' because 'ref' not in network.\"\n            WranglerLogger.error(msg)\n            raise Exception(msg)\n\n        WranglerLogger.debug(\"Trying selection query replacing 'name' with 'ref'\")\n        sel_query = sel_query.replace(\"name\", \"ref\")\n\n        self.selections[sel_key][\"candidate_links\"] = self.links_df.query(\n            sel_query, engine=\"python\"\n        )\n        candidate_links = self.selections[sel_key][\"candidate_links\"]\n\n        candidate_links[\"i\"] = 0\n\n        if len(candidate_links.index) == 0:\n            msg = \"No candidate links in search using either 'name' or 'ref' in query.\\\n                Selection Failed.\"\n            WranglerLogger.error(msg)\n            raise Exception(msg)\n\n    if unique_model_link_identifer_in_selection:\n        # unique identifier exists and no need to go through big search\n        self.selections[sel_key][\"selected_links\"] = self.selections[sel_key][\n            \"candidate_links\"\n        ]\n        self.selections[sel_key][\"selection_found\"] = True\n\n        return self.selections[sel_key][\"selected_links\"].index.tolist()\n\n    else:\n        WranglerLogger.debug(\"Not a unique ID selection, conduct search.\")\n        (\n            self.selections[sel_key][\"graph\"],\n            self.selections[sel_key][\"candidate_links\"],\n            self.selections[sel_key][\"route\"],\n            self.selections[sel_key][\"links\"],\n        ) = self.path_search(\n            self.selections[sel_key][\"candidate_links\"],\n            A_id,\n            B_id,\n            weight_factor=RoadwayNetwork.SP_WEIGHT_FACTOR,\n        )\n\n        if len(selection[\"links\"]) == 1:\n            self.selections[sel_key][\"selected_links\"] = self.selections[sel_key][\n                \"links\"\n            ]\n\n        # Conduct a \"selection on the selection\" if have additional requirements to satisfy\n        else:\n            resel_query = ProjectCard.build_selection_query(\n                selection=selection,\n                unique_ids=RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS,\n                mode=RoadwayNetwork.MODES_TO_NETWORK_LINK_VARIABLES[search_mode],\n                ignore=[\"name\"],\n            )\n            WranglerLogger.debug(\"Reselecting features:\\n{}\".format(resel_query))\n            self.selections[sel_key][\"selected_links\"] = self.selections[sel_key][\n                \"links\"\n            ].query(resel_query, engine=\"python\")\n\n        if len(self.selections[sel_key][\"selected_links\"]) &gt; 0:\n            self.selections[sel_key][\"selection_found\"] = True\n        else:\n            raise ValueError(f\"No links found for selection: {selection}\")\n\n        self.selections[sel_key][\"selection_found\"] = True\n        return self.selections[sel_key][\"selected_links\"].index.tolist()\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.selection_has_unique_link_id","title":"<code>selection_has_unique_link_id(selection_dict)</code>  <code>staticmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>selection_dictionary</code> <p>Dictionary representation of selection of roadway features, containing a \u201clinks\u201d key.</p> required <p>A boolean indicating if the selection dictionary contains</p> Type Description <code>bool</code> <p>a required unique link id.</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef selection_has_unique_link_id(selection_dict: dict) -&gt; bool:\n\"\"\"\n    Args:\n        selection_dictionary: Dictionary representation of selection\n            of roadway features, containing a \"links\" key.\n\n    Returns: A boolean indicating if the selection dictionary contains\n        a required unique link id.\n\n    \"\"\"\n    selection_keys = [k for li in selection_dict[\"links\"] for k, v in li.items()]\n    return bool(\n        set(RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS).intersection(\n            set(selection_keys)\n        )\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.selection_map","title":"<code>selection_map(selected_link_idx, A=None, B=None, candidate_link_idx=[])</code>","text":"<p>Shows which links are selected for roadway property change or parallel managed lanes category of roadway projects.</p> <p>Parameters:</p> Name Type Description Default <code>selected_links_idx</code> <p>list of selected link indices</p> required <code>candidate_links_idx</code> <p>optional list of candidate link indices to also include in map</p> required <code>A</code> <code>Optional[Any]</code> <p>optional foreign key of starting node of a route selection</p> <code>None</code> <code>B</code> <code>Optional[Any]</code> <p>optional foreign key of ending node of a route selection</p> <code>None</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def selection_map(\n    self,\n    selected_link_idx: list,\n    A: Optional[Any] = None,\n    B: Optional[Any] = None,\n    candidate_link_idx: Optional[List] = [],\n):\n\"\"\"\n    Shows which links are selected for roadway property change or parallel\n    managed lanes category of roadway projects.\n\n    Args:\n        selected_links_idx: list of selected link indices\n        candidate_links_idx: optional list of candidate link indices to also include in map\n        A: optional foreign key of starting node of a route selection\n        B: optional foreign key of ending node of a route selection\n    \"\"\"\n    WranglerLogger.debug(\n        \"Selected Links: {}\\nCandidate Links: {}\\n\".format(\n            selected_link_idx, candidate_link_idx\n        )\n    )\n\n    graph_link_idx = list(set(selected_link_idx + candidate_link_idx))\n    graph_links = self.links_df.loc[graph_link_idx]\n\n    node_list_foreign_keys = list(\n        set(\n            [\n                i\n                for fk in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE\n                for i in list(graph_links[fk])\n            ]\n        )\n    )\n\n    graph_nodes = self.nodes_df.loc[node_list_foreign_keys]\n\n    G = RoadwayNetwork.ox_graph(graph_nodes, graph_links)\n\n    # base map plot with whole graph\n    m = ox.plot_graph_folium(\n        G, edge_color=None, tiles=\"cartodbpositron\", width=\"300px\", height=\"250px\"\n    )\n\n    # plot selection\n    selected_links = self.links_df.loc[selected_link_idx]\n\n    for _, row in selected_links.iterrows():\n        pl = ox.folium._make_folium_polyline(\n            geom=row[\"geometry\"],\n            edge=row,\n            edge_color=\"blue\",\n            edge_width=5,\n            edge_opacity=0.8,\n        )\n        pl.add_to(m)\n\n    # if have A and B node add them to base map\n    def _folium_node(node_row, color=\"white\", icon=\"\"):\n        node_marker = folium.Marker(\n            location=[node_row[\"Y\"], node_row[\"X\"]],\n            icon=folium.Icon(icon=icon, color=color),\n        )\n        return node_marker\n\n    if A:\n        msg = f\"A: {A}\\n{self.nodes_df[self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY] == A]}\"\n        # WranglerLogger.debug(msg)\n        _folium_node(\n            self.nodes_df[self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY] == A],\n            color=\"green\",\n            icon=\"play\",\n        ).add_to(m)\n\n    if B:\n        _folium_node(\n            self.nodes_df[self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY] == B],\n            color=\"red\",\n            icon=\"star\",\n        ).add_to(m)\n\n    return m\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.shortest_path","title":"<code>shortest_path(graph_links_df, O_id, D_id, nodes_df=None, weight_column='i', weight_factor=1.0)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>graph_links_df</code> <code>gpd.GeoDataFrame</code> required <code>O_id</code> <p>foreign key for start node</p> required <code>D_id</code> <p>foreign key for end node</p> required <code>nodes_df</code> <code>gpd.GeoDataFrame</code> <p>optional nodes df, otherwise will use network instance</p> <code>None</code> <code>weight_column</code> <code>str</code> <p>column to use as a weight, defaults to \u201ci\u201d</p> <code>'i'</code> <code>weight_factor</code> <code>float</code> <p>any additional weighting to multiply the weight column by, defaults to RoadwayNetwork.SP_WEIGHT_FACTOR</p> <code>1.0</code> <ul> <li>Boolean if shortest path found</li> <li>nx Directed graph of graph links</li> <li>route of shortest path nodes as List</li> <li>links in shortest path selected from links_df</li> </ul> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def shortest_path(\n    self,\n    graph_links_df: gpd.GeoDataFrame,\n    O_id,\n    D_id,\n    nodes_df: gpd.GeoDataFrame = None,\n    weight_column: str = \"i\",\n    weight_factor: float = 1.0,\n) -&gt; tuple:\n\"\"\"\n\n    Args:\n        graph_links_df:\n        O_id: foreign key for start node\n        D_id: foreign key for end node\n        nodes_df: optional nodes df, otherwise will use network instance\n        weight_column: column to use as a weight, defaults to \"i\"\n        weight_factor: any additional weighting to multiply the weight column by, defaults\n            to RoadwayNetwork.SP_WEIGHT_FACTOR\n\n    Returns: tuple with length of four\n    - Boolean if shortest path found\n    - nx Directed graph of graph links\n    - route of shortest path nodes as List\n    - links in shortest path selected from links_df\n    \"\"\"\n    WranglerLogger.debug(\n        f\"Calculating shortest path from {O_id} to {D_id} using {weight_column} as \\\n            weight with a factor of {weight_factor}\"\n    )\n\n    # Prep Graph Links\n    if weight_column not in graph_links_df.columns:\n        WranglerLogger.warning(\n            \"{} not in graph_links_df so adding and initializing to 1.\".format(\n                weight_column\n            )\n        )\n        graph_links_df[weight_column] = 1\n\n    graph_links_df.loc[:, \"weight\"] = 1 + (\n        graph_links_df[weight_column] * weight_factor\n    )\n\n    # Select Graph Nodes\n    node_list_foreign_keys = RoadwayNetwork._get_fk_nodes(graph_links_df)\n\n    if O_id not in node_list_foreign_keys:\n        msg = \"O_id: {} not in Graph for finding shortest Path\".format(O_id)\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n    if D_id not in node_list_foreign_keys:\n        msg = \"D_id: {} not in Graph for finding shortest Path\".format(D_id)\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n\n    if not nodes_df:\n        nodes_df = self.nodes_df\n    graph_nodes_df = nodes_df.loc[node_list_foreign_keys]\n\n    # Create Graph\n    WranglerLogger.debug(\"Creating network graph\")\n    G = RoadwayNetwork.ox_graph(graph_nodes_df, graph_links_df)\n\n    try:\n        sp_route = nx.shortest_path(G, O_id, D_id, weight=\"weight\")\n        WranglerLogger.debug(\"Shortest path successfully routed\")\n    except nx.NetworkXNoPath:\n        WranglerLogger.debug(\"No SP from {} to {} Found.\".format(O_id, D_id))\n        return False, G, graph_links_df, None, None\n\n    sp_links = graph_links_df[\n        graph_links_df[\"A\"].isin(sp_route) &amp; graph_links_df[\"B\"].isin(sp_route)\n    ]\n\n    return True, G, graph_links_df, sp_route, sp_links\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.update_node_geometry","title":"<code>update_node_geometry(updated_nodes=None)</code>","text":"<p>Adds or updates the geometry of the nodes in the network based on XY coordinates.</p> <p>Assumes XY are in self.crs. Also updates the geometry of links and shapes that reference these nodes.</p> <p>Parameters:</p> Name Type Description Default <code>updated_nodes</code> <code>List</code> <p>List of nodes to update. Defaults to all nodes.</p> <code>None</code> <p>Returns:</p> Type Description <code>gpd.GeoDataFrame</code> <p>gpd.GeoDataFrame: nodes geodataframe with updated geometry.</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def update_node_geometry(self, updated_nodes: List = None) -&gt; gpd.GeoDataFrame:\n\"\"\"Adds or updates the geometry of the nodes in the network based on XY coordinates.\n\n    Assumes XY are in self.crs.\n    Also updates the geometry of links and shapes that reference these nodes.\n\n    Args:\n        updated_nodes: List of nodes to update. Defaults to all nodes.\n\n    Returns:\n       gpd.GeoDataFrame: nodes geodataframe with updated geometry.\n    \"\"\"\n    if updated_nodes:\n        updated_nodes_df = copy.deepcopy(\n            self.nodes_df.loc[\n                self.nodes_df[RoadwayNetwork.UNIQUE_NODE_KEY].isin(updated_nodes)\n            ]\n        )\n    else:\n        updated_nodes_df = copy.deepcopy(self.nodes_df)\n        updated_nodes = self.nodes_df.index.values.tolist()\n\n    if len(updated_nodes_df) &lt; 25:\n        WranglerLogger.debug(\n            f\"Original Nodes:\\n{updated_nodes_df[['X','Y','geometry']]}\"\n        )\n\n    updated_nodes_df[\"geometry\"] = updated_nodes_df.apply(\n        lambda x: point_from_xy(\n            x[\"X\"],\n            x[\"Y\"],\n            xy_crs=updated_nodes_df.crs,\n            point_crs=updated_nodes_df.crs,\n        ),\n        axis=1,\n    )\n    WranglerLogger.debug(f\"{len(self.nodes_df)} nodes in network before update\")\n    if len(updated_nodes_df) &lt; 25:\n        WranglerLogger.debug(\n            f\"Updated Nodes:\\n{updated_nodes_df[['X','Y','geometry']]}\"\n        )\n    self.nodes_df.update(\n        updated_nodes_df[[RoadwayNetwork.UNIQUE_NODE_KEY, \"geometry\"]]\n    )\n    WranglerLogger.debug(f\"{len(self.nodes_df)} nodes in network after update\")\n    if len(self.nodes_df) &lt; 25:\n        WranglerLogger.debug(\n            f\"Updated self.nodes_df:\\n{self.nodes_df[['X','Y','geometry']]}\"\n        )\n\n    self._update_node_geometry_in_links_shapes(updated_nodes_df)\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_link_schema","title":"<code>validate_link_schema(link_file, schema_location='roadway_network_link.json')</code>  <code>staticmethod</code>","text":"<p>Validate roadway network data link schema and output a boolean</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef validate_link_schema(\n    link_file, schema_location: str = \"roadway_network_link.json\"\n):\n\"\"\"\n    Validate roadway network data link schema and output a boolean\n    \"\"\"\n\n    if not os.path.exists(schema_location):\n        base_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n        )\n        schema_location = os.path.join(base_path, schema_location)\n\n    with open(schema_location) as schema_json_file:\n        schema = json.load(schema_json_file)\n\n    with open(link_file) as link_json_file:\n        json_data = json.load(link_json_file)\n\n    try:\n        validate(json_data, schema)\n        return True\n\n    except ValidationError as exc:\n        WranglerLogger.error(\"Failed Link schema validation: Validation Error\")\n        WranglerLogger.error(\"Link File Loc:{}\".format(link_file))\n        WranglerLogger.error(\"Path:{}\".format(exc.path))\n        WranglerLogger.error(exc.message)\n\n    except SchemaError as exc:\n        WranglerLogger.error(\"Invalid Link Schema\")\n        WranglerLogger.error(\"Link Schema Loc: {}\".format(schema_location))\n        WranglerLogger.error(json.dumps(exc.message, indent=2))\n\n    return False\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_node_schema","title":"<code>validate_node_schema(node_file, schema_location='roadway_network_node.json')</code>  <code>staticmethod</code>","text":"<p>Validate roadway network data node schema and output a boolean</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef validate_node_schema(\n    node_file, schema_location: str = \"roadway_network_node.json\"\n):\n\"\"\"\n    Validate roadway network data node schema and output a boolean\n    \"\"\"\n    if not os.path.exists(schema_location):\n        base_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n        )\n        schema_location = os.path.join(base_path, schema_location)\n\n    with open(schema_location) as schema_json_file:\n        schema = json.load(schema_json_file)\n\n    with open(node_file) as node_json_file:\n        json_data = json.load(node_json_file)\n\n    try:\n        validate(json_data, schema)\n        return True\n\n    except ValidationError as exc:\n        WranglerLogger.error(\"Failed Node schema validation: Validation Error\")\n        WranglerLogger.error(\"Node File Loc:{}\".format(node_file))\n        WranglerLogger.error(\"Node Schema Loc:{}\".format(schema_location))\n        WranglerLogger.error(exc.message)\n\n    except SchemaError as exc:\n        WranglerLogger.error(\"Invalid Node Schema\")\n        WranglerLogger.error(\"Node Schema Loc:{}\".format(schema_location))\n        WranglerLogger.error(json.dumps(exc.message, indent=2))\n\n    return False\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_object_types","title":"<code>validate_object_types(nodes, links, shapes)</code>  <code>staticmethod</code>","text":"<p>Determines if the roadway network is being built with the right object types. Does not validate schemas.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>GeoDataFrame</code> <p>nodes geodataframe</p> required <code>links</code> <code>GeoDataFrame</code> <p>link geodataframe</p> required <code>shapes</code> <code>GeoDataFrame</code> <p>shape geodataframe</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef validate_object_types(\n    nodes: GeoDataFrame, links: GeoDataFrame, shapes: GeoDataFrame\n):\n\"\"\"\n    Determines if the roadway network is being built with the right object types.\n    Does not validate schemas.\n\n    Args:\n        nodes: nodes geodataframe\n        links: link geodataframe\n        shapes: shape geodataframe\n\n    Returns: boolean\n    \"\"\"\n\n    errors = \"\"\n\n    if not isinstance(nodes, GeoDataFrame):\n        error_message = (\n            \"Incompatible nodes type:{}. Must provide a GeoDataFrame.  \".format(\n                type(nodes)\n            )\n        )\n        WranglerLogger.error(error_message)\n        errors.append(error_message)\n    if not isinstance(links, GeoDataFrame):\n        error_message = (\n            \"Incompatible links type:{}. Must provide a GeoDataFrame.  \".format(\n                type(links)\n            )\n        )\n        WranglerLogger.error(error_message)\n        errors.append(error_message)\n    if not isinstance(shapes, GeoDataFrame):\n        error_message = (\n            \"Incompatible shapes type:{}. Must provide a GeoDataFrame.  \".format(\n                type(shapes)\n            )\n        )\n        WranglerLogger.error(error_message)\n        errors.append(error_message)\n\n    if errors:\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_properties","title":"<code>validate_properties(df, properties, ignore_existing=False, require_existing_for_change=False)</code>","text":"<p>If there are change or existing commands, make sure that that property exists in the network.</p> <p>Parameters:</p> Name Type Description Default <code>properties</code> <p>properties dictionary to be evaluated</p> required <code>df</code> <code>pd.DataFrame</code> <p>links_df or nodes_df or shapes_df to check for compatibility with</p> required <code>ignore_existing</code> <code>bool</code> <p>If True, will only warn about properties that specify an \u201cexisting\u201d value.  If False, will fail.</p> <code>False</code> <code>require_existing_for_change</code> <code>bool</code> <p>If True, will fail if there isn\u2019t a specified value in theproject card for existing when a change is specified.</p> <code>False</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def validate_properties(\n    self,\n    df: pd.DataFrame,\n    properties: dict,\n    ignore_existing: bool = False,\n    require_existing_for_change: bool = False,\n) -&gt; bool:\n\"\"\"\n    If there are change or existing commands, make sure that that\n    property exists in the network.\n\n    Args:\n        properties : properties dictionary to be evaluated\n        df: links_df or nodes_df or shapes_df to check for compatibility with\n        ignore_existing: If True, will only warn about properties\n            that specify an \"existing\" value.  If False, will fail.\n        require_existing_for_change: If True, will fail if there isn't\n            a specified value in theproject card for existing when a\n            change is specified.\n\n    Returns: boolean value as to whether the properties dictonary is valid.\n    \"\"\"\n\n    valid = True\n    for p in properties:\n        if p[\"property\"] not in df.columns and p.get(\"change\"):\n            WranglerLogger.error(\n                f'\"Change\" is specified for attribute { p[\"property\"]}, but doesn\\'t \\\n                        exist in base network'\n            )\n            valid = False\n        if (\n            p[\"property\"] not in df.columns\n            and p.get(\"existing\")\n            and not ignore_existing\n        ):\n            WranglerLogger.error(\n                f'\"Existing\" is specified for attribute { p[\"property\"]}, but doesn\\'t \\\n                    exist in base network'\n            )\n            valid = False\n        if p.get(\"change\") and not p.get(\"existing\"):\n            if require_existing_for_change:\n                WranglerLogger.error(\n                    f'\"Change\" is specified for attribute {p[\"property\"]}, but there \\\n                        isn\\'t a value for existing.\\nTo proceed, run with the setting \\\n                        require_existing_for_change=False'\n                )\n                valid = False\n            else:\n                WranglerLogger.warning(\n                    f'\"Change\" is specified for attribute {p[\"property\"]}, but there \\\n                        isn\\'t a value for existing'\n                )\n\n    if not valid:\n        raise ValueError(\"Property changes are not valid:\\n  {properties\")\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_selection","title":"<code>validate_selection(selection)</code>","text":"<p>Evaluate whetther the selection dictionary contains the minimum required values.</p> <p>Parameters:</p> Name Type Description Default <code>selection</code> <code>dict</code> <p>selection dictionary to be evaluated</p> required Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def validate_selection(self, selection: dict) -&gt; bool:\n\"\"\"\n    Evaluate whetther the selection dictionary contains the\n    minimum required values.\n\n    Args:\n        selection: selection dictionary to be evaluated\n\n    Returns: boolean value as to whether the selection dictonary is valid.\n    \"\"\"\n    if selection.get(\"links\"):\n        return self._validate_link_selection(selection)\n\n    elif selection.get(\"nodes\"):\n        return self._validate_node_selection(selection)\n\n    else:\n        raise ValueError(\n            f\"Project Card Selection requires either 'links' or 'nodes' : \\\n            Selection provided: {selection.keys()}\"\n        )\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_shape_schema","title":"<code>validate_shape_schema(shape_file, schema_location='roadway_network_shape.json')</code>  <code>staticmethod</code>","text":"<p>Validate roadway network data shape schema and output a boolean</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>@staticmethod\ndef validate_shape_schema(\n    shape_file, schema_location: str = \"roadway_network_shape.json\"\n):\n\"\"\"\n    Validate roadway network data shape schema and output a boolean\n    \"\"\"\n\n    if not os.path.exists(schema_location):\n        base_path = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)), \"schemas\"\n        )\n        schema_location = os.path.join(base_path, schema_location)\n\n    with open(schema_location) as schema_json_file:\n        schema = json.load(schema_json_file)\n\n    with open(shape_file) as shape_json_file:\n        json_data = json.load(shape_json_file)\n\n    try:\n        validate(json_data, schema)\n        return True\n\n    except ValidationError as exc:\n        WranglerLogger.error(\"Failed Shape schema validation: Validation Error\")\n        WranglerLogger.error(\"Shape File Loc:{}\".format(shape_file))\n        WranglerLogger.error(\"Path:{}\".format(exc.path))\n        WranglerLogger.error(exc.message)\n\n    except SchemaError as exc:\n        WranglerLogger.error(\"Invalid Shape Schema\")\n        WranglerLogger.error(\"Shape Schema Loc: {}\".format(schema_location))\n        WranglerLogger.error(json.dumps(exc.message, indent=2))\n\n    return False\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_uniqueness","title":"<code>validate_uniqueness()</code>","text":"<p>Confirms that the unique identifiers are met.</p> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def validate_uniqueness(self) -&gt; bool:\n\"\"\"\n    Confirms that the unique identifiers are met.\n    \"\"\"\n    valid = True\n\n    for c in RoadwayNetwork.UNIQUE_MODEL_LINK_IDENTIFIERS:\n        if c not in self.links_df.columns:\n            valid = False\n            msg = f\"Network doesn't contain unique link identifier: {c}\"\n            WranglerLogger.error(msg)\n        if not self.links_df[c].is_unique:\n            valid = False\n            msg = f\"Unique identifier {c} is not unique in network links\"\n            WranglerLogger.error(msg)\n    for c in RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE:\n        if c not in self.links_df.columns:\n            valid = False\n            msg = f\"Network doesn't contain link foreign key identifier: {c}\"\n            WranglerLogger.error(msg)\n    link_foreign_key = self.links_df[RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE].apply(\n        lambda x: \"-\".join(x.map(str)), axis=1\n    )\n    if not link_foreign_key.is_unique:\n        valid = False\n        msg = f\"Foreign key: {RoadwayNetwork.LINK_FOREIGN_KEY_TO_NODE} is not unique in network links\"\n\n        WranglerLogger.error(msg)\n    for c in RoadwayNetwork.UNIQUE_NODE_IDENTIFIERS:\n        if c not in self.nodes_df.columns:\n            valid = False\n            msg = f\"Network doesn't contain unique node identifier: {c}\"\n            WranglerLogger.error(msg)\n        if not self.nodes_df[c].is_unique:\n            valid = False\n            msg = f\"Unique identifier {c} is not unique in network nodes\"\n            WranglerLogger.error(msg)\n    if RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK not in self.nodes_df.columns:\n        valid = False\n        msg = f\"Network doesn't contain node foreign key identifier: {RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK}\"\n        WranglerLogger.error(msg)\n    elif not self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].is_unique:\n        valid = False\n        msg = f\"Foreign key: {RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK} is not unique in network nodes\"\n        WranglerLogger.error(msg)\n    if RoadwayNetwork.UNIQUE_SHAPE_KEY not in self.shapes_df.columns:\n        valid = False\n        msg = \"Network doesn't contain unique shape id: {}\".format(\n            RoadwayNetwork.UNIQUE_SHAPE_KEY\n        )\n        WranglerLogger.error(msg)\n    elif not self.shapes_df[RoadwayNetwork.UNIQUE_SHAPE_KEY].is_unique:\n        valid = False\n        msg = \"Unique key: {} is not unique in network shapes\".format(\n            RoadwayNetwork.UNIQUE_SHAPE_KEY\n        )\n        WranglerLogger.error(msg)\n    return valid\n</code></pre>"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.write","title":"<code>write(path='.', filename=None, model=False)</code>","text":"<p>Writes a network in the roadway network standard</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>the path were the output will be saved</p> <code>'.'</code> <code>filename</code> <code>str</code> <p>the name prefix of the roadway files that will be generated</p> <code>None</code> <code>model</code> <code>bool</code> <p>determines if shoudl write model network with separated managed lanes, or standard wrangler network. Defaults to False.</p> <code>False</code> Source code in <code>network_wrangler/roadwaynetwork.py</code> <pre><code>def write(\n    self,\n    path: str = \".\",\n    filename: str = None,\n    model: bool = False,\n) -&gt; None:\n\"\"\"\n    Writes a network in the roadway network standard\n\n    args:\n        path: the path were the output will be saved\n        filename: the name prefix of the roadway files that will be generated\n        model: determines if shoudl write model network with separated managed lanes,\n            or standard wrangler network. Defaults to False.\n    \"\"\"\n\n    if not os.path.exists(path):\n        WranglerLogger.debug(\"\\nPath [%s] doesn't exist; creating.\" % path)\n        os.mkdir(path)\n\n    if filename:\n        links_file = os.path.join(path, filename + \"_\" + \"link.json\")\n        nodes_file = os.path.join(path, filename + \"_\" + \"node.geojson\")\n        shapes_file = os.path.join(path, filename + \"_\" + \"shape.geojson\")\n    else:\n        links_file = os.path.join(path, \"link.json\")\n        nodes_file = os.path.join(path, \"node.geojson\")\n        shapes_file = os.path.join(path, \"shape.geojson\")\n\n    if model:\n        from .roadway import create_managed_lane_network\n\n        net = create_managed_lane_network(self)\n        links_df = net.m_links_df\n        nodes_df = net.m_nodes_df\n        shapes_df = net.m_shapes_df\n    else:\n        links_df = self.links_df\n        nodes_df = self.nodes_df\n        shapes_df = self.shapes_df\n\n    # Make sure types are correct\n    nodes_df = RoadwayNetwork.coerce_types(nodes_df)\n    links_df = RoadwayNetwork.coerce_types(links_df)\n\n    link_property_columns = links_df.columns.values.tolist()\n    link_property_columns.remove(\"geometry\")\n    links_json = links_df_to_json(links_df, link_property_columns)\n    with open(links_file, \"w\") as f:\n        json.dump(links_json, f)\n\n    # geopandas wont let you write to geojson because\n    # it uses fiona, which doesn't accept a list as one of the properties\n    # so need to convert the df to geojson manually first\n    property_columns = nodes_df.columns.values.tolist()\n    property_columns.remove(\"geometry\")\n\n    nodes_geojson = point_df_to_geojson(nodes_df, property_columns)\n\n    with open(nodes_file, \"w\") as f:\n        json.dump(nodes_geojson, f)\n\n    shapes_df.to_file(shapes_file, driver=\"GeoJSON\")\n</code></pre>"},{"location":"api/#network_wrangler.TransitNetwork","title":"<code>network_wrangler.TransitNetwork</code>","text":"<p>         Bases: <code>object</code></p> <p>Representation of a Transit Network.</p> <p>Typical usage example: <pre><code>import network_wrangler as wr\nstpaul = r'/home/jovyan/work/example/stpaul'\ntc=wr.TransitNetwork.read(path=stpaul)\n</code></pre></p> <p>Attributes:</p> Name Type Description <code>feed</code> <code>DotDict</code> <p>Partridge feed mapping dataframes.</p> <code>config</code> <code>nx.DiGraph</code> <p>Partridge config</p> <code>road_net</code> <code>RoadwayNetwork</code> <p>Associated roadway network object.</p> <code>graph</code> <code>nx.MultiDiGraph</code> <p>Graph for associated roadway network object.</p> <code>feed_path</code> <code>str</code> <p>Where the feed was read in from.</p> <code>validated_frequencies</code> <code>bool</code> <p>The frequencies have been validated.</p> <code>validated_road_network_consistency</code> <p>The network has been validated against the road network.</p> <code>SHAPES_FOREIGN_KEY</code> <code>str</code> <p>foreign key between shapes dataframe and roadway network nodes</p> <code>STOPS_FOREIGN_KEY</code> <code>str</code> <p>foreign  key between stops dataframe and roadway network nodes</p> <code>ID_SCALAR</code> <code>int</code> <p>scalar value added to create new IDs when necessary.</p> <code>REQUIRED_FILES</code> <code>list[str]</code> <p>list of files that the transit network requires.</p> <p>.. todo::   investigate consolidating scalars this with RoadwayNetwork   consolidate thes foreign key constants into one if possible</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>class TransitNetwork(object):\n\"\"\"\n    Representation of a Transit Network.\n\n    Typical usage example:\n    ``` py\n    import network_wrangler as wr\n    stpaul = r'/home/jovyan/work/example/stpaul'\n    tc=wr.TransitNetwork.read(path=stpaul)\n    ```\n\n    Attributes:\n        feed (DotDict): Partridge feed mapping dataframes.\n        config (nx.DiGraph): Partridge config\n        road_net (RoadwayNetwork): Associated roadway network object.\n        graph (nx.MultiDiGraph): Graph for associated roadway network object.\n        feed_path (str): Where the feed was read in from.\n        validated_frequencies (bool): The frequencies have been validated.\n        validated_road_network_consistency (): The network has been validated against\n            the road network.\n        SHAPES_FOREIGN_KEY (str): foreign key between shapes dataframe and roadway network nodes\n        STOPS_FOREIGN_KEY (str): foreign  key between stops dataframe and roadway network nodes\n        ID_SCALAR (int): scalar value added to create new IDs when necessary.\n        REQUIRED_FILES (list[str]): list of files that the transit network requires.\n\n    .. todo::\n      investigate consolidating scalars this with RoadwayNetwork\n      consolidate thes foreign key constants into one if possible\n    \"\"\"\n\n    # PK = primary key, FK = foreign key\n    SHAPES_FOREIGN_KEY = \"shape_model_node_id\"\n    STOPS_FOREIGN_KEY = \"model_node_id\"\n\n    # TODO consolidate these two ^^^ constants if possible\n\n    ID_SCALAR = 100000000\n\n    # TODO investigate consolidating this with RoadwayNetwork\n\n    REQUIRED_FILES = [\n        \"agency.txt\",\n        \"frequencies.txt\",\n        \"routes.txt\",\n        \"shapes.txt\",\n        \"stop_times.txt\",\n        \"stops.txt\",\n        \"trips.txt\",\n    ]\n\n    def __init__(self, feed: DotDict = None, config: nx.DiGraph = None):\n\"\"\"\n        Constructor\n\n        .. todo:: Make graph a reference to associated RoadwayNetwork's graph, not its own thing.\n        \"\"\"\n        self.feed: DotDict = feed\n        self.config: nx.DiGraph = config\n        self.road_net: RoadwayNetwork = None\n        self.graph: nx.MultiDiGraph = None\n        self.feed_path = None\n\n        self.validated_frequencies = False\n        self.validated_road_network_consistency = False\n\n        if not self.validate_frequencies():\n            raise ValueError(\n                \"Transit lines with non-positive frequencies exist in the network\"\n            )\n\n    @staticmethod\n    def empty() -&gt; TransitNetwork:\n\"\"\"\n        Create an empty transit network instance using the default config.\n\n        .. todo:: fill out this method\n        \"\"\"\n        # TODO\n\n        msg = \"TransitNetwork.empty is not implemented.\"\n        WranglerLogger.error(msg)\n        raise NotImplementedError(msg)\n\n    @staticmethod\n    def read(feed_path: str) -&gt; TransitNetwork:\n\"\"\"\n        Read GTFS feed from folder and TransitNetwork object\n\n        Args:\n            feed_path: where to read transit network files from\n\n        Returns: a TransitNetwork object.\n        \"\"\"\n        config = default_config()\n        feed = ptg.load_feed(feed_path, config=config)\n        WranglerLogger.info(\"Read in transit feed from: {}\".format(feed_path))\n\n        updated_config = TransitNetwork.validate_feed(feed, config)\n\n        # Read in each feed so we can write over them\n        editable_feed = DotDict()\n        for node in updated_config.nodes.keys():\n            # Load (initiate Partridge's lazy load)\n            editable_feed[node.replace(\".txt\", \"\")] = feed.get(node)\n\n        transit_network = TransitNetwork(feed=editable_feed, config=updated_config)\n        transit_network.feed_path = feed_path\n        return transit_network\n\n    @staticmethod\n    def validate_feed(feed: DotDict, config: nx.DiGraph) -&gt; bool:\n\"\"\"\n        Since Partridge lazily loads the df, load each file to make sure it\n        actually works.\n\n        Partridge uses a DiGraph from the networkx library to represent the\n        relationships between GTFS files. Each file is a 'node', and the\n        relationship between files are 'edges'.\n\n        Args:\n            feed: partridge feed\n            config: partridge config\n        \"\"\"\n        updated_config = copy.deepcopy(config)\n        files_not_found = []\n        for node in config.nodes.keys():\n\n            n = feed.get(node)\n            WranglerLogger.debug(\"...{}:\\n{}\".format(node, n[:10]))\n            if n.shape[0] == 0:\n                WranglerLogger.info(\n                    \"Removing {} from transit network config because file not found\".format(\n                        node\n                    )\n                )\n                updated_config.remove_node(node)\n                if node in TransitNetwork.REQUIRED_FILES:\n                    files_not_found.append(node)\n\n        if files_not_found:\n            msg = \"Required files not found or valid: {}\".format(\n                \",\".join(files_not_found)\n            )\n            WranglerLogger.error(msg)\n            raise AttributeError(msg)\n            return False\n\n        TransitNetwork.validate_network_keys(feed)\n\n        return updated_config\n\n    def validate_frequencies(self) -&gt; bool:\n\"\"\"\n        Validates that there are no transit trips in the feed with zero frequencies.\n\n        Changes state of self.validated_frequencies boolean based on outcome.\n\n        Returns:\n            boolean indicating if valid or not.\n        \"\"\"\n\n        _valid = True\n        zero_freq = self.feed.frequencies[self.feed.frequencies.headway_secs &lt;= 0]\n\n        if len(zero_freq.index) &gt; 0:\n            _valid = False\n            msg = \"Transit lines {} have non-positive frequencies\".format(\n                zero_freq.trip_id.to_list()\n            )\n            WranglerLogger.error(msg)\n\n        self.validated_frequencies = True\n\n        return _valid\n\n    def validate_road_network_consistencies(self) -&gt; bool:\n\"\"\"\n        Validates transit network against the road network for both stops\n        and shapes.\n\n        Returns:\n            boolean indicating if valid or not.\n        \"\"\"\n        if self.road_net is None:\n            raise ValueError(\n                \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n            )\n\n        valid = True\n\n        valid_stops = self.validate_transit_stops()\n        valid_shapes = self.validate_transit_shapes()\n\n        self.validated_road_network_consistency = True\n\n        if not valid_stops or not valid_shapes:\n            valid = False\n            raise ValueError(\"Transit network is not consistent with road network.\")\n\n        return valid\n\n    def validate_transit_stops(self) -&gt; bool:\n\"\"\"\n        Validates that all transit stops are part of the roadway network.\n\n        Returns:\n            Boolean indicating if valid or not.\n        \"\"\"\n\n        if self.road_net is None:\n            raise ValueError(\n                \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n            )\n\n        stops = self.feed.stops\n        nodes = self.road_net.nodes_df\n\n        valid = True\n\n        stop_ids = [int(s) for s in stops[TransitNetwork.STOPS_FOREIGN_KEY].to_list()]\n        node_ids = [\n            int(n) for n in nodes[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].to_list()\n        ]\n\n        if not set(stop_ids).issubset(node_ids):\n            valid = False\n            missing_stops = list(set(stop_ids) - set(node_ids))\n            msg = \"Not all transit stops are part of the roadyway network. \"\n            msg += \"Missing stops ({}) from the roadway nodes are {}.\".format(\n                TransitNetwork.STOPS_FOREIGN_KEY, missing_stops\n            )\n            WranglerLogger.error(msg)\n\n        return valid\n\n    def validate_transit_shapes(self) -&gt; bool:\n\"\"\"\n        Validates that all transit shapes are part of the roadway network.\n\n        Returns:\n            Boolean indicating if valid or not.\n        \"\"\"\n\n        if self.road_net is None:\n            raise ValueError(\n                \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n            )\n\n        shapes_df = self.feed.shapes\n        nodes_df = self.road_net.nodes_df\n        links_df = self.road_net.links_df\n\n        valid = True\n\n        # check if all the node ids exist in the network\n        shape_ids = [\n            int(s) for s in shapes_df[TransitNetwork.SHAPES_FOREIGN_KEY].to_list()\n        ]\n        node_ids = [\n            int(n) for n in nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].to_list()\n        ]\n\n        if not set(shape_ids).issubset(node_ids):\n            valid = False\n            missing_shapes = list(set(shape_ids) - set(node_ids))\n            msg = \"Not all transit shapes are part of the roadyway network. \"\n            msg += \"Missing shapes ({}) from the roadway network are {}.\".format(\n                TransitNetwork.SHAPES_FOREIGN_KEY, missing_shapes\n            )\n            WranglerLogger.error(msg)\n            return valid\n\n        # check if all the links in transit shapes exist in the network\n        # and transit is allowed\n        shapes_df = shapes_df.astype({TransitNetwork.SHAPES_FOREIGN_KEY: int})\n        unique_shape_ids = shapes_df.shape_id.unique().tolist()\n\n        for id in unique_shape_ids:\n            subset_shapes_df = shapes_df[shapes_df[\"shape_id\"] == id]\n            subset_shapes_df = subset_shapes_df.sort_values(by=[\"shape_pt_sequence\"])\n            subset_shapes_df = subset_shapes_df.add_suffix(\"_1\").join(\n                subset_shapes_df.shift(-1).add_suffix(\"_2\")\n            )\n            subset_shapes_df = subset_shapes_df.dropna()\n\n            merged_df = subset_shapes_df.merge(\n                links_df,\n                how=\"left\",\n                left_on=[\n                    TransitNetwork.SHAPES_FOREIGN_KEY + \"_1\",\n                    TransitNetwork.SHAPES_FOREIGN_KEY + \"_2\",\n                ],\n                right_on=[\"A\", \"B\"],\n                indicator=True,\n            )\n\n            missing_links_df = merged_df.query('_merge == \"left_only\"')\n\n            # there are shape links which does not exist in the roadway network\n            if len(missing_links_df.index) &gt; 0:\n                valid = False\n                msg = f\"There are links for shape id {id} which are missing in the \\\n                    roadway network.\"\n                WranglerLogger.error(msg)\n\n            transit_not_allowed_df = merged_df.query(\n                '_merge == \"both\" &amp; drive_access == 0 &amp; bus_only == 0 &amp; rail_only == 0'\n            )\n\n            # there are shape links where transit is not allowed\n            if len(transit_not_allowed_df.index) &gt; 0:\n                valid = False\n                msg = f\"There are links for shape id {id} which does not allow transit \\\n                    in the roadway network.\"\n                WranglerLogger.error(msg)\n\n        return valid\n\n    @staticmethod\n    def route_ids_in_routestxt(feed: DotDict) -&gt; bool:\n\"\"\"\n        Wherever route_id occurs, make sure it is in routes.txt\n\n        Args:\n            feed: partridge feed object\n\n        Returns:\n            Boolean indicating if feed is okay.\n        \"\"\"\n        route_ids_routestxt = set(feed.routes.route_id.tolist())\n        route_ids_referenced = set(feed.trips.route_id.tolist())\n\n        missing_routes = route_ids_referenced - route_ids_routestxt\n\n        if missing_routes:\n            WranglerLogger.warning(\n                \"The following route_ids are referenced but missing from routes.txt: {}\".format(\n                    list(missing_routes)\n                )\n            )\n            return False\n        return True\n\n    @staticmethod\n    def trip_ids_in_tripstxt(feed: DotDict) -&gt; bool:\n\"\"\"\n        Wherever trip_id occurs, make sure it is in trips.txt\n\n        Args:\n            feed: partridge feed object\n\n        Returns:\n            Boolean indicating if feed is okay.\n        \"\"\"\n        trip_ids_tripstxt = set(feed.trips.trip_id.tolist())\n        trip_ids_referenced = set(\n            feed.stop_times.trip_id.tolist() + feed.frequencies.trip_id.tolist()\n        )\n\n        missing_trips = trip_ids_referenced - trip_ids_tripstxt\n\n        if missing_trips:\n            WranglerLogger.warning(\n                \"The following trip_ids are referenced but missing from trips.txt: {}\".format(\n                    list(missing_trips)\n                )\n            )\n            return False\n        return True\n\n    @staticmethod\n    def shape_ids_in_shapestxt(feed: DotDict) -&gt; bool:\n\"\"\"\n        Wherever shape_id occurs, make sure it is in shapes.txt\n\n        Args:\n            feed: partridge feed object\n\n        Returns:\n            Boolean indicating if feed is okay.\n        \"\"\"\n\n        shape_ids_shapestxt = set(feed.shapes.shape_id.tolist())\n        shape_ids_referenced = set(feed.trips.shape_id.tolist())\n\n        missing_shapes = shape_ids_referenced - shape_ids_shapestxt\n\n        if missing_shapes:\n            WranglerLogger.warning(\n                \"The following shape_ids from trips.txt are missing from shapes.txt: {}\".format(\n                    list(missing_shapes)\n                )\n            )\n            return False\n        return True\n\n    @staticmethod\n    def stop_ids_in_stopstxt(feed: DotDict) -&gt; bool:\n\"\"\"\n        Wherever stop_id occurs, make sure it is in stops.txt\n\n        Args:\n            feed: partridge feed object\n\n        Returns:\n            Boolean indicating if feed is okay.\n        \"\"\"\n        stop_ids_stopstxt = set(feed.stops.stop_id.tolist())\n        stop_ids_referenced = []\n\n        # STOP_TIMES\n        stop_ids_referenced.extend(feed.stop_times.stop_id.dropna().tolist())\n        stop_ids_referenced.extend(feed.stops.parent_station.dropna().tolist())\n\n        # TRANSFERS\n        if feed.get(\"transfers.txt\").shape[0] &gt; 0:\n            stop_ids_referenced.extend(feed.transfers.from_stop_id.dropna().tolist())\n            stop_ids_referenced.extend(feed.transfers.to_stop_id.dropna().tolist())\n\n        # PATHWAYS\n        if feed.get(\"pathways.txt\").shape[0] &gt; 0:\n            stop_ids_referenced.extend(feed.pathways.from_stop_id.dropna().tolist())\n            stop_ids_referenced.extend(feed.pathways.to_stop_id.dropna().tolist())\n\n        stop_ids_referenced = set(stop_ids_referenced)\n\n        missing_stops = stop_ids_referenced - stop_ids_stopstxt\n\n        if missing_stops:\n            WranglerLogger.warning(\n                \"The following stop_ids from are referenced but missing from stops.txt: {}\".format(\n                    list(missing_stops)\n                )\n            )\n            return False\n        return True\n\n    @staticmethod\n    def validate_network_keys(feed: DotDict) -&gt; bool:\n\"\"\"\n        Validates foreign keys are present in all connecting feed files.\n\n        Args:\n            feed: partridge feed object\n\n        Returns:\n            Boolean indicating if feed is okay.\n        \"\"\"\n        result = True\n        result = result and TransitNetwork.route_ids_in_routestxt(feed)\n        result = result and TransitNetwork.trip_ids_in_tripstxt(feed)\n        result = result and TransitNetwork.shape_ids_in_shapestxt(feed)\n        result = result and TransitNetwork.stop_ids_in_stopstxt(feed)\n        return result\n\n    def set_roadnet(\n        self,\n        road_net: RoadwayNetwork,\n        graph_shapes: bool = False,\n        graph_stops: bool = False,\n        validate_consistency: bool = True,\n    ) -&gt; None:\n        self.road_net: RoadwayNetwork = road_net\n        self.graph: nx.MultiDiGraph = RoadwayNetwork.ox_graph(\n            road_net.nodes_df, road_net.links_df\n        )\n        if graph_shapes:\n            self._graph_shapes()\n        if graph_stops:\n            self._graph_stops()\n\n        if validate_consistency:\n            self.validate_road_network_consistencies()\n\n    def _graph_shapes(self) -&gt; None:\n\"\"\"\n\n        .. todo:: Fill out this method.\n        \"\"\"\n        existing_shapes = self.feed.shapes\n        msg = \"_graph_shapes() not implemented yet.\"\n        WranglerLogger.error(msg)\n        raise NotImplementedError(msg)\n        # graphed_shapes = pd.DataFrame()\n\n        # for shape_id in shapes:\n        # TODO traverse point by point, mapping shortest path on graph,\n        # then append to a list\n        # return total list of all link ids\n        # rebuild rows in shapes dataframe and add to graphed_shapes\n        # make graphed_shapes a GeoDataFrame\n\n        # self.feed.shapes = graphed_shapes\n\n    def _graph_stops(self) -&gt; None:\n\"\"\"\n        .. todo:: Fill out this method.\n        \"\"\"\n        existing_stops = self.feed.stops\n        msg = \"_graph_stops() not implemented yet.\"\n        WranglerLogger.error(msg)\n        raise NotImplementedError(msg)\n        # graphed_stops = pd.DataFrame()\n\n        # for stop_id in stops:\n        # TODO\n\n        # self.feed.stops = graphed_stops\n\n    def write(self, path: str = \".\", filename: str = None) -&gt; None:\n\"\"\"\n        Writes a network in the transit network standard\n\n        Args:\n            path: the path were the output will be saved\n            filename: the name prefix of the transit files that will be generated\n        \"\"\"\n        WranglerLogger.info(\"Writing transit to directory: {}\".format(path))\n        for node in self.config.nodes.keys():\n\n            df = self.feed.get(node.replace(\".txt\", \"\"))\n            if not df.empty:\n                if filename:\n                    outpath = os.path.join(path, filename + \"_\" + node)\n                else:\n                    outpath = os.path.join(path, node)\n                WranglerLogger.debug(\"Writing file: {}\".format(outpath))\n\n                df.to_csv(outpath, index=False)\n\n    @staticmethod\n    def transit_net_to_gdf(transit: Union(\"TransitNetwork\", pd.DataFrame)):\n\"\"\"\n        Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame.\n\n        Args:\n            transit: either a TransitNetwork or a Shapes GeoDataFrame\n\n        .. todo:: Make more sophisticated.\n        \"\"\"\n        from partridge import geo\n\n        if type(transit) is pd.DataFrame:\n            shapes = transit\n        else:\n            shapes = transit.feed.shapes\n\n        transit_gdf = geo.build_shapes(shapes)\n        return transit_gdf\n\n    def apply(self, project_card_dictionary: dict):\n\"\"\"\n        Wrapper method to apply a project to a transit network.\n\n        Args:\n            project_card_dictionary: dict\n                a dictionary of the project card object\n\n        \"\"\"\n        WranglerLogger.info(\n            \"Applying Project to Transit Network: {}\".format(\n                project_card_dictionary[\"project\"]\n            )\n        )\n\n        def _apply_individual_change(project_dictionary: dict):\n            if (\n                project_dictionary[\"category\"].lower()\n                == \"transit service property change\"\n            ):\n                self.apply_transit_feature_change(\n                    self.select_transit_features(project_dictionary[\"facility\"]),\n                    project_dictionary[\"properties\"],\n                )\n            elif project_dictionary[\"category\"].lower() == \"parallel managed lanes\":\n                # Grab the list of nodes in the facility from road_net\n                # It should be cached because managed lane projects are\n                # processed by RoadwayNetwork first via\n                # Scenario.apply_all_projects\n                try:\n                    managed_lane_nodes = self.road_net.selections(\n                        self.road_net.build_selection_key(\n                            project_dictionary[\"facility\"]\n                        )\n                    )[\"route\"]\n                except ValueError:\n                    WranglerLogger.error(\n                        \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n                    )\n\n                # Reroute any transit using these nodes\n                self.apply_transit_managed_lane(\n                    self.select_transit_features_by_nodes(managed_lane_nodes),\n                    managed_lane_nodes,\n                )\n            elif project_dictionary[\"category\"].lower() == \"add transit\":\n                self.apply_python_calculation(project_dictionary[\"pycode\"])\n            elif project_dictionary[\"category\"].lower() == \"roadway deletion\":\n                WranglerLogger.warning(\n                    \"Roadway Deletion not yet implemented in Transit; ignoring\"\n                )\n            else:\n                msg = \"{} not implemented yet in TransitNetwork; can't apply.\".format(\n                    project_dictionary[\"category\"]\n                )\n                WranglerLogger.error(msg)\n                raise (msg)\n\n        if project_card_dictionary.get(\"changes\"):\n            for project_dictionary in project_card_dictionary[\"changes\"]:\n                _apply_individual_change(project_dictionary)\n        else:\n            _apply_individual_change(project_card_dictionary)\n\n    def apply_python_calculation(self, pycode: str) -&gt; \"TransitNetwork\":\n\"\"\"\n        Changes roadway network object by executing pycode.\n\n        Args:\n            pycode: python code which changes values in the roadway network object\n        \"\"\"\n        net = copy.deepcopy(self)\n        exec(pycode)\n        return net\n\n    def select_transit_features(self, selection: dict) -&gt; pd.Series:\n\"\"\"\n        combines multiple selections\n\n        Args:\n            selection : selection dictionary\n\n        Returns: trip identifiers : list of GTFS trip IDs in the selection\n        \"\"\"\n        trip_ids = pd.Series()\n\n        if selection.get(\"route\"):\n            for route_dictionary in selection[\"route\"]:\n                trip_ids = trip_ids.append(\n                    self._select_transit_features(route_dictionary)\n                )\n        else:\n            trip_ids = self._select_transit_features(selection)\n\n        return trip_ids\n\n    def _select_transit_features(self, selection: dict) -&gt; pd.Series:\n\"\"\"\n        Selects transit features that satisfy selection criteria\n\n        Args:\n            selection : selection dictionary\n\n        Returns: trip identifiers : list of GTFS trip IDs in the selection\n        \"\"\"\n        trips = self.feed.trips\n        routes = self.feed.routes\n        freq = self.feed.frequencies\n\n        # Turn selection's values into lists if they are not already\n        for key in selection.keys():\n            if type(selection[key]) not in [list, tuple]:\n                selection[key] = [selection[key]]\n\n        # Based on the key in selection, filter trips\n        if \"trip_id\" in selection:\n            trips = trips[trips.trip_id.isin(selection[\"trip_id\"])]\n\n        elif \"route_id\" in selection:\n            trips = trips[trips.route_id.isin(selection[\"route_id\"])]\n\n        elif \"route_short_name\" in selection:\n            routes = routes[routes.route_short_name.isin(selection[\"route_short_name\"])]\n            trips = trips[trips.route_id.isin(routes[\"route_id\"])]\n\n        elif \"route_long_name\" in selection:\n            matches = []\n            for sel in selection[\"route_long_name\"]:\n                for route_long_name in routes[\"route_long_name\"]:\n                    x = re.search(sel, route_long_name)\n                    if x is not None:\n                        matches.append(route_long_name)\n\n            routes = routes[routes.route_long_name.isin(matches)]\n            trips = trips[trips.route_id.isin(routes[\"route_id\"])]\n\n        else:\n            WranglerLogger.error(\"Selection not supported %s\", selection.keys())\n            raise ValueError\n\n        # If a time key exists, filter trips using frequency table\n        if selection.get(\"time\"):\n            selection[\"time\"] = parse_time_spans_to_secs(selection[\"time\"])\n        elif selection.get(\"start_time\") and selection.get(\"end_time\"):\n            selection[\"time\"] = parse_time_spans_to_secs(\n                [selection[\"start_time\"][0], selection[\"end_time\"][0]]\n            )\n            # Filter freq to trips in selection\n            freq = freq[freq.trip_id.isin(trips[\"trip_id\"])]\n            freq = freq[freq.start_time == selection[\"time\"][0]]\n            freq = freq[freq.end_time == selection[\"time\"][1]]\n\n            # Filter trips table to those still in freq table\n            trips = trips[trips.trip_id.isin(freq[\"trip_id\"])]\n\n        # If any other key exists, filter routes or trips accordingly\n        for key in selection.keys():\n            if key not in [\n                \"trip_id\",\n                \"route_id\",\n                \"route_short_name\",\n                \"route_long_name\",\n                \"time\",\n                \"start_time\",\n                \"end_time\",\n            ]:\n                if key in trips:\n                    trips = trips[trips[key].isin(selection[key])]\n                elif key in routes:\n                    routes = routes[routes[key].isin(selection[key])]\n                    trips = trips[trips.route_id.isin(routes[\"route_id\"])]\n                else:\n                    WranglerLogger.error(\"Selection not supported %s\", key)\n                    raise ValueError\n\n        # Check that there is at least one trip in trips table or raise error\n        if len(trips) &lt; 1:\n            WranglerLogger.error(\"Selection returned zero trips\")\n            raise ValueError\n\n        # Return pandas.Series of trip_ids\n        return trips[\"trip_id\"]\n\n    def select_transit_features_by_nodes(\n        self, node_ids: list, require_all: bool = False\n    ) -&gt; pd.Series:\n\"\"\"\n        Selects transit features that use any one of a list of node_ids\n\n        Args:\n            node_ids: list (generally coming from nx.shortest_path)\n            require_all : bool if True, the returned trip_ids must traverse all of\n              the nodes (default = False)\n\n        Returns:\n            trip identifiers  list of GTFS trip IDs in the selection\n        \"\"\"\n        # If require_all, the returned trip_ids must traverse all of the nodes\n        # Else, filter any shapes that use any one of the nodes in node_ids\n        if require_all:\n            shape_ids = (\n                self.feed.shapes.groupby(\"shape_id\").filter(\n                    lambda x: all(\n                        i in x[TransitNetwork.SHAPES_FOREIGN_KEY].tolist()\n                        for i in node_ids\n                    )\n                )\n            ).shape_id.drop_duplicates()\n        else:\n            shape_ids = self.feed.shapes[\n                self.feed.shapes[TransitNetwork.SHAPES_FOREIGN_KEY].isin(node_ids)\n            ].shape_id.drop_duplicates()\n\n        # Return pandas.Series of trip_ids\n        return self.feed.trips[self.feed.trips.shape_id.isin(shape_ids)].trip_id\n\n    def apply_transit_feature_change(\n        self,\n        trip_ids: pd.Series,\n        properties: list,\n    ) -&gt; \"TransitNetwork\":\n\"\"\"\n        Changes the transit attributes for the selected features based on the\n        project card information passed\n\n        Args:\n            net: transit network to manipulate\n            trip_ids : pd.Series\n                all trip_ids to apply change to\n            properties : list of dictionaries\n                transit properties to change\n\n        Returns:\n            None\n        \"\"\"\n        net = copy.deepcopy(self)\n\n        for i in properties:\n            if i[\"property\"] in [\"headway_secs\"]:\n                net = TransitNetwork._apply_transit_feature_change_frequencies(\n                    net, trip_ids, i\n                )\n\n            elif i[\"property\"] in [\"routing\"]:\n                net = TransitNetwork._apply_transit_feature_change_routing(\n                    net, trip_ids, i\n                )\n        return net\n\n    def _apply_transit_feature_change_routing(\n        self,\n        trip_ids: pd.Series,\n        properties: dict,\n    ) -&gt; TransitNetwork:\n\n        net = copy.deepcopy(self)\n        shapes = net.feed.shapes.copy()\n        stop_times = net.feed.stop_times.copy()\n        stops = net.feed.stops.copy()\n\n        # A negative sign in \"set\" indicates a traversed node without a stop\n        # If any positive numbers, stops have changed\n        stops_change = False\n        if any(x &gt; 0 for x in properties[\"set\"]):\n            # Simplify \"set\" and \"existing\" to only stops\n            properties[\"set_stops\"] = [str(i) for i in properties[\"set\"] if i &gt; 0]\n            if properties.get(\"existing\") is not None:\n                properties[\"existing_stops\"] = [\n                    str(i) for i in properties[\"existing\"] if i &gt; 0\n                ]\n            stops_change = True\n\n        # Convert ints to objects\n        properties[\"set_shapes\"] = [str(abs(i)) for i in properties[\"set\"]]\n        if properties.get(\"existing\") is not None:\n            properties[\"existing_shapes\"] = [\n                str(abs(i)) for i in properties[\"existing\"]\n            ]\n\n        # Replace shapes records\n        trips = net.feed.trips  # create pointer rather than a copy\n        shape_ids = trips[trips[\"trip_id\"].isin(trip_ids)].shape_id\n        for shape_id in shape_ids:\n            # Check if `shape_id` is used by trips that are not in\n            # parameter `trip_ids`\n            trips_using_shape_id = trips.loc[trips[\"shape_id\"] == shape_id, [\"trip_id\"]]\n            if not all(trips_using_shape_id.isin(trip_ids)[\"trip_id\"]):\n                # In this case, we need to create a new shape_id so as to leave\n                # the trips not part of the query alone\n                WranglerLogger.warning(\n                    \"Trips that were not in your query selection use the \"\n                    \"same `shape_id` as trips that are in your query. Only \"\n                    \"the trips' shape in your query will be changed.\"\n                )\n                old_shape_id = shape_id\n                shape_id = str(int(shape_id) + TransitNetwork.ID_SCALAR)\n                if shape_id in shapes[\"shape_id\"].tolist():\n                    WranglerLogger.error(\"Cannot create a unique new shape_id.\")\n                dup_shape = shapes[shapes.shape_id == old_shape_id].copy()\n                dup_shape[\"shape_id\"] = shape_id\n                shapes = pd.concat([shapes, dup_shape], ignore_index=True)\n\n            # Pop the rows that match shape_id\n            this_shape = shapes[shapes.shape_id == shape_id]\n\n            # Make sure they are ordered by shape_pt_sequence\n            this_shape = this_shape.sort_values(by=[\"shape_pt_sequence\"])\n\n            # Build a pd.DataFrame of new shape records\n            new_shape_rows = pd.DataFrame(\n                {\n                    \"shape_id\": shape_id,\n                    \"shape_pt_lat\": None,  # FIXME Populate from self.road_net?\n                    \"shape_pt_lon\": None,  # FIXME\n                    \"shape_osm_node_id\": None,  # FIXME\n                    \"shape_pt_sequence\": None,\n                    TransitNetwork.SHAPES_FOREIGN_KEY: properties[\"set_shapes\"],\n                }\n            )\n\n            # If \"existing\" is specified, replace only that segment\n            # Else, replace the whole thing\n            if properties.get(\"existing\") is not None:\n                # Match list\n                nodes = this_shape[TransitNetwork.SHAPES_FOREIGN_KEY].tolist()\n                index_replacement_starts = [\n                    i\n                    for i, d in enumerate(nodes)\n                    if d == properties[\"existing_shapes\"][0]\n                ][0]\n                index_replacement_ends = [\n                    i\n                    for i, d in enumerate(nodes)\n                    if d == properties[\"existing_shapes\"][-1]\n                ][-1]\n                this_shape = pd.concat(\n                    [\n                        this_shape.iloc[:index_replacement_starts],\n                        new_shape_rows,\n                        this_shape.iloc[index_replacement_ends + 1 :],\n                    ],\n                    ignore_index=True,\n                    sort=False,\n                )\n            else:\n                this_shape = new_shape_rows\n\n            # Renumber shape_pt_sequence\n            this_shape[\"shape_pt_sequence\"] = np.arange(len(this_shape))\n\n            # Add rows back into shapes\n            shapes = pd.concat(\n                [shapes[shapes.shape_id != shape_id], this_shape],\n                ignore_index=True,\n                sort=False,\n            )\n\n        # Replace stop_times and stops records (if required)\n        if stops_change:\n            # If node IDs in properties[\"set_stops\"] are not already\n            # in stops.txt, create a new stop_id for them in stops\n            existing_fk_ids = set(stops[TransitNetwork.STOPS_FOREIGN_KEY].tolist())\n            nodes_df = net.road_net.nodes_df.loc[\n                :, [TransitNetwork.STOPS_FOREIGN_KEY, \"X\", \"Y\"]\n            ]\n            for fk_i in properties[\"set_stops\"]:\n                if fk_i not in existing_fk_ids:\n                    WranglerLogger.info(\n                        \"Creating a new stop in stops.txt for node ID: {}\".format(fk_i)\n                    )\n                    # Add new row to stops\n                    new_stop_id = str(int(fk_i) + TransitNetwork.ID_SCALAR)\n                    if new_stop_id in stops[\"stop_id\"].tolist():\n                        WranglerLogger.error(\"Cannot create a unique new stop_id.\")\n                    stops.loc[\n                        len(stops.index) + 1,\n                        [\n                            \"stop_id\",\n                            \"stop_lat\",\n                            \"stop_lon\",\n                            TransitNetwork.STOPS_FOREIGN_KEY,\n                        ],\n                    ] = [\n                        new_stop_id,\n                        nodes_df.loc[\n                            nodes_df[TransitNetwork.STOPS_FOREIGN_KEY] == int(fk_i), \"Y\"\n                        ],\n                        nodes_df.loc[\n                            nodes_df[TransitNetwork.STOPS_FOREIGN_KEY] == int(fk_i), \"X\"\n                        ],\n                        fk_i,\n                    ]\n\n            # Loop through all the trip_ids\n            for trip_id in trip_ids:\n                # Pop the rows that match trip_id\n                this_stoptime = stop_times[stop_times.trip_id == trip_id]\n\n                # Merge on node IDs using stop_id (one node ID per stop_id)\n                this_stoptime = this_stoptime.merge(\n                    stops[[\"stop_id\", TransitNetwork.STOPS_FOREIGN_KEY]],\n                    how=\"left\",\n                    on=\"stop_id\",\n                )\n\n                # Make sure the stop_times are ordered by stop_sequence\n                this_stoptime = this_stoptime.sort_values(by=[\"stop_sequence\"])\n\n                # Build a pd.DataFrame of new shape records from properties\n                new_stoptime_rows = pd.DataFrame(\n                    {\n                        \"trip_id\": trip_id,\n                        \"arrival_time\": None,\n                        \"departure_time\": None,\n                        \"pickup_type\": None,\n                        \"drop_off_type\": None,\n                        \"stop_distance\": None,\n                        \"timepoint\": None,\n                        \"stop_is_skipped\": None,\n                        TransitNetwork.STOPS_FOREIGN_KEY: properties[\"set_stops\"],\n                    }\n                )\n\n                # Merge on stop_id using node IDs (many stop_id per node ID)\n                new_stoptime_rows = (\n                    new_stoptime_rows.merge(\n                        stops[[\"stop_id\", TransitNetwork.STOPS_FOREIGN_KEY]],\n                        how=\"left\",\n                        on=TransitNetwork.STOPS_FOREIGN_KEY,\n                    )\n                    .groupby([TransitNetwork.STOPS_FOREIGN_KEY])\n                    .head(1)\n                )  # pick first\n\n                # If \"existing\" is specified, replace only that segment\n                # Else, replace the whole thing\n                if properties.get(\"existing\") is not None:\n                    # Match list (remember stops are passed in with node IDs)\n                    nodes = this_stoptime[TransitNetwork.STOPS_FOREIGN_KEY].tolist()\n                    index_replacement_starts = nodes.index(\n                        properties[\"existing_stops\"][0]\n                    )\n                    index_replacement_ends = nodes.index(\n                        properties[\"existing_stops\"][-1]\n                    )\n                    this_stoptime = pd.concat(\n                        [\n                            this_stoptime.iloc[:index_replacement_starts],\n                            new_stoptime_rows,\n                            this_stoptime.iloc[index_replacement_ends + 1 :],\n                        ],\n                        ignore_index=True,\n                        sort=False,\n                    )\n                else:\n                    this_stoptime = new_stoptime_rows\n\n                # Remove node ID\n                del this_stoptime[TransitNetwork.STOPS_FOREIGN_KEY]\n\n                # Renumber stop_sequence\n                this_stoptime[\"stop_sequence\"] = np.arange(len(this_stoptime))\n\n                # Add rows back into stoptime\n                stop_times = pd.concat(\n                    [stop_times[stop_times.trip_id != trip_id], this_stoptime],\n                    ignore_index=True,\n                    sort=False,\n                )\n\n            net.feed.shapes = shapes\n            net.feed.stops = stops\n            net.feed.stop_times = stop_times\n        return net\n\n    def _apply_transit_feature_change_frequencies(\n        self, trip_ids: pd.Series, properties: dict\n    ) -&gt; TransitNetwork:\n\n        net = copy.deepcopy(self)\n        freq = net.feed.frequencies.copy()\n\n        # Grab only those records matching trip_ids (aka selection)\n        freq = freq[freq.trip_id.isin(trip_ids)]\n\n        # Check all `existing` properties if given\n        if properties.get(\"existing\") is not None:\n            if not all(freq.headway_secs == properties[\"existing\"]):\n                WranglerLogger.error(\n                    \"Existing does not match for at least \"\n                    \"1 trip in:\\n {}\".format(trip_ids.to_string())\n                )\n                raise ValueError\n\n        # Calculate build value\n        if properties.get(\"set\") is not None:\n            build_value = properties[\"set\"]\n        else:\n            build_value = [i + properties[\"change\"] for i in freq.headway_secs]\n\n        q = net.feed.frequencies.trip_id.isin(freq[\"trip_id\"])\n\n        net.feed.frequencies.loc[q, properties[\"property\"]] = build_value\n        return net\n\n    def apply_transit_managed_lane(\n        self,\n        trip_ids: pd.Series,\n        node_ids: list,\n    ) -&gt; TransitNetwork:\n\n        # Traversed nodes without a stop should be negative integers\n        net = copy.deepcopy(self)\n        all_stops = net.feed.stops[TransitNetwork.STOPS_FOREIGN_KEY].tolist()\n        node_ids = [int(x) if str(x) in all_stops else int(x) * -1 for x in node_ids]\n\n        TransitNetwork._apply_transit_feature_change_routing(\n            net,\n            trip_ids=trip_ids,\n            properties={\n                \"existing\": node_ids,\n                \"set\": RoadwayNetwork.get_managed_lane_node_ids(node_ids),\n            },\n        )\n        return net\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.__init__","title":"<code>__init__(feed=None, config=None)</code>","text":"<p>Constructor</p> <p>.. todo:: Make graph a reference to associated RoadwayNetwork\u2019s graph, not its own thing.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def __init__(self, feed: DotDict = None, config: nx.DiGraph = None):\n\"\"\"\n    Constructor\n\n    .. todo:: Make graph a reference to associated RoadwayNetwork's graph, not its own thing.\n    \"\"\"\n    self.feed: DotDict = feed\n    self.config: nx.DiGraph = config\n    self.road_net: RoadwayNetwork = None\n    self.graph: nx.MultiDiGraph = None\n    self.feed_path = None\n\n    self.validated_frequencies = False\n    self.validated_road_network_consistency = False\n\n    if not self.validate_frequencies():\n        raise ValueError(\n            \"Transit lines with non-positive frequencies exist in the network\"\n        )\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.apply","title":"<code>apply(project_card_dictionary)</code>","text":"<p>Wrapper method to apply a project to a transit network.</p> <p>Parameters:</p> Name Type Description Default <code>project_card_dictionary</code> <code>dict</code> <p>dict a dictionary of the project card object</p> required Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def apply(self, project_card_dictionary: dict):\n\"\"\"\n    Wrapper method to apply a project to a transit network.\n\n    Args:\n        project_card_dictionary: dict\n            a dictionary of the project card object\n\n    \"\"\"\n    WranglerLogger.info(\n        \"Applying Project to Transit Network: {}\".format(\n            project_card_dictionary[\"project\"]\n        )\n    )\n\n    def _apply_individual_change(project_dictionary: dict):\n        if (\n            project_dictionary[\"category\"].lower()\n            == \"transit service property change\"\n        ):\n            self.apply_transit_feature_change(\n                self.select_transit_features(project_dictionary[\"facility\"]),\n                project_dictionary[\"properties\"],\n            )\n        elif project_dictionary[\"category\"].lower() == \"parallel managed lanes\":\n            # Grab the list of nodes in the facility from road_net\n            # It should be cached because managed lane projects are\n            # processed by RoadwayNetwork first via\n            # Scenario.apply_all_projects\n            try:\n                managed_lane_nodes = self.road_net.selections(\n                    self.road_net.build_selection_key(\n                        project_dictionary[\"facility\"]\n                    )\n                )[\"route\"]\n            except ValueError:\n                WranglerLogger.error(\n                    \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n                )\n\n            # Reroute any transit using these nodes\n            self.apply_transit_managed_lane(\n                self.select_transit_features_by_nodes(managed_lane_nodes),\n                managed_lane_nodes,\n            )\n        elif project_dictionary[\"category\"].lower() == \"add transit\":\n            self.apply_python_calculation(project_dictionary[\"pycode\"])\n        elif project_dictionary[\"category\"].lower() == \"roadway deletion\":\n            WranglerLogger.warning(\n                \"Roadway Deletion not yet implemented in Transit; ignoring\"\n            )\n        else:\n            msg = \"{} not implemented yet in TransitNetwork; can't apply.\".format(\n                project_dictionary[\"category\"]\n            )\n            WranglerLogger.error(msg)\n            raise (msg)\n\n    if project_card_dictionary.get(\"changes\"):\n        for project_dictionary in project_card_dictionary[\"changes\"]:\n            _apply_individual_change(project_dictionary)\n    else:\n        _apply_individual_change(project_card_dictionary)\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.apply_python_calculation","title":"<code>apply_python_calculation(pycode)</code>","text":"<p>Changes roadway network object by executing pycode.</p> <p>Parameters:</p> Name Type Description Default <code>pycode</code> <code>str</code> <p>python code which changes values in the roadway network object</p> required Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def apply_python_calculation(self, pycode: str) -&gt; \"TransitNetwork\":\n\"\"\"\n    Changes roadway network object by executing pycode.\n\n    Args:\n        pycode: python code which changes values in the roadway network object\n    \"\"\"\n    net = copy.deepcopy(self)\n    exec(pycode)\n    return net\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.apply_transit_feature_change","title":"<code>apply_transit_feature_change(trip_ids, properties)</code>","text":"<p>Changes the transit attributes for the selected features based on the project card information passed</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <p>transit network to manipulate</p> required <code>trip_ids</code> <p>pd.Series all trip_ids to apply change to</p> required <code>properties</code> <p>list of dictionaries transit properties to change</p> required <p>Returns:</p> Type Description <code>TransitNetwork</code> <p>None</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def apply_transit_feature_change(\n    self,\n    trip_ids: pd.Series,\n    properties: list,\n) -&gt; \"TransitNetwork\":\n\"\"\"\n    Changes the transit attributes for the selected features based on the\n    project card information passed\n\n    Args:\n        net: transit network to manipulate\n        trip_ids : pd.Series\n            all trip_ids to apply change to\n        properties : list of dictionaries\n            transit properties to change\n\n    Returns:\n        None\n    \"\"\"\n    net = copy.deepcopy(self)\n\n    for i in properties:\n        if i[\"property\"] in [\"headway_secs\"]:\n            net = TransitNetwork._apply_transit_feature_change_frequencies(\n                net, trip_ids, i\n            )\n\n        elif i[\"property\"] in [\"routing\"]:\n            net = TransitNetwork._apply_transit_feature_change_routing(\n                net, trip_ids, i\n            )\n    return net\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.empty","title":"<code>empty()</code>  <code>staticmethod</code>","text":"<p>Create an empty transit network instance using the default config.</p> <p>.. todo:: fill out this method</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef empty() -&gt; TransitNetwork:\n\"\"\"\n    Create an empty transit network instance using the default config.\n\n    .. todo:: fill out this method\n    \"\"\"\n    # TODO\n\n    msg = \"TransitNetwork.empty is not implemented.\"\n    WranglerLogger.error(msg)\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.read","title":"<code>read(feed_path)</code>  <code>staticmethod</code>","text":"<p>Read GTFS feed from folder and TransitNetwork object</p> <p>Parameters:</p> Name Type Description Default <code>feed_path</code> <code>str</code> <p>where to read transit network files from</p> required Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef read(feed_path: str) -&gt; TransitNetwork:\n\"\"\"\n    Read GTFS feed from folder and TransitNetwork object\n\n    Args:\n        feed_path: where to read transit network files from\n\n    Returns: a TransitNetwork object.\n    \"\"\"\n    config = default_config()\n    feed = ptg.load_feed(feed_path, config=config)\n    WranglerLogger.info(\"Read in transit feed from: {}\".format(feed_path))\n\n    updated_config = TransitNetwork.validate_feed(feed, config)\n\n    # Read in each feed so we can write over them\n    editable_feed = DotDict()\n    for node in updated_config.nodes.keys():\n        # Load (initiate Partridge's lazy load)\n        editable_feed[node.replace(\".txt\", \"\")] = feed.get(node)\n\n    transit_network = TransitNetwork(feed=editable_feed, config=updated_config)\n    transit_network.feed_path = feed_path\n    return transit_network\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.route_ids_in_routestxt","title":"<code>route_ids_in_routestxt(feed)</code>  <code>staticmethod</code>","text":"<p>Wherever route_id occurs, make sure it is in routes.txt</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>DotDict</code> <p>partridge feed object</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if feed is okay.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef route_ids_in_routestxt(feed: DotDict) -&gt; bool:\n\"\"\"\n    Wherever route_id occurs, make sure it is in routes.txt\n\n    Args:\n        feed: partridge feed object\n\n    Returns:\n        Boolean indicating if feed is okay.\n    \"\"\"\n    route_ids_routestxt = set(feed.routes.route_id.tolist())\n    route_ids_referenced = set(feed.trips.route_id.tolist())\n\n    missing_routes = route_ids_referenced - route_ids_routestxt\n\n    if missing_routes:\n        WranglerLogger.warning(\n            \"The following route_ids are referenced but missing from routes.txt: {}\".format(\n                list(missing_routes)\n            )\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.select_transit_features","title":"<code>select_transit_features(selection)</code>","text":"<p>combines multiple selections</p> <p>Parameters:</p> Name Type Description Default <code>selection</code> <p>selection dictionary</p> required Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def select_transit_features(self, selection: dict) -&gt; pd.Series:\n\"\"\"\n    combines multiple selections\n\n    Args:\n        selection : selection dictionary\n\n    Returns: trip identifiers : list of GTFS trip IDs in the selection\n    \"\"\"\n    trip_ids = pd.Series()\n\n    if selection.get(\"route\"):\n        for route_dictionary in selection[\"route\"]:\n            trip_ids = trip_ids.append(\n                self._select_transit_features(route_dictionary)\n            )\n    else:\n        trip_ids = self._select_transit_features(selection)\n\n    return trip_ids\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.select_transit_features_by_nodes","title":"<code>select_transit_features_by_nodes(node_ids, require_all=False)</code>","text":"<p>Selects transit features that use any one of a list of node_ids</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>list</code> <p>list (generally coming from nx.shortest_path)</p> required <code>require_all</code> <p>bool if True, the returned trip_ids must traverse all of the nodes (default = False)</p> <code>False</code> <p>Returns:</p> Type Description <code>pd.Series</code> <p>trip identifiers  list of GTFS trip IDs in the selection</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def select_transit_features_by_nodes(\n    self, node_ids: list, require_all: bool = False\n) -&gt; pd.Series:\n\"\"\"\n    Selects transit features that use any one of a list of node_ids\n\n    Args:\n        node_ids: list (generally coming from nx.shortest_path)\n        require_all : bool if True, the returned trip_ids must traverse all of\n          the nodes (default = False)\n\n    Returns:\n        trip identifiers  list of GTFS trip IDs in the selection\n    \"\"\"\n    # If require_all, the returned trip_ids must traverse all of the nodes\n    # Else, filter any shapes that use any one of the nodes in node_ids\n    if require_all:\n        shape_ids = (\n            self.feed.shapes.groupby(\"shape_id\").filter(\n                lambda x: all(\n                    i in x[TransitNetwork.SHAPES_FOREIGN_KEY].tolist()\n                    for i in node_ids\n                )\n            )\n        ).shape_id.drop_duplicates()\n    else:\n        shape_ids = self.feed.shapes[\n            self.feed.shapes[TransitNetwork.SHAPES_FOREIGN_KEY].isin(node_ids)\n        ].shape_id.drop_duplicates()\n\n    # Return pandas.Series of trip_ids\n    return self.feed.trips[self.feed.trips.shape_id.isin(shape_ids)].trip_id\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.shape_ids_in_shapestxt","title":"<code>shape_ids_in_shapestxt(feed)</code>  <code>staticmethod</code>","text":"<p>Wherever shape_id occurs, make sure it is in shapes.txt</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>DotDict</code> <p>partridge feed object</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if feed is okay.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef shape_ids_in_shapestxt(feed: DotDict) -&gt; bool:\n\"\"\"\n    Wherever shape_id occurs, make sure it is in shapes.txt\n\n    Args:\n        feed: partridge feed object\n\n    Returns:\n        Boolean indicating if feed is okay.\n    \"\"\"\n\n    shape_ids_shapestxt = set(feed.shapes.shape_id.tolist())\n    shape_ids_referenced = set(feed.trips.shape_id.tolist())\n\n    missing_shapes = shape_ids_referenced - shape_ids_shapestxt\n\n    if missing_shapes:\n        WranglerLogger.warning(\n            \"The following shape_ids from trips.txt are missing from shapes.txt: {}\".format(\n                list(missing_shapes)\n            )\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.stop_ids_in_stopstxt","title":"<code>stop_ids_in_stopstxt(feed)</code>  <code>staticmethod</code>","text":"<p>Wherever stop_id occurs, make sure it is in stops.txt</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>DotDict</code> <p>partridge feed object</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if feed is okay.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef stop_ids_in_stopstxt(feed: DotDict) -&gt; bool:\n\"\"\"\n    Wherever stop_id occurs, make sure it is in stops.txt\n\n    Args:\n        feed: partridge feed object\n\n    Returns:\n        Boolean indicating if feed is okay.\n    \"\"\"\n    stop_ids_stopstxt = set(feed.stops.stop_id.tolist())\n    stop_ids_referenced = []\n\n    # STOP_TIMES\n    stop_ids_referenced.extend(feed.stop_times.stop_id.dropna().tolist())\n    stop_ids_referenced.extend(feed.stops.parent_station.dropna().tolist())\n\n    # TRANSFERS\n    if feed.get(\"transfers.txt\").shape[0] &gt; 0:\n        stop_ids_referenced.extend(feed.transfers.from_stop_id.dropna().tolist())\n        stop_ids_referenced.extend(feed.transfers.to_stop_id.dropna().tolist())\n\n    # PATHWAYS\n    if feed.get(\"pathways.txt\").shape[0] &gt; 0:\n        stop_ids_referenced.extend(feed.pathways.from_stop_id.dropna().tolist())\n        stop_ids_referenced.extend(feed.pathways.to_stop_id.dropna().tolist())\n\n    stop_ids_referenced = set(stop_ids_referenced)\n\n    missing_stops = stop_ids_referenced - stop_ids_stopstxt\n\n    if missing_stops:\n        WranglerLogger.warning(\n            \"The following stop_ids from are referenced but missing from stops.txt: {}\".format(\n                list(missing_stops)\n            )\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.transit_net_to_gdf","title":"<code>transit_net_to_gdf(transit)</code>  <code>staticmethod</code>","text":"<p>Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>transit</code> <code>Union(TransitNetwork, pd.DataFrame)</code> <p>either a TransitNetwork or a Shapes GeoDataFrame</p> required <p>.. todo:: Make more sophisticated.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef transit_net_to_gdf(transit: Union(\"TransitNetwork\", pd.DataFrame)):\n\"\"\"\n    Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame.\n\n    Args:\n        transit: either a TransitNetwork or a Shapes GeoDataFrame\n\n    .. todo:: Make more sophisticated.\n    \"\"\"\n    from partridge import geo\n\n    if type(transit) is pd.DataFrame:\n        shapes = transit\n    else:\n        shapes = transit.feed.shapes\n\n    transit_gdf = geo.build_shapes(shapes)\n    return transit_gdf\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.trip_ids_in_tripstxt","title":"<code>trip_ids_in_tripstxt(feed)</code>  <code>staticmethod</code>","text":"<p>Wherever trip_id occurs, make sure it is in trips.txt</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>DotDict</code> <p>partridge feed object</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if feed is okay.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef trip_ids_in_tripstxt(feed: DotDict) -&gt; bool:\n\"\"\"\n    Wherever trip_id occurs, make sure it is in trips.txt\n\n    Args:\n        feed: partridge feed object\n\n    Returns:\n        Boolean indicating if feed is okay.\n    \"\"\"\n    trip_ids_tripstxt = set(feed.trips.trip_id.tolist())\n    trip_ids_referenced = set(\n        feed.stop_times.trip_id.tolist() + feed.frequencies.trip_id.tolist()\n    )\n\n    missing_trips = trip_ids_referenced - trip_ids_tripstxt\n\n    if missing_trips:\n        WranglerLogger.warning(\n            \"The following trip_ids are referenced but missing from trips.txt: {}\".format(\n                list(missing_trips)\n            )\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_feed","title":"<code>validate_feed(feed, config)</code>  <code>staticmethod</code>","text":"<p>Since Partridge lazily loads the df, load each file to make sure it actually works.</p> <p>Partridge uses a DiGraph from the networkx library to represent the relationships between GTFS files. Each file is a \u2018node\u2019, and the relationship between files are \u2018edges\u2019.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>DotDict</code> <p>partridge feed</p> required <code>config</code> <code>nx.DiGraph</code> <p>partridge config</p> required Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef validate_feed(feed: DotDict, config: nx.DiGraph) -&gt; bool:\n\"\"\"\n    Since Partridge lazily loads the df, load each file to make sure it\n    actually works.\n\n    Partridge uses a DiGraph from the networkx library to represent the\n    relationships between GTFS files. Each file is a 'node', and the\n    relationship between files are 'edges'.\n\n    Args:\n        feed: partridge feed\n        config: partridge config\n    \"\"\"\n    updated_config = copy.deepcopy(config)\n    files_not_found = []\n    for node in config.nodes.keys():\n\n        n = feed.get(node)\n        WranglerLogger.debug(\"...{}:\\n{}\".format(node, n[:10]))\n        if n.shape[0] == 0:\n            WranglerLogger.info(\n                \"Removing {} from transit network config because file not found\".format(\n                    node\n                )\n            )\n            updated_config.remove_node(node)\n            if node in TransitNetwork.REQUIRED_FILES:\n                files_not_found.append(node)\n\n    if files_not_found:\n        msg = \"Required files not found or valid: {}\".format(\n            \",\".join(files_not_found)\n        )\n        WranglerLogger.error(msg)\n        raise AttributeError(msg)\n        return False\n\n    TransitNetwork.validate_network_keys(feed)\n\n    return updated_config\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_frequencies","title":"<code>validate_frequencies()</code>","text":"<p>Validates that there are no transit trips in the feed with zero frequencies.</p> <p>Changes state of self.validated_frequencies boolean based on outcome.</p> <p>Returns:</p> Type Description <code>bool</code> <p>boolean indicating if valid or not.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def validate_frequencies(self) -&gt; bool:\n\"\"\"\n    Validates that there are no transit trips in the feed with zero frequencies.\n\n    Changes state of self.validated_frequencies boolean based on outcome.\n\n    Returns:\n        boolean indicating if valid or not.\n    \"\"\"\n\n    _valid = True\n    zero_freq = self.feed.frequencies[self.feed.frequencies.headway_secs &lt;= 0]\n\n    if len(zero_freq.index) &gt; 0:\n        _valid = False\n        msg = \"Transit lines {} have non-positive frequencies\".format(\n            zero_freq.trip_id.to_list()\n        )\n        WranglerLogger.error(msg)\n\n    self.validated_frequencies = True\n\n    return _valid\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_network_keys","title":"<code>validate_network_keys(feed)</code>  <code>staticmethod</code>","text":"<p>Validates foreign keys are present in all connecting feed files.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>DotDict</code> <p>partridge feed object</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if feed is okay.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>@staticmethod\ndef validate_network_keys(feed: DotDict) -&gt; bool:\n\"\"\"\n    Validates foreign keys are present in all connecting feed files.\n\n    Args:\n        feed: partridge feed object\n\n    Returns:\n        Boolean indicating if feed is okay.\n    \"\"\"\n    result = True\n    result = result and TransitNetwork.route_ids_in_routestxt(feed)\n    result = result and TransitNetwork.trip_ids_in_tripstxt(feed)\n    result = result and TransitNetwork.shape_ids_in_shapestxt(feed)\n    result = result and TransitNetwork.stop_ids_in_stopstxt(feed)\n    return result\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_road_network_consistencies","title":"<code>validate_road_network_consistencies()</code>","text":"<p>Validates transit network against the road network for both stops and shapes.</p> <p>Returns:</p> Type Description <code>bool</code> <p>boolean indicating if valid or not.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def validate_road_network_consistencies(self) -&gt; bool:\n\"\"\"\n    Validates transit network against the road network for both stops\n    and shapes.\n\n    Returns:\n        boolean indicating if valid or not.\n    \"\"\"\n    if self.road_net is None:\n        raise ValueError(\n            \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n        )\n\n    valid = True\n\n    valid_stops = self.validate_transit_stops()\n    valid_shapes = self.validate_transit_shapes()\n\n    self.validated_road_network_consistency = True\n\n    if not valid_stops or not valid_shapes:\n        valid = False\n        raise ValueError(\"Transit network is not consistent with road network.\")\n\n    return valid\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_transit_shapes","title":"<code>validate_transit_shapes()</code>","text":"<p>Validates that all transit shapes are part of the roadway network.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if valid or not.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def validate_transit_shapes(self) -&gt; bool:\n\"\"\"\n    Validates that all transit shapes are part of the roadway network.\n\n    Returns:\n        Boolean indicating if valid or not.\n    \"\"\"\n\n    if self.road_net is None:\n        raise ValueError(\n            \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n        )\n\n    shapes_df = self.feed.shapes\n    nodes_df = self.road_net.nodes_df\n    links_df = self.road_net.links_df\n\n    valid = True\n\n    # check if all the node ids exist in the network\n    shape_ids = [\n        int(s) for s in shapes_df[TransitNetwork.SHAPES_FOREIGN_KEY].to_list()\n    ]\n    node_ids = [\n        int(n) for n in nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].to_list()\n    ]\n\n    if not set(shape_ids).issubset(node_ids):\n        valid = False\n        missing_shapes = list(set(shape_ids) - set(node_ids))\n        msg = \"Not all transit shapes are part of the roadyway network. \"\n        msg += \"Missing shapes ({}) from the roadway network are {}.\".format(\n            TransitNetwork.SHAPES_FOREIGN_KEY, missing_shapes\n        )\n        WranglerLogger.error(msg)\n        return valid\n\n    # check if all the links in transit shapes exist in the network\n    # and transit is allowed\n    shapes_df = shapes_df.astype({TransitNetwork.SHAPES_FOREIGN_KEY: int})\n    unique_shape_ids = shapes_df.shape_id.unique().tolist()\n\n    for id in unique_shape_ids:\n        subset_shapes_df = shapes_df[shapes_df[\"shape_id\"] == id]\n        subset_shapes_df = subset_shapes_df.sort_values(by=[\"shape_pt_sequence\"])\n        subset_shapes_df = subset_shapes_df.add_suffix(\"_1\").join(\n            subset_shapes_df.shift(-1).add_suffix(\"_2\")\n        )\n        subset_shapes_df = subset_shapes_df.dropna()\n\n        merged_df = subset_shapes_df.merge(\n            links_df,\n            how=\"left\",\n            left_on=[\n                TransitNetwork.SHAPES_FOREIGN_KEY + \"_1\",\n                TransitNetwork.SHAPES_FOREIGN_KEY + \"_2\",\n            ],\n            right_on=[\"A\", \"B\"],\n            indicator=True,\n        )\n\n        missing_links_df = merged_df.query('_merge == \"left_only\"')\n\n        # there are shape links which does not exist in the roadway network\n        if len(missing_links_df.index) &gt; 0:\n            valid = False\n            msg = f\"There are links for shape id {id} which are missing in the \\\n                roadway network.\"\n            WranglerLogger.error(msg)\n\n        transit_not_allowed_df = merged_df.query(\n            '_merge == \"both\" &amp; drive_access == 0 &amp; bus_only == 0 &amp; rail_only == 0'\n        )\n\n        # there are shape links where transit is not allowed\n        if len(transit_not_allowed_df.index) &gt; 0:\n            valid = False\n            msg = f\"There are links for shape id {id} which does not allow transit \\\n                in the roadway network.\"\n            WranglerLogger.error(msg)\n\n    return valid\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_transit_stops","title":"<code>validate_transit_stops()</code>","text":"<p>Validates that all transit stops are part of the roadway network.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if valid or not.</p> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def validate_transit_stops(self) -&gt; bool:\n\"\"\"\n    Validates that all transit stops are part of the roadway network.\n\n    Returns:\n        Boolean indicating if valid or not.\n    \"\"\"\n\n    if self.road_net is None:\n        raise ValueError(\n            \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\"\n        )\n\n    stops = self.feed.stops\n    nodes = self.road_net.nodes_df\n\n    valid = True\n\n    stop_ids = [int(s) for s in stops[TransitNetwork.STOPS_FOREIGN_KEY].to_list()]\n    node_ids = [\n        int(n) for n in nodes[RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK].to_list()\n    ]\n\n    if not set(stop_ids).issubset(node_ids):\n        valid = False\n        missing_stops = list(set(stop_ids) - set(node_ids))\n        msg = \"Not all transit stops are part of the roadyway network. \"\n        msg += \"Missing stops ({}) from the roadway nodes are {}.\".format(\n            TransitNetwork.STOPS_FOREIGN_KEY, missing_stops\n        )\n        WranglerLogger.error(msg)\n\n    return valid\n</code></pre>"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.write","title":"<code>write(path='.', filename=None)</code>","text":"<p>Writes a network in the transit network standard</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>the path were the output will be saved</p> <code>'.'</code> <code>filename</code> <code>str</code> <p>the name prefix of the transit files that will be generated</p> <code>None</code> Source code in <code>network_wrangler/transitnetwork.py</code> <pre><code>def write(self, path: str = \".\", filename: str = None) -&gt; None:\n\"\"\"\n    Writes a network in the transit network standard\n\n    Args:\n        path: the path were the output will be saved\n        filename: the name prefix of the transit files that will be generated\n    \"\"\"\n    WranglerLogger.info(\"Writing transit to directory: {}\".format(path))\n    for node in self.config.nodes.keys():\n\n        df = self.feed.get(node.replace(\".txt\", \"\"))\n        if not df.empty:\n            if filename:\n                outpath = os.path.join(path, filename + \"_\" + node)\n            else:\n                outpath = os.path.join(path, node)\n            WranglerLogger.debug(\"Writing file: {}\".format(outpath))\n\n            df.to_csv(outpath, index=False)\n</code></pre>"},{"location":"api/#utils-and-functions","title":"Utils and Functions","text":""},{"location":"api/#network_wrangler.utils","title":"<code>network_wrangler.utils</code>","text":""},{"location":"api/#network_wrangler.utils.create_unique_shape_id","title":"<code>create_unique_shape_id(line_string)</code>","text":"<p>Creates a unique hash id using the coordinates of the geometry using first and last locations.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def create_unique_shape_id(line_string: LineString):\n\"\"\"\n    Creates a unique hash id using the coordinates of the geometry using first and last locations.\n\n    Args:\n    line_string: Line Geometry as a LineString\n\n    Returns: string\n    \"\"\"\n\n    x1, y1 = list(line_string.coords)[0]  # first coordinate (A node)\n    x2, y2 = list(line_string.coords)[-1]  # last coordinate (B node)\n\n    message = \"Geometry {} {} {} {}\".format(x1, y1, x2, y2)\n    unhashed = message.encode(\"utf-8\")\n    hash = hashlib.md5(unhashed).hexdigest()\n\n    return hash\n</code></pre>"},{"location":"api/#network_wrangler.utils.haversine_distance","title":"<code>haversine_distance(origin, destination)</code>","text":"<p>Returns haversine distance between the coordinates of two points in lat/lon.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def haversine_distance(origin: list, destination: list) -&gt; float:\n\"\"\"\n    Returns haversine distance between the coordinates of two points in lat/lon.\n\n    Args:\n    origin: lat/lon for point A\n    destination: lat/lon for point B\n\n    Returns: string\n    \"\"\"\n\n    lon1, lat1 = origin\n    lon2, lat2 = destination\n    radius = 6378137  # meter\n\n    dlat = math.radians(lat2 - lat1)\n    dlon = math.radians(lon2 - lon1)\n    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(\n        math.radians(lat1)\n    ) * math.cos(math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    d = radius * c  # meters\n    d = d * 0.000621371  # miles\n\n    return d\n</code></pre>"},{"location":"api/#network_wrangler.utils.line_string_from_location_references","title":"<code>line_string_from_location_references(location_references)</code>","text":"<p>Creates a geometry as a LineString using a list of location references.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def line_string_from_location_references(location_references: list):\n\"\"\"\n    Creates a geometry as a LineString using a list of location references.\n    \"\"\"\n    # WranglerLogger.debug(\n    #    f\"line_string_from_location_references.location_references: {[lr['point'] for lr in location_references]}.\"\n    #    )\n    return LineString([lr[\"point\"] for lr in location_references])\n</code></pre>"},{"location":"api/#network_wrangler.utils.links_df_to_json","title":"<code>links_df_to_json(df, properties)</code>","text":"<p>Export pandas dataframe as a json object.</p> <p>Modified from: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>Dataframe to export</p> required <code>properties</code> <code>list</code> <p>list of properties to export</p> required Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def links_df_to_json(df: pd.DataFrame, properties: list):\n\"\"\"Export pandas dataframe as a json object.\n\n    Modified from: Geoff Boeing:\n    https://geoffboeing.com/2015/10/exporting-python-data-geojson/\n\n    Args:\n        df: Dataframe to export\n        properties: list of properties to export\n    \"\"\"\n\n    # can't remember why we need this?\n    if \"distance\" in properties:\n        df[\"distance\"].fillna(0)\n\n    json = []\n    for _, row in df.iterrows():\n        feature = {}\n        for prop in properties:\n            feature[prop] = row[prop]\n        json.append(feature)\n\n    return json\n</code></pre>"},{"location":"api/#network_wrangler.utils.location_reference_from_nodes","title":"<code>location_reference_from_nodes(node_list)</code>","text":"<p>Creates a location references using a list of nodes coordinates</p> <p>Parameters:</p> Name Type Description Default <code>node_list</code> <code>Collection[pd.Series]</code> <p>List of nodes represented as series or dicts with \u201cX\u201d and \u201cY\u201d values.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def location_reference_from_nodes(node_list: Collection[pd.Series]):\n\"\"\"\n    Creates a location references using a list of nodes coordinates\n\n    Args:\n        node_list: List of nodes represented as series or dicts with \"X\" and \"Y\" values.\n\n    \"\"\"\n\n    out_location_references = [\n        {\"sequence\": idx + 1, \"point\": [n[\"X\"], n[\"Y\"]]}\n        for idx, n in enumerate(node_list)\n    ]\n\n    # WranglerLogger.debug(f\"out_location_references: {out_location_references}\")\n\n    return out_location_references\n</code></pre>"},{"location":"api/#network_wrangler.utils.make_slug","title":"<code>make_slug(text, delimiter='_')</code>","text":"<p>makes a slug from text</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def make_slug(text, delimiter: str = \"_\"):\n\"\"\"\n    makes a slug from text\n    \"\"\"\n    import re\n\n    text = re.sub(\"[,.;@#?!&amp;$']+\", \"\", text.lower())\n    return re.sub(\"[\\ ]+\", delimiter, text)\n</code></pre>"},{"location":"api/#network_wrangler.utils.offset_location_reference","title":"<code>offset_location_reference(location_reference, offset_meters=10)</code>","text":"<p>Creates a new location reference line using the first and last nodes of given polyline location reference, offseting it by 90 degree to the bearing of given location reference and distance equals to offset_meters</p> <p>Parameters:</p> Name Type Description Default <code>location_reference</code> <p>existing location reference</p> required <code>offset_meters</code> <code>float</code> <p>(Optional) meters to offset the existing</p> <code>10</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def offset_location_reference(location_reference, offset_meters: float = 10):\n\"\"\"\n    Creates a new location reference line\n    using the first and last nodes of given polyline location reference,\n    offseting it by 90 degree to the bearing of given location reference\n    and distance equals to offset_meters\n\n    args:\n        location_reference: existing location reference\n        offset_meters: (Optional) meters to offset the existing\n\n    returns: new location_reference with offset\n    \"\"\"\n    lon_1 = location_reference[0][\"point\"][0]\n    lat_1 = location_reference[0][\"point\"][1]\n    lon_2 = location_reference[-1][\"point\"][0]\n    lat_2 = location_reference[-1][\"point\"][1]\n\n    bearing = get_bearing(lat_1, lon_1, lat_2, lon_2)\n    # adding 90 degrees (1.57 radians) to the current bearing\n    bearing = bearing + 1.57\n\n    out_location_reference = [\n        {\n            \"sequence\": idx + 1,\n            \"point\": offset_point_with_distance_and_bearing(\n                lr[\"point\"][0], lr[\"point\"][1], offset_meters, bearing\n            ),\n        }\n        for idx, lr in enumerate(location_reference)\n    ]\n\n    return out_location_reference\n</code></pre>"},{"location":"api/#network_wrangler.utils.parse_time_spans_to_secs","title":"<code>parse_time_spans_to_secs(times)</code>","text":"<p>parse time spans into tuples of seconds from midnight can also be used as an apply function for a pandas series Parameters</p> <p>times: tuple(string) or tuple(int) or list(string) or list(int)</p>"},{"location":"api/#network_wrangler.utils.parse_time_spans_to_secs--returns","title":"returns","text":"<p>tuple(integer)   time span as seconds from midnight</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def parse_time_spans_to_secs(times):\n\"\"\"\n    parse time spans into tuples of seconds from midnight\n    can also be used as an apply function for a pandas series\n    Parameters\n    -----------\n    times: tuple(string) or tuple(int) or list(string) or list(int)\n\n    returns\n    --------\n    tuple(integer)\n      time span as seconds from midnight\n    \"\"\"\n    try:\n        start_time, end_time = times\n    except:\n        msg = \"ERROR: times should be a tuple or list of two, got: {}\".format(times)\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n\n    # If times are strings, convert to int in seconds, else return as ints\n    if isinstance(start_time, str) and isinstance(end_time, str):\n        start_time = start_time.strip()\n        end_time = end_time.strip()\n\n        # If time is given without seconds, add 00\n        if len(start_time) &lt;= 5:\n            start_time += \":00\"\n        if len(end_time) &lt;= 5:\n            end_time += \":00\"\n\n        # Convert times to seconds from midnight (Partride's time storage)\n        h0, m0, s0 = start_time.split(\":\")\n        start_time_sec = int(h0) * 3600 + int(m0) * 60 + int(s0)\n\n        h1, m1, s1 = end_time.split(\":\")\n        end_time_sec = int(h1) * 3600 + int(m1) * 60 + int(s1)\n\n        return (start_time_sec, end_time_sec)\n\n    elif isinstance(start_time, int) and isinstance(end_time, int):\n        return times\n\n    else:\n        WranglerLogger.error(\"ERROR: times should be ints or strings\")\n        raise ValueError()\n\n    return (start_time_sec, end_time_sec)\n</code></pre>"},{"location":"api/#network_wrangler.utils.point_df_to_geojson","title":"<code>point_df_to_geojson(df, properties)</code>","text":"Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def point_df_to_geojson(df: pd.DataFrame, properties: list):\n\"\"\"\n    Author: Geoff Boeing:\n    https://geoffboeing.com/2015/10/exporting-python-data-geojson/\n    \"\"\"\n    from ..roadwaynetwork import RoadwayNetwork\n\n    geojson = {\"type\": \"FeatureCollection\", \"features\": []}\n    for _, row in df.iterrows():\n        feature = {\n            \"type\": \"Feature\",\n            \"properties\": {},\n            \"geometry\": {\"type\": \"Point\", \"coordinates\": []},\n        }\n        feature[\"geometry\"][\"coordinates\"] = [row[\"geometry\"].x, row[\"geometry\"].y]\n        feature[\"properties\"][RoadwayNetwork.NODE_FOREIGN_KEY_TO_LINK] = row.name\n        for prop in properties:\n            feature[\"properties\"][prop] = row[prop]\n        geojson[\"features\"].append(feature)\n    return geojson\n</code></pre>"},{"location":"api/#network_wrangler.utils.point_from_xy","title":"<code>point_from_xy(x, y, xy_crs=4326, point_crs=4326)</code>","text":"<p>Creates a point geometry from x and y coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>x coordinate, in xy_crs</p> required <code>y</code> <p>y coordinate, in xy_crs</p> required <code>xy_crs</code> <code>int</code> <p>coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)</p> <code>4326</code> <code>point_crs</code> <code>int</code> <p>coordinate reference system in ESPG code for point output. Defaults to 4326 (WGS84)</p> <code>4326</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def point_from_xy(x, y, xy_crs: int = 4326, point_crs: int = 4326):\n\"\"\"\n    Creates a point geometry from x and y coordinates.\n\n    Args:\n        x: x coordinate, in xy_crs\n        y: y coordinate, in xy_crs\n        xy_crs: coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)\n        point_crs: coordinate reference system in ESPG code for point output. Defaults to 4326 (WGS84)\n\n    Returns: Shapely Point in point_crs\n    \"\"\"\n\n    point = Point(x, y)\n\n    if xy_crs == point_crs:\n        return point\n\n    if (xy_crs, point_crs) not in transformers:\n        # store transformers in dictionary because they are an \"expensive\" operation\n        transformers[(xy_crs, point_crs)] = Transformer.from_proj(\n            Proj(init=\"epsg:\" + str(xy_crs)),\n            Proj(init=\"epsg:\" + str(point_crs)),\n            always_xy=True,  # required b/c Proj v6+ uses lon/lat instead of x/y\n        )\n\n    return transform(transformers[(xy_crs, point_crs)].transform, point)\n</code></pre>"},{"location":"api/#network_wrangler.utils.topological_sort","title":"<code>topological_sort(adjacency_list, visited_list)</code>","text":"<p>Topological sorting for Acyclic Directed Graph</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def topological_sort(adjacency_list, visited_list):\n\"\"\"\n    Topological sorting for Acyclic Directed Graph\n    \"\"\"\n\n    output_stack = []\n\n    def _topology_sort_util(vertex):\n        if not visited_list[vertex]:\n            visited_list[vertex] = True\n            for neighbor in adjacency_list[vertex]:\n                _topology_sort_util(neighbor)\n            output_stack.insert(0, vertex)\n\n    for vertex in visited_list:\n        _topology_sort_util(vertex)\n\n    return output_stack\n</code></pre>"},{"location":"api/#network_wrangler.utils.update_points_in_linestring","title":"<code>update_points_in_linestring(linestring, updated_coords, position)</code>","text":"<p>Replaces</p> <p>Parameters:</p> Name Type Description Default <code>linestring</code> <code>LineString</code> <p>description</p> required <code>point_coords</code> <code>List[float]</code> <p>description</p> required <code>position</code> <code>int</code> <p>description</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_points_in_linestring(\n    linestring: LineString, updated_coords: List[float], position: int\n):\n\"\"\"Replaces\n\n    Args:\n        linestring (LineString): _description_\n        point_coords (List[float]): _description_\n        position (int): _description_\n    \"\"\"\n    coords = [c for c in linestring.coords]\n    coords[position] = updated_coords\n    return LineString(coords)\n</code></pre>"},{"location":"api/#network_wrangler.logger","title":"<code>network_wrangler.logger</code>","text":""},{"location":"api/#network_wrangler.logger.setup_logging","title":"<code>setup_logging(info_log_filename=None, debug_log_filename='wrangler_{}.debug.log'.format(datetime.now().strftime('%Y_%m_%d__%H_%M_%S')), log_to_console=False)</code>","text":"<p>Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.</p> <p>Parameters:</p> Name Type Description Default <code>info_log_filename</code> <code>str</code> <p>the location of the log file that will get created to add the INFO log. The INFO Log is terse, just gives the bare minimum of details. Defaults to file in cwd() <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> <code>None</code> <code>debug_log_filename</code> <code>str</code> <p>the location of the log file that will get created to add the DEBUG log. The DEBUG log is very noisy, for debugging. Defaults to file in cwd()  <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> <code>'wrangler_{}.debug.log'.format(datetime.now().strftime('%Y_%m_%d__%H_%M_%S'))</code> <code>log_to_console</code> <code>bool</code> <p>if True, logging will go to the console at DEBUG level. Defaults to False.</p> <code>False</code> Source code in <code>network_wrangler/logger.py</code> <pre><code>def setup_logging(\n    info_log_filename: str = None, \n    debug_log_filename: str = \"wrangler_{}.debug.log\".format(datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")),\n    log_to_console: bool = False\n):\n\"\"\"\n    Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.\n\n    args:\n        info_log_filename: the location of the log file that will get created to add the INFO log.\n            The INFO Log is terse, just gives the bare minimum of details.\n            Defaults to file in cwd() `wrangler_[datetime].log`. To turn off logging to a file,\n            use log_filename = None.\n        debug_log_filename: the location of the log file that will get created to add the DEBUG log.\n            The DEBUG log is very noisy, for debugging. Defaults to file in cwd() \n            `wrangler_[datetime].log`. To turn off logging to a file, use log_filename = None.\n        log_to_console: if True, logging will go to the console at DEBUG level. Defaults to False.\n    \"\"\"\n\n    #add function variable so that we know if logging has been called\n    setup_logging.called = True\n\n    # Clear handles if any exist already\n    WranglerLogger.handlers = []\n\n    WranglerLogger.setLevel(logging.DEBUG)\n\n    FORMAT = logging.Formatter(\n        \"%(asctime)-15s %(levelname)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S,\"\n    )\n    if not info_log_filename:\n        info_log_filename = os.path.join(\n                os.getcwd(),\n                \"network_wrangler_{}.info.log\".format(datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")),\n                )\n\n    info_file_handler = logging.StreamHandler(open(info_log_filename,'w'))\n    info_file_handler.setLevel(logging.INFO)\n    info_file_handler.setFormatter(FORMAT)\n    WranglerLogger.addHandler(info_file_handler)\n\n    # create debug file only when debug_log_filename is provided\n    if debug_log_filename:\n        debug_log_handler = logging.StreamHandler(open(debug_log_filename, \"w\"))\n        debug_log_handler.setLevel(logging.DEBUG)\n        debug_log_handler.setFormatter(FORMAT)\n        WranglerLogger.addHandler(debug_log_handler)\n\n    if log_to_console:\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setLevel(logging.DEBUG)\n        console_handler.setFormatter(FORMAT)\n        WranglerLogger.addHandler(console_handler)\n</code></pre>"},{"location":"api/#schemas","title":"Schemas","text":""},{"location":"design/","title":"Design","text":""},{"location":"design/#atomic-parts","title":"Atomic Parts","text":"<p>NetworkWrangler deals with four primary atomic parts:</p> <p>1. <code>Scenario</code> objects describe a Roadway Network, Transit Network, and collection of Projects. Scenarios manage the addition and construction of projects on the network via projct cards. Scenarios can be based on or tiered from other scenarios.</p> <p>2. <code>RoadwayNetwork</code> objects stores information about roadway nodes, directed links between nodes, and the shapes of links (note that the same shape can be shared between two or more links). Network Wrangler reads/writes roadway network objects from/to three files: <code>links.json</code>, <code>shapes.geojson</code>, and <code>nodes.geojson</code>. Their data is stored as GeoDataFrames in the object.</p> <p>3. <code>TransitNetwork</code> objects contain information about stops, routes, trips, shapes, stoptimes, and frequencies. Network Wrangler reads/writes transit network information from/to gtfs csv files and stores them as DataFrames within a <code>Partridge</code> <code>feed</code> object.  Transit networks can be associated with Roadway networks.</p> <p>4.<code>ProjectCard</code> objects store infromation (including  metadata) about changes to the network.  Network Wtanglr reads project cards from .yml files validates them, and manages them within a <code>Scenario</code> object.</p>"},{"location":"development/","title":"Development","text":""},{"location":"development/#contributing-to-network-wrangler","title":"Contributing to Network Wrangler","text":""},{"location":"development/#roles","title":"Roles","text":""},{"location":"development/#how-to-contribute","title":"How to Contribute","text":""},{"location":"development/#setup","title":"Setup","text":"<ol> <li>Make sure you have a GitHub account.  </li> <li>Make sure you have git, a terminal (e.g. Mac Terminal, CygWin, etc.), and a text editor installed on your local machine.  Optionally, you will likely find it easier to use GitHub Desktop, an IDE instead of a simple text editor like VSCode, Eclipse, Sublime Text, etc.  </li> <li>Fork the repository into your own GitHub account and clone it locally.  </li> <li>Install your <code>network_wrangler</code> clone in development mode: <code>pip install . -e</code></li> <li>Install documentation requirements: <code>pip install -r requirements.docs.txt</code></li> <li>Install development requirements: <code>pip install -r requirements.tests.txt</code></li> <li>[Optional] Install act to run github actions locally.  </li> </ol>"},{"location":"development/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create an issue for any features/bugs that you are working on.</li> <li>Create a branch to work on a new issue (or checkout an existing one where the issue is being worked on).  </li> <li>Develop comprehensive tests in the <code>/tests</code> folder.</li> <li>Modify code including inline documentation such that it passes all  tests (not just your new ones)</li> <li>Lint code using <code>pre-commit run --all-files</code></li> <li>Fill out information in the pull request template</li> <li>Submit all pull requests to the <code>develop</code> branch.</li> <li>Core developer will review your pull request and suggest changes.</li> <li>After requested changes are complete, core developer will sign off on pull-request merge.</li> </ol> <p>!tip: Keep pull requests small and focused. One issue is best.</p> <p>!tip: Don\u2019t forget to update any associated #documentation as well!</p>"},{"location":"development/#documentation","title":"Documentation","text":"<p>Documentation is produced by mkdocs:</p> <ul> <li><code>mkdocs build</code>: builds documentation</li> <li><code>mkdocs serve</code>: builds and serves documentation to review locally in browswer</li> </ul> <p>Documentation is built and deployed using the <code>mike</code> package and Github Actions configured in <code>.github/workflows/</code> for each \u201cref\u201d (i.e. branch) in the network_wrangler repository.</p>"},{"location":"development/#testing-and-continuous-integration","title":"Testing and Continuous Integration","text":"<p>Tests and test data reside in the <code>/tests</code> directory:</p> <ul> <li><code>pytest</code>: runs all tests</li> </ul> <p>Continuous Integration is managed by Github Actions in <code>.github/workflows</code>. All tests other than those with the decorator <code>@pytest.mark.skipci</code> will be run.</p>"},{"location":"development/#project-governance","title":"Project Governance","text":"<p>The project is currently governed by representatives of its two major organizational contributors:</p> <ul> <li>Metropolitan Council (MN)</li> <li>Metropolitan Transportation Commission (California)</li> </ul>"},{"location":"development/#code-of-conduct","title":"Code of Conduct","text":"<p>Contributors to the Network Wrangler Project are expected to read and follow the CODE_OF_CONDUCT for the project.</p>"},{"location":"development/#contributors","title":"Contributors","text":"<ol> <li>Lisa Zorn - initial Network Wrangler implementation at SFCTA</li> <li>Billy Charlton</li> <li>Elizabeh Sall</li> <li>Sijia Wang</li> <li>David Ory</li> <li>Ashish K.</li> </ol> <p>!Note: There are likely more contributors - feel free to add your name if we missed it!</p>"}]}