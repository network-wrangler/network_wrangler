{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"network_wrangler \u00b6 Network Wrangler is a Python library for managing travel model network scenarios. System Requirements \u00b6 Network Wrangler should be operating system agonistic and has been tested on Ubuntu and Mac OS. In order to assist in installation, its helpful to have either miniconda , anaconda or Docker CE installed. If you don\u2019t have any of these already, we reommend starting with Miniconda for Python 3.7 as it has the smallest footprint. conda is the environment manager that is contained within both the Anaconda and mini-conda applications. All commands described below should be entered into the Ananconda Prompt command window. Network Wrangler does require Python 3.7+. If you have a different version of Python installed, conda will take care of installing it for you in the installation instructions below. Installation \u00b6 Network Wrangler uses Python 3.6 and above. Requirements are stored in requirements.txt but are automatically installed when using pip . If you are managing multiple python versions, we suggest using virtualenv or conda virtual environments. conda is the environment manager that is contained within both the Anaconda and mini-conda applications. Do not add Anaconda to the system path during installation. This may cause problems with other programs that require python 2.7 to be placed in the system path. Example installing and running tests using conda in the command line: conda config --add channels conda-forge conda create python = 3 .7 rtree geopandas osmnx -n <my_wrangler_environment> conda activate <my_wrangler_environment> pip install network-wrangler pytest -s -m travis Network wrangler can be installed in several ways depending on the user\u2019s needs. Installing from github is the simplest method and is appropriate when the user does not anticipate needing to update network wrangler. An update will require rebuilding the network wrangler environment. Installing from clone is slightly more involved and requires the user to have a git manager on their machine, but permits the user to install network wrangler with the -e , edit, option so that their network wrangler installation can be updated through pulling new commits from the network wrangler repo without a full reinstallation. From GitHub \u00b6 Use the package manager pip to install Network Wrangler from the source on GitHub. conda config --add channels conda-forge conda create python = 3 .7 rtree geopandas osmnx -n <my_wrangler_environment> conda activate <my_wrangler_environment> pip install git+https://github.com/wsp-sag/network_wrangler.git@master#egg = network_wrangler Note: if you wanted to install from a specific tag/version number or branch, replace @master with @<branchname> or @tag From Clone \u00b6 If you are going to be working on Network Wrangler locally, you might want to clone it to your local machine and install it from the clone. The -e will install it in editable mode . This is also useful if you want to continue to update your Network Wrangler as it is developed on GitHub. 1. Open a terminal to get a command prompt. 2. Consider using a virtual environment manager like conda. Create a new environment by typing the following commands into the command prompt (it might take a few minutes). conda create python = 3 .7 -n wrangler_env conda activate wrangler_env I chose wrangler_env as the name of my environment, but you could choose something else\u2026just remember it so that you can access it later. NOTE in order to get back to \u201cthis\u201d conda environment (i.e. after you close this command prompt), you will need to access it from the command line by using the following command: conda activate wrangler_env 3. Install finicky Requirements Some requirements are best installed using conda rather than \u201cpip\u201d conda config --add channels conda-forge conda install rtree geopandas osmnx 4. \u201cClone\u201d (aka download) network wrangler from Github on to your machine If you have GitHub desktop installed, you can either do this by using the GitHub user interface by clicking on the green button \u201cclone or download\u201d in the main network wrangler repository page . Otherwise, you can use the command prompt to navigate to the directory that you would like to store your network wrangler clone and then using a git command to clone it. cd path to where you want to put wrangler git clone https://github.com/wsp-sag/network_wrangler Expected output: cloning into network_wrangler... remote: Enumerating objects: 53 , done . remote: Counting objects: 100 % ( 53 /53 ) , done . remote: Compressing objects: 100 % ( 34 /34 ) , done . remote: Total 307 ( delta 28 ) , reused 29 ( delta 19 ) , pack-reused 254 Receiving objects: 100 % ( 307 /307 ) , 15 .94 MiB | 10 .49 MiB/s, done . Resolving deltas: 100 % ( 140 /140 ) , done . 5. Install Network Wrangler in \u201cdevelop\u201d mode. Navigate your command prompt into the network wrangler folder and then install network wrangler in editable mode. This will take a few minutes because it is also installing all the prerequisites. cd network_wrangler pip install -e . There will be a lot of messy output, but it should end with something like: Running setup.py develop for network-wrangler Successfully installed Rtree-0.8.3 attrs-19.1.0 cchardet-2.1.4 chardet-3.0.4 click-7.0 click-plugins-1.1.1 cligj-0.5.0 cycler-0.10.0 decorator-4.4.0 descartes-1.1.0 fiona-1.8.6 geojson-2.4.1 geopandas-0.5.1 idna-2.8 isoweek-1.3.3 jsonschema-3.0.2 kiwisolver-1.1.0 matplotlib-3.1.1 munch-2.3.2 network-wrangler networkx-2.3 numpy-1.17.0 osmnx-0.10 pandas-0.25.0 partridge-1.1.0 pyparsing-2.4.2 pyproj-2.2.1 pyrsistent-0.15.4 python-dateutil-2.8.0 pytz-2019.2 pyyaml-5.1.2 requests-2.22.0 shapely-1.6.4.post2 six-1.12.0 urllib3-1.25.3 6. Test the Installation You can test that network wrangler was properly installed by running the tests as follows: pytest -s -m travis Using the -s flag will run all the tests in \u201cnoisy\u201d mode. The -m travis flag runs only tests that are marked as for \u201ctravis\u201d continuous integration Note: if you are not part of the project team and want to contribute code back to the project, please fork before you clone and then add the original repository to your upstream origin list per these directions on github . Using Docker \u00b6 Install Docker Clone git repository (see instructions above) NOTE: this is easiest way right now since repo is private. When it is public we can clone right from github without having to muck around with logins or keys From the cloned repository, open a terminal from the /docker folder and build and run the docker container corresponding to what you want to do by running docker-compose run <container name> <entry point (optional)> --build Command to exit container: exit Containers: - wrangler-jupyter started by running docker-compose run wrangler-jupyter --build is appropriate for running and testing wrangler. - Default action is to start jupyter notebook which can be found at http://127.0.0.1:8888 - Safe: It creates an empty folder to store jupyter notebooks within the container but wont overwrite the source files on your actual machine. - Starting Bash: You can also start the container with a command line using docker-compose run wrangler-jupyter /bin/bash --build . - Doesn\u2019t install development dependencies (although they can be installed from within the container) - wrangler-ci is a small image without extras meant for running tests and deploying to continuous integration server. - default command is to run pytest . - contains development dependencies so that it can run tests and build docs. - wrangler-dev is the most powerful but dangerous container docker-compose run wrangler-dev /bin/bash --build - Warning: It will synchronize code edited from the container to your wrangler clone. This is great for developing within an IDE, but please take this into account. Common Installation Issues \u00b6 Issue: clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated] If you are using MacOS, you might need to update your xcode command line tools and headers Issue: OSError: Could not find libspatialindex_c library file * Try installing rtree on its own from the Anaconda cloud conda install rtree Issue: Shapely, a pre-requisite, doesn\u2019t install propertly because it is missing GEOS module Try installing shapely on its own from the Anaconda cloud conda install shapely Issue: Conda is unable to install a library or to update to a specific library version Try installing libraries from conda-forge conda install -c conda-forge *library* Issue: User does not have permission to install in directories Try running Anaconda Prompt as an administrator. Quickstart \u00b6 To get a feel for the API and using project cards, please refer to the \u201cWrangler Quickstart\u201d jupyter notebook. To start the notebook, open a command line in the network_wrangler top-level directory and type: jupyter notebook Documentation \u00b6 Documentation can be built from the /docs folder using the command: make html Usage \u00b6 import network_wrangler ##todo this is just an example for now ## Network Manipulation my_network = network_wrangler . read_roadway_network ( ... ) # returns my_network . apply_project_card ( ... ) # returns my_network . write_roadway_network ( ... ) # returns ## Scenario Building my_scenario = scenario_from_network ( roadway_network , transit_network ) my_scenario . add_projects ( directory , keyword ) my_scenario . write_networks ( directory , format ) Attribution \u00b6 This project is built upon the ideas and concepts implemented in the network wrangler project by the San Francisco County Transportation Authority and expanded upon by the Metropolitan Transportation Commission . While Network Wrangler as written here is based on these concepts, the code is distinct and builds upon other packages such as geopandas and partridge which hadn\u2019t been implemented when networkwrangler 1.0 was developed. Contributing \u00b6 Pull requests are welcome. Please open an issue first to discuss what you would like to change. Please make sure to update tests as appropriate. License \u00b6 Apache-2.0","title":"Home"},{"location":"#network_wrangler","text":"Network Wrangler is a Python library for managing travel model network scenarios.","title":"network_wrangler"},{"location":"#system-requirements","text":"Network Wrangler should be operating system agonistic and has been tested on Ubuntu and Mac OS. In order to assist in installation, its helpful to have either miniconda , anaconda or Docker CE installed. If you don\u2019t have any of these already, we reommend starting with Miniconda for Python 3.7 as it has the smallest footprint. conda is the environment manager that is contained within both the Anaconda and mini-conda applications. All commands described below should be entered into the Ananconda Prompt command window. Network Wrangler does require Python 3.7+. If you have a different version of Python installed, conda will take care of installing it for you in the installation instructions below.","title":"System Requirements"},{"location":"#installation","text":"Network Wrangler uses Python 3.6 and above. Requirements are stored in requirements.txt but are automatically installed when using pip . If you are managing multiple python versions, we suggest using virtualenv or conda virtual environments. conda is the environment manager that is contained within both the Anaconda and mini-conda applications. Do not add Anaconda to the system path during installation. This may cause problems with other programs that require python 2.7 to be placed in the system path. Example installing and running tests using conda in the command line: conda config --add channels conda-forge conda create python = 3 .7 rtree geopandas osmnx -n <my_wrangler_environment> conda activate <my_wrangler_environment> pip install network-wrangler pytest -s -m travis Network wrangler can be installed in several ways depending on the user\u2019s needs. Installing from github is the simplest method and is appropriate when the user does not anticipate needing to update network wrangler. An update will require rebuilding the network wrangler environment. Installing from clone is slightly more involved and requires the user to have a git manager on their machine, but permits the user to install network wrangler with the -e , edit, option so that their network wrangler installation can be updated through pulling new commits from the network wrangler repo without a full reinstallation.","title":"Installation"},{"location":"#from-github","text":"Use the package manager pip to install Network Wrangler from the source on GitHub. conda config --add channels conda-forge conda create python = 3 .7 rtree geopandas osmnx -n <my_wrangler_environment> conda activate <my_wrangler_environment> pip install git+https://github.com/wsp-sag/network_wrangler.git@master#egg = network_wrangler Note: if you wanted to install from a specific tag/version number or branch, replace @master with @<branchname> or @tag","title":"From GitHub"},{"location":"#from-clone","text":"If you are going to be working on Network Wrangler locally, you might want to clone it to your local machine and install it from the clone. The -e will install it in editable mode . This is also useful if you want to continue to update your Network Wrangler as it is developed on GitHub. 1. Open a terminal to get a command prompt. 2. Consider using a virtual environment manager like conda. Create a new environment by typing the following commands into the command prompt (it might take a few minutes). conda create python = 3 .7 -n wrangler_env conda activate wrangler_env I chose wrangler_env as the name of my environment, but you could choose something else\u2026just remember it so that you can access it later. NOTE in order to get back to \u201cthis\u201d conda environment (i.e. after you close this command prompt), you will need to access it from the command line by using the following command: conda activate wrangler_env 3. Install finicky Requirements Some requirements are best installed using conda rather than \u201cpip\u201d conda config --add channels conda-forge conda install rtree geopandas osmnx 4. \u201cClone\u201d (aka download) network wrangler from Github on to your machine If you have GitHub desktop installed, you can either do this by using the GitHub user interface by clicking on the green button \u201cclone or download\u201d in the main network wrangler repository page . Otherwise, you can use the command prompt to navigate to the directory that you would like to store your network wrangler clone and then using a git command to clone it. cd path to where you want to put wrangler git clone https://github.com/wsp-sag/network_wrangler Expected output: cloning into network_wrangler... remote: Enumerating objects: 53 , done . remote: Counting objects: 100 % ( 53 /53 ) , done . remote: Compressing objects: 100 % ( 34 /34 ) , done . remote: Total 307 ( delta 28 ) , reused 29 ( delta 19 ) , pack-reused 254 Receiving objects: 100 % ( 307 /307 ) , 15 .94 MiB | 10 .49 MiB/s, done . Resolving deltas: 100 % ( 140 /140 ) , done . 5. Install Network Wrangler in \u201cdevelop\u201d mode. Navigate your command prompt into the network wrangler folder and then install network wrangler in editable mode. This will take a few minutes because it is also installing all the prerequisites. cd network_wrangler pip install -e . There will be a lot of messy output, but it should end with something like: Running setup.py develop for network-wrangler Successfully installed Rtree-0.8.3 attrs-19.1.0 cchardet-2.1.4 chardet-3.0.4 click-7.0 click-plugins-1.1.1 cligj-0.5.0 cycler-0.10.0 decorator-4.4.0 descartes-1.1.0 fiona-1.8.6 geojson-2.4.1 geopandas-0.5.1 idna-2.8 isoweek-1.3.3 jsonschema-3.0.2 kiwisolver-1.1.0 matplotlib-3.1.1 munch-2.3.2 network-wrangler networkx-2.3 numpy-1.17.0 osmnx-0.10 pandas-0.25.0 partridge-1.1.0 pyparsing-2.4.2 pyproj-2.2.1 pyrsistent-0.15.4 python-dateutil-2.8.0 pytz-2019.2 pyyaml-5.1.2 requests-2.22.0 shapely-1.6.4.post2 six-1.12.0 urllib3-1.25.3 6. Test the Installation You can test that network wrangler was properly installed by running the tests as follows: pytest -s -m travis Using the -s flag will run all the tests in \u201cnoisy\u201d mode. The -m travis flag runs only tests that are marked as for \u201ctravis\u201d continuous integration Note: if you are not part of the project team and want to contribute code back to the project, please fork before you clone and then add the original repository to your upstream origin list per these directions on github .","title":"From Clone"},{"location":"#using-docker","text":"Install Docker Clone git repository (see instructions above) NOTE: this is easiest way right now since repo is private. When it is public we can clone right from github without having to muck around with logins or keys From the cloned repository, open a terminal from the /docker folder and build and run the docker container corresponding to what you want to do by running docker-compose run <container name> <entry point (optional)> --build Command to exit container: exit Containers: - wrangler-jupyter started by running docker-compose run wrangler-jupyter --build is appropriate for running and testing wrangler. - Default action is to start jupyter notebook which can be found at http://127.0.0.1:8888 - Safe: It creates an empty folder to store jupyter notebooks within the container but wont overwrite the source files on your actual machine. - Starting Bash: You can also start the container with a command line using docker-compose run wrangler-jupyter /bin/bash --build . - Doesn\u2019t install development dependencies (although they can be installed from within the container) - wrangler-ci is a small image without extras meant for running tests and deploying to continuous integration server. - default command is to run pytest . - contains development dependencies so that it can run tests and build docs. - wrangler-dev is the most powerful but dangerous container docker-compose run wrangler-dev /bin/bash --build - Warning: It will synchronize code edited from the container to your wrangler clone. This is great for developing within an IDE, but please take this into account.","title":"Using Docker"},{"location":"#common-installation-issues","text":"Issue: clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated] If you are using MacOS, you might need to update your xcode command line tools and headers Issue: OSError: Could not find libspatialindex_c library file * Try installing rtree on its own from the Anaconda cloud conda install rtree Issue: Shapely, a pre-requisite, doesn\u2019t install propertly because it is missing GEOS module Try installing shapely on its own from the Anaconda cloud conda install shapely Issue: Conda is unable to install a library or to update to a specific library version Try installing libraries from conda-forge conda install -c conda-forge *library* Issue: User does not have permission to install in directories Try running Anaconda Prompt as an administrator.","title":"Common Installation Issues"},{"location":"#quickstart","text":"To get a feel for the API and using project cards, please refer to the \u201cWrangler Quickstart\u201d jupyter notebook. To start the notebook, open a command line in the network_wrangler top-level directory and type: jupyter notebook","title":"Quickstart"},{"location":"#documentation","text":"Documentation can be built from the /docs folder using the command: make html","title":"Documentation"},{"location":"#usage","text":"import network_wrangler ##todo this is just an example for now ## Network Manipulation my_network = network_wrangler . read_roadway_network ( ... ) # returns my_network . apply_project_card ( ... ) # returns my_network . write_roadway_network ( ... ) # returns ## Scenario Building my_scenario = scenario_from_network ( roadway_network , transit_network ) my_scenario . add_projects ( directory , keyword ) my_scenario . write_networks ( directory , format )","title":"Usage"},{"location":"#attribution","text":"This project is built upon the ideas and concepts implemented in the network wrangler project by the San Francisco County Transportation Authority and expanded upon by the Metropolitan Transportation Commission . While Network Wrangler as written here is based on these concepts, the code is distinct and builds upon other packages such as geopandas and partridge which hadn\u2019t been implemented when networkwrangler 1.0 was developed.","title":"Attribution"},{"location":"#contributing","text":"Pull requests are welcome. Please open an issue first to discuss what you would like to change. Please make sure to update tests as appropriate.","title":"Contributing"},{"location":"#license","text":"Apache-2.0","title":"License"},{"location":"api/","text":"API Documentation \u00b6 Base Classes \u00b6 network_wrangler.ProjectCard \u00b6 Bases: object Representation of a Project Card Attributes: Name Type Description __dict__ Dictionary of project card attributes valid Boolean indicating if data conforms to project card data schema Source code in network_wrangler/projectcard.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 class ProjectCard ( object ): \"\"\" Representation of a Project Card Attributes: __dict__: Dictionary of project card attributes valid: Boolean indicating if data conforms to project card data schema \"\"\" TRANSIT_CATEGORIES = [ \"Transit Service Property Change\" ] # categories that may affect transit, but only as a secondary # effect of changing roadways SECONDARY_TRANSIT_CATEGORIES = [ \"Roadway Deletion\" , \"Parallel Managed Lanes\" ] ROADWAY_CATEGORIES = [ \"Roadway Property Change\" , \"Roadway Deletion\" , \"Parallel Managed lanes\" , \"Add New Roadway\" , \"Calculated Roadway\" , ] UNSPECIFIED_PROJECT_NAMES = [ \"\" , \"TO DO User Define\" , \"USER TO define\" ] def __init__ ( self , attribute_dictonary : dict ): \"\"\" Constructor args: attribute_dictonary: a nested dictionary of attributes \"\"\" # add these first so they are first on write out self . project = None self . tags = \"\" self . dependencies = \"\" self . __dict__ . update ( attribute_dictonary ) self . valid = False # todo more unstructuring of project card yaml def __str__ ( self ): s = [ \" {} : {} \" . format ( key , value ) for key , value in self . __dict__ . items ()] return \" \\n \" . join ( s ) @staticmethod def read ( path_to_card : str , validate : bool = True ): \"\"\" Reads and validates a Project card args: path_to_card: the path to the project card Returns a Project Card object \"\"\" card_suffix = path_to_card . split ( \".\" )[ - 1 ] . lower () if card_suffix in [ \"yaml\" , 'yml' ]: attribute_dictionary = ProjectCard . read_yml ( path_to_card ) elif card_suffix in [ \"wrangler\" , 'wr' ]: attribute_dictionary = ProjectCard . read_wrangler_card ( path_to_card ) else : msg = \"Card should have a suffix of yaml, yml, wrangler, or wr. Found suffix: {} \" . format ( card_suffix ) raise ValueError ( msg ) card = ProjectCard ( attribute_dictionary ) if card . project in ProjectCard . UNSPECIFIED_PROJECT_NAMES : msg = \"Card must have valid project name: {} \" . format ( path_to_card ) WranglerLogger . error ( msg ) raise ValueError ( msg ) card . valid = False if validate : card . valid = ProjectCard . validate_project_card_schema ( path_to_card ) return card @staticmethod def read_wrangler_card ( path_to_card : str ) -> dict : \"\"\" Reads wrangler project cards with YAML front matter and then python code. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading Wrangler-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : delim = cardfile . readline () WranglerLogger . debug ( \"Using delimiter: {} \" . format ( delim )) _yaml , _pycode = cardfile . read () . split ( delim ) WranglerLogger . debug ( \"_yaml: {} \\n _pycode: {} \" . format ( _yaml , _pycode )) attribute_dictionary = yaml . load ( _yaml ) attribute_dictionary [ \"file\" ] = path_to_card attribute_dictionary [ \"pycode\" ] = _pycode . lstrip ( \" \\n \" ) return attribute_dictionary @staticmethod def read_yml ( path_to_card : str ) -> dict : \"\"\" Reads \"normal\" wrangler project cards defined in YAML. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading YAML-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : attribute_dictionary = yaml . safe_load ( cardfile ) attribute_dictionary [ \"file\" ] = path_to_card return attribute_dictionary def write ( self , filename : str = None ): \"\"\" Writes project card dictionary to YAML file \"\"\" if not filename : from network_wrangler.utils import make_slug filename = make_slug ( self . project ) + \".yml\" # import collections # out_dict = collections.OrderedDict() out_dict = {} out_dict [ \"project\" ] = None out_dict [ \"tags\" ] = \"\" out_dict [ \"dependencies\" ] = \"\" out_dict . update ( self . __dict__ ) with open ( filename , \"w\" ) as outfile : yaml . dump ( out_dict , outfile , default_flow_style = False , sort_keys = False ) WranglerLogger . info ( \"Wrote project card to: {} \" . format ( filename )) @staticmethod def validate_project_card_schema ( card_file , card_schema_file : str = \"project_card.json\" ) -> bool : \"\"\" Tests project card schema validity by evaluating if it conforms to the schemas returns: boolean \"\"\" if not os . path . exists ( card_schema_file ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) card_schema_file = os . path . join ( base_path , card_schema_file ) with open ( card_schema_file ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( card_file , \"r\" ) as card : card_json = yaml . safe_load ( card ) try : validate ( card_json , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Project Card validation: Validation Error\" ) WranglerLogger . error ( \"Project Card File Loc: {} \" . format ( card_file )) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Failed Project Card schema validation: Schema Error\" ) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except yaml . YAMLError as exc : WranglerLogger . error ( exc . message ) @staticmethod def build_link_selection_query ( selection : dict , unique_model_link_identifiers : [], mode : List [ str ] = [ \"drive_access\" ], ignore = [], ): sel_query = \"(\" count = 0 selection_keys = [ k for l in selection [ \"link\" ] for k , v in l . items ()] num_unique_model_link_identifiers = len ( set ( unique_model_link_identifiers ) . intersection ( selection_keys ) ) unique_model_link_identifer_exist = num_unique_model_link_identifiers > 0 for l in selection [ \"link\" ]: for key , value in l . items (): if key in ignore : continue if ( unique_model_link_identifer_exist and key not in unique_model_link_identifiers ): continue count = count + 1 if isinstance ( value , list ): sel_query = sel_query + \"(\" v = 1 for i in value : # building an OR query with each element in list if isinstance ( i , str ): sel_query = sel_query + key + '.str.contains(\"' + i + '\")' else : sel_query = sel_query + key + \"==\" + str ( i ) if v != len ( value ): sel_query = sel_query + \" or \" v = v + 1 sel_query = sel_query + \")\" else : sel_query = sel_query + key + \"==\" + '\"' + str ( value ) + '\"' if not unique_model_link_identifer_exist and count != ( len ( selection [ \"link\" ]) - len ( ignore ) ): sel_query = sel_query + \" and \" if ( unique_model_link_identifer_exist and count != num_unique_model_link_identifiers ): sel_query = sel_query + \" and \" if not unique_model_link_identifer_exist : if count > 0 : sel_query = sel_query + \" and \" # add mode query mode_sel = \"(\" + \" or \" . join ( m + \"==1\" for m in mode ) + \")\" sel_query = sel_query + mode_sel sel_query = sel_query + \")\" return sel_query def roadway_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Roadway Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def new_roadway ( self , card : dict ): \"\"\" Probably delete. Reads a New Roadway card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def transit_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Transit Service Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def new_transit_right_of_way ( self , card : dict ): \"\"\" Probably delete. Reads a New Transit Dedicated Right of Way card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def parallel_managed_lanes ( self , card : dict ): \"\"\" Probably delete. Reads a Parallel Managed lanes card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) __init__ ( attribute_dictonary ) \u00b6 Constructor Source code in network_wrangler/projectcard.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , attribute_dictonary : dict ): \"\"\" Constructor args: attribute_dictonary: a nested dictionary of attributes \"\"\" # add these first so they are first on write out self . project = None self . tags = \"\" self . dependencies = \"\" self . __dict__ . update ( attribute_dictonary ) self . valid = False new_roadway ( card ) \u00b6 Probably delete. Reads a New Roadway card. Source code in network_wrangler/projectcard.py 275 276 277 278 279 280 281 282 283 def new_roadway ( self , card : dict ): \"\"\" Probably delete. Reads a New Roadway card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) new_transit_right_of_way ( card ) \u00b6 Probably delete. Reads a New Transit Dedicated Right of Way card. Source code in network_wrangler/projectcard.py 295 296 297 298 299 300 301 302 303 def new_transit_right_of_way ( self , card : dict ): \"\"\" Probably delete. Reads a New Transit Dedicated Right of Way card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) parallel_managed_lanes ( card ) \u00b6 Probably delete. Reads a Parallel Managed lanes card. Source code in network_wrangler/projectcard.py 305 306 307 308 309 310 311 312 313 def parallel_managed_lanes ( self , card : dict ): \"\"\" Probably delete. Reads a Parallel Managed lanes card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) read ( path_to_card , validate = True ) staticmethod \u00b6 Reads and validates a Project card Returns a Project Card object Source code in network_wrangler/projectcard.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @staticmethod def read ( path_to_card : str , validate : bool = True ): \"\"\" Reads and validates a Project card args: path_to_card: the path to the project card Returns a Project Card object \"\"\" card_suffix = path_to_card . split ( \".\" )[ - 1 ] . lower () if card_suffix in [ \"yaml\" , 'yml' ]: attribute_dictionary = ProjectCard . read_yml ( path_to_card ) elif card_suffix in [ \"wrangler\" , 'wr' ]: attribute_dictionary = ProjectCard . read_wrangler_card ( path_to_card ) else : msg = \"Card should have a suffix of yaml, yml, wrangler, or wr. Found suffix: {} \" . format ( card_suffix ) raise ValueError ( msg ) card = ProjectCard ( attribute_dictionary ) if card . project in ProjectCard . UNSPECIFIED_PROJECT_NAMES : msg = \"Card must have valid project name: {} \" . format ( path_to_card ) WranglerLogger . error ( msg ) raise ValueError ( msg ) card . valid = False if validate : card . valid = ProjectCard . validate_project_card_schema ( path_to_card ) return card read_wrangler_card ( path_to_card ) staticmethod \u00b6 Reads wrangler project cards with YAML front matter and then python code. Parameters: Name Type Description Default path_to_card str where the project card is required Source code in network_wrangler/projectcard.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 @staticmethod def read_wrangler_card ( path_to_card : str ) -> dict : \"\"\" Reads wrangler project cards with YAML front matter and then python code. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading Wrangler-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : delim = cardfile . readline () WranglerLogger . debug ( \"Using delimiter: {} \" . format ( delim )) _yaml , _pycode = cardfile . read () . split ( delim ) WranglerLogger . debug ( \"_yaml: {} \\n _pycode: {} \" . format ( _yaml , _pycode )) attribute_dictionary = yaml . load ( _yaml ) attribute_dictionary [ \"file\" ] = path_to_card attribute_dictionary [ \"pycode\" ] = _pycode . lstrip ( \" \\n \" ) return attribute_dictionary read_yml ( path_to_card ) staticmethod \u00b6 Reads \u201cnormal\u201d wrangler project cards defined in YAML. Parameters: Name Type Description Default path_to_card str where the project card is required Source code in network_wrangler/projectcard.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 @staticmethod def read_yml ( path_to_card : str ) -> dict : \"\"\" Reads \"normal\" wrangler project cards defined in YAML. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading YAML-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : attribute_dictionary = yaml . safe_load ( cardfile ) attribute_dictionary [ \"file\" ] = path_to_card return attribute_dictionary roadway_attribute_change ( card ) \u00b6 Probably delete. Reads a Roadway Attribute Change card. Source code in network_wrangler/projectcard.py 265 266 267 268 269 270 271 272 273 def roadway_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Roadway Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) transit_attribute_change ( card ) \u00b6 Probably delete. Reads a Transit Service Attribute Change card. Source code in network_wrangler/projectcard.py 285 286 287 288 289 290 291 292 293 def transit_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Transit Service Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) validate_project_card_schema ( card_file , card_schema_file = 'project_card.json' ) staticmethod \u00b6 Tests project card schema validity by evaluating if it conforms to the schemas Source code in network_wrangler/projectcard.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 @staticmethod def validate_project_card_schema ( card_file , card_schema_file : str = \"project_card.json\" ) -> bool : \"\"\" Tests project card schema validity by evaluating if it conforms to the schemas returns: boolean \"\"\" if not os . path . exists ( card_schema_file ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) card_schema_file = os . path . join ( base_path , card_schema_file ) with open ( card_schema_file ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( card_file , \"r\" ) as card : card_json = yaml . safe_load ( card ) try : validate ( card_json , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Project Card validation: Validation Error\" ) WranglerLogger . error ( \"Project Card File Loc: {} \" . format ( card_file )) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Failed Project Card schema validation: Schema Error\" ) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except yaml . YAMLError as exc : WranglerLogger . error ( exc . message ) write ( filename = None ) \u00b6 Writes project card dictionary to YAML file Source code in network_wrangler/projectcard.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def write ( self , filename : str = None ): \"\"\" Writes project card dictionary to YAML file \"\"\" if not filename : from network_wrangler.utils import make_slug filename = make_slug ( self . project ) + \".yml\" # import collections # out_dict = collections.OrderedDict() out_dict = {} out_dict [ \"project\" ] = None out_dict [ \"tags\" ] = \"\" out_dict [ \"dependencies\" ] = \"\" out_dict . update ( self . __dict__ ) with open ( filename , \"w\" ) as outfile : yaml . dump ( out_dict , outfile , default_flow_style = False , sort_keys = False ) WranglerLogger . info ( \"Wrote project card to: {} \" . format ( filename )) network_wrangler.Scenario \u00b6 Bases: object Holds information about a scenario. .. highlight:: python Typical usage example: :: my_base_scenario = { \u201croad_net\u201d: RoadwayNetwork.read( link_file=STPAUL_LINK_FILE, node_file=STPAUL_NODE_FILE, shape_file=STPAUL_SHAPE_FILE, fast=True, ), \u201ctransit_net\u201d: TransitNetwork.read(STPAUL_DIR), } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 card_filenames = [ \"3_multiple_roadway_attribute_change.yml\" , \"multiple_changes.yml\" , \"4_simple_managed_lane.yml\" , ] project_card_directory = os . path . join ( STPAUL_DIR , \"project_cards\" ) project_cards_list = [ ProjectCard . read ( os . path . join ( project_card_directory , filename ) , validate = False ) for filename in card_filenames ] my_scenario = Scenario . create_scenario ( base_scenario = my_base_scenario , project_cards_list = project_cards_list , ) my_scenario . check_scenario_requisites () my_scenario . apply_all_projects () my_scenario . scenario_summary () Attributes: Name Type Description base_scenario dictionary representation of a scenario project_cards Optional list of Project Card Instances road_net instance of RoadwayNetwork for the scenario transit_net instance of TransitNetwork for the scenario applied_projects list of project names that have been applied project_cards list of project card instances ordered_project_cards prerequisites dictionary storing prerequiste information corequisites dictionary storing corequisite information conflicts dictionary storing conflict information requisites_checked boolean indicating if the co- and pre-requisites have been checked in the project cards conflicts_checked boolean indicating if the project conflicts have been checked has_requisite_error boolean indicating if there is a conflict in the pre- or co-requisites of project cards has_conflict_error boolean indicating if there is are conflicting project cards prerequisites_sorted boolean indicating if the project cards have been sorted to make sure cards that are pre-requisites are applied first Source code in network_wrangler/scenario.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 class Scenario ( object ): \"\"\" Holds information about a scenario. .. highlight:: python Typical usage example: :: my_base_scenario = { \"road_net\": RoadwayNetwork.read( link_file=STPAUL_LINK_FILE, node_file=STPAUL_NODE_FILE, shape_file=STPAUL_SHAPE_FILE, fast=True, ), \"transit_net\": TransitNetwork.read(STPAUL_DIR), } card_filenames = [ \"3_multiple_roadway_attribute_change.yml\", \"multiple_changes.yml\", \"4_simple_managed_lane.yml\", ] project_card_directory = os.path.join(STPAUL_DIR, \"project_cards\") project_cards_list = [ ProjectCard.read(os.path.join(project_card_directory, filename), validate=False) for filename in card_filenames ] my_scenario = Scenario.create_scenario( base_scenario=my_base_scenario, project_cards_list=project_cards_list, ) my_scenario.check_scenario_requisites() my_scenario.apply_all_projects() my_scenario.scenario_summary() Attributes: base_scenario: dictionary representation of a scenario project_cards (Optional): list of Project Card Instances road_net: instance of RoadwayNetwork for the scenario transit_net: instance of TransitNetwork for the scenario applied_projects: list of project names that have been applied project_cards: list of project card instances ordered_project_cards: prerequisites: dictionary storing prerequiste information corequisites: dictionary storing corequisite information conflicts: dictionary storing conflict information requisites_checked: boolean indicating if the co- and pre-requisites have been checked in the project cards conflicts_checked: boolean indicating if the project conflicts have been checked has_requisite_error: boolean indicating if there is a conflict in the pre- or co-requisites of project cards has_conflict_error: boolean indicating if there is are conflicting project cards prerequisites_sorted: boolean indicating if the project cards have been sorted to make sure cards that are pre-requisites are applied first \"\"\" def __init__ ( self , base_scenario : dict , project_cards : [ ProjectCard ] = None ): \"\"\" Constructor args: base_scenario: dict the base scenario project_cards: list this scenario's project cards \"\"\" self . road_net = None self . transit_net = None self . base_scenario = base_scenario # if the base scenario had roadway or transit networks, use them as the basis. if self . base_scenario . get ( \"road_net\" ): self . road_net = copy . deepcopy ( self . base_scenario [ \"road_net\" ]) if self . base_scenario . get ( \"transit_net\" ): self . transit_net = copy . deepcopy ( self . base_scenario [ \"transit_net\" ]) # if the base scenario had applied projects, add them to the list of applied self . applied_projects = [] if self . base_scenario . get ( \"applied_projects\" ): self . applied_projects = base_scenario [ \"applied_projects\" ] self . project_cards = project_cards self . ordered_project_cards = OrderedDict () self . prerequisites = {} self . corequisites = {} self . conflicts = {} self . requisites_checked = False self . conflicts_checked = False self . has_requisite_error = False self . has_conflict_error = False self . prerequisites_sorted = False for card in self . project_cards : if not card . __dict__ . get ( \"dependencies\" ): continue if card . dependencies . get ( \"prerequisites\" ): self . prerequisites . update ( { card . project : card . dependencies [ \"prerequisites\" ]} ) if card . dependencies . get ( \"corequisites\" ): self . corequisites . update ( { card . project : card . dependencies [ \"corequisites\" ]} ) @staticmethod def create_base_scenario ( base_shape_name : str , base_link_name : str , base_node_name : str , roadway_dir : str = \"\" , transit_dir : str = \"\" , validate : bool = True , ) -> Scenario : \"\"\" args ----- roadway_dir: optional path to the base scenario roadway network files base_shape_name: filename of the base network shape base_link_name: filename of the base network link base_node_name: filename of the base network node transit_dir: optional path to base scenario transit files validate: boolean indicating whether to validate the base network or not \"\"\" if roadway_dir : base_network_shape_file = os . path . join ( roadway_dir , base_shape_name ) base_network_link_file = os . path . join ( roadway_dir , base_link_name ) base_network_node_file = os . path . join ( roadway_dir , base_node_name ) else : base_network_shape_file = base_shape_name base_network_link_file = base_link_name base_network_node_file = base_node_name road_net = RoadwayNetwork . read ( link_file = base_network_link_file , node_file = base_network_node_file , shape_file = base_network_shape_file , fast = not validate , ) if transit_dir : transit_net = TransitNetwork . read ( transit_dir ) else : transit_net = None WranglerLogger . info ( \"No transit directory specified, base scenario will have empty transit network.\" ) transit_net . set_roadnet ( road_net , validate_consistency = validate ) base_scenario = { \"road_net\" : road_net , \"transit_net\" : transit_net } return base_scenario @staticmethod def create_scenario ( base_scenario : dict = {}, card_directory : str = \"\" , tags : [ str ] = None , project_cards_list = [], glob_search = \"\" , validate_project_cards = True , ) -> Scenario : \"\"\" Validates project cards with a specific tag from the specified folder or list of user specified project cards and creates a scenario object with the valid project card. args ----- base_scenario: object dictionary for the base scenario (i.e. my_base_scenario.__dict__) tags: only project cards with these tags will be read/validated folder: the folder location where the project cards will be project_cards_list: list of project cards to be applied glob_search: \"\"\" WranglerLogger . info ( \"Creating Scenario\" ) if project_cards_list : WranglerLogger . debug ( \"Adding project cards from List. \\n {} \" . format ( \",\" . join ([ p . project for p in project_cards_list ]) ) ) scenario = Scenario ( base_scenario , project_cards = project_cards_list ) if card_directory and tags : WranglerLogger . debug ( \"Adding project cards from directory and tags. \\n Dir: {} \\n Tags: {} \" . format ( card_directory , \",\" . join ( tags ) ) ) scenario . add_project_cards_from_tags ( card_directory , tags = tags , glob_search = glob_search , validate = validate_project_cards , ) elif card_directory : WranglerLogger . debug ( \"Adding project cards from directory. \\n Dir: {} \" . format ( card_directory ) ) scenario . add_project_cards_from_directory ( card_directory , glob_search = glob_search , validate = validate_project_cards ) return scenario def add_project_card_from_file ( self , project_card_file : str , validate : bool = True , tags : list = [] ): WranglerLogger . debug ( \"Trying to add project card from file: {} \" . format ( project_card_file ) ) project_card = ProjectCard . read ( project_card_file , validate = validate ) if project_card == None : msg = \"project card not read: {} \" . format ( project_card_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if tags and set ( tags ) . isdisjoint ( project_card . tags ): WranglerLogger . debug ( \"Project card tags: {} don't match search tags: {} \" . format ( \",\" . join ( project_card . tags ), \",\" . join ( tags ) ) ) return if project_card . project in self . get_project_names (): msg = \"project card with name ' {} ' already in Scenario. Project names must be unique\" . format ( project_card . project ) WranglerLogger . error ( msg ) raise ValueError ( msg ) self . requisites_checked = False self . conflicts_checked = False self . prerequisites_sorted = False WranglerLogger . debug ( \"Adding project card to scenario: {} \" . format ( project_card . project ) ) self . project_cards . append ( project_card ) if not project_card . __dict__ . get ( \"dependencies\" ): return WranglerLogger . debug ( \"Adding project card dependencies\" ) if project_card . dependencies . get ( \"prerequisites\" ): self . prerequisites . update ( { project_card . project : project_card . dependencies [ \"prerequisites\" ]} ) if project_card . dependencies . get ( \"corequisites\" ): self . corequisites . update ( { project_card . project : project_card . dependencies [ \"corequisites\" ]} ) if project_card . dependencies . get ( \"conflicts\" ): self . conflicts . update ( { project_card . project : project_card . dependencies [ \"conflicts\" ]} ) def add_project_cards_from_directory ( self , folder : str , glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards and if applicable, a glob-style search. i.e. glob_search = 'road*.yml' args: folder: the folder location where the project cards will be glob_search: https://docs.python.org/2/library/glob.html \"\"\" if not os . path . exists ( folder ): msg = \"Cannot find specified directory to add project cards: {} \" . format ( folder ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if glob_search : WranglerLogger . debug ( \"Adding project cards using glob search: {} \" . format ( glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( file , validate = validate ) else : for file in os . listdir ( folder ): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( os . path . join ( folder , file ), validate = validate ) def add_project_cards_from_tags ( self , folder : str , tags : [ str ] = [], glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards that have a matching tag that is passed to the method. args: folder: the folder location where the project cards will be tags: only project cards with these tags will be validated and added to the returning scenario \"\"\" if glob_search : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} and \\n glob search: {} \" . format ( tags , glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): self . add_project_card_from_file ( file , tags = tags , validate = validate ) else : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} \" . format ( tags )) for file in os . listdir ( folder ): self . add_project_card_from_file ( file , tags = tags , validate = validate ) def __str__ ( self ): s = [ \" {} : {} \" . format ( key , value ) for key , value in self . __dict__ . items ()] return \" \\n \" . join ( s ) def get_project_names ( self ) -> list : \"\"\" Returns a list of project names \"\"\" return [ project_card . project for project_card in self . project_cards ] def check_scenario_conflicts ( self ) -> bool : \"\"\" Checks if there are any conflicting projects in the scenario Fail if the project A specifies that project B is a conflict and project B is included in the scenario Returns: boolean indicating if the check was successful or returned an error \"\"\" conflict_dict = self . conflicts scenario_projects = [ p . project for p in self . project_cards ] for project , conflicts in conflict_dict . items (): if conflicts : for name in conflicts : if name in scenario_projects : self . project_cards WranglerLogger . error ( \"Projects %s has %s as conflicting project\" % ( project , name ) ) self . has_conflict_error = True self . conflicts_checked = True return self . has_conflict_error def check_scenario_requisites ( self ) -> bool : \"\"\" Checks if there are any missing pre- or co-requisite projects in the scenario Fail if the project A specifies that project B is a pre- or co-requisite and project B is not included in the scenario Returns: boolean indicating if the checks were successful or returned an error \"\"\" corequisite_dict = self . corequisites prerequisite_dict = self . prerequisites scenario_projects = [ p . project for p in self . project_cards ] for project , coreq in corequisite_dict . items (): if coreq : for name in coreq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as corequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True for project , prereq in prerequisite_dict . items (): if prereq : for name in prereq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as prerequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True self . requisites_checked = True return self . has_requisite_error def order_project_cards ( self ): \"\"\" create a list of project cards such that they are in order based on pre-requisites Returns: ordered list of project cards to be applied to scenario \"\"\" scenario_projects = [ p . project . lower () for p in self . project_cards ] # build prereq (adjacency) list for topological sort adjacency_list = defaultdict ( list ) visited_list = defaultdict () for project in scenario_projects : visited_list [ project ] = False if not self . prerequisites . get ( project ): continue for prereq in self . prerequisites [ project ]: if ( prereq . lower () in scenario_projects ): # this will always be true, else would have been flagged in missing prerequsite check, but just in case adjacency_list [ prereq . lower ()] = [ project ] # sorted_project_names is topological sorted project card names (based on prerequsiite) sorted_project_names = topological_sort ( adjacency_list = adjacency_list , visited_list = visited_list ) # get the project card objects for these sorted project names project_card_and_name_dict = {} for project_card in self . project_cards : project_card_and_name_dict [ project_card . project . lower ()] = project_card sorted_project_cards = [ project_card_and_name_dict [ project_name ] for project_name in sorted_project_names ] try : assert len ( sorted_project_cards ) == len ( self . project_cards ) except : msg = \"Sorted project cards ( {} ) are not of same number as unsorted ( {} ).\" . format ( len ( sorted_project_cards ), len ( self . project_cards ) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) self . prerequisites_sorted = True self . ordered_project_cards = { project_name : project_card_and_name_dict [ project_name ] for project_name in sorted_project_names } WranglerLogger . debug ( \"Ordered Project Cards: {} \" . format ( self . ordered_project_cards ) ) self . project_cards = sorted_project_cards WranglerLogger . debug ( \"Project Cards: {} \" . format ( self . project_cards )) return sorted_project_cards def apply_all_projects ( self ): # Get everything in order if not self . requisites_checked : self . check_scenario_requisites () if not self . conflicts_checked : self . check_scenario_conflicts () if not self . prerequisites_sorted : self . order_project_cards () for p in self . project_cards : self . apply_project ( p . __dict__ ) def apply_project ( self , p ): if isinstance ( p , ProjectCard ): p = p . __dict__ if p . get ( \"project\" ): WranglerLogger . info ( \"Applying {} \" . format ( p [ \"project\" ])) if p . get ( \"changes\" ): part = 1 for pc in p [ \"changes\" ]: pc [ \"project\" ] = p [ \"project\" ] self . apply_project ( pc ) else : if p [ \"category\" ] in ProjectCard . ROADWAY_CATEGORIES : if not self . road_net : raise ( \"Missing Roadway Network\" ) self . road_net . apply ( p ) if p [ \"category\" ] in ProjectCard . TRANSIT_CATEGORIES : if not self . transit_net : raise ( \"Missing Transit Network\" ) self . transit_net . apply ( p ) if ( p [ \"category\" ] in ProjectCard . SECONDARY_TRANSIT_CATEGORIES and self . transit_net ): self . transit_net . apply ( p ) if p [ \"project\" ] not in self . applied_projects : self . applied_projects . append ( p [ \"project\" ]) def remove_all_projects ( self ): self . project_cards = [] def applied_project_card_summary ( self , project_card_dictionary : dict ) -> dict : \"\"\" Create a summary of applied project card and what they changed for the scenario. Args: project_card_dictionary: dictionary representation of the values of a project card (i.e. ProjectCard.__dict__ ) Returns: A dict of project summary change dictionaries for each change \"\"\" changes = project_card_dictionary . get ( \"changes\" , [ project_card_dictionary ]) summary = { \"project_card\" : project_card_dictionary [ \"file\" ], \"total_parts\" : len ( changes ), } def _summarize_change_roadway ( change : dict , change_summary : dict ): sel_key = RoadwayNetwork . build_selection_key ( self . road_net , change [ \"facility\" ] ) change_summary [ \"sel_idx\" ] = self . road_net . selections [ sel_key ][ \"selected_links\" ] . index . tolist () change_summary [ \"attributes\" ] = [ p [ \"property\" ] for p in change [ \"properties\" ]] if type ( sel_key ) == tuple : _ , A_id , B_id = sel_key else : A_id , B_id = ( None , None ) change_summary [ \"map\" ] = self . road_net . selection_map ( change_summary [ \"sel_idx\" ], A = A_id , B = B_id , candidate_link_idx = self . road_net . selections [ sel_key ] . get ( \"candidate_links\" , pd . DataFrame ([])) . index . tolist (), ) return change_summary def _summarize_add_roadway ( change : dict , change_summary : dict ): change_summary [ \"added_links\" ] = pd . DataFrame ( change . get ( \"links\" )) change_summary [ \"added_nodes\" ] = pd . DataFrame ( change . get ( \"nodes\" )) change_summary [ \"map\" ] = RoadwayNetwork . addition_map ( self . road_net , change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary def _summarize_deletion ( change : dict , change_summary : dict ): change_summary [ \"deleted_links\" ] = change . get ( \"links\" ) change_summary [ \"deleted_nodes\" ] = change . get ( \"nodes\" ) change_summary [ \"map\" ] = RoadwayNetwork . deletion_map ( self . base_scenario [ \"road_net\" ], change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary for i , change in enumerate ( changes ): WranglerLogger . debug ( \"Summarizing {} Part: {} \" . format ( project_card_dictionary [ \"project\" ], i + 1 ) ) change_summary = { \"project\" : project_card_dictionary [ \"project\" ] + \" \u2013 Part \" + str ( i + 1 ), \"category\" : change [ \"category\" ] . lower (), } if change [ \"category\" ] . lower () == \"roadway deletion\" : change_summary = _summarize_deletion ( change , change_summary ) elif change [ \"category\" ] . lower () == \"add new roadway\" : change_summary = _summarize_add_roadway ( change , change_summary ) elif change [ \"category\" ] . lower () in [ \"roadway property change\" , \"parallel managed lanes\" , ]: change_summary = _summarize_change_roadway ( change , change_summary ) summary [ \"Part \" + str ( i + 1 )] = change_summary return summary def scenario_summary ( self , project_detail : bool = True , outfile : str = \"\" , mode : str = \"a\" ) -> str : \"\"\" A high level summary of the created scenario. Args: project_detail: If True (default), will write out project card summaries. outfile: If specified, will write scenario summary to text file. mode: Outfile open mode. 'a' to append 'w' to overwrite. Returns: string of summary \"\"\" WranglerLogger . info ( \"Summarizing Scenario\" ) report_str = \"------------------------------ \\n \" report_str += \"Scenario created on {} \\n \" . format ( datetime . now ()) report_str += \"Base Scenario: \\n \" report_str += \"--Road Network: \\n \" report_str += \"----Link File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . link_file ) report_str += \"----Node File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . node_file ) report_str += \"----Shape File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . shape_file ) report_str += \"--Transit Network: \\n \" report_str += \"----Feed Path: {} \\n \" . format ( self . base_scenario [ \"transit_net\" ] . feed_path ) report_str += \" \\n Project Cards: \\n -\" report_str += \" \\n -\" . join ( p . file for p in self . project_cards ) report_str += \" \\n Applied Projects: \\n -\" report_str += \" \\n -\" . join ( self . applied_projects ) if project_detail : report_str += \" \\n ---Project Card Details--- \\n \" for p in self . project_cards : report_str += \" \\n {} \" . format ( pprint . pformat ( self . applied_project_card_summary ( p . __dict__ )) ) if outfile : with open ( outfile , mode ) as f : f . write ( report_str ) WranglerLogger . info ( \"Wrote Scenario Report to: {} \" . format ( outfile )) return report_str __init__ ( base_scenario , project_cards = None ) \u00b6 Constructor Source code in network_wrangler/scenario.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def __init__ ( self , base_scenario : dict , project_cards : [ ProjectCard ] = None ): \"\"\" Constructor args: base_scenario: dict the base scenario project_cards: list this scenario's project cards \"\"\" self . road_net = None self . transit_net = None self . base_scenario = base_scenario # if the base scenario had roadway or transit networks, use them as the basis. if self . base_scenario . get ( \"road_net\" ): self . road_net = copy . deepcopy ( self . base_scenario [ \"road_net\" ]) if self . base_scenario . get ( \"transit_net\" ): self . transit_net = copy . deepcopy ( self . base_scenario [ \"transit_net\" ]) # if the base scenario had applied projects, add them to the list of applied self . applied_projects = [] if self . base_scenario . get ( \"applied_projects\" ): self . applied_projects = base_scenario [ \"applied_projects\" ] self . project_cards = project_cards self . ordered_project_cards = OrderedDict () self . prerequisites = {} self . corequisites = {} self . conflicts = {} self . requisites_checked = False self . conflicts_checked = False self . has_requisite_error = False self . has_conflict_error = False self . prerequisites_sorted = False for card in self . project_cards : if not card . __dict__ . get ( \"dependencies\" ): continue if card . dependencies . get ( \"prerequisites\" ): self . prerequisites . update ( { card . project : card . dependencies [ \"prerequisites\" ]} ) if card . dependencies . get ( \"corequisites\" ): self . corequisites . update ( { card . project : card . dependencies [ \"corequisites\" ]} ) add_project_cards_from_directory ( folder , glob_search = '' , validate = True ) \u00b6 Adds projects cards to the scenario. A folder is provided to look for project cards and if applicable, a glob-style search. i.e. glob_search = \u2018road*.yml\u2019 Source code in network_wrangler/scenario.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def add_project_cards_from_directory ( self , folder : str , glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards and if applicable, a glob-style search. i.e. glob_search = 'road*.yml' args: folder: the folder location where the project cards will be glob_search: https://docs.python.org/2/library/glob.html \"\"\" if not os . path . exists ( folder ): msg = \"Cannot find specified directory to add project cards: {} \" . format ( folder ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if glob_search : WranglerLogger . debug ( \"Adding project cards using glob search: {} \" . format ( glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( file , validate = validate ) else : for file in os . listdir ( folder ): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( os . path . join ( folder , file ), validate = validate ) add_project_cards_from_tags ( folder , tags = [], glob_search = '' , validate = True ) \u00b6 Adds projects cards to the scenario. A folder is provided to look for project cards that have a matching tag that is passed to the method. Source code in network_wrangler/scenario.py 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 def add_project_cards_from_tags ( self , folder : str , tags : [ str ] = [], glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards that have a matching tag that is passed to the method. args: folder: the folder location where the project cards will be tags: only project cards with these tags will be validated and added to the returning scenario \"\"\" if glob_search : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} and \\n glob search: {} \" . format ( tags , glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): self . add_project_card_from_file ( file , tags = tags , validate = validate ) else : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} \" . format ( tags )) for file in os . listdir ( folder ): self . add_project_card_from_file ( file , tags = tags , validate = validate ) applied_project_card_summary ( project_card_dictionary ) \u00b6 Create a summary of applied project card and what they changed for the scenario. Parameters: Name Type Description Default project_card_dictionary dict dictionary representation of the values of a project card (i.e. ProjectCard. dict ) required Returns: Type Description dict A dict of project summary change dictionaries for each change Source code in network_wrangler/scenario.py 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 def applied_project_card_summary ( self , project_card_dictionary : dict ) -> dict : \"\"\" Create a summary of applied project card and what they changed for the scenario. Args: project_card_dictionary: dictionary representation of the values of a project card (i.e. ProjectCard.__dict__ ) Returns: A dict of project summary change dictionaries for each change \"\"\" changes = project_card_dictionary . get ( \"changes\" , [ project_card_dictionary ]) summary = { \"project_card\" : project_card_dictionary [ \"file\" ], \"total_parts\" : len ( changes ), } def _summarize_change_roadway ( change : dict , change_summary : dict ): sel_key = RoadwayNetwork . build_selection_key ( self . road_net , change [ \"facility\" ] ) change_summary [ \"sel_idx\" ] = self . road_net . selections [ sel_key ][ \"selected_links\" ] . index . tolist () change_summary [ \"attributes\" ] = [ p [ \"property\" ] for p in change [ \"properties\" ]] if type ( sel_key ) == tuple : _ , A_id , B_id = sel_key else : A_id , B_id = ( None , None ) change_summary [ \"map\" ] = self . road_net . selection_map ( change_summary [ \"sel_idx\" ], A = A_id , B = B_id , candidate_link_idx = self . road_net . selections [ sel_key ] . get ( \"candidate_links\" , pd . DataFrame ([])) . index . tolist (), ) return change_summary def _summarize_add_roadway ( change : dict , change_summary : dict ): change_summary [ \"added_links\" ] = pd . DataFrame ( change . get ( \"links\" )) change_summary [ \"added_nodes\" ] = pd . DataFrame ( change . get ( \"nodes\" )) change_summary [ \"map\" ] = RoadwayNetwork . addition_map ( self . road_net , change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary def _summarize_deletion ( change : dict , change_summary : dict ): change_summary [ \"deleted_links\" ] = change . get ( \"links\" ) change_summary [ \"deleted_nodes\" ] = change . get ( \"nodes\" ) change_summary [ \"map\" ] = RoadwayNetwork . deletion_map ( self . base_scenario [ \"road_net\" ], change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary for i , change in enumerate ( changes ): WranglerLogger . debug ( \"Summarizing {} Part: {} \" . format ( project_card_dictionary [ \"project\" ], i + 1 ) ) change_summary = { \"project\" : project_card_dictionary [ \"project\" ] + \" \u2013 Part \" + str ( i + 1 ), \"category\" : change [ \"category\" ] . lower (), } if change [ \"category\" ] . lower () == \"roadway deletion\" : change_summary = _summarize_deletion ( change , change_summary ) elif change [ \"category\" ] . lower () == \"add new roadway\" : change_summary = _summarize_add_roadway ( change , change_summary ) elif change [ \"category\" ] . lower () in [ \"roadway property change\" , \"parallel managed lanes\" , ]: change_summary = _summarize_change_roadway ( change , change_summary ) summary [ \"Part \" + str ( i + 1 )] = change_summary return summary check_scenario_conflicts () \u00b6 Checks if there are any conflicting projects in the scenario Fail if the project A specifies that project B is a conflict and project B is included in the scenario Source code in network_wrangler/scenario.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 def check_scenario_conflicts ( self ) -> bool : \"\"\" Checks if there are any conflicting projects in the scenario Fail if the project A specifies that project B is a conflict and project B is included in the scenario Returns: boolean indicating if the check was successful or returned an error \"\"\" conflict_dict = self . conflicts scenario_projects = [ p . project for p in self . project_cards ] for project , conflicts in conflict_dict . items (): if conflicts : for name in conflicts : if name in scenario_projects : self . project_cards WranglerLogger . error ( \"Projects %s has %s as conflicting project\" % ( project , name ) ) self . has_conflict_error = True self . conflicts_checked = True return self . has_conflict_error check_scenario_requisites () \u00b6 Checks if there are any missing pre- or co-requisite projects in the scenario Fail if the project A specifies that project B is a pre- or co-requisite and project B is not included in the scenario Source code in network_wrangler/scenario.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 def check_scenario_requisites ( self ) -> bool : \"\"\" Checks if there are any missing pre- or co-requisite projects in the scenario Fail if the project A specifies that project B is a pre- or co-requisite and project B is not included in the scenario Returns: boolean indicating if the checks were successful or returned an error \"\"\" corequisite_dict = self . corequisites prerequisite_dict = self . prerequisites scenario_projects = [ p . project for p in self . project_cards ] for project , coreq in corequisite_dict . items (): if coreq : for name in coreq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as corequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True for project , prereq in prerequisite_dict . items (): if prereq : for name in prereq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as prerequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True self . requisites_checked = True return self . has_requisite_error create_base_scenario ( base_shape_name , base_link_name , base_node_name , roadway_dir = '' , transit_dir = '' , validate = True ) staticmethod \u00b6 args \u00b6 optional path to the base scenario roadway network files base_shape_name filename of the base network shape base_link_name filename of the base network link base_node_name filename of the base network node optional path to base scenario transit files validate boolean indicating whether to validate the base network or not Source code in network_wrangler/scenario.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 @staticmethod def create_base_scenario ( base_shape_name : str , base_link_name : str , base_node_name : str , roadway_dir : str = \"\" , transit_dir : str = \"\" , validate : bool = True , ) -> Scenario : \"\"\" args ----- roadway_dir: optional path to the base scenario roadway network files base_shape_name: filename of the base network shape base_link_name: filename of the base network link base_node_name: filename of the base network node transit_dir: optional path to base scenario transit files validate: boolean indicating whether to validate the base network or not \"\"\" if roadway_dir : base_network_shape_file = os . path . join ( roadway_dir , base_shape_name ) base_network_link_file = os . path . join ( roadway_dir , base_link_name ) base_network_node_file = os . path . join ( roadway_dir , base_node_name ) else : base_network_shape_file = base_shape_name base_network_link_file = base_link_name base_network_node_file = base_node_name road_net = RoadwayNetwork . read ( link_file = base_network_link_file , node_file = base_network_node_file , shape_file = base_network_shape_file , fast = not validate , ) if transit_dir : transit_net = TransitNetwork . read ( transit_dir ) else : transit_net = None WranglerLogger . info ( \"No transit directory specified, base scenario will have empty transit network.\" ) transit_net . set_roadnet ( road_net , validate_consistency = validate ) base_scenario = { \"road_net\" : road_net , \"transit_net\" : transit_net } return base_scenario create_scenario ( base_scenario = {}, card_directory = '' , tags = None , project_cards_list = [], glob_search = '' , validate_project_cards = True ) staticmethod \u00b6 Validates project cards with a specific tag from the specified folder or list of user specified project cards and creates a scenario object with the valid project card. args \u00b6 base_scenario object dictionary for the base scenario (i.e. my_base_scenario. dict ) tags only project cards with these tags will be read/validated folder the folder location where the project cards will be project_cards_list list of project cards to be applied Source code in network_wrangler/scenario.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 @staticmethod def create_scenario ( base_scenario : dict = {}, card_directory : str = \"\" , tags : [ str ] = None , project_cards_list = [], glob_search = \"\" , validate_project_cards = True , ) -> Scenario : \"\"\" Validates project cards with a specific tag from the specified folder or list of user specified project cards and creates a scenario object with the valid project card. args ----- base_scenario: object dictionary for the base scenario (i.e. my_base_scenario.__dict__) tags: only project cards with these tags will be read/validated folder: the folder location where the project cards will be project_cards_list: list of project cards to be applied glob_search: \"\"\" WranglerLogger . info ( \"Creating Scenario\" ) if project_cards_list : WranglerLogger . debug ( \"Adding project cards from List. \\n {} \" . format ( \",\" . join ([ p . project for p in project_cards_list ]) ) ) scenario = Scenario ( base_scenario , project_cards = project_cards_list ) if card_directory and tags : WranglerLogger . debug ( \"Adding project cards from directory and tags. \\n Dir: {} \\n Tags: {} \" . format ( card_directory , \",\" . join ( tags ) ) ) scenario . add_project_cards_from_tags ( card_directory , tags = tags , glob_search = glob_search , validate = validate_project_cards , ) elif card_directory : WranglerLogger . debug ( \"Adding project cards from directory. \\n Dir: {} \" . format ( card_directory ) ) scenario . add_project_cards_from_directory ( card_directory , glob_search = glob_search , validate = validate_project_cards ) return scenario get_project_names () \u00b6 Returns a list of project names Source code in network_wrangler/scenario.py 376 377 378 379 380 def get_project_names ( self ) -> list : \"\"\" Returns a list of project names \"\"\" return [ project_card . project for project_card in self . project_cards ] order_project_cards () \u00b6 create a list of project cards such that they are in order based on pre-requisites Source code in network_wrangler/scenario.py 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def order_project_cards ( self ): \"\"\" create a list of project cards such that they are in order based on pre-requisites Returns: ordered list of project cards to be applied to scenario \"\"\" scenario_projects = [ p . project . lower () for p in self . project_cards ] # build prereq (adjacency) list for topological sort adjacency_list = defaultdict ( list ) visited_list = defaultdict () for project in scenario_projects : visited_list [ project ] = False if not self . prerequisites . get ( project ): continue for prereq in self . prerequisites [ project ]: if ( prereq . lower () in scenario_projects ): # this will always be true, else would have been flagged in missing prerequsite check, but just in case adjacency_list [ prereq . lower ()] = [ project ] # sorted_project_names is topological sorted project card names (based on prerequsiite) sorted_project_names = topological_sort ( adjacency_list = adjacency_list , visited_list = visited_list ) # get the project card objects for these sorted project names project_card_and_name_dict = {} for project_card in self . project_cards : project_card_and_name_dict [ project_card . project . lower ()] = project_card sorted_project_cards = [ project_card_and_name_dict [ project_name ] for project_name in sorted_project_names ] try : assert len ( sorted_project_cards ) == len ( self . project_cards ) except : msg = \"Sorted project cards ( {} ) are not of same number as unsorted ( {} ).\" . format ( len ( sorted_project_cards ), len ( self . project_cards ) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) self . prerequisites_sorted = True self . ordered_project_cards = { project_name : project_card_and_name_dict [ project_name ] for project_name in sorted_project_names } WranglerLogger . debug ( \"Ordered Project Cards: {} \" . format ( self . ordered_project_cards ) ) self . project_cards = sorted_project_cards WranglerLogger . debug ( \"Project Cards: {} \" . format ( self . project_cards )) return sorted_project_cards scenario_summary ( project_detail = True , outfile = '' , mode = 'a' ) \u00b6 A high level summary of the created scenario. Parameters: Name Type Description Default project_detail bool If True (default), will write out project card summaries. True outfile str If specified, will write scenario summary to text file. '' mode str Outfile open mode. \u2018a\u2019 to append \u2018w\u2019 to overwrite. 'a' Returns: Type Description str string of summary Source code in network_wrangler/scenario.py 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def scenario_summary ( self , project_detail : bool = True , outfile : str = \"\" , mode : str = \"a\" ) -> str : \"\"\" A high level summary of the created scenario. Args: project_detail: If True (default), will write out project card summaries. outfile: If specified, will write scenario summary to text file. mode: Outfile open mode. 'a' to append 'w' to overwrite. Returns: string of summary \"\"\" WranglerLogger . info ( \"Summarizing Scenario\" ) report_str = \"------------------------------ \\n \" report_str += \"Scenario created on {} \\n \" . format ( datetime . now ()) report_str += \"Base Scenario: \\n \" report_str += \"--Road Network: \\n \" report_str += \"----Link File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . link_file ) report_str += \"----Node File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . node_file ) report_str += \"----Shape File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . shape_file ) report_str += \"--Transit Network: \\n \" report_str += \"----Feed Path: {} \\n \" . format ( self . base_scenario [ \"transit_net\" ] . feed_path ) report_str += \" \\n Project Cards: \\n -\" report_str += \" \\n -\" . join ( p . file for p in self . project_cards ) report_str += \" \\n Applied Projects: \\n -\" report_str += \" \\n -\" . join ( self . applied_projects ) if project_detail : report_str += \" \\n ---Project Card Details--- \\n \" for p in self . project_cards : report_str += \" \\n {} \" . format ( pprint . pformat ( self . applied_project_card_summary ( p . __dict__ )) ) if outfile : with open ( outfile , mode ) as f : f . write ( report_str ) WranglerLogger . info ( \"Wrote Scenario Report to: {} \" . format ( outfile )) return report_str network_wrangler.RoadwayNetwork \u00b6 Bases: object Representation of a Roadway Network. Typical usage example: net = RoadwayNetwork . read ( link_file = MY_LINK_FILE , node_file = MY_NODE_FILE , shape_file = MY_SHAPE_FILE , ) my_selection = { \"link\" : [{ \"name\" : [ \"I 35E\" ]}], \"A\" : { \"osm_node_id\" : \"961117623\" }, # start searching for segments at A \"B\" : { \"osm_node_id\" : \"2564047368\" }, } net . select_roadway_features ( my_selection ) my_change = [ { 'property' : 'lanes' , 'existing' : 1 , 'set' : 2 , }, { 'property' : 'drive_access' , 'set' : 0 , }, ] my_net . apply_roadway_feature_change ( my_net . select_roadway_features ( my_selection ), my_change ) ml_net = net . create_managed_lane_network ( in_place = False ) ml_net . is_network_connected ( mode = \"drive\" )) _ , disconnected_nodes = ml_net . assess_connectivity ( mode = \"walk\" , ignore_end_nodes = True ) ml_net . write ( filename = my_out_prefix , path = my_dir ) Attributes: Name Type Description nodes_df GeoDataFrame node data links_df GeoDataFrame link data, including start and end nodes and associated shape shapes_df GeoDataFrame detailed shape data selections dict dictionary storing selections in case they are made repeatedly CRS str coordinate reference system in PROJ4 format. See https://proj.org/operations/projections/index.html# ESPG int integer representing coordinate system https://epsg.io/ NODE_FOREIGN_KEY str column in nodes_df associated with the LINK_FOREIGN_KEY LINK_FOREIGN_KEY list(str list of columns in link_df that represent the NODE_FOREIGN_KEY UNIQUE_LINK_KEY str column that is a unique key for links UNIQUE_NODE_KEY str column that is a unique key for nodes UNIQUE_SHAPE_KEY str column that is a unique shape key UNIQUE_MODEL_LINK_IDENTIFIERS list(str list of all unique identifiers for links, including the UNIQUE_LINK_KEY UNIQUE_NODE_IDENTIFIERS list(str list of all unique identifiers for nodes, including the UNIQUE_NODE_KEY SELECTION_REQUIRES list(str required attributes in the selection if a unique identifier is not used SEARCH_BREADTH int initial number of links from name-based selection that are traveresed before trying another shortest path when searching for paths between A and B node MAX_SEARCH_BREADTH int maximum number of links traversed between links that match the searched name when searching for paths between A and B node SP_WEIGHT_FACTOR Union(int, float penalty assigned for each degree of distance between a link and a link with the searched-for name when searching for paths between A and B node MANAGED_LANES_TO_NODE_ID_SCALAR int scalar value added to the general purpose lanes\u2019 model_node_id when creating an associated node for a parallel managed lane MANAGED_LANES_TO_LINK_ID_SCALAR int scalar value added to the general purpose lanes\u2019 model_link_id when creating an associated link for a parallel managed lane MANAGED_LANES_REQUIRED_ATTRIBUTES list(str list of attributes that must be provided in managed lanes KEEP_SAME_ATTRIBUTES_ML_AND_GP list(str list of attributes to copy from a general purpose lane to managed lane Source code in network_wrangler/roadwaynetwork.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 class RoadwayNetwork ( object ): \"\"\" Representation of a Roadway Network. Typical usage example: ``` py net = RoadwayNetwork.read( link_file=MY_LINK_FILE, node_file=MY_NODE_FILE, shape_file=MY_SHAPE_FILE, ) my_selection = { \"link\": [{\"name\": [\"I 35E\"]}], \"A\": {\"osm_node_id\": \"961117623\"}, # start searching for segments at A \"B\": {\"osm_node_id\": \"2564047368\"}, } net.select_roadway_features(my_selection) my_change = [ { 'property': 'lanes', 'existing': 1, 'set': 2, }, { 'property': 'drive_access', 'set': 0, }, ] my_net.apply_roadway_feature_change( my_net.select_roadway_features(my_selection), my_change ) ml_net = net.create_managed_lane_network(in_place=False) ml_net.is_network_connected(mode=\"drive\")) _, disconnected_nodes = ml_net.assess_connectivity(mode=\"walk\", ignore_end_nodes=True) ml_net.write(filename=my_out_prefix, path=my_dir) ``` Attributes: nodes_df (GeoDataFrame): node data links_df (GeoDataFrame): link data, including start and end nodes and associated shape shapes_df (GeoDataFrame): detailed shape data selections (dict): dictionary storing selections in case they are made repeatedly CRS (str): coordinate reference system in PROJ4 format. See https://proj.org/operations/projections/index.html# ESPG (int): integer representing coordinate system https://epsg.io/ NODE_FOREIGN_KEY (str): column in `nodes_df` associated with the LINK_FOREIGN_KEY LINK_FOREIGN_KEY (list(str)): list of columns in `link_df` that represent the NODE_FOREIGN_KEY UNIQUE_LINK_KEY (str): column that is a unique key for links UNIQUE_NODE_KEY (str): column that is a unique key for nodes UNIQUE_SHAPE_KEY (str): column that is a unique shape key UNIQUE_MODEL_LINK_IDENTIFIERS (list(str)): list of all unique identifiers for links, including the UNIQUE_LINK_KEY UNIQUE_NODE_IDENTIFIERS (list(str)): list of all unique identifiers for nodes, including the UNIQUE_NODE_KEY SELECTION_REQUIRES (list(str))): required attributes in the selection if a unique identifier is not used SEARCH_BREADTH (int): initial number of links from name-based selection that are traveresed before trying another shortest path when searching for paths between A and B node MAX_SEARCH_BREADTH (int): maximum number of links traversed between links that match the searched name when searching for paths between A and B node SP_WEIGHT_FACTOR (Union(int, float)): penalty assigned for each degree of distance between a link and a link with the searched-for name when searching for paths between A and B node MANAGED_LANES_TO_NODE_ID_SCALAR (int): scalar value added to the general purpose lanes' `model_node_id` when creating an associated node for a parallel managed lane MANAGED_LANES_TO_LINK_ID_SCALAR (int): scalar value added to the general purpose lanes' `model_link_id` when creating an associated link for a parallel managed lane MANAGED_LANES_REQUIRED_ATTRIBUTES (list(str)): list of attributes that must be provided in managed lanes KEEP_SAME_ATTRIBUTES_ML_AND_GP (list(str)): list of attributes to copy from a general purpose lane to managed lane \"\"\" # CRS = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\" CRS = 4326 # \"EPSG:4326\" NODE_FOREIGN_KEY = \"model_node_id\" LINK_FOREIGN_KEY = [ \"A\" , \"B\" ] SEARCH_BREADTH = 5 MAX_SEARCH_BREADTH = 10 SP_WEIGHT_FACTOR = 100 MANAGED_LANES_NODE_ID_SCALAR = 500000 MANAGED_LANES_LINK_ID_SCALAR = 1000000 SELECTION_REQUIRES = [ \"link\" ] UNIQUE_LINK_KEY = \"model_link_id\" UNIQUE_NODE_KEY = \"model_node_id\" UNIQUE_MODEL_LINK_IDENTIFIERS = [ \"model_link_id\" ] UNIQUE_NODE_IDENTIFIERS = [ \"model_node_id\" ] UNIQUE_SHAPE_KEY = \"shape_id\" MANAGED_LANES_REQUIRED_ATTRIBUTES = [ \"A\" , \"B\" , \"model_link_id\" , \"locationReferences\" , ] KEEP_SAME_ATTRIBUTES_ML_AND_GP = [ \"distance\" , \"bike_access\" , \"drive_access\" , \"transit_access\" , \"walk_access\" , \"maxspeed\" , \"name\" , \"oneway\" , \"ref\" , \"roadway\" , \"length\" , \"segment_id\" , ] MANAGED_LANES_SCALAR = 500000 MODES_TO_NETWORK_LINK_VARIABLES = { \"drive\" : [ \"drive_access\" ], \"bus\" : [ \"bus_only\" , \"drive_access\" ], \"rail\" : [ \"rail_only\" ], \"transit\" : [ \"bus_only\" , \"rail_only\" , \"drive_access\" ], \"walk\" : [ \"walk_access\" ], \"bike\" : [ \"bike_access\" ], } MODES_TO_NETWORK_NODE_VARIABLES = { \"drive\" : [ \"drive_node\" ], \"rail\" : [ \"rail_only\" , \"drive_node\" ], \"bus\" : [ \"bus_only\" , \"drive_node\" ], \"transit\" : [ \"bus_only\" , \"rail_only\" , \"drive_node\" ], \"walk\" : [ \"walk_node\" ], \"bike\" : [ \"bike_node\" ], } def __init__ ( self , nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Constructor \"\"\" if not RoadwayNetwork . validate_object_types ( nodes , links , shapes ): sys . exit ( \"RoadwayNetwork: Invalid constructor data type\" ) self . nodes_df = nodes self . links_df = links self . shapes_df = shapes self . link_file = None self . node_file = None self . shape_file = None # Add non-required fields if they aren't there. # for field, default_value in RoadwayNetwork.OPTIONAL_FIELDS: # if field not in self.links_df.columns: # self.links_df[field] = default_value if not self . validate_uniqueness (): raise ValueError ( \"IDs in network not unique\" ) self . selections = {} @staticmethod def read ( link_file : str , node_file : str , shape_file : str , fast : bool = True ) -> RoadwayNetwork : \"\"\" Reads a network from the roadway network standard Validates that it conforms to the schema args: link_file: full path to the link file node_file: full path to the node file shape_file: full path to the shape file fast: boolean that will skip validation to speed up read time Returns: a RoadwayNetwork instance .. todo:: Turn off fast=True as default \"\"\" WranglerLogger . info ( \"Reading from following files: \\n - {} \\n - {} \\n - {} .\" . format ( link_file , node_file , shape_file ) ) \"\"\" Validate Input \"\"\" if not os . path . exists ( link_file ): msg = \"Link file doesn't exist at: {} \" . format ( link_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( node_file ): msg = \"Node file doesn't exist at: {} \" . format ( node_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( shape_file ): msg = \"Shape file doesn't exist at: {} \" . format ( shape_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not fast : if not ( RoadwayNetwork . validate_node_schema ( node_file ) and RoadwayNetwork . validate_link_schema ( link_file ) and RoadwayNetwork . validate_shape_schema ( shape_file ) ): sys . exit ( \"RoadwayNetwork: Data doesn't conform to schema\" ) with open ( link_file ) as f : link_json = json . load ( f ) link_properties = pd . DataFrame ( link_json ) link_geometries = [ create_line_string ( g [ \"locationReferences\" ]) for g in link_json ] links_df = gpd . GeoDataFrame ( link_properties , geometry = link_geometries ) links_df . crs = RoadwayNetwork . CRS # coerce types for booleans which might not have a 1 and are therefore read in as intersection bool_columns = [ \"rail_only\" , \"bus_only\" , \"drive_access\" , \"bike_access\" , \"walk_access\" , \"truck_access\" , ] for bc in list ( set ( bool_columns ) & set ( links_df . columns )): links_df [ bc ] = links_df [ bc ] . astype ( bool ) shapes_df = gpd . read_file ( shape_file ) shapes_df . dropna ( subset = [ \"geometry\" , \"id\" ], inplace = True ) shapes_df . crs = RoadwayNetwork . CRS # geopandas uses fiona OGR drivers, which doesn't let you have # a list as a property type. Therefore, must read in node_properties # separately in a vanilla dataframe and then convert to geopandas with open ( node_file ) as f : node_geojson = json . load ( f ) node_properties = pd . DataFrame ( [ g [ \"properties\" ] for g in node_geojson [ \"features\" ]] ) node_geometries = [ Point ( g [ \"geometry\" ][ \"coordinates\" ]) for g in node_geojson [ \"features\" ] ] nodes_df = gpd . GeoDataFrame ( node_properties , geometry = node_geometries ) nodes_df . gdf_name = \"network_nodes\" # set a copy of the foreign key to be the index so that the # variable itself remains queryiable nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" ] = nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] nodes_df . set_index ( RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" , inplace = True ) nodes_df . crs = RoadwayNetwork . CRS nodes_df [ \"X\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) nodes_df [ \"Y\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) WranglerLogger . info ( \"Read %s links from %s \" % ( len ( links_df ), link_file )) WranglerLogger . info ( \"Read %s nodes from %s \" % ( len ( nodes_df ), node_file )) WranglerLogger . info ( \"Read %s shapes from %s \" % ( len ( shapes_df ), shape_file )) roadway_network = RoadwayNetwork ( nodes = nodes_df , links = links_df , shapes = shapes_df ) roadway_network . link_file = link_file roadway_network . node_file = node_file roadway_network . shape_file = shape_file return roadway_network def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the roadway network standard args: path: the path were the output will be saved filename: the name prefix of the roadway files that will be generated \"\"\" if not os . path . exists ( path ): WranglerLogger . debug ( \" \\n Path [ %s ] doesn't exist; creating.\" % path ) os . mkdir ( path ) if filename : links_file = os . path . join ( path , filename + \"_\" + \"link.json\" ) nodes_file = os . path . join ( path , filename + \"_\" + \"node.geojson\" ) shapes_file = os . path . join ( path , filename + \"_\" + \"shape.geojson\" ) else : links_file = os . path . join ( path , \"link.json\" ) nodes_file = os . path . join ( path , \"node.geojson\" ) shapes_file = os . path . join ( path , \"shape.geojson\" ) link_property_columns = self . links_df . columns . values . tolist () link_property_columns . remove ( \"geometry\" ) links_json = link_df_to_json ( self . links_df , link_property_columns ) with open ( links_file , \"w\" ) as f : json . dump ( links_json , f ) # geopandas wont let you write to geojson because # it uses fiona, which doesn't accept a list as one of the properties # so need to convert the df to geojson manually first property_columns = self . nodes_df . columns . values . tolist () property_columns . remove ( \"geometry\" ) nodes_geojson = point_df_to_geojson ( self . nodes_df , property_columns ) with open ( nodes_file , \"w\" ) as f : json . dump ( nodes_geojson , f ) self . shapes_df . to_file ( shapes_file , driver = \"GeoJSON\" ) @staticmethod def roadway_net_to_gdf ( roadway_net : RoadwayNetwork ) -> gpd . GeoDataFrame : \"\"\" Turn the roadway network into a GeoDataFrame args: roadway_net: the roadway network to export returns: shapes dataframe .. todo:: Make this much more sophisticated, for example attach link info to shapes \"\"\" return roadway_net . shapes_df def validate_uniqueness ( self ) -> Bool : \"\"\" Confirms that the unique identifiers are met. \"\"\" valid = True for c in RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain unique link identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . links_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network links\" . format ( c ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . LINK_FOREIGN_KEY : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain link foreign key identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) link_foreign_key = self . links_df [ RoadwayNetwork . LINK_FOREIGN_KEY ] . apply ( lambda x : \"-\" . join ( x . map ( str )), axis = 1 ) if not link_foreign_key . is_unique : valid = False msg = \"Foreign key: {} is not unique in network links\" . format ( RoadwayNetwork . LINK_FOREIGN_KEY ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . UNIQUE_NODE_IDENTIFIERS : if c not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain unique node identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . nodes_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network nodes\" . format ( c ) WranglerLogger . error ( msg ) if RoadwayNetwork . NODE_FOREIGN_KEY not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain node foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) elif not self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . is_unique : valid = False msg = \"Foreign key: {} is not unique in network nodes\" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) if RoadwayNetwork . UNIQUE_SHAPE_KEY not in self . shapes_df . columns : valid = False msg = \"Network doesn't contain unique shape id: {} \" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) elif not self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . is_unique : valid = False msg = \"Unique key: {} is not unique in network shapes\" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) return valid @staticmethod def validate_object_types ( nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Determines if the roadway network is being built with the right object types. Does not validate schemas. Args: nodes: nodes geodataframe links: link geodataframe shapes: shape geodataframe Returns: boolean \"\"\" errors = \"\" if not isinstance ( nodes , GeoDataFrame ): error_message = \"Incompatible nodes type: {} . Must provide a GeoDataFrame. \" . format ( type ( nodes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( links , GeoDataFrame ): error_message = \"Incompatible links type: {} . Must provide a GeoDataFrame. \" . format ( type ( links ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( shapes , GeoDataFrame ): error_message = \"Incompatible shapes type: {} . Must provide a GeoDataFrame. \" . format ( type ( shapes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if errors : return False return True @staticmethod def validate_node_schema ( node_file , schema_location : str = \"roadway_network_node.json\" ): \"\"\" Validate roadway network data node schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( node_file ) as node_json_file : json_data = json . load ( node_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Node schema validation: Validation Error\" ) WranglerLogger . error ( \"Node File Loc: {} \" . format ( node_file )) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Node Schema\" ) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False @staticmethod def validate_link_schema ( link_file , schema_location : str = \"roadway_network_link.json\" ): \"\"\" Validate roadway network data link schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( link_file ) as link_json_file : json_data = json . load ( link_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Link schema validation: Validation Error\" ) WranglerLogger . error ( \"Link File Loc: {} \" . format ( link_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Link Schema\" ) WranglerLogger . error ( \"Link Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False @staticmethod def validate_shape_schema ( shape_file , schema_location : str = \"roadway_network_shape.json\" ): \"\"\" Validate roadway network data shape schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( shape_file ) as shape_json_file : json_data = json . load ( shape_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Shape schema validation: Validation Error\" ) WranglerLogger . error ( \"Shape File Loc: {} \" . format ( shape_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Shape Schema\" ) WranglerLogger . error ( \"Shape Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False def validate_selection ( self , selection : dict ) -> Bool : \"\"\" Evaluate whetther the selection dictionary contains the minimum required values. Args: selection: selection dictionary to be evaluated Returns: boolean value as to whether the selection dictonary is valid. \"\"\" if not set ( RoadwayNetwork . SELECTION_REQUIRES ) . issubset ( selection ): err_msg = \"Project Card Selection requires: {} \" . format ( \",\" . join ( RoadwayNetwork . SELECTION_REQUIRES ) ) err_msg += \", but selection only contains: {} \" . format ( \",\" . join ( selection )) WranglerLogger . error ( err_msg ) raise KeyError ( err_msg ) err = [] for l in selection [ \"link\" ]: for k , v in l . items (): if k not in self . links_df . columns : err . append ( \" {} specified in link selection but not an attribute in network \\n \" . format ( k ) ) selection_keys = [ k for l in selection [ \"link\" ] for k , v in l . items ()] unique_link_id = bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) ) if not unique_link_id : for k , v in selection [ \"A\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in A node selection but not an attribute in network \\n \" . format ( k ) ) for k , v in selection [ \"B\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in B node selection but not an attribute in network \\n \" . format ( k ) ) if err : WranglerLogger . error ( \"ERROR: Selection variables in project card not found in network\" ) WranglerLogger . error ( \" \\n \" . join ( err )) WranglerLogger . error ( \"--existing node columns: {} \" . format ( \" \" . join ( self . nodes_df . columns )) ) WranglerLogger . error ( \"--existing link columns: {} \" . format ( \" \" . join ( self . links_df . columns )) ) raise ValueError () return False else : return True def orig_dest_nodes_foreign_key ( self , selection : dict , node_foreign_key : str = \"\" ) -> tuple : \"\"\" Returns the foreign key id (whatever is used in the u and v variables in the links file) for the AB nodes as a tuple. Args: selection : selection dictionary with A and B keys node_foreign_key: variable name for whatever is used by the u and v variable in the links_df file. If nothing is specified, assume whatever default is (usually osm_node_id) Returns: tuple of (A_id, B_id) \"\"\" if not node_foreign_key : node_foreign_key = RoadwayNetwork . NODE_FOREIGN_KEY if len ( selection [ \"A\" ]) > 1 : raise ( \"Selection A node dictionary should be of length 1\" ) if len ( selection [ \"B\" ]) > 1 : raise ( \"Selection B node dictionary should be of length 1\" ) A_node_key , A_id = next ( iter ( selection [ \"A\" ] . items ())) B_node_key , B_id = next ( iter ( selection [ \"B\" ] . items ())) if A_node_key != node_foreign_key : A_id = self . nodes_df [ self . nodes_df [ A_node_key ] == A_id ][ node_foreign_key ] . values [ 0 ] if B_node_key != node_foreign_key : B_id = self . nodes_df [ self . nodes_df [ B_node_key ] == B_id ][ node_foreign_key ] . values [ 0 ] return ( A_id , B_id ) @staticmethod def get_managed_lane_node_ids ( nodes_list ): return [ x + RoadwayNetwork . MANAGED_LANES_SCALAR for x in nodes_list ] @staticmethod def ox_graph ( nodes_df : GeoDataFrame , links_df : GeoDataFrame ): \"\"\" create an osmnx-flavored network graph osmnx doesn't like values that are arrays, so remove the variables that have arrays. osmnx also requires that certain variables be filled in, so do that too. Args: nodes_df : GeoDataFrame of nodes link_df : GeoDataFrame of links Returns: a networkx multidigraph \"\"\" WranglerLogger . debug ( \"starting ox_graph()\" ) graph_nodes = nodes_df . copy () . drop ( [ \"inboundReferenceIds\" , \"outboundReferenceIds\" ], axis = 1 ) graph_nodes . gdf_name = \"network_nodes\" WranglerLogger . debug ( \"GRAPH NODES: {} \" . format ( graph_nodes . columns )) graph_nodes [ \"id\" ] = graph_nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] graph_nodes [ \"x\" ] = graph_nodes [ \"X\" ] graph_nodes [ \"y\" ] = graph_nodes [ \"Y\" ] graph_links = links_df . copy () . drop ( [ \"osm_link_id\" , \"locationReferences\" ], axis = 1 ) # have to change this over into u,v b/c this is what osm-nx is expecting graph_links [ \"u\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 0 ]] graph_links [ \"v\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 1 ]] graph_links [ \"id\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] graph_links [ \"key\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] WranglerLogger . debug ( \"starting ox.gdfs_to_graph()\" ) try : G = ox . graph_from_gdfs ( graph_nodes , graph_links ) except : WranglerLogger . debug ( \"Please upgrade your OSMNX package. For now, using depricated osmnx.gdfs_to_graph because osmnx.graph_from_gdfs not found\" ) G = ox . gdfs_to_graph ( graph_nodes , graph_links ) WranglerLogger . debug ( \"finished ox.gdfs_to_graph()\" ) return G @staticmethod def selection_has_unique_link_id ( selection_dict : dict ) -> bool : \"\"\" Args: selection_dictionary: Dictionary representation of selection of roadway features, containing a \"link\" key. Returns: A boolean indicating if the selection dictionary contains a required unique link id. \"\"\" selection_keys = [ k for l in selection_dict [ \"link\" ] for k , v in l . items ()] return bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) ) def build_selection_key ( self , selection_dict : dict ) -> tuple : \"\"\" Selections are stored by a key combining the query and the A and B ids. This method combines the two for you based on the selection dictionary. Args: selection_dictonary: Selection Dictionary Returns: Tuple serving as the selection key. \"\"\" sel_query = ProjectCard . build_link_selection_query ( selection = selection_dict , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , ) if RoadwayNetwork . selection_has_unique_link_id ( selection_dict ): return sel_query A_id , B_id = self . orig_dest_nodes_foreign_key ( selection_dict ) return ( sel_query , A_id , B_id ) def select_roadway_features ( self , selection : dict , search_mode = \"drive\" , force_search = False ) -> GeoDataFrame : \"\"\" Selects roadway features that satisfy selection criteria Example usage: net.select_roadway_features( selection = [ { # a match condition for the from node using osm, # shared streets, or model node number 'from': {'osm_model_link_id': '1234'}, # a match for the to-node.. 'to': {'shstid': '4321'}, # a regex or match for facility condition # could be # of lanes, facility type, etc. 'facility': {'name':'Main St'}, }, ... ]) Args: selection : dictionary with keys for: A - from node B - to node link - which includes at least a variable for `name` Returns: a list of node foreign IDs on shortest path \"\"\" WranglerLogger . debug ( \"validating selection\" ) self . validate_selection ( selection ) # create a unique key for the selection so that we can cache it sel_key = self . build_selection_key ( selection ) WranglerLogger . debug ( \"Selection Key: {} \" . format ( sel_key )) # if this selection has been queried before, just return the # previously selected links if sel_key in self . selections and not force_search : if self . selections [ sel_key ][ \"selection_found\" ]: return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : msg = \"Selection previously queried but no selection found\" WranglerLogger . error ( msg ) raise Exception ( msg ) self . selections [ sel_key ] = {} self . selections [ sel_key ][ \"selection_found\" ] = False unique_model_link_identifer_in_selection = RoadwayNetwork . selection_has_unique_link_id ( selection ) if not unique_model_link_identifer_in_selection : A_id , B_id = self . orig_dest_nodes_foreign_key ( selection ) # identify candidate links which match the initial query # assign them as iteration = 0 # subsequent iterations that didn't match the query will be # assigned a heigher weight in the shortest path WranglerLogger . debug ( \"Building selection query\" ) # build a selection query based on the selection dictionary sel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ) WranglerLogger . debug ( \"Selecting features: \\n {} \" . format ( sel_query )) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) WranglerLogger . debug ( \"Completed query\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] # b/c too long to keep that way candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 and unique_model_link_identifer_in_selection : msg = \"No links found based on unique link identifiers. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if len ( candidate_links . index ) == 0 : WranglerLogger . debug ( \"No candidate links in initial search. \\n Retrying query using 'ref' instead of 'name'\" ) # if the query doesn't come back with something from 'name' # try it again with 'ref' instead selection_has_name_key = any ( \"name\" in d for d in selection [ \"link\" ]) if not selection_has_name_key : msg = \"Not able to complete search using 'ref' instead of 'name' because 'name' not in search.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if not \"ref\" in self . links_df . columns : msg = \"Not able to complete search using 'ref' because 'ref' not in network.\" WranglerLogger . error ( msg ) raise Exception ( msg ) WranglerLogger . debug ( \"Trying selection query replacing 'name' with 'ref'\" ) sel_query = sel_query . replace ( \"name\" , \"ref\" ) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 : msg = \"No candidate links in search using either 'name' or 'ref' in query. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) def _add_breadth ( candidate_links : DataFrame , nodes : Data , links , i ): \"\"\" Add outbound and inbound reference IDs to candidate links from existing nodes Args: candidate_links : GeoDataFrame df with the links from the previous iteration that we want to add on to nodes : GeoDataFrame df of all nodes in the full network links : GeoDataFrame df of all links in the full network i : int iteration of adding breadth Returns: candidate_links : GeoDataFrame updated df with one more degree of added breadth node_list_foreign_keys : list list of foreign key ids for nodes in the updated candidate links to test if the A and B nodes are in there. ..todo:: Make unique ID for links in the settings \"\"\" WranglerLogger . debug ( \"-Adding Breadth-\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = nodes . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"Candidate Nodes: {} \" . format ( len ( candidate_nodes ))) links_shstRefId_to_add = list ( set ( sum ( candidate_nodes [ \"outboundReferenceIds\" ] . tolist (), []) + sum ( candidate_nodes [ \"inboundReferenceIds\" ] . tolist (), []) ) - set ( candidate_links [ \"shstReferenceId\" ] . tolist ()) - set ([ \"\" ]) ) ##TODO make unique ID for links in the settings # print(\"Link IDs to add: {}\".format(links_shstRefId_to_add)) # print(\"Links: \", links_id_to_add) links_to_add = links [ links . shstReferenceId . isin ( links_shstRefId_to_add )] # print(\"Adding Links:\",links_to_add) WranglerLogger . debug ( \"Adding {} links.\" . format ( links_to_add . shape [ 0 ])) links [ links . model_link_id . isin ( links_shstRefId_to_add )][ \"i\" ] = i candidate_links = candidate_links . append ( links_to_add ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) return candidate_links , node_list_foreign_keys def _shortest_path (): WranglerLogger . debug ( \"_shortest_path(): calculating shortest path from graph\" ) candidate_links . loc [:, \"weight\" ] = 1 + ( candidate_links [ \"i\" ] * RoadwayNetwork . SP_WEIGHT_FACTOR ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"creating network graph\" ) G = RoadwayNetwork . ox_graph ( candidate_nodes , candidate_links ) self . selections [ sel_key ][ \"graph\" ] = G self . selections [ sel_key ][ \"candidate_links\" ] = candidate_links try : WranglerLogger . debug ( \"Calculating NX shortest path from A_id: {} to B_id: {} \" . format ( A_id , B_id ) ) sp_route = nx . shortest_path ( G , A_id , B_id , weight = \"weight\" ) WranglerLogger . debug ( \"Shortest path successfully routed\" ) except nx . NetworkXNoPath : return False sp_links = candidate_links [ candidate_links [ \"A\" ] . isin ( sp_route ) & candidate_links [ \"B\" ] . isin ( sp_route ) ] self . selections [ sel_key ][ \"route\" ] = sp_route self . selections [ sel_key ][ \"links\" ] = sp_links return True if not unique_model_link_identifer_in_selection : # find the node ids for the candidate links WranglerLogger . debug ( \"Not a unique ID selection, conduct search\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) WranglerLogger . debug ( \"Foreign key list: {} \" . format ( node_list_foreign_keys )) i = 0 max_i = RoadwayNetwork . SEARCH_BREADTH while ( A_id not in node_list_foreign_keys and B_id not in node_list_foreign_keys and i <= max_i ): WranglerLogger . debug ( \"Adding breadth, no shortest path. i: {} , Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) WranglerLogger . debug ( \"calculating shortest path from graph\" ) sp_found = _shortest_path () if not sp_found : WranglerLogger . info ( \"No shortest path found with {} , trying greater breadth until SP found\" . format ( i ) ) while not sp_found and i <= RoadwayNetwork . MAX_SEARCH_BREADTH : WranglerLogger . debug ( \"Adding breadth, with shortest path iteration. i: {} Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) sp_found = _shortest_path () if sp_found : # reselect from the links in the shortest path, the ones with # the desired values....ignoring name. if len ( selection [ \"link\" ]) > 1 : resel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ignore = [ \"name\" ], ) WranglerLogger . info ( \"Reselecting features: \\n {} \" . format ( resel_query )) self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] . query ( resel_query , engine = \"python\" ) else : self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True # Return pandas.Series of links_ids return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : WranglerLogger . error ( \"Couldn't find path from {} to {} \" . format ( A_id , B_id ) ) raise ValueError else : # unique identifier exists and no need to go through big search self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"candidate_links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () def validate_properties ( self , properties : dict , ignore_existing : bool = False , require_existing_for_change : bool = False , ) -> bool : \"\"\" If there are change or existing commands, make sure that that property exists in the network. Args: properties : properties dictionary to be evaluated ignore_existing: If True, will only warn about properties that specify an \"existing\" value. If False, will fail. require_existing_for_change: If True, will fail if there isn't a specified value in theproject card for existing when a change is specified. Returns: boolean value as to whether the properties dictonary is valid. \"\"\" validation_error_message = [] for p in properties : if p [ \"property\" ] not in self . links_df . columns : if p . get ( \"change\" ): validation_error_message . append ( '\"Change\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"existing\" ) and not ignore_existing : validation_error_message . append ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) elif p . get ( \"existing\" ): WranglerLogger . warning ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"change\" ) and not p . get ( \"existing\" ): if require_existing_for_change : validation_error_message . append ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n To proceed, run with the setting require_existing_for_change=False' . format ( p [ \"property\" ] ) ) else : WranglerLogger . warning ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n ' . format ( p [ \"property\" ] ) ) if validation_error_message : WranglerLogger . error ( \" \" . join ( validation_error_message )) raise ValueError () def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a roadway network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Roadway Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if project_dictionary [ \"category\" ] . lower () == \"roadway property change\" : self . apply_roadway_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : self . apply_managed_lane_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"add new roadway\" : self . add_new_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : self . delete_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"calculated roadway\" : self . apply_python_calculation ( project_dictionary [ 'pycode' ] ) else : raise ( BaseException ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary ) def apply_python_calculation ( self , pycode : str , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes roadway network object by executing pycode. Args: pycode: python code which changes values in the roadway network object in_place: update self or return a new roadway network object \"\"\" exec ( pycode ) def apply_roadway_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes the roadway attributes for the selected features based on the project card information passed Args: link_idx : list lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean update self or return a new roadway network object \"\"\" # check if there are change or existing commands that that property # exists in the network # if there is a set command, add that property to network self . validate_properties ( properties ) for i , p in enumerate ( properties ): attribute = p [ \"property\" ] # if project card specifies an existing value in the network # check and see if the existing value in the network matches if p . get ( \"existing\" ): network_values = self . links_df . loc [ link_idx , attribute ] . tolist () if not set ( network_values ) . issubset ([ p . get ( \"existing\" )]): WranglerLogger . warning ( \"Existing value defined for {} in project card does \" \"not match the value in the roadway network for the \" \"selected links\" . format ( attribute ) ) if in_place : if \"set\" in p . keys (): self . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : self . links_df . loc [ link_idx , attribute ] = ( self . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) else : if i == 0 : updated_network = copy . deepcopy ( self ) if \"set\" in p . keys (): updated_network . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : updated_network . links_df . loc [ link_idx , attribute ] = ( updated_network . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) if i == len ( properties ) - 1 : return updated_network def apply_managed_lane_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Apply the managed lane feature changes to the roadway network Args: link_idx : list of lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean to indicate whether to update self or return a new roadway network object .. todo:: decide on connectors info when they are more specific in project card \"\"\" # add ML flag if \"managed\" in self . links_df . columns : self . links_df . loc [ link_idx , \"managed\" ] = 1 else : self . links_df [ \"managed\" ] = 0 self . links_df . loc [ link_idx , \"managed\" ] = 1 for p in properties : attribute = p [ \"property\" ] if \"group\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for g in p [ \"group\" ]: category = g [ \"category\" ] for tod in g [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"category\" : category , \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ], } ) elif \"timeofday\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for tod in p [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ]} ) elif \"set\" in p . keys (): attr_value = p [ \"set\" ] else : attr_value = \"\" # TODO: decide on connectors info when they are more specific in project card if attribute == \"ML_ACCESS\" and attr_value == \"all\" : attr_value = 1 if attribute == \"ML_EGRESS\" and attr_value == \"all\" : attr_value = 1 if in_place : if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object self . links_df [ attribute ] = self . links_df [ attribute ] . astype ( object ) if attribute not in self . links_df . columns : # if it is a new attribute then initiate with NaN values self . links_df [ attribute ] = \"NaN\" for idx in link_idx : self . links_df . at [ idx , attribute ] = attr_value else : if i == 0 : updated_network = copy . deepcopy ( self ) if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object updated_network . links_df [ attribute ] = updated_network . links_df [ attribute ] . astype ( object ) if attribute not in updated_network . links_df . columns : # if it is a new attribute then initiate with NaN values updated_network . links_df [ attribute ] = \"NaN\" for idx in link_idx : updated_network . links_df . at [ idx , attribute ] = attr_value if i == len ( properties ) - 1 : return updated_network def add_new_roadway_feature_change ( self , links : dict , nodes : dict ) -> None : \"\"\" add the new roadway features defined in the project card. new shapes are also added for the new roadway links. args: links : list of dictionaries nodes : list of dictionaries returns: None .. todo:: validate links and nodes dictionary \"\"\" def _add_dict_to_df ( df , new_dict ): df_column_names = df . columns new_row_to_add = {} # add the fields from project card that are in the network for property in df_column_names : if property in new_dict . keys (): if df [ property ] . dtype == np . float64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"float\" ) elif df [ property ] . dtype == np . int64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"integer\" ) else : value = str ( new_dict [ property ]) else : value = \"\" new_row_to_add [ property ] = value # add the fields from project card that are NOT in the network for key , value in new_dict . items (): if key not in df_column_names : new_row_to_add [ key ] = new_dict [ key ] out_df = df . append ( new_row_to_add , ignore_index = True ) return out_df if nodes is not None : for node in nodes : if node . get ( RoadwayNetwork . NODE_FOREIGN_KEY ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) raise ValueError ( msg ) node_query = ( RoadwayNetwork . UNIQUE_NODE_KEY + \" == \" + str ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ]) ) if not self . nodes_df . query ( node_query , engine = \"python\" ) . empty : msg = \"Node with id = {} already exist in the network\" . format ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for node in nodes : self . nodes_df = _add_dict_to_df ( self . nodes_df , node ) if links is not None : for link in links : for key in RoadwayNetwork . LINK_FOREIGN_KEY : if link . get ( key ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( key ) WranglerLogger . error ( msg ) raise ValueError ( msg ) ab_query = \"A == \" + str ( link [ \"A\" ]) + \" and B == \" + str ( link [ \"B\" ]) if not self . links_df . query ( ab_query , engine = \"python\" ) . empty : msg = \"Link with A = {} and B = {} already exist in the network\" . format ( link [ \"A\" ], link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"A\" ] ] . empty : msg = \"New link to add has A node = {} but the node does not exist in the network\" . format ( link [ \"A\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"B\" ] ] . empty : msg = \"New link to add has B node = {} but the node does not exist in the network\" . format ( link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for link in links : link [ \"new_link\" ] = 1 self . links_df = _add_dict_to_df ( self . links_df , link ) # add location reference and geometry for new links self . links_df [ \"locationReferences\" ] = self . links_df . apply ( lambda x : create_location_reference_from_nodes ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"A\" ] ] . squeeze (), self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"B\" ] ] . squeeze (), ) if x [ \"new_link\" ] == 1 else x [ \"locationReferences\" ], axis = 1 , ) self . links_df [ \"geometry\" ] = self . links_df . apply ( lambda x : create_line_string ( x [ \"locationReferences\" ]) if x [ \"new_link\" ] == 1 else x [ \"geometry\" ], axis = 1 , ) self . links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = self . links_df . apply ( lambda x : create_unique_shape_id ( x [ \"geometry\" ]) if x [ \"new_link\" ] == 1 else x [ RoadwayNetwork . UNIQUE_SHAPE_KEY ], axis = 1 , ) # add new shapes added_links = self . links_df [ self . links_df [ \"new_link\" ] == 1 ] added_shapes_df = pd . DataFrame ({ \"geometry\" : added_links [ \"geometry\" ]}) added_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = added_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) self . shapes_df = self . shapes_df . append ( added_shapes_df ) self . links_df . drop ([ \"new_link\" ], axis = 1 , inplace = True ) def delete_roadway_feature_change ( self , links : dict , nodes : dict , ignore_missing = True ) -> None : \"\"\" delete the roadway features defined in the project card. valid links and nodes defined in the project gets deleted and shapes corresponding to the deleted links are also deleted. Args: links : dict list of dictionaries nodes : dict list of dictionaries ignore_missing: bool If True, will only warn about links/nodes that are missing from network but specified to \"delete\" in project card If False, will fail. \"\"\" missing_error_message = [] if links is not None : shapes_to_delete = [] for key , val in links . items (): missing_links = [ v for v in val if v not in self . links_df [ key ] . tolist ()] if missing_links : message = \"Links attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] shapes_to_delete . extend ( deleted_links [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . tolist () ) self . links_df . drop ( self . links_df . index [ self . links_df [ key ] . isin ( val )], inplace = True ) self . shapes_df . drop ( self . shapes_df . index [ self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . isin ( shapes_to_delete ) ], inplace = True , ) if nodes is not None : for key , val in nodes . items (): missing_nodes = [ v for v in val if v not in self . nodes_df [ key ] . tolist ()] if missing_nodes : message = \"Nodes attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) self . nodes_df = self . nodes_df [ ~ self . nodes_df [ key ] . isin ( val )] if missing_error_message : WranglerLogger . error ( \" \" . join ( missing_error_message )) raise ValueError () def get_property_by_time_period_and_group ( self , property , time_period = None , category = None ): \"\"\" Return a series for the properties with a specific group or time period. args ------ property: str the variable that you want from network time_period: list(str) the time period that you are querying for i.e. ['16:00', '19:00'] category: str or list(str)(Optional) the group category i.e. \"sov\" or list of group categories in order of search, i.e. [\"hov3\",\"hov2\"] returns -------- pandas series \"\"\" def _get_property ( v , time_spans = None , category = None , return_partial_match : bool = False , partial_match_minutes : int = 60 , ): \"\"\" .. todo:: return the time period with the largest overlap \"\"\" if category and not time_spans : WranglerLogger . error ( \" \\n Shouldn't have a category group without time spans\" ) raise ValueError ( \"Shouldn't have a category group without time spans\" ) # simple case if type ( v ) in ( int , float , str ): return v if not category : category = [ \"default\" ] elif isinstance ( category , str ): category = [ category ] search_cats = [ c . lower () for c in category ] # if no time or group specified, but it is a complex link situation if not time_spans : if \"default\" in v . keys (): return v [ \"default\" ] else : WranglerLogger . debug ( \"variable: \" . format ( v )) msg = \"Variable {} is more complex in network than query\" . format ( v ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if v . get ( \"timeofday\" ): categories = [] for tg in v [ \"timeofday\" ]: if ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ] ): if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", time_spans, category, tg[\"value\"] # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] # if there isn't a fully matched time period, see if there is an overlapping one # right now just return the first overlapping ones # TODO return the time period with the largest overlap if ( ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 0 ] <= tg [ \"time\" ][ 1 ]) ) or ( ( time_spans [ 1 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ]) ): overlap_minutes = max ( 0 , min ( tg [ \"time\" ][ 1 ], time_spans [ 1 ]) - max ( time_spans [ 0 ], tg [ \"time\" ][ 0 ]), ) # print(\"OLM\",overlap_minutes) if not return_partial_match and overlap_minutes > 0 : WranglerLogger . debug ( \"Couldn't find time period consistent with {} , but found a partial match: {} . Consider allowing partial matches using 'return_partial_match' keyword or updating query.\" . format ( time_spans , tg [ \"time\" ] ) ) elif ( overlap_minutes < partial_match_minutes and overlap_minutes > 0 ): WranglerLogger . debug ( \"Time period: {} overlapped less than the minimum number of minutes ( {} < {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) elif overlap_minutes > 0 : WranglerLogger . debug ( \"Returning a partial time period match. Time period: {} overlapped the minimum number of minutes ( {} >= {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", # time_spans, # category, # tg[\"value\"], # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] \"\"\" WranglerLogger.debug( \"\\nCouldn't find time period for {}, returning default\".format( str(time_spans) ) ) \"\"\" if \"default\" in v . keys (): # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, v[\"default\"]) return v [ \"default\" ] else : # print(\"Var:\", v) WranglerLogger . error ( \" \\n Can't find default; must specify a category in {} \" . format ( str ( categories ) ) ) raise ValueError ( \"Can't find default, must specify a category in: {} \" . format ( str ( categories ) ) ) time_spans = parse_time_spans ( time_period ) return self . links_df [ property ] . apply ( _get_property , time_spans = time_spans , category = category ) def create_dummy_connector_links ( gp_df : GeoDataFrame , ml_df : GeoDataFrame ): \"\"\" create dummy connector links between the general purpose and managed lanes args: gp_df : GeoDataFrame dataframe of general purpose links (where managed lane also exists) ml_df : GeoDataFrame dataframe of corresponding managed lane links \"\"\" gp_ml_links_df = pd . concat ( [ gp_df , ml_df . add_prefix ( \"ML_\" )], axis = 1 , join = \"inner\" ) access_df = gp_df . iloc [ 0 : 0 , :] . copy () egress_df = gp_df . iloc [ 0 : 0 , :] . copy () def _get_connector_references ( ref_1 : list , ref_2 : list , type : str ): if type == \"access\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_1 [ 0 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_2 [ 0 ][ \"point\" ]}, ] if type == \"egress\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_2 [ 1 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_1 [ 1 ][ \"point\" ]}, ] return out_location_reference for index , row in gp_ml_links_df . iterrows (): access_row = {} access_row [ \"A\" ] = row [ \"A\" ] access_row [ \"B\" ] = row [ \"ML_A\" ] access_row [ \"lanes\" ] = 1 access_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 1 ) access_row [ \"access\" ] = row [ \"ML_access\" ] access_row [ \"drive_access\" ] = row [ \"drive_access\" ] access_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"access\" ) access_row [ \"distance\" ] = haversine_distance ( access_row [ \"locationReferences\" ][ 0 ][ \"point\" ], access_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) access_row [ \"roadway\" ] = \"ml_access\" access_row [ \"name\" ] = \"Access Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : access_row [ \"ref\" ] = row [ \"ref\" ] else : access_row [ \"ref\" ] = \"\" access_df = access_df . append ( access_row , ignore_index = True ) egress_row = {} egress_row [ \"A\" ] = row [ \"ML_B\" ] egress_row [ \"B\" ] = row [ \"B\" ] egress_row [ \"lanes\" ] = 1 egress_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 2 ) egress_row [ \"access\" ] = row [ \"ML_access\" ] egress_row [ \"drive_access\" ] = row [ \"drive_access\" ] egress_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"egress\" ) egress_row [ \"distance\" ] = haversine_distance ( egress_row [ \"locationReferences\" ][ 0 ][ \"point\" ], egress_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) egress_row [ \"roadway\" ] = \"ml_egress\" egress_row [ \"name\" ] = \"Egress Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : egress_row [ \"ref\" ] = row [ \"ref\" ] else : egress_row [ \"ref\" ] = \"\" egress_df = egress_df . append ( egress_row , ignore_index = True ) return ( access_df , egress_df ) def create_managed_lane_network ( self , in_place : bool = False ) -> RoadwayNetwork : \"\"\" Create a roadway network with managed lanes links separated out. Add new parallel managed lane links, access/egress links, and add shapes corresponding to the new links args: in_place: update self or return a new roadway network object returns: A RoadwayNetwork instance .. todo:: make this a more rigorous test \"\"\" WranglerLogger . info ( \"Creating network with duplicated managed lanes\" ) if \"ml_access\" in self . links_df [ \"roadway\" ] . tolist (): msg = \"managed lane access links already exist in network; shouldn't be running create managed lane network. Returning network as-is.\" WranglerLogger . error ( msg ) if in_place : return else : return copy . deepcopy ( self ) link_attributes = self . links_df . columns . values . tolist () ml_attributes = [ i for i in link_attributes if i . startswith ( \"ML_\" )] # non_ml_links are links in the network where there is no managed lane. # gp_links are the gp lanes and ml_links are ml lanes respectively for the ML roadways. non_ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 0 ] non_ml_links_df = non_ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 1 ] gp_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) for attr in link_attributes : if attr == \"name\" : ml_links_df [ \"name\" ] = \"Managed Lane \" + gp_links_df [ \"name\" ] elif attr in ml_attributes and attr not in [ \"ML_ACCESS\" , \"ML_EGRESS\" ]: gp_attr = attr . split ( \"_\" , 1 )[ 1 ] ml_links_df . loc [:, gp_attr ] = ml_links_df [ attr ] if ( attr not in RoadwayNetwork . KEEP_SAME_ATTRIBUTES_ML_AND_GP and attr not in RoadwayNetwork . MANAGED_LANES_REQUIRED_ATTRIBUTES ): ml_links_df [ attr ] = \"\" ml_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df [ \"managed\" ] = 1 gp_links_df [ \"managed\" ] = 0 def _update_location_reference ( location_reference : list ): out_location_reference = copy . deepcopy ( location_reference ) out_location_reference [ 0 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 0 ][ \"point\" ] ) out_location_reference [ 1 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 1 ][ \"point\" ] ) return out_location_reference ml_links_df [ \"A\" ] = ( ml_links_df [ \"A\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ \"B\" ] = ( ml_links_df [ \"B\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] = ( ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] + RoadwayNetwork . MANAGED_LANES_LINK_ID_SCALAR ) ml_links_df [ \"locationReferences\" ] = ml_links_df [ \"locationReferences\" ] . apply ( # lambda x: _update_location_reference(x) lambda x : offset_location_reference ( x ) ) ml_links_df [ \"geometry\" ] = ml_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) ml_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = ml_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x ) ) access_links_df , egress_links_df = RoadwayNetwork . create_dummy_connector_links ( gp_links_df , ml_links_df ) access_links_df [ \"geometry\" ] = access_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) egress_links_df [ \"geometry\" ] = egress_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) access_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = access_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) egress_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = egress_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_links_df = gp_links_df . append ( ml_links_df ) out_links_df = out_links_df . append ( access_links_df ) out_links_df = out_links_df . append ( egress_links_df ) out_links_df = out_links_df . append ( non_ml_links_df ) # only the ml_links_df has the new nodes added added_a_nodes = ml_links_df [ \"A\" ] added_b_nodes = ml_links_df [ \"B\" ] out_nodes_df = self . nodes_df for a_node in added_a_nodes : out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : a_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"A\" ] == a_node ] . iloc [ 0 ][ \"locationReferences\" ][ 0 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) for b_node in added_b_nodes : if b_node not in out_nodes_df [ \"model_node_id\" ] . tolist (): out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : b_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"B\" ] == b_node ] . iloc [ 0 ][ \"locationReferences\" ][ 1 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) out_nodes_df [ \"X\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) out_nodes_df [ \"Y\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) out_shapes_df = self . shapes_df # managed lanes, access and egress connectors are new geometry new_shapes_df = pd . DataFrame ( { \"geometry\" : ml_links_df [ \"geometry\" ] . append ( access_links_df [ \"geometry\" ]) . append ( egress_links_df [ \"geometry\" ]) } ) new_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = new_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_shapes_df = out_shapes_df . append ( new_shapes_df ) out_links_df = out_links_df . reset_index () out_nodes_df = out_nodes_df . reset_index () out_shapes_df = out_shapes_df . reset_index () if in_place : self . links_df = out_links_df self . nodes_df = out_nodes_df self . shapes_df = out_shapes_df else : out_network = copy . deepcopy ( self ) out_network . links_df = out_links_df out_network . nodes_df = out_nodes_df out_network . shapes_df = out_shapes_df return out_network @staticmethod def get_modal_links_nodes ( links_df : DataFrame , nodes_df : DataFrame , modes : list [ str ] = None ) -> tuple ( DataFrame , DataFrame ): \"\"\"Returns nodes and link dataframes for specific mode. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes modes: list of the modes of the network to be kept, must be in `drive`,`transit`,`rail`,`bus`, `walk`, `bike`. For example, if bike and walk are selected, both bike and walk links will be kept. Returns: tuple of DataFrames for links, nodes filtered by mode .. todo:: Right now we don't filter the nodes because transit-only links with walk access are not marked as having walk access Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] \"\"\" for mode in modes : if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} , got {} \" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()), mode , ) WranglerLogger . error ( msg ) raise ValueError ( msg ) mode_link_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ mode ] ] ) ) mode_node_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_NODE_VARIABLES [ mode ] ] ) ) if not set ( mode_link_variables ) . issubset ( set ( links_df . columns )): msg = \" {} not in provided links_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_link_variables ) - set ( links_df . columns ), links_df . columns ) WranglerLogger . error ( msg ) if not set ( mode_node_variables ) . issubset ( set ( nodes_df . columns )): msg = \" {} not in provided nodes_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_node_variables ) - set ( nodes_df . columns ), nodes_df . columns ) WranglerLogger . error ( msg ) modal_links_df = links_df . loc [ links_df [ mode_link_variables ] . any ( axis = 1 )] ##TODO right now we don't filter the nodes because transit-only # links with walk access are not marked as having walk access # Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 # modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] modal_nodes_df = nodes_df return modal_links_df , modal_nodes_df @staticmethod def get_modal_graph ( links_df : DataFrame , nodes_df : DataFrame , mode : str = None ): \"\"\"Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` Returns: networkx: osmnx: DiGraph of network \"\"\" if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} .\" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( links_df , nodes_df , modes = [ mode ], ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) return G def is_network_connected ( self , mode : str = None , links_df : DataFrame = None , nodes_df : DataFrame = None ): \"\"\" Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes Returns: boolean .. todo:: Consider caching graphs if they take a long time. \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) # TODO: consider caching graphs if they start to take forever # and we are calling them more than once. G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) is_connected = nx . is_strongly_connected ( G ) return is_connected def assess_connectivity ( self , mode : str = \"\" , ignore_end_nodes : bool = True , links_df : DataFrame = None , nodes_df : DataFrame = None , ): \"\"\"Returns a network graph and list of disconnected subgraphs as described by a list of their member nodes. Args: mode: list of modes of the network, one of `drive`,`transit`, `walk`, `bike` ignore_end_nodes: if True, ignores stray singleton nodes links_df: if specified, will assess connectivity of this links list rather than self.links_df nodes_df: if specified, will assess connectivity of this nodes list rather than self.nodes_df Returns: Tuple of Network Graph (osmnx flavored networkX DiGraph) List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`) \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) # sub_graphs = [s for s in sorted(nx.strongly_connected_component_subgraphs(G), key=len, reverse=True)] sub_graphs = [ s for s in sorted ( ( G . subgraph ( c ) for c in nx . strongly_connected_components ( G )), key = len , reverse = True , ) ] sub_graph_nodes = [ list ( s ) for s in sorted ( nx . strongly_connected_components ( G ), key = len , reverse = True ) ] # sorted on decreasing length, dropping the main sub-graph disconnected_sub_graph_nodes = sub_graph_nodes [ 1 :] # dropping the sub-graphs with only 1 node if ignore_end_nodes : disconnected_sub_graph_nodes = [ list ( s ) for s in disconnected_sub_graph_nodes if len ( s ) > 1 ] WranglerLogger . info ( \" {} for disconnected networks for mode = {} : \\n {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY , mode , \" \\n \" . join ( list ( map ( str , disconnected_sub_graph_nodes ))), ) ) return G , disconnected_sub_graph_nodes @staticmethod def network_connection_plot ( G , disconnected_subgraph_nodes : list ): \"\"\"Plot a graph to check for network connection. Args: G: OSMNX flavored networkX graph. disconnected_subgraph_nodes: List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`). returns: fig, ax : tuple \"\"\" colors = [] for i in range ( len ( disconnected_subgraph_nodes )): colors . append ( \"# %06X \" % randint ( 0 , 0xFFFFFF )) fig , ax = ox . plot_graph ( G , figsize = ( 16 , 16 ), show = False , close = True , edge_color = \"black\" , edge_alpha = 0.1 , node_color = \"black\" , node_alpha = 0.5 , node_size = 10 , ) i = 0 for nodes in disconnected_subgraph_nodes : for n in nodes : size = 100 ax . scatter ( G . nodes [ n ][ \"X\" ], G . nodes [ n ][ \"Y\" ], c = colors [ i ], s = size ) i = i + 1 return fig , ax def selection_map ( self , selected_link_idx : list , A : Optional [ Any ] = None , B : Optional [ Any ] = None , candidate_link_idx : Optional [ List ] = [], ): \"\"\" Shows which links are selected for roadway property change or parallel managed lanes category of roadway projects. Args: selected_links_idx: list of selected link indices candidate_links_idx: optional list of candidate link indices to also include in map A: optional foreign key of starting node of a route selection B: optional foreign key of ending node of a route selection \"\"\" WranglerLogger . debug ( \"Selected Links: {} \\n Candidate Links: {} \\n \" . format ( selected_link_idx , candidate_link_idx ) ) graph_link_idx = list ( set ( selected_link_idx + candidate_link_idx )) graph_links = self . links_df . loc [ graph_link_idx ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( graph_links [ fk ]) ] ) ) graph_nodes = self . nodes_df . loc [ node_list_foreign_keys ] G = RoadwayNetwork . ox_graph ( graph_nodes , graph_links ) # base map plot with whole graph m = ox . plot_graph_folium ( G , edge_color = None , tiles = \"cartodbpositron\" , width = \"300px\" , height = \"250px\" ) # plot selection selected_links = self . links_df . loc [ selected_link_idx ] for _ , row in selected_links . iterrows (): pl = ox . folium . _make_folium_polyline ( edge = row , edge_color = \"blue\" , edge_width = 5 , edge_opacity = 0.8 ) pl . add_to ( m ) # if have A and B node add them to base map def _folium_node ( node_row , color = \"white\" , icon = \"\" ): node_marker = folium . Marker ( location = [ node_row [ \"Y\" ], node_row [ \"X\" ]], icon = folium . Icon ( icon = icon , color = color ), ) return node_marker if A : # WranglerLogger.debug(\"A: {}\\n{}\".format(A,self.nodes_df[self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY] == A])) _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == A ], color = \"green\" , icon = \"play\" , ) . add_to ( m ) if B : _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == B ], color = \"red\" , icon = \"star\" , ) . add_to ( m ) return m def deletion_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are deleted from the roadway network \"\"\" # deleted_links = None # deleted_nodes = None missing_error_message = [] if links is not None : for key , val in links . items (): deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( deleted_links [ fk ]) ] ) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] else : deleted_links = None if nodes is not None : for key , val in nodes . items (): deleted_nodes = self . nodes_df [ self . nodes_df [ key ] . isin ( val )] else : deleted_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , deleted_links ) m = ox . plot_graph_folium ( G , edge_color = \"red\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if deleted_nodes is not None : for _ , row in deleted_nodes . iterrows (): _folium_node ( row , color = \"red\" ) . add_to ( m ) return m def addition_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are added to the roadway network \"\"\" if links is not None : link_ids = [] for link in links : link_ids . append ( link . get ( RoadwayNetwork . UNIQUE_LINK_KEY )) added_links = self . links_df [ self . links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] . isin ( link_ids ) ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( added_links [ fk ]) ] ) ) try : candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] except : return None if nodes is not None : node_ids = [] for node in nodes : node_ids . append ( node . get ( RoadwayNetwork . UNIQUE_NODE_KEY )) added_nodes = self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] . isin ( node_ids ) ] else : added_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , added_links ) m = ox . plot_graph_folium ( G , edge_color = \"green\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if added_nodes is not None : for _ , row in added_nodes . iterrows (): _folium_node ( row , color = \"green\" ) . add_to ( m ) return m __init__ ( nodes , links , shapes ) \u00b6 Constructor Source code in network_wrangler/roadwaynetwork.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def __init__ ( self , nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Constructor \"\"\" if not RoadwayNetwork . validate_object_types ( nodes , links , shapes ): sys . exit ( \"RoadwayNetwork: Invalid constructor data type\" ) self . nodes_df = nodes self . links_df = links self . shapes_df = shapes self . link_file = None self . node_file = None self . shape_file = None # Add non-required fields if they aren't there. # for field, default_value in RoadwayNetwork.OPTIONAL_FIELDS: # if field not in self.links_df.columns: # self.links_df[field] = default_value if not self . validate_uniqueness (): raise ValueError ( \"IDs in network not unique\" ) self . selections = {} add_new_roadway_feature_change ( links , nodes ) \u00b6 add the new roadway features defined in the project card. new shapes are also added for the new roadway links. Parameters: Name Type Description Default links list of dictionaries required nodes list of dictionaries required .. todo:: validate links and nodes dictionary Source code in network_wrangler/roadwaynetwork.py 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 def add_new_roadway_feature_change ( self , links : dict , nodes : dict ) -> None : \"\"\" add the new roadway features defined in the project card. new shapes are also added for the new roadway links. args: links : list of dictionaries nodes : list of dictionaries returns: None .. todo:: validate links and nodes dictionary \"\"\" def _add_dict_to_df ( df , new_dict ): df_column_names = df . columns new_row_to_add = {} # add the fields from project card that are in the network for property in df_column_names : if property in new_dict . keys (): if df [ property ] . dtype == np . float64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"float\" ) elif df [ property ] . dtype == np . int64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"integer\" ) else : value = str ( new_dict [ property ]) else : value = \"\" new_row_to_add [ property ] = value # add the fields from project card that are NOT in the network for key , value in new_dict . items (): if key not in df_column_names : new_row_to_add [ key ] = new_dict [ key ] out_df = df . append ( new_row_to_add , ignore_index = True ) return out_df if nodes is not None : for node in nodes : if node . get ( RoadwayNetwork . NODE_FOREIGN_KEY ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) raise ValueError ( msg ) node_query = ( RoadwayNetwork . UNIQUE_NODE_KEY + \" == \" + str ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ]) ) if not self . nodes_df . query ( node_query , engine = \"python\" ) . empty : msg = \"Node with id = {} already exist in the network\" . format ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for node in nodes : self . nodes_df = _add_dict_to_df ( self . nodes_df , node ) if links is not None : for link in links : for key in RoadwayNetwork . LINK_FOREIGN_KEY : if link . get ( key ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( key ) WranglerLogger . error ( msg ) raise ValueError ( msg ) ab_query = \"A == \" + str ( link [ \"A\" ]) + \" and B == \" + str ( link [ \"B\" ]) if not self . links_df . query ( ab_query , engine = \"python\" ) . empty : msg = \"Link with A = {} and B = {} already exist in the network\" . format ( link [ \"A\" ], link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"A\" ] ] . empty : msg = \"New link to add has A node = {} but the node does not exist in the network\" . format ( link [ \"A\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"B\" ] ] . empty : msg = \"New link to add has B node = {} but the node does not exist in the network\" . format ( link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for link in links : link [ \"new_link\" ] = 1 self . links_df = _add_dict_to_df ( self . links_df , link ) # add location reference and geometry for new links self . links_df [ \"locationReferences\" ] = self . links_df . apply ( lambda x : create_location_reference_from_nodes ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"A\" ] ] . squeeze (), self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"B\" ] ] . squeeze (), ) if x [ \"new_link\" ] == 1 else x [ \"locationReferences\" ], axis = 1 , ) self . links_df [ \"geometry\" ] = self . links_df . apply ( lambda x : create_line_string ( x [ \"locationReferences\" ]) if x [ \"new_link\" ] == 1 else x [ \"geometry\" ], axis = 1 , ) self . links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = self . links_df . apply ( lambda x : create_unique_shape_id ( x [ \"geometry\" ]) if x [ \"new_link\" ] == 1 else x [ RoadwayNetwork . UNIQUE_SHAPE_KEY ], axis = 1 , ) # add new shapes added_links = self . links_df [ self . links_df [ \"new_link\" ] == 1 ] added_shapes_df = pd . DataFrame ({ \"geometry\" : added_links [ \"geometry\" ]}) added_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = added_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) self . shapes_df = self . shapes_df . append ( added_shapes_df ) self . links_df . drop ([ \"new_link\" ], axis = 1 , inplace = True ) addition_map ( links , nodes ) \u00b6 Shows which links and nodes are added to the roadway network Source code in network_wrangler/roadwaynetwork.py 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 def addition_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are added to the roadway network \"\"\" if links is not None : link_ids = [] for link in links : link_ids . append ( link . get ( RoadwayNetwork . UNIQUE_LINK_KEY )) added_links = self . links_df [ self . links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] . isin ( link_ids ) ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( added_links [ fk ]) ] ) ) try : candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] except : return None if nodes is not None : node_ids = [] for node in nodes : node_ids . append ( node . get ( RoadwayNetwork . UNIQUE_NODE_KEY )) added_nodes = self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] . isin ( node_ids ) ] else : added_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , added_links ) m = ox . plot_graph_folium ( G , edge_color = \"green\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if added_nodes is not None : for _ , row in added_nodes . iterrows (): _folium_node ( row , color = \"green\" ) . add_to ( m ) return m apply ( project_card_dictionary ) \u00b6 Wrapper method to apply a project to a roadway network. Parameters: Name Type Description Default project_card_dictionary dict dict a dictionary of the project card object required Source code in network_wrangler/roadwaynetwork.py 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a roadway network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Roadway Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if project_dictionary [ \"category\" ] . lower () == \"roadway property change\" : self . apply_roadway_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : self . apply_managed_lane_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"add new roadway\" : self . add_new_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : self . delete_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"calculated roadway\" : self . apply_python_calculation ( project_dictionary [ 'pycode' ] ) else : raise ( BaseException ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary ) apply_managed_lane_feature_change ( link_idx , properties , in_place = True ) \u00b6 Apply the managed lane feature changes to the roadway network Parameters: Name Type Description Default link_idx list of lndices of all links to apply change to required properties list of dictionarys roadway properties to change required in_place bool boolean to indicate whether to update self or return a new roadway network object True .. todo:: decide on connectors info when they are more specific in project card Source code in network_wrangler/roadwaynetwork.py 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 def apply_managed_lane_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Apply the managed lane feature changes to the roadway network Args: link_idx : list of lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean to indicate whether to update self or return a new roadway network object .. todo:: decide on connectors info when they are more specific in project card \"\"\" # add ML flag if \"managed\" in self . links_df . columns : self . links_df . loc [ link_idx , \"managed\" ] = 1 else : self . links_df [ \"managed\" ] = 0 self . links_df . loc [ link_idx , \"managed\" ] = 1 for p in properties : attribute = p [ \"property\" ] if \"group\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for g in p [ \"group\" ]: category = g [ \"category\" ] for tod in g [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"category\" : category , \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ], } ) elif \"timeofday\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for tod in p [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ]} ) elif \"set\" in p . keys (): attr_value = p [ \"set\" ] else : attr_value = \"\" # TODO: decide on connectors info when they are more specific in project card if attribute == \"ML_ACCESS\" and attr_value == \"all\" : attr_value = 1 if attribute == \"ML_EGRESS\" and attr_value == \"all\" : attr_value = 1 if in_place : if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object self . links_df [ attribute ] = self . links_df [ attribute ] . astype ( object ) if attribute not in self . links_df . columns : # if it is a new attribute then initiate with NaN values self . links_df [ attribute ] = \"NaN\" for idx in link_idx : self . links_df . at [ idx , attribute ] = attr_value else : if i == 0 : updated_network = copy . deepcopy ( self ) if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object updated_network . links_df [ attribute ] = updated_network . links_df [ attribute ] . astype ( object ) if attribute not in updated_network . links_df . columns : # if it is a new attribute then initiate with NaN values updated_network . links_df [ attribute ] = \"NaN\" for idx in link_idx : updated_network . links_df . at [ idx , attribute ] = attr_value if i == len ( properties ) - 1 : return updated_network apply_python_calculation ( pycode , in_place = True ) \u00b6 Changes roadway network object by executing pycode. Parameters: Name Type Description Default pycode str python code which changes values in the roadway network object required in_place bool update self or return a new roadway network object True Source code in network_wrangler/roadwaynetwork.py 1255 1256 1257 1258 1259 1260 1261 1262 1263 def apply_python_calculation ( self , pycode : str , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes roadway network object by executing pycode. Args: pycode: python code which changes values in the roadway network object in_place: update self or return a new roadway network object \"\"\" exec ( pycode ) apply_roadway_feature_change ( link_idx , properties , in_place = True ) \u00b6 Changes the roadway attributes for the selected features based on the project card information passed Parameters: Name Type Description Default link_idx list lndices of all links to apply change to required properties list of dictionarys roadway properties to change required in_place bool boolean update self or return a new roadway network object True Source code in network_wrangler/roadwaynetwork.py 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 def apply_roadway_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes the roadway attributes for the selected features based on the project card information passed Args: link_idx : list lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean update self or return a new roadway network object \"\"\" # check if there are change or existing commands that that property # exists in the network # if there is a set command, add that property to network self . validate_properties ( properties ) for i , p in enumerate ( properties ): attribute = p [ \"property\" ] # if project card specifies an existing value in the network # check and see if the existing value in the network matches if p . get ( \"existing\" ): network_values = self . links_df . loc [ link_idx , attribute ] . tolist () if not set ( network_values ) . issubset ([ p . get ( \"existing\" )]): WranglerLogger . warning ( \"Existing value defined for {} in project card does \" \"not match the value in the roadway network for the \" \"selected links\" . format ( attribute ) ) if in_place : if \"set\" in p . keys (): self . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : self . links_df . loc [ link_idx , attribute ] = ( self . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) else : if i == 0 : updated_network = copy . deepcopy ( self ) if \"set\" in p . keys (): updated_network . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : updated_network . links_df . loc [ link_idx , attribute ] = ( updated_network . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) if i == len ( properties ) - 1 : return updated_network assess_connectivity ( mode = '' , ignore_end_nodes = True , links_df = None , nodes_df = None ) \u00b6 Returns a network graph and list of disconnected subgraphs as described by a list of their member nodes. Parameters: Name Type Description Default mode str list of modes of the network, one of drive , transit , walk , bike '' ignore_end_nodes bool if True, ignores stray singleton nodes True links_df DataFrame if specified, will assess connectivity of this links list rather than self.links_df None nodes_df DataFrame if specified, will assess connectivity of this nodes list rather than self.nodes_df None Tuple of Type Description Network Graph (osmnx flavored networkX DiGraph) List of disconnected subgraphs described by the list of their member nodes (as described by their model_node_id ) Source code in network_wrangler/roadwaynetwork.py 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 def assess_connectivity ( self , mode : str = \"\" , ignore_end_nodes : bool = True , links_df : DataFrame = None , nodes_df : DataFrame = None , ): \"\"\"Returns a network graph and list of disconnected subgraphs as described by a list of their member nodes. Args: mode: list of modes of the network, one of `drive`,`transit`, `walk`, `bike` ignore_end_nodes: if True, ignores stray singleton nodes links_df: if specified, will assess connectivity of this links list rather than self.links_df nodes_df: if specified, will assess connectivity of this nodes list rather than self.nodes_df Returns: Tuple of Network Graph (osmnx flavored networkX DiGraph) List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`) \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) # sub_graphs = [s for s in sorted(nx.strongly_connected_component_subgraphs(G), key=len, reverse=True)] sub_graphs = [ s for s in sorted ( ( G . subgraph ( c ) for c in nx . strongly_connected_components ( G )), key = len , reverse = True , ) ] sub_graph_nodes = [ list ( s ) for s in sorted ( nx . strongly_connected_components ( G ), key = len , reverse = True ) ] # sorted on decreasing length, dropping the main sub-graph disconnected_sub_graph_nodes = sub_graph_nodes [ 1 :] # dropping the sub-graphs with only 1 node if ignore_end_nodes : disconnected_sub_graph_nodes = [ list ( s ) for s in disconnected_sub_graph_nodes if len ( s ) > 1 ] WranglerLogger . info ( \" {} for disconnected networks for mode = {} : \\n {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY , mode , \" \\n \" . join ( list ( map ( str , disconnected_sub_graph_nodes ))), ) ) return G , disconnected_sub_graph_nodes build_selection_key ( selection_dict ) \u00b6 Selections are stored by a key combining the query and the A and B ids. This method combines the two for you based on the selection dictionary. Parameters: Name Type Description Default selection_dictonary Selection Dictionary required Source code in network_wrangler/roadwaynetwork.py 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 def build_selection_key ( self , selection_dict : dict ) -> tuple : \"\"\" Selections are stored by a key combining the query and the A and B ids. This method combines the two for you based on the selection dictionary. Args: selection_dictonary: Selection Dictionary Returns: Tuple serving as the selection key. \"\"\" sel_query = ProjectCard . build_link_selection_query ( selection = selection_dict , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , ) if RoadwayNetwork . selection_has_unique_link_id ( selection_dict ): return sel_query A_id , B_id = self . orig_dest_nodes_foreign_key ( selection_dict ) return ( sel_query , A_id , B_id ) create_dummy_connector_links ( gp_df , ml_df ) \u00b6 create dummy connector links between the general purpose and managed lanes Parameters: Name Type Description Default gp_df GeoDataFrame dataframe of general purpose links (where managed lane also exists) required ml_df GeoDataFrame dataframe of corresponding managed lane links required Source code in network_wrangler/roadwaynetwork.py 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 def create_dummy_connector_links ( gp_df : GeoDataFrame , ml_df : GeoDataFrame ): \"\"\" create dummy connector links between the general purpose and managed lanes args: gp_df : GeoDataFrame dataframe of general purpose links (where managed lane also exists) ml_df : GeoDataFrame dataframe of corresponding managed lane links \"\"\" gp_ml_links_df = pd . concat ( [ gp_df , ml_df . add_prefix ( \"ML_\" )], axis = 1 , join = \"inner\" ) access_df = gp_df . iloc [ 0 : 0 , :] . copy () egress_df = gp_df . iloc [ 0 : 0 , :] . copy () def _get_connector_references ( ref_1 : list , ref_2 : list , type : str ): if type == \"access\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_1 [ 0 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_2 [ 0 ][ \"point\" ]}, ] if type == \"egress\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_2 [ 1 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_1 [ 1 ][ \"point\" ]}, ] return out_location_reference for index , row in gp_ml_links_df . iterrows (): access_row = {} access_row [ \"A\" ] = row [ \"A\" ] access_row [ \"B\" ] = row [ \"ML_A\" ] access_row [ \"lanes\" ] = 1 access_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 1 ) access_row [ \"access\" ] = row [ \"ML_access\" ] access_row [ \"drive_access\" ] = row [ \"drive_access\" ] access_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"access\" ) access_row [ \"distance\" ] = haversine_distance ( access_row [ \"locationReferences\" ][ 0 ][ \"point\" ], access_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) access_row [ \"roadway\" ] = \"ml_access\" access_row [ \"name\" ] = \"Access Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : access_row [ \"ref\" ] = row [ \"ref\" ] else : access_row [ \"ref\" ] = \"\" access_df = access_df . append ( access_row , ignore_index = True ) egress_row = {} egress_row [ \"A\" ] = row [ \"ML_B\" ] egress_row [ \"B\" ] = row [ \"B\" ] egress_row [ \"lanes\" ] = 1 egress_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 2 ) egress_row [ \"access\" ] = row [ \"ML_access\" ] egress_row [ \"drive_access\" ] = row [ \"drive_access\" ] egress_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"egress\" ) egress_row [ \"distance\" ] = haversine_distance ( egress_row [ \"locationReferences\" ][ 0 ][ \"point\" ], egress_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) egress_row [ \"roadway\" ] = \"ml_egress\" egress_row [ \"name\" ] = \"Egress Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : egress_row [ \"ref\" ] = row [ \"ref\" ] else : egress_row [ \"ref\" ] = \"\" egress_df = egress_df . append ( egress_row , ignore_index = True ) return ( access_df , egress_df ) create_managed_lane_network ( in_place = False ) \u00b6 Create a roadway network with managed lanes links separated out. Add new parallel managed lane links, access/egress links, and add shapes corresponding to the new links Parameters: Name Type Description Default in_place bool update self or return a new roadway network object False .. todo:: make this a more rigorous test Source code in network_wrangler/roadwaynetwork.py 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 def create_managed_lane_network ( self , in_place : bool = False ) -> RoadwayNetwork : \"\"\" Create a roadway network with managed lanes links separated out. Add new parallel managed lane links, access/egress links, and add shapes corresponding to the new links args: in_place: update self or return a new roadway network object returns: A RoadwayNetwork instance .. todo:: make this a more rigorous test \"\"\" WranglerLogger . info ( \"Creating network with duplicated managed lanes\" ) if \"ml_access\" in self . links_df [ \"roadway\" ] . tolist (): msg = \"managed lane access links already exist in network; shouldn't be running create managed lane network. Returning network as-is.\" WranglerLogger . error ( msg ) if in_place : return else : return copy . deepcopy ( self ) link_attributes = self . links_df . columns . values . tolist () ml_attributes = [ i for i in link_attributes if i . startswith ( \"ML_\" )] # non_ml_links are links in the network where there is no managed lane. # gp_links are the gp lanes and ml_links are ml lanes respectively for the ML roadways. non_ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 0 ] non_ml_links_df = non_ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 1 ] gp_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) for attr in link_attributes : if attr == \"name\" : ml_links_df [ \"name\" ] = \"Managed Lane \" + gp_links_df [ \"name\" ] elif attr in ml_attributes and attr not in [ \"ML_ACCESS\" , \"ML_EGRESS\" ]: gp_attr = attr . split ( \"_\" , 1 )[ 1 ] ml_links_df . loc [:, gp_attr ] = ml_links_df [ attr ] if ( attr not in RoadwayNetwork . KEEP_SAME_ATTRIBUTES_ML_AND_GP and attr not in RoadwayNetwork . MANAGED_LANES_REQUIRED_ATTRIBUTES ): ml_links_df [ attr ] = \"\" ml_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df [ \"managed\" ] = 1 gp_links_df [ \"managed\" ] = 0 def _update_location_reference ( location_reference : list ): out_location_reference = copy . deepcopy ( location_reference ) out_location_reference [ 0 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 0 ][ \"point\" ] ) out_location_reference [ 1 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 1 ][ \"point\" ] ) return out_location_reference ml_links_df [ \"A\" ] = ( ml_links_df [ \"A\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ \"B\" ] = ( ml_links_df [ \"B\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] = ( ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] + RoadwayNetwork . MANAGED_LANES_LINK_ID_SCALAR ) ml_links_df [ \"locationReferences\" ] = ml_links_df [ \"locationReferences\" ] . apply ( # lambda x: _update_location_reference(x) lambda x : offset_location_reference ( x ) ) ml_links_df [ \"geometry\" ] = ml_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) ml_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = ml_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x ) ) access_links_df , egress_links_df = RoadwayNetwork . create_dummy_connector_links ( gp_links_df , ml_links_df ) access_links_df [ \"geometry\" ] = access_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) egress_links_df [ \"geometry\" ] = egress_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) access_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = access_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) egress_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = egress_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_links_df = gp_links_df . append ( ml_links_df ) out_links_df = out_links_df . append ( access_links_df ) out_links_df = out_links_df . append ( egress_links_df ) out_links_df = out_links_df . append ( non_ml_links_df ) # only the ml_links_df has the new nodes added added_a_nodes = ml_links_df [ \"A\" ] added_b_nodes = ml_links_df [ \"B\" ] out_nodes_df = self . nodes_df for a_node in added_a_nodes : out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : a_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"A\" ] == a_node ] . iloc [ 0 ][ \"locationReferences\" ][ 0 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) for b_node in added_b_nodes : if b_node not in out_nodes_df [ \"model_node_id\" ] . tolist (): out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : b_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"B\" ] == b_node ] . iloc [ 0 ][ \"locationReferences\" ][ 1 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) out_nodes_df [ \"X\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) out_nodes_df [ \"Y\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) out_shapes_df = self . shapes_df # managed lanes, access and egress connectors are new geometry new_shapes_df = pd . DataFrame ( { \"geometry\" : ml_links_df [ \"geometry\" ] . append ( access_links_df [ \"geometry\" ]) . append ( egress_links_df [ \"geometry\" ]) } ) new_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = new_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_shapes_df = out_shapes_df . append ( new_shapes_df ) out_links_df = out_links_df . reset_index () out_nodes_df = out_nodes_df . reset_index () out_shapes_df = out_shapes_df . reset_index () if in_place : self . links_df = out_links_df self . nodes_df = out_nodes_df self . shapes_df = out_shapes_df else : out_network = copy . deepcopy ( self ) out_network . links_df = out_links_df out_network . nodes_df = out_nodes_df out_network . shapes_df = out_shapes_df return out_network delete_roadway_feature_change ( links , nodes , ignore_missing = True ) \u00b6 delete the roadway features defined in the project card. valid links and nodes defined in the project gets deleted and shapes corresponding to the deleted links are also deleted. Parameters: Name Type Description Default links dict list of dictionaries required nodes dict list of dictionaries required ignore_missing bool If True, will only warn about links/nodes that are missing from network but specified to \u201cdelete\u201d in project card If False, will fail. True Source code in network_wrangler/roadwaynetwork.py 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 def delete_roadway_feature_change ( self , links : dict , nodes : dict , ignore_missing = True ) -> None : \"\"\" delete the roadway features defined in the project card. valid links and nodes defined in the project gets deleted and shapes corresponding to the deleted links are also deleted. Args: links : dict list of dictionaries nodes : dict list of dictionaries ignore_missing: bool If True, will only warn about links/nodes that are missing from network but specified to \"delete\" in project card If False, will fail. \"\"\" missing_error_message = [] if links is not None : shapes_to_delete = [] for key , val in links . items (): missing_links = [ v for v in val if v not in self . links_df [ key ] . tolist ()] if missing_links : message = \"Links attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] shapes_to_delete . extend ( deleted_links [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . tolist () ) self . links_df . drop ( self . links_df . index [ self . links_df [ key ] . isin ( val )], inplace = True ) self . shapes_df . drop ( self . shapes_df . index [ self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . isin ( shapes_to_delete ) ], inplace = True , ) if nodes is not None : for key , val in nodes . items (): missing_nodes = [ v for v in val if v not in self . nodes_df [ key ] . tolist ()] if missing_nodes : message = \"Nodes attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) self . nodes_df = self . nodes_df [ ~ self . nodes_df [ key ] . isin ( val )] if missing_error_message : WranglerLogger . error ( \" \" . join ( missing_error_message )) raise ValueError () deletion_map ( links , nodes ) \u00b6 Shows which links and nodes are deleted from the roadway network Source code in network_wrangler/roadwaynetwork.py 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 def deletion_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are deleted from the roadway network \"\"\" # deleted_links = None # deleted_nodes = None missing_error_message = [] if links is not None : for key , val in links . items (): deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( deleted_links [ fk ]) ] ) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] else : deleted_links = None if nodes is not None : for key , val in nodes . items (): deleted_nodes = self . nodes_df [ self . nodes_df [ key ] . isin ( val )] else : deleted_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , deleted_links ) m = ox . plot_graph_folium ( G , edge_color = \"red\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if deleted_nodes is not None : for _ , row in deleted_nodes . iterrows (): _folium_node ( row , color = \"red\" ) . add_to ( m ) return m get_modal_graph ( links_df , nodes_df , mode = None ) staticmethod \u00b6 Determines if the network graph is \u201cstrongly\u201d connected A graph is strongly connected if each vertex is reachable from every other vertex. Parameters: Name Type Description Default links_df DataFrame DataFrame of standard network links required nodes_df DataFrame DataFrame of standard network nodes required mode str mode of the network, one of drive , transit , walk , bike None Source code in network_wrangler/roadwaynetwork.py 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 @staticmethod def get_modal_graph ( links_df : DataFrame , nodes_df : DataFrame , mode : str = None ): \"\"\"Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` Returns: networkx: osmnx: DiGraph of network \"\"\" if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} .\" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( links_df , nodes_df , modes = [ mode ], ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) return G get_modal_links_nodes ( links_df , nodes_df , modes = None ) staticmethod \u00b6 Returns nodes and link dataframes for specific mode. Parameters: Name Type Description Default links_df DataFrame DataFrame of standard network links required nodes_df DataFrame DataFrame of standard network nodes required modes list [ str ] list of the modes of the network to be kept, must be in drive , transit , rail , bus , walk , bike . For example, if bike and walk are selected, both bike and walk links will be kept. None .. todo:: Right now we don\u2019t filter the nodes because transit-only links with walk access are not marked as having walk access Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] Source code in network_wrangler/roadwaynetwork.py 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 @staticmethod def get_modal_links_nodes ( links_df : DataFrame , nodes_df : DataFrame , modes : list [ str ] = None ) -> tuple ( DataFrame , DataFrame ): \"\"\"Returns nodes and link dataframes for specific mode. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes modes: list of the modes of the network to be kept, must be in `drive`,`transit`,`rail`,`bus`, `walk`, `bike`. For example, if bike and walk are selected, both bike and walk links will be kept. Returns: tuple of DataFrames for links, nodes filtered by mode .. todo:: Right now we don't filter the nodes because transit-only links with walk access are not marked as having walk access Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] \"\"\" for mode in modes : if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} , got {} \" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()), mode , ) WranglerLogger . error ( msg ) raise ValueError ( msg ) mode_link_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ mode ] ] ) ) mode_node_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_NODE_VARIABLES [ mode ] ] ) ) if not set ( mode_link_variables ) . issubset ( set ( links_df . columns )): msg = \" {} not in provided links_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_link_variables ) - set ( links_df . columns ), links_df . columns ) WranglerLogger . error ( msg ) if not set ( mode_node_variables ) . issubset ( set ( nodes_df . columns )): msg = \" {} not in provided nodes_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_node_variables ) - set ( nodes_df . columns ), nodes_df . columns ) WranglerLogger . error ( msg ) modal_links_df = links_df . loc [ links_df [ mode_link_variables ] . any ( axis = 1 )] ##TODO right now we don't filter the nodes because transit-only # links with walk access are not marked as having walk access # Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 # modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] modal_nodes_df = nodes_df return modal_links_df , modal_nodes_df get_property_by_time_period_and_group ( property , time_period = None , category = None ) \u00b6 Return a series for the properties with a specific group or time period. args \u00b6 str the variable that you want from network list(str) the time period that you are querying for i.e. [\u201816:00\u2019, \u201819:00\u2019] str or list(str)(Optional) the group category i.e. \u201csov\u201d or list of group categories in order of search, i.e. [\u201chov3\u201d,\u201dhov2\u201d] returns \u00b6 pandas series Source code in network_wrangler/roadwaynetwork.py 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 def get_property_by_time_period_and_group ( self , property , time_period = None , category = None ): \"\"\" Return a series for the properties with a specific group or time period. args ------ property: str the variable that you want from network time_period: list(str) the time period that you are querying for i.e. ['16:00', '19:00'] category: str or list(str)(Optional) the group category i.e. \"sov\" or list of group categories in order of search, i.e. [\"hov3\",\"hov2\"] returns -------- pandas series \"\"\" def _get_property ( v , time_spans = None , category = None , return_partial_match : bool = False , partial_match_minutes : int = 60 , ): \"\"\" .. todo:: return the time period with the largest overlap \"\"\" if category and not time_spans : WranglerLogger . error ( \" \\n Shouldn't have a category group without time spans\" ) raise ValueError ( \"Shouldn't have a category group without time spans\" ) # simple case if type ( v ) in ( int , float , str ): return v if not category : category = [ \"default\" ] elif isinstance ( category , str ): category = [ category ] search_cats = [ c . lower () for c in category ] # if no time or group specified, but it is a complex link situation if not time_spans : if \"default\" in v . keys (): return v [ \"default\" ] else : WranglerLogger . debug ( \"variable: \" . format ( v )) msg = \"Variable {} is more complex in network than query\" . format ( v ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if v . get ( \"timeofday\" ): categories = [] for tg in v [ \"timeofday\" ]: if ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ] ): if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", time_spans, category, tg[\"value\"] # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] # if there isn't a fully matched time period, see if there is an overlapping one # right now just return the first overlapping ones # TODO return the time period with the largest overlap if ( ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 0 ] <= tg [ \"time\" ][ 1 ]) ) or ( ( time_spans [ 1 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ]) ): overlap_minutes = max ( 0 , min ( tg [ \"time\" ][ 1 ], time_spans [ 1 ]) - max ( time_spans [ 0 ], tg [ \"time\" ][ 0 ]), ) # print(\"OLM\",overlap_minutes) if not return_partial_match and overlap_minutes > 0 : WranglerLogger . debug ( \"Couldn't find time period consistent with {} , but found a partial match: {} . Consider allowing partial matches using 'return_partial_match' keyword or updating query.\" . format ( time_spans , tg [ \"time\" ] ) ) elif ( overlap_minutes < partial_match_minutes and overlap_minutes > 0 ): WranglerLogger . debug ( \"Time period: {} overlapped less than the minimum number of minutes ( {} < {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) elif overlap_minutes > 0 : WranglerLogger . debug ( \"Returning a partial time period match. Time period: {} overlapped the minimum number of minutes ( {} >= {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", # time_spans, # category, # tg[\"value\"], # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] \"\"\" WranglerLogger.debug( \"\\nCouldn't find time period for {}, returning default\".format( str(time_spans) ) ) \"\"\" if \"default\" in v . keys (): # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, v[\"default\"]) return v [ \"default\" ] else : # print(\"Var:\", v) WranglerLogger . error ( \" \\n Can't find default; must specify a category in {} \" . format ( str ( categories ) ) ) raise ValueError ( \"Can't find default, must specify a category in: {} \" . format ( str ( categories ) ) ) time_spans = parse_time_spans ( time_period ) return self . links_df [ property ] . apply ( _get_property , time_spans = time_spans , category = category ) is_network_connected ( mode = None , links_df = None , nodes_df = None ) \u00b6 Determines if the network graph is \u201cstrongly\u201d connected A graph is strongly connected if each vertex is reachable from every other vertex. Parameters: Name Type Description Default mode str mode of the network, one of drive , transit , walk , bike None links_df DataFrame DataFrame of standard network links None nodes_df DataFrame DataFrame of standard network nodes None .. todo:: Consider caching graphs if they take a long time. Source code in network_wrangler/roadwaynetwork.py 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 def is_network_connected ( self , mode : str = None , links_df : DataFrame = None , nodes_df : DataFrame = None ): \"\"\" Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes Returns: boolean .. todo:: Consider caching graphs if they take a long time. \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) # TODO: consider caching graphs if they start to take forever # and we are calling them more than once. G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) is_connected = nx . is_strongly_connected ( G ) return is_connected network_connection_plot ( G , disconnected_subgraph_nodes ) staticmethod \u00b6 Plot a graph to check for network connection. Parameters: Name Type Description Default G OSMNX flavored networkX graph. required disconnected_subgraph_nodes list List of disconnected subgraphs described by the list of their member nodes (as described by their model_node_id ). required Source code in network_wrangler/roadwaynetwork.py 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 @staticmethod def network_connection_plot ( G , disconnected_subgraph_nodes : list ): \"\"\"Plot a graph to check for network connection. Args: G: OSMNX flavored networkX graph. disconnected_subgraph_nodes: List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`). returns: fig, ax : tuple \"\"\" colors = [] for i in range ( len ( disconnected_subgraph_nodes )): colors . append ( \"# %06X \" % randint ( 0 , 0xFFFFFF )) fig , ax = ox . plot_graph ( G , figsize = ( 16 , 16 ), show = False , close = True , edge_color = \"black\" , edge_alpha = 0.1 , node_color = \"black\" , node_alpha = 0.5 , node_size = 10 , ) i = 0 for nodes in disconnected_subgraph_nodes : for n in nodes : size = 100 ax . scatter ( G . nodes [ n ][ \"X\" ], G . nodes [ n ][ \"Y\" ], c = colors [ i ], s = size ) i = i + 1 return fig , ax orig_dest_nodes_foreign_key ( selection , node_foreign_key = '' ) \u00b6 Returns the foreign key id (whatever is used in the u and v variables in the links file) for the AB nodes as a tuple. Parameters: Name Type Description Default selection selection dictionary with A and B keys required node_foreign_key str variable name for whatever is used by the u and v variable '' Source code in network_wrangler/roadwaynetwork.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 def orig_dest_nodes_foreign_key ( self , selection : dict , node_foreign_key : str = \"\" ) -> tuple : \"\"\" Returns the foreign key id (whatever is used in the u and v variables in the links file) for the AB nodes as a tuple. Args: selection : selection dictionary with A and B keys node_foreign_key: variable name for whatever is used by the u and v variable in the links_df file. If nothing is specified, assume whatever default is (usually osm_node_id) Returns: tuple of (A_id, B_id) \"\"\" if not node_foreign_key : node_foreign_key = RoadwayNetwork . NODE_FOREIGN_KEY if len ( selection [ \"A\" ]) > 1 : raise ( \"Selection A node dictionary should be of length 1\" ) if len ( selection [ \"B\" ]) > 1 : raise ( \"Selection B node dictionary should be of length 1\" ) A_node_key , A_id = next ( iter ( selection [ \"A\" ] . items ())) B_node_key , B_id = next ( iter ( selection [ \"B\" ] . items ())) if A_node_key != node_foreign_key : A_id = self . nodes_df [ self . nodes_df [ A_node_key ] == A_id ][ node_foreign_key ] . values [ 0 ] if B_node_key != node_foreign_key : B_id = self . nodes_df [ self . nodes_df [ B_node_key ] == B_id ][ node_foreign_key ] . values [ 0 ] return ( A_id , B_id ) ox_graph ( nodes_df , links_df ) staticmethod \u00b6 create an osmnx-flavored network graph osmnx doesn\u2019t like values that are arrays, so remove the variables that have arrays. osmnx also requires that certain variables be filled in, so do that too. Parameters: Name Type Description Default nodes_df GeoDataFrame of nodes required link_df GeoDataFrame of links required Source code in network_wrangler/roadwaynetwork.py 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 @staticmethod def ox_graph ( nodes_df : GeoDataFrame , links_df : GeoDataFrame ): \"\"\" create an osmnx-flavored network graph osmnx doesn't like values that are arrays, so remove the variables that have arrays. osmnx also requires that certain variables be filled in, so do that too. Args: nodes_df : GeoDataFrame of nodes link_df : GeoDataFrame of links Returns: a networkx multidigraph \"\"\" WranglerLogger . debug ( \"starting ox_graph()\" ) graph_nodes = nodes_df . copy () . drop ( [ \"inboundReferenceIds\" , \"outboundReferenceIds\" ], axis = 1 ) graph_nodes . gdf_name = \"network_nodes\" WranglerLogger . debug ( \"GRAPH NODES: {} \" . format ( graph_nodes . columns )) graph_nodes [ \"id\" ] = graph_nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] graph_nodes [ \"x\" ] = graph_nodes [ \"X\" ] graph_nodes [ \"y\" ] = graph_nodes [ \"Y\" ] graph_links = links_df . copy () . drop ( [ \"osm_link_id\" , \"locationReferences\" ], axis = 1 ) # have to change this over into u,v b/c this is what osm-nx is expecting graph_links [ \"u\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 0 ]] graph_links [ \"v\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 1 ]] graph_links [ \"id\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] graph_links [ \"key\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] WranglerLogger . debug ( \"starting ox.gdfs_to_graph()\" ) try : G = ox . graph_from_gdfs ( graph_nodes , graph_links ) except : WranglerLogger . debug ( \"Please upgrade your OSMNX package. For now, using depricated osmnx.gdfs_to_graph because osmnx.graph_from_gdfs not found\" ) G = ox . gdfs_to_graph ( graph_nodes , graph_links ) WranglerLogger . debug ( \"finished ox.gdfs_to_graph()\" ) return G read ( link_file , node_file , shape_file , fast = True ) staticmethod \u00b6 Reads a network from the roadway network standard Validates that it conforms to the schema Parameters: Name Type Description Default link_file str full path to the link file required node_file str full path to the node file required shape_file str full path to the shape file required fast bool boolean that will skip validation to speed up read time True .. todo:: Turn off fast=True as default Source code in network_wrangler/roadwaynetwork.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 @staticmethod def read ( link_file : str , node_file : str , shape_file : str , fast : bool = True ) -> RoadwayNetwork : \"\"\" Reads a network from the roadway network standard Validates that it conforms to the schema args: link_file: full path to the link file node_file: full path to the node file shape_file: full path to the shape file fast: boolean that will skip validation to speed up read time Returns: a RoadwayNetwork instance .. todo:: Turn off fast=True as default \"\"\" WranglerLogger . info ( \"Reading from following files: \\n - {} \\n - {} \\n - {} .\" . format ( link_file , node_file , shape_file ) ) \"\"\" Validate Input \"\"\" if not os . path . exists ( link_file ): msg = \"Link file doesn't exist at: {} \" . format ( link_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( node_file ): msg = \"Node file doesn't exist at: {} \" . format ( node_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( shape_file ): msg = \"Shape file doesn't exist at: {} \" . format ( shape_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not fast : if not ( RoadwayNetwork . validate_node_schema ( node_file ) and RoadwayNetwork . validate_link_schema ( link_file ) and RoadwayNetwork . validate_shape_schema ( shape_file ) ): sys . exit ( \"RoadwayNetwork: Data doesn't conform to schema\" ) with open ( link_file ) as f : link_json = json . load ( f ) link_properties = pd . DataFrame ( link_json ) link_geometries = [ create_line_string ( g [ \"locationReferences\" ]) for g in link_json ] links_df = gpd . GeoDataFrame ( link_properties , geometry = link_geometries ) links_df . crs = RoadwayNetwork . CRS # coerce types for booleans which might not have a 1 and are therefore read in as intersection bool_columns = [ \"rail_only\" , \"bus_only\" , \"drive_access\" , \"bike_access\" , \"walk_access\" , \"truck_access\" , ] for bc in list ( set ( bool_columns ) & set ( links_df . columns )): links_df [ bc ] = links_df [ bc ] . astype ( bool ) shapes_df = gpd . read_file ( shape_file ) shapes_df . dropna ( subset = [ \"geometry\" , \"id\" ], inplace = True ) shapes_df . crs = RoadwayNetwork . CRS # geopandas uses fiona OGR drivers, which doesn't let you have # a list as a property type. Therefore, must read in node_properties # separately in a vanilla dataframe and then convert to geopandas with open ( node_file ) as f : node_geojson = json . load ( f ) node_properties = pd . DataFrame ( [ g [ \"properties\" ] for g in node_geojson [ \"features\" ]] ) node_geometries = [ Point ( g [ \"geometry\" ][ \"coordinates\" ]) for g in node_geojson [ \"features\" ] ] nodes_df = gpd . GeoDataFrame ( node_properties , geometry = node_geometries ) nodes_df . gdf_name = \"network_nodes\" # set a copy of the foreign key to be the index so that the # variable itself remains queryiable nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" ] = nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] nodes_df . set_index ( RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" , inplace = True ) nodes_df . crs = RoadwayNetwork . CRS nodes_df [ \"X\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) nodes_df [ \"Y\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) WranglerLogger . info ( \"Read %s links from %s \" % ( len ( links_df ), link_file )) WranglerLogger . info ( \"Read %s nodes from %s \" % ( len ( nodes_df ), node_file )) WranglerLogger . info ( \"Read %s shapes from %s \" % ( len ( shapes_df ), shape_file )) roadway_network = RoadwayNetwork ( nodes = nodes_df , links = links_df , shapes = shapes_df ) roadway_network . link_file = link_file roadway_network . node_file = node_file roadway_network . shape_file = shape_file return roadway_network roadway_net_to_gdf ( roadway_net ) staticmethod \u00b6 Turn the roadway network into a GeoDataFrame Parameters: Name Type Description Default roadway_net RoadwayNetwork the roadway network to export required .. todo:: Make this much more sophisticated, for example attach link info to shapes Source code in network_wrangler/roadwaynetwork.py 390 391 392 393 394 395 396 397 398 399 400 401 @staticmethod def roadway_net_to_gdf ( roadway_net : RoadwayNetwork ) -> gpd . GeoDataFrame : \"\"\" Turn the roadway network into a GeoDataFrame args: roadway_net: the roadway network to export returns: shapes dataframe .. todo:: Make this much more sophisticated, for example attach link info to shapes \"\"\" return roadway_net . shapes_df select_roadway_features ( selection , search_mode = 'drive' , force_search = False ) \u00b6 Selects roadway features that satisfy selection criteria Example usage net.select_roadway_features( selection = [ { # a match condition for the from node using osm, # shared streets, or model node number \u2018from\u2019: {\u2018osm_model_link_id\u2019: \u20181234\u2019}, # a match for the to-node.. \u2018to\u2019: {\u2018shstid\u2019: \u20184321\u2019}, # a regex or match for facility condition # could be # of lanes, facility type, etc. \u2018facility\u2019: {\u2018name\u2019:\u2019Main St\u2019}, }, \u2026 ]) Parameters: Name Type Description Default selection dictionary with keys for: A - from node B - to node link - which includes at least a variable for name required Source code in network_wrangler/roadwaynetwork.py 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 def select_roadway_features ( self , selection : dict , search_mode = \"drive\" , force_search = False ) -> GeoDataFrame : \"\"\" Selects roadway features that satisfy selection criteria Example usage: net.select_roadway_features( selection = [ { # a match condition for the from node using osm, # shared streets, or model node number 'from': {'osm_model_link_id': '1234'}, # a match for the to-node.. 'to': {'shstid': '4321'}, # a regex or match for facility condition # could be # of lanes, facility type, etc. 'facility': {'name':'Main St'}, }, ... ]) Args: selection : dictionary with keys for: A - from node B - to node link - which includes at least a variable for `name` Returns: a list of node foreign IDs on shortest path \"\"\" WranglerLogger . debug ( \"validating selection\" ) self . validate_selection ( selection ) # create a unique key for the selection so that we can cache it sel_key = self . build_selection_key ( selection ) WranglerLogger . debug ( \"Selection Key: {} \" . format ( sel_key )) # if this selection has been queried before, just return the # previously selected links if sel_key in self . selections and not force_search : if self . selections [ sel_key ][ \"selection_found\" ]: return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : msg = \"Selection previously queried but no selection found\" WranglerLogger . error ( msg ) raise Exception ( msg ) self . selections [ sel_key ] = {} self . selections [ sel_key ][ \"selection_found\" ] = False unique_model_link_identifer_in_selection = RoadwayNetwork . selection_has_unique_link_id ( selection ) if not unique_model_link_identifer_in_selection : A_id , B_id = self . orig_dest_nodes_foreign_key ( selection ) # identify candidate links which match the initial query # assign them as iteration = 0 # subsequent iterations that didn't match the query will be # assigned a heigher weight in the shortest path WranglerLogger . debug ( \"Building selection query\" ) # build a selection query based on the selection dictionary sel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ) WranglerLogger . debug ( \"Selecting features: \\n {} \" . format ( sel_query )) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) WranglerLogger . debug ( \"Completed query\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] # b/c too long to keep that way candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 and unique_model_link_identifer_in_selection : msg = \"No links found based on unique link identifiers. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if len ( candidate_links . index ) == 0 : WranglerLogger . debug ( \"No candidate links in initial search. \\n Retrying query using 'ref' instead of 'name'\" ) # if the query doesn't come back with something from 'name' # try it again with 'ref' instead selection_has_name_key = any ( \"name\" in d for d in selection [ \"link\" ]) if not selection_has_name_key : msg = \"Not able to complete search using 'ref' instead of 'name' because 'name' not in search.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if not \"ref\" in self . links_df . columns : msg = \"Not able to complete search using 'ref' because 'ref' not in network.\" WranglerLogger . error ( msg ) raise Exception ( msg ) WranglerLogger . debug ( \"Trying selection query replacing 'name' with 'ref'\" ) sel_query = sel_query . replace ( \"name\" , \"ref\" ) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 : msg = \"No candidate links in search using either 'name' or 'ref' in query. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) def _add_breadth ( candidate_links : DataFrame , nodes : Data , links , i ): \"\"\" Add outbound and inbound reference IDs to candidate links from existing nodes Args: candidate_links : GeoDataFrame df with the links from the previous iteration that we want to add on to nodes : GeoDataFrame df of all nodes in the full network links : GeoDataFrame df of all links in the full network i : int iteration of adding breadth Returns: candidate_links : GeoDataFrame updated df with one more degree of added breadth node_list_foreign_keys : list list of foreign key ids for nodes in the updated candidate links to test if the A and B nodes are in there. ..todo:: Make unique ID for links in the settings \"\"\" WranglerLogger . debug ( \"-Adding Breadth-\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = nodes . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"Candidate Nodes: {} \" . format ( len ( candidate_nodes ))) links_shstRefId_to_add = list ( set ( sum ( candidate_nodes [ \"outboundReferenceIds\" ] . tolist (), []) + sum ( candidate_nodes [ \"inboundReferenceIds\" ] . tolist (), []) ) - set ( candidate_links [ \"shstReferenceId\" ] . tolist ()) - set ([ \"\" ]) ) ##TODO make unique ID for links in the settings # print(\"Link IDs to add: {}\".format(links_shstRefId_to_add)) # print(\"Links: \", links_id_to_add) links_to_add = links [ links . shstReferenceId . isin ( links_shstRefId_to_add )] # print(\"Adding Links:\",links_to_add) WranglerLogger . debug ( \"Adding {} links.\" . format ( links_to_add . shape [ 0 ])) links [ links . model_link_id . isin ( links_shstRefId_to_add )][ \"i\" ] = i candidate_links = candidate_links . append ( links_to_add ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) return candidate_links , node_list_foreign_keys def _shortest_path (): WranglerLogger . debug ( \"_shortest_path(): calculating shortest path from graph\" ) candidate_links . loc [:, \"weight\" ] = 1 + ( candidate_links [ \"i\" ] * RoadwayNetwork . SP_WEIGHT_FACTOR ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"creating network graph\" ) G = RoadwayNetwork . ox_graph ( candidate_nodes , candidate_links ) self . selections [ sel_key ][ \"graph\" ] = G self . selections [ sel_key ][ \"candidate_links\" ] = candidate_links try : WranglerLogger . debug ( \"Calculating NX shortest path from A_id: {} to B_id: {} \" . format ( A_id , B_id ) ) sp_route = nx . shortest_path ( G , A_id , B_id , weight = \"weight\" ) WranglerLogger . debug ( \"Shortest path successfully routed\" ) except nx . NetworkXNoPath : return False sp_links = candidate_links [ candidate_links [ \"A\" ] . isin ( sp_route ) & candidate_links [ \"B\" ] . isin ( sp_route ) ] self . selections [ sel_key ][ \"route\" ] = sp_route self . selections [ sel_key ][ \"links\" ] = sp_links return True if not unique_model_link_identifer_in_selection : # find the node ids for the candidate links WranglerLogger . debug ( \"Not a unique ID selection, conduct search\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) WranglerLogger . debug ( \"Foreign key list: {} \" . format ( node_list_foreign_keys )) i = 0 max_i = RoadwayNetwork . SEARCH_BREADTH while ( A_id not in node_list_foreign_keys and B_id not in node_list_foreign_keys and i <= max_i ): WranglerLogger . debug ( \"Adding breadth, no shortest path. i: {} , Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) WranglerLogger . debug ( \"calculating shortest path from graph\" ) sp_found = _shortest_path () if not sp_found : WranglerLogger . info ( \"No shortest path found with {} , trying greater breadth until SP found\" . format ( i ) ) while not sp_found and i <= RoadwayNetwork . MAX_SEARCH_BREADTH : WranglerLogger . debug ( \"Adding breadth, with shortest path iteration. i: {} Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) sp_found = _shortest_path () if sp_found : # reselect from the links in the shortest path, the ones with # the desired values....ignoring name. if len ( selection [ \"link\" ]) > 1 : resel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ignore = [ \"name\" ], ) WranglerLogger . info ( \"Reselecting features: \\n {} \" . format ( resel_query )) self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] . query ( resel_query , engine = \"python\" ) else : self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True # Return pandas.Series of links_ids return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : WranglerLogger . error ( \"Couldn't find path from {} to {} \" . format ( A_id , B_id ) ) raise ValueError else : # unique identifier exists and no need to go through big search self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"candidate_links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () selection_has_unique_link_id ( selection_dict ) staticmethod \u00b6 Parameters: Name Type Description Default selection_dictionary Dictionary representation of selection of roadway features, containing a \u201clink\u201d key. required A boolean indicating if the selection dictionary contains Type Description bool a required unique link id. Source code in network_wrangler/roadwaynetwork.py 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 @staticmethod def selection_has_unique_link_id ( selection_dict : dict ) -> bool : \"\"\" Args: selection_dictionary: Dictionary representation of selection of roadway features, containing a \"link\" key. Returns: A boolean indicating if the selection dictionary contains a required unique link id. \"\"\" selection_keys = [ k for l in selection_dict [ \"link\" ] for k , v in l . items ()] return bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) ) selection_map ( selected_link_idx , A = None , B = None , candidate_link_idx = []) \u00b6 Shows which links are selected for roadway property change or parallel managed lanes category of roadway projects. Parameters: Name Type Description Default selected_links_idx list of selected link indices required candidate_links_idx optional list of candidate link indices to also include in map required A Optional [ Any ] optional foreign key of starting node of a route selection None B Optional [ Any ] optional foreign key of ending node of a route selection None Source code in network_wrangler/roadwaynetwork.py 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 def selection_map ( self , selected_link_idx : list , A : Optional [ Any ] = None , B : Optional [ Any ] = None , candidate_link_idx : Optional [ List ] = [], ): \"\"\" Shows which links are selected for roadway property change or parallel managed lanes category of roadway projects. Args: selected_links_idx: list of selected link indices candidate_links_idx: optional list of candidate link indices to also include in map A: optional foreign key of starting node of a route selection B: optional foreign key of ending node of a route selection \"\"\" WranglerLogger . debug ( \"Selected Links: {} \\n Candidate Links: {} \\n \" . format ( selected_link_idx , candidate_link_idx ) ) graph_link_idx = list ( set ( selected_link_idx + candidate_link_idx )) graph_links = self . links_df . loc [ graph_link_idx ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( graph_links [ fk ]) ] ) ) graph_nodes = self . nodes_df . loc [ node_list_foreign_keys ] G = RoadwayNetwork . ox_graph ( graph_nodes , graph_links ) # base map plot with whole graph m = ox . plot_graph_folium ( G , edge_color = None , tiles = \"cartodbpositron\" , width = \"300px\" , height = \"250px\" ) # plot selection selected_links = self . links_df . loc [ selected_link_idx ] for _ , row in selected_links . iterrows (): pl = ox . folium . _make_folium_polyline ( edge = row , edge_color = \"blue\" , edge_width = 5 , edge_opacity = 0.8 ) pl . add_to ( m ) # if have A and B node add them to base map def _folium_node ( node_row , color = \"white\" , icon = \"\" ): node_marker = folium . Marker ( location = [ node_row [ \"Y\" ], node_row [ \"X\" ]], icon = folium . Icon ( icon = icon , color = color ), ) return node_marker if A : # WranglerLogger.debug(\"A: {}\\n{}\".format(A,self.nodes_df[self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY] == A])) _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == A ], color = \"green\" , icon = \"play\" , ) . add_to ( m ) if B : _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == B ], color = \"red\" , icon = \"star\" , ) . add_to ( m ) return m validate_link_schema ( link_file , schema_location = 'roadway_network_link.json' ) staticmethod \u00b6 Validate roadway network data link schema and output a boolean Source code in network_wrangler/roadwaynetwork.py 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 @staticmethod def validate_link_schema ( link_file , schema_location : str = \"roadway_network_link.json\" ): \"\"\" Validate roadway network data link schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( link_file ) as link_json_file : json_data = json . load ( link_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Link schema validation: Validation Error\" ) WranglerLogger . error ( \"Link File Loc: {} \" . format ( link_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Link Schema\" ) WranglerLogger . error ( \"Link Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False validate_node_schema ( node_file , schema_location = 'roadway_network_node.json' ) staticmethod \u00b6 Validate roadway network data node schema and output a boolean Source code in network_wrangler/roadwaynetwork.py 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 @staticmethod def validate_node_schema ( node_file , schema_location : str = \"roadway_network_node.json\" ): \"\"\" Validate roadway network data node schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( node_file ) as node_json_file : json_data = json . load ( node_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Node schema validation: Validation Error\" ) WranglerLogger . error ( \"Node File Loc: {} \" . format ( node_file )) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Node Schema\" ) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False validate_object_types ( nodes , links , shapes ) staticmethod \u00b6 Determines if the roadway network is being built with the right object types. Does not validate schemas. Parameters: Name Type Description Default nodes GeoDataFrame nodes geodataframe required links GeoDataFrame link geodataframe required shapes GeoDataFrame shape geodataframe required Source code in network_wrangler/roadwaynetwork.py 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 @staticmethod def validate_object_types ( nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Determines if the roadway network is being built with the right object types. Does not validate schemas. Args: nodes: nodes geodataframe links: link geodataframe shapes: shape geodataframe Returns: boolean \"\"\" errors = \"\" if not isinstance ( nodes , GeoDataFrame ): error_message = \"Incompatible nodes type: {} . Must provide a GeoDataFrame. \" . format ( type ( nodes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( links , GeoDataFrame ): error_message = \"Incompatible links type: {} . Must provide a GeoDataFrame. \" . format ( type ( links ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( shapes , GeoDataFrame ): error_message = \"Incompatible shapes type: {} . Must provide a GeoDataFrame. \" . format ( type ( shapes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if errors : return False return True validate_properties ( properties , ignore_existing = False , require_existing_for_change = False ) \u00b6 If there are change or existing commands, make sure that that property exists in the network. Parameters: Name Type Description Default properties properties dictionary to be evaluated required ignore_existing bool If True, will only warn about properties that specify an \u201cexisting\u201d value. If False, will fail. False require_existing_for_change bool If True, will fail if there isn\u2019t a specified value in theproject card for existing when a change is specified. False Source code in network_wrangler/roadwaynetwork.py 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 def validate_properties ( self , properties : dict , ignore_existing : bool = False , require_existing_for_change : bool = False , ) -> bool : \"\"\" If there are change or existing commands, make sure that that property exists in the network. Args: properties : properties dictionary to be evaluated ignore_existing: If True, will only warn about properties that specify an \"existing\" value. If False, will fail. require_existing_for_change: If True, will fail if there isn't a specified value in theproject card for existing when a change is specified. Returns: boolean value as to whether the properties dictonary is valid. \"\"\" validation_error_message = [] for p in properties : if p [ \"property\" ] not in self . links_df . columns : if p . get ( \"change\" ): validation_error_message . append ( '\"Change\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"existing\" ) and not ignore_existing : validation_error_message . append ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) elif p . get ( \"existing\" ): WranglerLogger . warning ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"change\" ) and not p . get ( \"existing\" ): if require_existing_for_change : validation_error_message . append ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n To proceed, run with the setting require_existing_for_change=False' . format ( p [ \"property\" ] ) ) else : WranglerLogger . warning ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n ' . format ( p [ \"property\" ] ) ) if validation_error_message : WranglerLogger . error ( \" \" . join ( validation_error_message )) raise ValueError () validate_selection ( selection ) \u00b6 Evaluate whetther the selection dictionary contains the minimum required values. Parameters: Name Type Description Default selection dict selection dictionary to be evaluated required Source code in network_wrangler/roadwaynetwork.py 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 def validate_selection ( self , selection : dict ) -> Bool : \"\"\" Evaluate whetther the selection dictionary contains the minimum required values. Args: selection: selection dictionary to be evaluated Returns: boolean value as to whether the selection dictonary is valid. \"\"\" if not set ( RoadwayNetwork . SELECTION_REQUIRES ) . issubset ( selection ): err_msg = \"Project Card Selection requires: {} \" . format ( \",\" . join ( RoadwayNetwork . SELECTION_REQUIRES ) ) err_msg += \", but selection only contains: {} \" . format ( \",\" . join ( selection )) WranglerLogger . error ( err_msg ) raise KeyError ( err_msg ) err = [] for l in selection [ \"link\" ]: for k , v in l . items (): if k not in self . links_df . columns : err . append ( \" {} specified in link selection but not an attribute in network \\n \" . format ( k ) ) selection_keys = [ k for l in selection [ \"link\" ] for k , v in l . items ()] unique_link_id = bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) ) if not unique_link_id : for k , v in selection [ \"A\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in A node selection but not an attribute in network \\n \" . format ( k ) ) for k , v in selection [ \"B\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in B node selection but not an attribute in network \\n \" . format ( k ) ) if err : WranglerLogger . error ( \"ERROR: Selection variables in project card not found in network\" ) WranglerLogger . error ( \" \\n \" . join ( err )) WranglerLogger . error ( \"--existing node columns: {} \" . format ( \" \" . join ( self . nodes_df . columns )) ) WranglerLogger . error ( \"--existing link columns: {} \" . format ( \" \" . join ( self . links_df . columns )) ) raise ValueError () return False else : return True validate_shape_schema ( shape_file , schema_location = 'roadway_network_shape.json' ) staticmethod \u00b6 Validate roadway network data shape schema and output a boolean Source code in network_wrangler/roadwaynetwork.py 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 @staticmethod def validate_shape_schema ( shape_file , schema_location : str = \"roadway_network_shape.json\" ): \"\"\" Validate roadway network data shape schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( shape_file ) as shape_json_file : json_data = json . load ( shape_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Shape schema validation: Validation Error\" ) WranglerLogger . error ( \"Shape File Loc: {} \" . format ( shape_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Shape Schema\" ) WranglerLogger . error ( \"Shape Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False validate_uniqueness () \u00b6 Confirms that the unique identifiers are met. Source code in network_wrangler/roadwaynetwork.py 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 def validate_uniqueness ( self ) -> Bool : \"\"\" Confirms that the unique identifiers are met. \"\"\" valid = True for c in RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain unique link identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . links_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network links\" . format ( c ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . LINK_FOREIGN_KEY : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain link foreign key identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) link_foreign_key = self . links_df [ RoadwayNetwork . LINK_FOREIGN_KEY ] . apply ( lambda x : \"-\" . join ( x . map ( str )), axis = 1 ) if not link_foreign_key . is_unique : valid = False msg = \"Foreign key: {} is not unique in network links\" . format ( RoadwayNetwork . LINK_FOREIGN_KEY ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . UNIQUE_NODE_IDENTIFIERS : if c not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain unique node identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . nodes_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network nodes\" . format ( c ) WranglerLogger . error ( msg ) if RoadwayNetwork . NODE_FOREIGN_KEY not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain node foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) elif not self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . is_unique : valid = False msg = \"Foreign key: {} is not unique in network nodes\" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) if RoadwayNetwork . UNIQUE_SHAPE_KEY not in self . shapes_df . columns : valid = False msg = \"Network doesn't contain unique shape id: {} \" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) elif not self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . is_unique : valid = False msg = \"Unique key: {} is not unique in network shapes\" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) return valid write ( path = '.' , filename = None ) \u00b6 Writes a network in the roadway network standard Parameters: Name Type Description Default path str the path were the output will be saved '.' filename str the name prefix of the roadway files that will be generated None Source code in network_wrangler/roadwaynetwork.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the roadway network standard args: path: the path were the output will be saved filename: the name prefix of the roadway files that will be generated \"\"\" if not os . path . exists ( path ): WranglerLogger . debug ( \" \\n Path [ %s ] doesn't exist; creating.\" % path ) os . mkdir ( path ) if filename : links_file = os . path . join ( path , filename + \"_\" + \"link.json\" ) nodes_file = os . path . join ( path , filename + \"_\" + \"node.geojson\" ) shapes_file = os . path . join ( path , filename + \"_\" + \"shape.geojson\" ) else : links_file = os . path . join ( path , \"link.json\" ) nodes_file = os . path . join ( path , \"node.geojson\" ) shapes_file = os . path . join ( path , \"shape.geojson\" ) link_property_columns = self . links_df . columns . values . tolist () link_property_columns . remove ( \"geometry\" ) links_json = link_df_to_json ( self . links_df , link_property_columns ) with open ( links_file , \"w\" ) as f : json . dump ( links_json , f ) # geopandas wont let you write to geojson because # it uses fiona, which doesn't accept a list as one of the properties # so need to convert the df to geojson manually first property_columns = self . nodes_df . columns . values . tolist () property_columns . remove ( \"geometry\" ) nodes_geojson = point_df_to_geojson ( self . nodes_df , property_columns ) with open ( nodes_file , \"w\" ) as f : json . dump ( nodes_geojson , f ) self . shapes_df . to_file ( shapes_file , driver = \"GeoJSON\" ) network_wrangler.TransitNetwork \u00b6 Bases: object Representation of a Transit Network. Typical usage example: import network_wrangler as wr stpaul = r '/home/jovyan/work/example/stpaul' tc = wr . TransitNetwork . read ( path = stpaul ) Attributes: Name Type Description feed DotDict Partridge feed mapping dataframes. config nx . DiGraph Partridge config road_net RoadwayNetwork Associated roadway network object. graph nx . MultiDiGraph Graph for associated roadway network object. feed_path str Where the feed was read in from. validated_frequencies bool The frequencies have been validated. validated_road_network_consistency The network has been validated against the road network. SHAPES_FOREIGN_KEY str foreign key between shapes dataframe and roadway network nodes STOPS_FOREIGN_KEY str foreign key between stops dataframe and roadway network nodes ID_SCALAR int scalar value added to create new IDs when necessary. REQUIRED_FILES list [ str ] list of files that the transit network requires. .. todo:: investigate consolidating scalars this with RoadwayNetwork consolidate thes foreign key constants into one if possible Source code in network_wrangler/transitnetwork.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 class TransitNetwork ( object ): \"\"\" Representation of a Transit Network. Typical usage example: ``` py import network_wrangler as wr stpaul = r'/home/jovyan/work/example/stpaul' tc=wr.TransitNetwork.read(path=stpaul) ``` Attributes: feed (DotDict): Partridge feed mapping dataframes. config (nx.DiGraph): Partridge config road_net (RoadwayNetwork): Associated roadway network object. graph (nx.MultiDiGraph): Graph for associated roadway network object. feed_path (str): Where the feed was read in from. validated_frequencies (bool): The frequencies have been validated. validated_road_network_consistency (): The network has been validated against the road network. SHAPES_FOREIGN_KEY (str): foreign key between shapes dataframe and roadway network nodes STOPS_FOREIGN_KEY (str): foreign key between stops dataframe and roadway network nodes ID_SCALAR (int): scalar value added to create new IDs when necessary. REQUIRED_FILES (list[str]): list of files that the transit network requires. .. todo:: investigate consolidating scalars this with RoadwayNetwork consolidate thes foreign key constants into one if possible \"\"\" # PK = primary key, FK = foreign key SHAPES_FOREIGN_KEY = \"shape_model_node_id\" STOPS_FOREIGN_KEY = \"model_node_id\" ##TODO consolidate these two ^^^ constants if possible ID_SCALAR = 100000000 ##TODO investigate consolidating this with RoadwayNetwork REQUIRED_FILES = [ \"agency.txt\" , \"frequencies.txt\" , \"routes.txt\" , \"shapes.txt\" , \"stop_times.txt\" , \"stops.txt\" , \"trips.txt\" , ] def __init__ ( self , feed : DotDict = None , config : nx . DiGraph = None ): \"\"\" Constructor .. todo:: Make graph a reference to associated RoadwayNetwork's graph, not its own thing. \"\"\" self . feed : DotDict = feed self . config : nx . DiGraph = config self . road_net : RoadwayNetwork = None self . graph : nx . MultiDiGraph = None self . feed_path = None self . validated_frequencies = False self . validated_road_network_consistency = False if not self . validate_frequencies (): raise ValueError ( \"Transit lines with non-positive frequencies exist in the network\" ) @staticmethod def empty () -> TransitNetwork : \"\"\" Create an empty transit network instance using the default config. .. todo:: fill out this method \"\"\" ##TODO msg = \"TransitNetwork.empty is not implemented.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg ) @staticmethod def read ( feed_path : str ) -> TransitNetwork : \"\"\" Read GTFS feed from folder and TransitNetwork object Args: feed_path: where to read transit network files from Returns: a TransitNetwork object. \"\"\" config = default_config () feed = ptg . load_feed ( feed_path , config = config ) WranglerLogger . info ( \"Read in transit feed from: {} \" . format ( feed_path )) updated_config = TransitNetwork . validate_feed ( feed , config ) # Read in each feed so we can write over them editable_feed = DotDict () for node in updated_config . nodes . keys (): # Load (initiate Partridge's lazy load) editable_feed [ node . replace ( \".txt\" , \"\" )] = feed . get ( node ) transit_network = TransitNetwork ( feed = editable_feed , config = updated_config ) transit_network . feed_path = feed_path return transit_network @staticmethod def validate_feed ( feed : DotDict , config : nx . DiGraph ) -> bool : \"\"\" Since Partridge lazily loads the df, load each file to make sure it actually works. Partridge uses a DiGraph from the networkx library to represent the relationships between GTFS files. Each file is a 'node', and the relationship between files are 'edges'. Args: feed: partridge feed config: partridge config \"\"\" updated_config = copy . deepcopy ( config ) files_not_found = [] for node in config . nodes . keys (): n = feed . get ( node ) WranglerLogger . debug ( \"... {} : \\n {} \" . format ( node , n [: 10 ])) if n . shape [ 0 ] == 0 : WranglerLogger . info ( \"Removing {} from transit network config because file not found\" . format ( node ) ) updated_config . remove_node ( node ) if node in TransitNetwork . REQUIRED_FILES : files_not_found . append ( node ) if files_not_found : msg = \"Required files not found or valid: {} \" . format ( \",\" . join ( files_not_found ) ) WranglerLogger . error ( msg ) raise AttributeError ( msg ) return False TransitNetwork . validate_network_keys ( feed ) return updated_config def validate_frequencies ( self ) -> bool : \"\"\" Validates that there are no transit trips in the feed with zero frequencies. Changes state of self.validated_frequencies boolean based on outcome. Returns: boolean indicating if valid or not. \"\"\" _valid = True zero_freq = self . feed . frequencies [ self . feed . frequencies . headway_secs <= 0 ] if len ( zero_freq . index ) > 0 : _valid = False msg = \"Transit lines {} have non-positive frequencies\" . format ( zero_freq . trip_id . to_list () ) WranglerLogger . error ( msg ) self . validated_frequencies = True return _valid def validate_road_network_consistencies ( self ) -> bool : \"\"\" Validates transit network against the road network for both stops and shapes. Returns: boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) valid = True valid_stops = self . validate_transit_stops () valid_shapes = self . validate_transit_shapes () self . validated_road_network_consistency = True if not valid_stops or not valid_shapes : valid = False raise ValueError ( \"Transit network is not consistent with road network.\" ) return valid def validate_transit_stops ( self ) -> bool : \"\"\" Validates that all transit stops are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) stops = self . feed . stops nodes = self . road_net . nodes_df valid = True stop_ids = [ int ( s ) for s in stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . to_list ()] node_ids = [ int ( n ) for n in nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( stop_ids ) . issubset ( node_ids ): valid = False missing_stops = list ( set ( stop_ids ) - set ( node_ids )) msg = \"Not all transit stops are part of the roadyway network. \" msg += \"Missing stops ( {} ) from the roadway nodes are {} .\" . format ( TransitNetwork . STOPS_FOREIGN_KEY , missing_stops ) WranglerLogger . error ( msg ) return valid def validate_transit_shapes ( self ) -> bool : \"\"\" Validates that all transit shapes are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) shapes_df = self . feed . shapes nodes_df = self . road_net . nodes_df links_df = self . road_net . links_df valid = True # check if all the node ids exist in the network shape_ids = [ int ( s ) for s in shapes_df [ TransitNetwork . SHAPES_FOREIGN_KEY ] . to_list () ] node_ids = [ int ( n ) for n in nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( shape_ids ) . issubset ( node_ids ): valid = False missing_shapes = list ( set ( shape_ids ) - set ( node_ids )) msg = \"Not all transit shapes are part of the roadyway network. \" msg += \"Missing shapes ( {} ) from the roadway network are {} .\" . format ( TransitNetwork . SHAPES_FOREIGN_KEY , missing_shapes ) WranglerLogger . error ( msg ) return valid # check if all the links in transit shapes exist in the network # and transit is allowed shapes_df = shapes_df . astype ({ TransitNetwork . SHAPES_FOREIGN_KEY : int }) unique_shape_ids = shapes_df . shape_id . unique () . tolist () for id in unique_shape_ids : subset_shapes_df = shapes_df [ shapes_df [ \"shape_id\" ] == id ] subset_shapes_df = subset_shapes_df . sort_values ( by = [ \"shape_pt_sequence\" ]) subset_shapes_df = subset_shapes_df . add_suffix ( \"_1\" ) . join ( subset_shapes_df . shift ( - 1 ) . add_suffix ( \"_2\" ) ) subset_shapes_df = subset_shapes_df . dropna () merged_df = subset_shapes_df . merge ( links_df , how = \"left\" , left_on = [ TransitNetwork . SHAPES_FOREIGN_KEY + \"_1\" , TransitNetwork . SHAPES_FOREIGN_KEY + \"_2\" , ], right_on = [ \"A\" , \"B\" ], indicator = True , ) missing_links_df = merged_df . query ( '_merge == \"left_only\"' ) # there are shape links which does not exist in the roadway network if len ( missing_links_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which are missing in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) transit_not_allowed_df = merged_df . query ( '_merge == \"both\" & drive_access == 0 & bus_only == 0 & rail_only == 0' ) # there are shape links where transit is not allowed if len ( transit_not_allowed_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which does not allow transit in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) return valid @staticmethod def route_ids_in_routestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever route_id occurs, make sure it is in routes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" route_ids_routestxt = set ( feed . routes . route_id . tolist ()) route_ids_referenced = set ( feed . trips . route_id . tolist ()) missing_routes = route_ids_referenced - route_ids_routestxt if missing_routes : WranglerLogger . warning ( \"The following route_ids are referenced but missing from routes.txt: {} \" . format ( list ( missing_routes ) ) ) return False return True @staticmethod def trip_ids_in_tripstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever trip_id occurs, make sure it is in trips.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" trip_ids_tripstxt = set ( feed . trips . trip_id . tolist ()) trip_ids_referenced = set ( feed . stop_times . trip_id . tolist () + feed . frequencies . trip_id . tolist () ) missing_trips = trip_ids_referenced - trip_ids_tripstxt if missing_trips : WranglerLogger . warning ( \"The following trip_ids are referenced but missing from trips.txt: {} \" . format ( list ( missing_trips ) ) ) return False return True @staticmethod def shape_ids_in_shapestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever shape_id occurs, make sure it is in shapes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" shape_ids_shapestxt = set ( feed . shapes . shape_id . tolist ()) shape_ids_referenced = set ( feed . trips . shape_id . tolist ()) missing_shapes = shape_ids_referenced - shape_ids_shapestxt if missing_shapes : WranglerLogger . warning ( \"The following shape_ids from trips.txt are missing from shapes.txt: {} \" . format ( list ( missing_shapes ) ) ) return False return True @staticmethod def stop_ids_in_stopstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever stop_id occurs, make sure it is in stops.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" stop_ids_stopstxt = set ( feed . stops . stop_id . tolist ()) stop_ids_referenced = [] # STOP_TIMES stop_ids_referenced . extend ( feed . stop_times . stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . stops . parent_station . dropna () . tolist ()) # TRANSFERS if feed . get ( \"transfers.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . transfers . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . transfers . to_stop_id . dropna () . tolist ()) # PATHWAYS if feed . get ( \"pathways.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . pathways . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . pathways . to_stop_id . dropna () . tolist ()) stop_ids_referenced = set ( stop_ids_referenced ) missing_stops = stop_ids_referenced - stop_ids_stopstxt if missing_stops : WranglerLogger . warning ( \"The following stop_ids from are referenced but missing from stops.txt: {} \" . format ( list ( missing_stops ) ) ) return False return True @staticmethod def validate_network_keys ( feed : DotDict ) -> Bool : \"\"\" Validates foreign keys are present in all connecting feed files. Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" result = True result = result and TransitNetwork . route_ids_in_routestxt ( feed ) result = result and TransitNetwork . trip_ids_in_tripstxt ( feed ) result = result and TransitNetwork . shape_ids_in_shapestxt ( feed ) result = result and TransitNetwork . stop_ids_in_stopstxt ( feed ) return result def set_roadnet ( self , road_net : RoadwayNetwork , graph_shapes : bool = False , graph_stops : bool = False , validate_consistency : bool = True , ) -> None : self . road_net : RoadwayNetwork = road_net self . graph : nx . MultiDiGraph = RoadwayNetwork . ox_graph ( road_net . nodes_df , road_net . links_df ) if graph_shapes : self . _graph_shapes () if graph_stops : self . _graph_stops () if validate_consistency : self . validate_road_network_consistencies () def _graph_shapes ( self ) -> None : \"\"\" .. todo:: Fill out this method. \"\"\" existing_shapes = self . feed . shapes msg = \"_graph_shapes() not implemented yet.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg ) # graphed_shapes = pd.DataFrame() # for shape_id in shapes: # TODO traverse point by point, mapping shortest path on graph, # then append to a list # return total list of all link ids # rebuild rows in shapes dataframe and add to graphed_shapes # make graphed_shapes a GeoDataFrame # self.feed.shapes = graphed_shapes def _graph_stops ( self ) -> None : \"\"\" .. todo:: Fill out this method. \"\"\" existing_stops = self . feed . stops msg = \"_graph_stops() not implemented yet.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg ) # graphed_stops = pd.DataFrame() # for stop_id in stops: # TODO # self.feed.stops = graphed_stops def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the transit network standard Args: path: the path were the output will be saved filename: the name prefix of the transit files that will be generated \"\"\" WranglerLogger . info ( \"Writing transit to directory: {} \" . format ( path )) for node in self . config . nodes . keys (): df = self . feed . get ( node . replace ( \".txt\" , \"\" )) if not df . empty : if filename : outpath = os . path . join ( path , filename + \"_\" + node ) else : outpath = os . path . join ( path , node ) WranglerLogger . debug ( \"Writing file: {} \" . format ( outpath )) df . to_csv ( outpath , index = False ) @staticmethod def transit_net_to_gdf ( transit : Union ( TransitNetwork , pd . DataFrame )): \"\"\" Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame. Args: transit: either a TransitNetwork or a Shapes GeoDataFrame .. todo:: Make more sophisticated. \"\"\" from partridge import geo if type ( transit ) is pd . DataFrame : shapes = transit else : shapes = transit . feed . shapes transit_gdf = geo . build_shapes ( shapes ) return transit_gdf def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a transit network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Transit Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if ( project_dictionary [ \"category\" ] . lower () == \"transit service property change\" ): self . apply_transit_feature_change ( self . select_transit_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : # Grab the list of nodes in the facility from road_net # It should be cached because managed lane projects are # processed by RoadwayNetwork first via # Scenario.apply_all_projects try : managed_lane_nodes = self . road_net . selections ( self . road_net . build_selection_key ( project_dictionary [ \"facility\" ] ) )[ \"route\" ] except ValueError : WranglerLogger . error ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) # Reroute any transit using these nodes self . apply_transit_managed_lane ( self . select_transit_features_by_nodes ( managed_lane_nodes ), managed_lane_nodes , ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : WranglerLogger . warning ( \"Roadway Deletion not yet implemented in Transit; ignoring\" ) else : msg = \" {} not implemented yet in TransitNetwork; can't apply.\" . format ( project_dictionary [ \"category\" ] ) WranglerLogger . error ( msg ) raise ( msg ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary ) def select_transit_features ( self , selection : dict ) -> pd . Series : \"\"\" Selects transit features that satisfy selection criteria Args: selection : selection dictionary Returns: trip identifiers : list of GTFS trip IDs in the selection \"\"\" trips = self . feed . trips routes = self . feed . routes freq = self . feed . frequencies # Turn selection's values into lists if they are not already for key in selection . keys (): if type ( selection [ key ]) not in [ list , tuple ]: selection [ key ] = [ selection [ key ]] # Based on the key in selection, filter trips if \"trip_id\" in selection : trips = trips [ trips . trip_id . isin ( selection [ \"trip_id\" ])] elif \"route_id\" in selection : trips = trips [ trips . route_id . isin ( selection [ \"route_id\" ])] elif \"route_short_name\" in selection : routes = routes [ routes . route_short_name . isin ( selection [ \"route_short_name\" ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] elif \"route_long_name\" in selection : matches = [] for sel in selection [ \"route_long_name\" ]: for route_long_name in routes [ \"route_long_name\" ]: x = re . search ( sel , route_long_name ) if x is not None : matches . append ( route_long_name ) routes = routes [ routes . route_long_name . isin ( matches )] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , selection . keys ()) raise ValueError # If a time key exists, filter trips using frequency table if selection . get ( \"time\" ): selection [ \"time\" ] = parse_time_spans ( selection [ \"time\" ]) elif selection . get ( \"start_time\" ) and selection . get ( \"end_time\" ): selection [ \"time\" ] = parse_time_spans ( [ selection [ \"start_time\" ], selection [ \"end_time\" ]] ) # Filter freq to trips in selection freq = freq [ freq . trip_id . isin ( trips [ \"trip_id\" ])] freq = freq [ freq . start_time == selection [ \"time\" ][ 0 ]] freq = freq [ freq . end_time == selection [ \"time\" ][ 1 ]] # Filter trips table to those still in freq table trips = trips [ trips . trip_id . isin ( freq [ \"trip_id\" ])] # If any other key exists, filter routes or trips accordingly for key in selection . keys (): if key not in [ \"trip_id\" , \"route_id\" , \"route_short_name\" , \"route_long_name\" , \"time\" , ]: if key in trips : trips = trips [ trips [ key ] . isin ( selection [ key ])] elif key in routes : routes = routes [ routes [ key ] . isin ( selection [ key ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , key ) raise ValueError # Check that there is at least one trip in trips table or raise error if len ( trips ) < 1 : WranglerLogger . error ( \"Selection returned zero trips\" ) raise ValueError # Return pandas.Series of trip_ids return trips [ \"trip_id\" ] def select_transit_features_by_nodes ( self , node_ids : list , require_all : bool = False ) -> pd . Series : \"\"\" Selects transit features that use any one of a list of node_ids Args: node_ids: list (generally coming from nx.shortest_path) require_all : bool if True, the returned trip_ids must traverse all of the nodes (default = False) Returns: trip identifiers list of GTFS trip IDs in the selection \"\"\" # If require_all, the returned trip_ids must traverse all of the nodes # Else, filter any shapes that use any one of the nodes in node_ids if require_all : shape_ids = ( self . feed . shapes . groupby ( \"shape_id\" ) . filter ( lambda x : all ( i in x [ TransitNetwork . SHAPES_FOREIGN_KEY ] . tolist () for i in node_ids ) ) ) . shape_id . drop_duplicates () else : shape_ids = self . feed . shapes [ self . feed . shapes [ TransitNetwork . SHAPES_FOREIGN_KEY ] . isin ( node_ids ) ] . shape_id . drop_duplicates () # Return pandas.Series of trip_ids return self . feed . trips [ self . feed . trips . shape_id . isin ( shape_ids )] . trip_id def apply_transit_feature_change ( self , trip_ids : pd . Series , properties : list , in_place : bool = True ) -> Union ( None , TransitNetwork ): \"\"\" Changes the transit attributes for the selected features based on the project card information passed Args: trip_ids : pd.Series all trip_ids to apply change to properties : list of dictionaries transit properties to change in_place : bool whether to apply changes in place or return a new network Returns: None \"\"\" for i in properties : if i [ \"property\" ] in [ \"headway_secs\" ]: self . _apply_transit_feature_change_frequencies ( trip_ids , i , in_place ) elif i [ \"property\" ] in [ \"routing\" ]: self . _apply_transit_feature_change_routing ( trip_ids , i , in_place ) def _apply_transit_feature_change_routing ( self , trip_ids : pd . Series , properties : dict , in_place : bool = True ) -> Union ( None , TransitNetwork ): shapes = self . feed . shapes . copy () stop_times = self . feed . stop_times . copy () stops = self . feed . stops . copy () # A negative sign in \"set\" indicates a traversed node without a stop # If any positive numbers, stops have changed stops_change = False if any ( x > 0 for x in properties [ \"set\" ]): # Simplify \"set\" and \"existing\" to only stops properties [ \"set_stops\" ] = [ str ( i ) for i in properties [ \"set\" ] if i > 0 ] if properties . get ( \"existing\" ) is not None : properties [ \"existing_stops\" ] = [ str ( i ) for i in properties [ \"existing\" ] if i > 0 ] stops_change = True # Convert ints to objects properties [ \"set_shapes\" ] = [ str ( abs ( i )) for i in properties [ \"set\" ]] if properties . get ( \"existing\" ) is not None : properties [ \"existing_shapes\" ] = [ str ( abs ( i )) for i in properties [ \"existing\" ] ] # Replace shapes records trips = self . feed . trips # create pointer rather than a copy shape_ids = trips [ trips [ \"trip_id\" ] . isin ( trip_ids )] . shape_id for shape_id in shape_ids : # Check if `shape_id` is used by trips that are not in # parameter `trip_ids` trips_using_shape_id = trips . loc [ trips [ \"shape_id\" ] == shape_id , [ \"trip_id\" ]] if not all ( trips_using_shape_id . isin ( trip_ids )[ \"trip_id\" ]): # In this case, we need to create a new shape_id so as to leave # the trips not part of the query alone WranglerLogger . warning ( \"Trips that were not in your query selection use the \" \"same `shape_id` as trips that are in your query. Only \" \"the trips' shape in your query will be changed.\" ) old_shape_id = shape_id shape_id = str ( int ( shape_id ) + TransitNetwork . ID_SCALAR ) if shape_id in shapes [ \"shape_id\" ] . tolist (): WranglerLogger . error ( \"Cannot create a unique new shape_id.\" ) dup_shape = shapes [ shapes . shape_id == old_shape_id ] . copy () dup_shape [ \"shape_id\" ] = shape_id shapes = pd . concat ([ shapes , dup_shape ], ignore_index = True ) # Pop the rows that match shape_id this_shape = shapes [ shapes . shape_id == shape_id ] # Make sure they are ordered by shape_pt_sequence this_shape = this_shape . sort_values ( by = [ \"shape_pt_sequence\" ]) # Build a pd.DataFrame of new shape records new_shape_rows = pd . DataFrame ( { \"shape_id\" : shape_id , \"shape_pt_lat\" : None , # FIXME Populate from self.road_net? \"shape_pt_lon\" : None , # FIXME \"shape_osm_node_id\" : None , # FIXME \"shape_pt_sequence\" : None , TransitNetwork . SHAPES_FOREIGN_KEY : properties [ \"set_shapes\" ], } ) # If \"existing\" is specified, replace only that segment # Else, replace the whole thing if properties . get ( \"existing\" ) is not None : # Match list nodes = this_shape [ TransitNetwork . SHAPES_FOREIGN_KEY ] . tolist () index_replacement_starts = nodes . index ( properties [ \"existing_shapes\" ][ 0 ]) index_replacement_ends = nodes . index ( properties [ \"existing_shapes\" ][ - 1 ]) this_shape = pd . concat ( [ this_shape . iloc [: index_replacement_starts ], new_shape_rows , this_shape . iloc [ index_replacement_ends + 1 :], ], ignore_index = True , sort = False , ) else : this_shape = new_shape_rows # Renumber shape_pt_sequence this_shape [ \"shape_pt_sequence\" ] = np . arange ( len ( this_shape )) # Add rows back into shapes shapes = pd . concat ( [ shapes [ shapes . shape_id != shape_id ], this_shape ], ignore_index = True , sort = False , ) # Replace stop_times and stops records (if required) if stops_change : # If node IDs in properties[\"set_stops\"] are not already # in stops.txt, create a new stop_id for them in stops existing_fk_ids = set ( stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . tolist ()) nodes_df = self . road_net . nodes_df . loc [ :, [ TransitNetwork . STOPS_FOREIGN_KEY , \"X\" , \"Y\" ] ] for fk_i in properties [ \"set_stops\" ]: if fk_i not in existing_fk_ids : WranglerLogger . info ( \"Creating a new stop in stops.txt for node ID: {} \" . format ( fk_i ) ) # Add new row to stops new_stop_id = str ( int ( fk_i ) + TransitNetwork . ID_SCALAR ) if stop_id in stops [ \"stop_id\" ] . tolist (): WranglerLogger . error ( \"Cannot create a unique new stop_id.\" ) stops . loc [ len ( stops . index ) + 1 , [ \"stop_id\" , \"stop_lat\" , \"stop_lon\" , TransitNetwork . STOPS_FOREIGN_KEY , ], ] = [ new_stop_id , nodes_df . loc [ int ( fk_i ), \"Y\" ], nodes_df . loc [ int ( fk_i ), \"X\" ], fk_i , ] # Loop through all the trip_ids for trip_id in trip_ids : # Pop the rows that match trip_id this_stoptime = stop_times [ stop_times . trip_id == trip_id ] # Merge on node IDs using stop_id (one node ID per stop_id) this_stoptime = this_stoptime . merge ( stops [[ \"stop_id\" , TransitNetwork . STOPS_FOREIGN_KEY ]], how = \"left\" , on = \"stop_id\" , ) # Make sure the stop_times are ordered by stop_sequence this_stoptime = this_stoptime . sort_values ( by = [ \"stop_sequence\" ]) # Build a pd.DataFrame of new shape records from properties new_stoptime_rows = pd . DataFrame ( { \"trip_id\" : trip_id , \"arrival_time\" : None , \"departure_time\" : None , \"pickup_type\" : None , \"drop_off_type\" : None , \"stop_distance\" : None , \"timepoint\" : None , \"stop_is_skipped\" : None , TransitNetwork . STOPS_FOREIGN_KEY : properties [ \"set_stops\" ], } ) # Merge on stop_id using node IDs (many stop_id per node ID) new_stoptime_rows = ( new_stoptime_rows . merge ( stops [[ \"stop_id\" , TransitNetwork . STOPS_FOREIGN_KEY ]], how = \"left\" , on = TransitNetwork . STOPS_FOREIGN_KEY , ) . groupby ([ TransitNetwork . STOPS_FOREIGN_KEY ]) . head ( 1 ) ) # pick first # If \"existing\" is specified, replace only that segment # Else, replace the whole thing if properties . get ( \"existing\" ) is not None : # Match list (remember stops are passed in with node IDs) nodes = this_stoptime [ TransitNetwork . STOPS_FOREIGN_KEY ] . tolist () index_replacement_starts = nodes . index ( properties [ \"existing_stops\" ][ 0 ] ) index_replacement_ends = nodes . index ( properties [ \"existing_stops\" ][ - 1 ] ) this_stoptime = pd . concat ( [ this_stoptime . iloc [: index_replacement_starts ], new_stoptime_rows , this_stoptime . iloc [ index_replacement_ends + 1 :], ], ignore_index = True , sort = False , ) else : this_stoptime = new_stoptime_rows # Remove node ID del this_stoptime [ TransitNetwork . STOPS_FOREIGN_KEY ] # Renumber stop_sequence this_stoptime [ \"stop_sequence\" ] = np . arange ( len ( this_stoptime )) # Add rows back into stoptime stop_times = pd . concat ( [ stop_times [ stop_times . trip_id != trip_id ], this_stoptime ], ignore_index = True , sort = False , ) # Replace self if in_place, else return if in_place : self . feed . shapes = shapes self . feed . stops = stops self . feed . stop_times = stop_times else : updated_network = copy . deepcopy ( self ) updated_network . feed . shapes = shapes updated_network . feed . stops = stops updated_network . feed . stop_times = stop_times return updated_network def _apply_transit_feature_change_frequencies ( self , trip_ids : pd . Series , properties : dict , in_place : bool = True ) -> Union ( None , TransitNetwork ): freq = self . feed . frequencies . copy () # Grab only those records matching trip_ids (aka selection) freq = freq [ freq . trip_id . isin ( trip_ids )] # Check all `existing` properties if given if properties . get ( \"existing\" ) is not None : if not all ( freq . headway_secs == properties [ \"existing\" ]): WranglerLogger . error ( \"Existing does not match for at least \" \"1 trip in: \\n {} \" . format ( trip_ids . to_string ()) ) raise ValueError # Calculate build value if properties . get ( \"set\" ) is not None : build_value = properties [ \"set\" ] else : build_value = [ i + properties [ \"change\" ] for i in freq . headway_secs ] # Update self or return a new object q = self . feed . frequencies . trip_id . isin ( freq [ \"trip_id\" ]) if in_place : self . feed . frequencies . loc [ q , properties [ \"property\" ]] = build_value else : updated_network = copy . deepcopy ( self ) updated_network . loc [ q , properties [ \"property\" ]] = build_value return updated_network def apply_transit_managed_lane ( self , trip_ids : pd . Series , node_ids : list , in_place : bool = True ) -> Union ( None , TransitNetwork ): # Traversed nodes without a stop should be negative integers all_stops = self . feed . stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . tolist () node_ids = [ int ( x ) if str ( x ) in all_stops else int ( x ) * - 1 for x in node_ids ] self . _apply_transit_feature_change_routing ( trip_ids = trip_ids , properties = { \"existing\" : node_ids , \"set\" : RoadwayNetwork . get_managed_lane_node_ids ( node_ids ), }, in_place = in_place , ) __init__ ( feed = None , config = None ) \u00b6 Constructor .. todo:: Make graph a reference to associated RoadwayNetwork\u2019s graph, not its own thing. Source code in network_wrangler/transitnetwork.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def __init__ ( self , feed : DotDict = None , config : nx . DiGraph = None ): \"\"\" Constructor .. todo:: Make graph a reference to associated RoadwayNetwork's graph, not its own thing. \"\"\" self . feed : DotDict = feed self . config : nx . DiGraph = config self . road_net : RoadwayNetwork = None self . graph : nx . MultiDiGraph = None self . feed_path = None self . validated_frequencies = False self . validated_road_network_consistency = False if not self . validate_frequencies (): raise ValueError ( \"Transit lines with non-positive frequencies exist in the network\" ) apply ( project_card_dictionary ) \u00b6 Wrapper method to apply a project to a transit network. Parameters: Name Type Description Default project_card_dictionary dict dict a dictionary of the project card object required Source code in network_wrangler/transitnetwork.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a transit network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Transit Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if ( project_dictionary [ \"category\" ] . lower () == \"transit service property change\" ): self . apply_transit_feature_change ( self . select_transit_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : # Grab the list of nodes in the facility from road_net # It should be cached because managed lane projects are # processed by RoadwayNetwork first via # Scenario.apply_all_projects try : managed_lane_nodes = self . road_net . selections ( self . road_net . build_selection_key ( project_dictionary [ \"facility\" ] ) )[ \"route\" ] except ValueError : WranglerLogger . error ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) # Reroute any transit using these nodes self . apply_transit_managed_lane ( self . select_transit_features_by_nodes ( managed_lane_nodes ), managed_lane_nodes , ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : WranglerLogger . warning ( \"Roadway Deletion not yet implemented in Transit; ignoring\" ) else : msg = \" {} not implemented yet in TransitNetwork; can't apply.\" . format ( project_dictionary [ \"category\" ] ) WranglerLogger . error ( msg ) raise ( msg ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary ) apply_transit_feature_change ( trip_ids , properties , in_place = True ) \u00b6 Changes the transit attributes for the selected features based on the project card information passed Parameters: Name Type Description Default trip_ids pd.Series all trip_ids to apply change to required properties list of dictionaries transit properties to change required in_place bool whether to apply changes in place or return a new network True Returns: Type Description Union (None, TransitNetwork ) None Source code in network_wrangler/transitnetwork.py 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 def apply_transit_feature_change ( self , trip_ids : pd . Series , properties : list , in_place : bool = True ) -> Union ( None , TransitNetwork ): \"\"\" Changes the transit attributes for the selected features based on the project card information passed Args: trip_ids : pd.Series all trip_ids to apply change to properties : list of dictionaries transit properties to change in_place : bool whether to apply changes in place or return a new network Returns: None \"\"\" for i in properties : if i [ \"property\" ] in [ \"headway_secs\" ]: self . _apply_transit_feature_change_frequencies ( trip_ids , i , in_place ) elif i [ \"property\" ] in [ \"routing\" ]: self . _apply_transit_feature_change_routing ( trip_ids , i , in_place ) empty () staticmethod \u00b6 Create an empty transit network instance using the default config. .. todo:: fill out this method Source code in network_wrangler/transitnetwork.py 91 92 93 94 95 96 97 98 99 100 101 102 @staticmethod def empty () -> TransitNetwork : \"\"\" Create an empty transit network instance using the default config. .. todo:: fill out this method \"\"\" ##TODO msg = \"TransitNetwork.empty is not implemented.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg ) read ( feed_path ) staticmethod \u00b6 Read GTFS feed from folder and TransitNetwork object Parameters: Name Type Description Default feed_path str where to read transit network files from required Source code in network_wrangler/transitnetwork.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @staticmethod def read ( feed_path : str ) -> TransitNetwork : \"\"\" Read GTFS feed from folder and TransitNetwork object Args: feed_path: where to read transit network files from Returns: a TransitNetwork object. \"\"\" config = default_config () feed = ptg . load_feed ( feed_path , config = config ) WranglerLogger . info ( \"Read in transit feed from: {} \" . format ( feed_path )) updated_config = TransitNetwork . validate_feed ( feed , config ) # Read in each feed so we can write over them editable_feed = DotDict () for node in updated_config . nodes . keys (): # Load (initiate Partridge's lazy load) editable_feed [ node . replace ( \".txt\" , \"\" )] = feed . get ( node ) transit_network = TransitNetwork ( feed = editable_feed , config = updated_config ) transit_network . feed_path = feed_path return transit_network route_ids_in_routestxt ( feed ) staticmethod \u00b6 Wherever route_id occurs, make sure it is in routes.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 @staticmethod def route_ids_in_routestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever route_id occurs, make sure it is in routes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" route_ids_routestxt = set ( feed . routes . route_id . tolist ()) route_ids_referenced = set ( feed . trips . route_id . tolist ()) missing_routes = route_ids_referenced - route_ids_routestxt if missing_routes : WranglerLogger . warning ( \"The following route_ids are referenced but missing from routes.txt: {} \" . format ( list ( missing_routes ) ) ) return False return True select_transit_features ( selection ) \u00b6 Selects transit features that satisfy selection criteria Parameters: Name Type Description Default selection selection dictionary required Source code in network_wrangler/transitnetwork.py 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 def select_transit_features ( self , selection : dict ) -> pd . Series : \"\"\" Selects transit features that satisfy selection criteria Args: selection : selection dictionary Returns: trip identifiers : list of GTFS trip IDs in the selection \"\"\" trips = self . feed . trips routes = self . feed . routes freq = self . feed . frequencies # Turn selection's values into lists if they are not already for key in selection . keys (): if type ( selection [ key ]) not in [ list , tuple ]: selection [ key ] = [ selection [ key ]] # Based on the key in selection, filter trips if \"trip_id\" in selection : trips = trips [ trips . trip_id . isin ( selection [ \"trip_id\" ])] elif \"route_id\" in selection : trips = trips [ trips . route_id . isin ( selection [ \"route_id\" ])] elif \"route_short_name\" in selection : routes = routes [ routes . route_short_name . isin ( selection [ \"route_short_name\" ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] elif \"route_long_name\" in selection : matches = [] for sel in selection [ \"route_long_name\" ]: for route_long_name in routes [ \"route_long_name\" ]: x = re . search ( sel , route_long_name ) if x is not None : matches . append ( route_long_name ) routes = routes [ routes . route_long_name . isin ( matches )] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , selection . keys ()) raise ValueError # If a time key exists, filter trips using frequency table if selection . get ( \"time\" ): selection [ \"time\" ] = parse_time_spans ( selection [ \"time\" ]) elif selection . get ( \"start_time\" ) and selection . get ( \"end_time\" ): selection [ \"time\" ] = parse_time_spans ( [ selection [ \"start_time\" ], selection [ \"end_time\" ]] ) # Filter freq to trips in selection freq = freq [ freq . trip_id . isin ( trips [ \"trip_id\" ])] freq = freq [ freq . start_time == selection [ \"time\" ][ 0 ]] freq = freq [ freq . end_time == selection [ \"time\" ][ 1 ]] # Filter trips table to those still in freq table trips = trips [ trips . trip_id . isin ( freq [ \"trip_id\" ])] # If any other key exists, filter routes or trips accordingly for key in selection . keys (): if key not in [ \"trip_id\" , \"route_id\" , \"route_short_name\" , \"route_long_name\" , \"time\" , ]: if key in trips : trips = trips [ trips [ key ] . isin ( selection [ key ])] elif key in routes : routes = routes [ routes [ key ] . isin ( selection [ key ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , key ) raise ValueError # Check that there is at least one trip in trips table or raise error if len ( trips ) < 1 : WranglerLogger . error ( \"Selection returned zero trips\" ) raise ValueError # Return pandas.Series of trip_ids return trips [ \"trip_id\" ] select_transit_features_by_nodes ( node_ids , require_all = False ) \u00b6 Selects transit features that use any one of a list of node_ids Parameters: Name Type Description Default node_ids list list (generally coming from nx.shortest_path) required require_all bool if True, the returned trip_ids must traverse all of the nodes (default = False) False Returns: Type Description pd . Series trip identifiers list of GTFS trip IDs in the selection Source code in network_wrangler/transitnetwork.py 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 def select_transit_features_by_nodes ( self , node_ids : list , require_all : bool = False ) -> pd . Series : \"\"\" Selects transit features that use any one of a list of node_ids Args: node_ids: list (generally coming from nx.shortest_path) require_all : bool if True, the returned trip_ids must traverse all of the nodes (default = False) Returns: trip identifiers list of GTFS trip IDs in the selection \"\"\" # If require_all, the returned trip_ids must traverse all of the nodes # Else, filter any shapes that use any one of the nodes in node_ids if require_all : shape_ids = ( self . feed . shapes . groupby ( \"shape_id\" ) . filter ( lambda x : all ( i in x [ TransitNetwork . SHAPES_FOREIGN_KEY ] . tolist () for i in node_ids ) ) ) . shape_id . drop_duplicates () else : shape_ids = self . feed . shapes [ self . feed . shapes [ TransitNetwork . SHAPES_FOREIGN_KEY ] . isin ( node_ids ) ] . shape_id . drop_duplicates () # Return pandas.Series of trip_ids return self . feed . trips [ self . feed . trips . shape_id . isin ( shape_ids )] . trip_id shape_ids_in_shapestxt ( feed ) staticmethod \u00b6 Wherever shape_id occurs, make sure it is in shapes.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 @staticmethod def shape_ids_in_shapestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever shape_id occurs, make sure it is in shapes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" shape_ids_shapestxt = set ( feed . shapes . shape_id . tolist ()) shape_ids_referenced = set ( feed . trips . shape_id . tolist ()) missing_shapes = shape_ids_referenced - shape_ids_shapestxt if missing_shapes : WranglerLogger . warning ( \"The following shape_ids from trips.txt are missing from shapes.txt: {} \" . format ( list ( missing_shapes ) ) ) return False return True stop_ids_in_stopstxt ( feed ) staticmethod \u00b6 Wherever stop_id occurs, make sure it is in stops.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 @staticmethod def stop_ids_in_stopstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever stop_id occurs, make sure it is in stops.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" stop_ids_stopstxt = set ( feed . stops . stop_id . tolist ()) stop_ids_referenced = [] # STOP_TIMES stop_ids_referenced . extend ( feed . stop_times . stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . stops . parent_station . dropna () . tolist ()) # TRANSFERS if feed . get ( \"transfers.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . transfers . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . transfers . to_stop_id . dropna () . tolist ()) # PATHWAYS if feed . get ( \"pathways.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . pathways . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . pathways . to_stop_id . dropna () . tolist ()) stop_ids_referenced = set ( stop_ids_referenced ) missing_stops = stop_ids_referenced - stop_ids_stopstxt if missing_stops : WranglerLogger . warning ( \"The following stop_ids from are referenced but missing from stops.txt: {} \" . format ( list ( missing_stops ) ) ) return False return True transit_net_to_gdf ( transit ) staticmethod \u00b6 Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame. Parameters: Name Type Description Default transit Union ( TransitNetwork , pd . DataFrame ) either a TransitNetwork or a Shapes GeoDataFrame required .. todo:: Make more sophisticated. Source code in network_wrangler/transitnetwork.py 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 @staticmethod def transit_net_to_gdf ( transit : Union ( TransitNetwork , pd . DataFrame )): \"\"\" Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame. Args: transit: either a TransitNetwork or a Shapes GeoDataFrame .. todo:: Make more sophisticated. \"\"\" from partridge import geo if type ( transit ) is pd . DataFrame : shapes = transit else : shapes = transit . feed . shapes transit_gdf = geo . build_shapes ( shapes ) return transit_gdf trip_ids_in_tripstxt ( feed ) staticmethod \u00b6 Wherever trip_id occurs, make sure it is in trips.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 @staticmethod def trip_ids_in_tripstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever trip_id occurs, make sure it is in trips.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" trip_ids_tripstxt = set ( feed . trips . trip_id . tolist ()) trip_ids_referenced = set ( feed . stop_times . trip_id . tolist () + feed . frequencies . trip_id . tolist () ) missing_trips = trip_ids_referenced - trip_ids_tripstxt if missing_trips : WranglerLogger . warning ( \"The following trip_ids are referenced but missing from trips.txt: {} \" . format ( list ( missing_trips ) ) ) return False return True validate_feed ( feed , config ) staticmethod \u00b6 Since Partridge lazily loads the df, load each file to make sure it actually works. Partridge uses a DiGraph from the networkx library to represent the relationships between GTFS files. Each file is a \u2018node\u2019, and the relationship between files are \u2018edges\u2019. Parameters: Name Type Description Default feed DotDict partridge feed required config nx . DiGraph partridge config required Source code in network_wrangler/transitnetwork.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @staticmethod def validate_feed ( feed : DotDict , config : nx . DiGraph ) -> bool : \"\"\" Since Partridge lazily loads the df, load each file to make sure it actually works. Partridge uses a DiGraph from the networkx library to represent the relationships between GTFS files. Each file is a 'node', and the relationship between files are 'edges'. Args: feed: partridge feed config: partridge config \"\"\" updated_config = copy . deepcopy ( config ) files_not_found = [] for node in config . nodes . keys (): n = feed . get ( node ) WranglerLogger . debug ( \"... {} : \\n {} \" . format ( node , n [: 10 ])) if n . shape [ 0 ] == 0 : WranglerLogger . info ( \"Removing {} from transit network config because file not found\" . format ( node ) ) updated_config . remove_node ( node ) if node in TransitNetwork . REQUIRED_FILES : files_not_found . append ( node ) if files_not_found : msg = \"Required files not found or valid: {} \" . format ( \",\" . join ( files_not_found ) ) WranglerLogger . error ( msg ) raise AttributeError ( msg ) return False TransitNetwork . validate_network_keys ( feed ) return updated_config validate_frequencies () \u00b6 Validates that there are no transit trips in the feed with zero frequencies. Changes state of self.validated_frequencies boolean based on outcome. Returns: Type Description bool boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def validate_frequencies ( self ) -> bool : \"\"\" Validates that there are no transit trips in the feed with zero frequencies. Changes state of self.validated_frequencies boolean based on outcome. Returns: boolean indicating if valid or not. \"\"\" _valid = True zero_freq = self . feed . frequencies [ self . feed . frequencies . headway_secs <= 0 ] if len ( zero_freq . index ) > 0 : _valid = False msg = \"Transit lines {} have non-positive frequencies\" . format ( zero_freq . trip_id . to_list () ) WranglerLogger . error ( msg ) self . validated_frequencies = True return _valid validate_network_keys ( feed ) staticmethod \u00b6 Validates foreign keys are present in all connecting feed files. Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 @staticmethod def validate_network_keys ( feed : DotDict ) -> Bool : \"\"\" Validates foreign keys are present in all connecting feed files. Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" result = True result = result and TransitNetwork . route_ids_in_routestxt ( feed ) result = result and TransitNetwork . trip_ids_in_tripstxt ( feed ) result = result and TransitNetwork . shape_ids_in_shapestxt ( feed ) result = result and TransitNetwork . stop_ids_in_stopstxt ( feed ) return result validate_road_network_consistencies () \u00b6 Validates transit network against the road network for both stops and shapes. Returns: Type Description bool boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def validate_road_network_consistencies ( self ) -> bool : \"\"\" Validates transit network against the road network for both stops and shapes. Returns: boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) valid = True valid_stops = self . validate_transit_stops () valid_shapes = self . validate_transit_shapes () self . validated_road_network_consistency = True if not valid_stops or not valid_shapes : valid = False raise ValueError ( \"Transit network is not consistent with road network.\" ) return valid validate_transit_shapes () \u00b6 Validates that all transit shapes are part of the roadway network. Returns: Type Description bool Boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 def validate_transit_shapes ( self ) -> bool : \"\"\" Validates that all transit shapes are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) shapes_df = self . feed . shapes nodes_df = self . road_net . nodes_df links_df = self . road_net . links_df valid = True # check if all the node ids exist in the network shape_ids = [ int ( s ) for s in shapes_df [ TransitNetwork . SHAPES_FOREIGN_KEY ] . to_list () ] node_ids = [ int ( n ) for n in nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( shape_ids ) . issubset ( node_ids ): valid = False missing_shapes = list ( set ( shape_ids ) - set ( node_ids )) msg = \"Not all transit shapes are part of the roadyway network. \" msg += \"Missing shapes ( {} ) from the roadway network are {} .\" . format ( TransitNetwork . SHAPES_FOREIGN_KEY , missing_shapes ) WranglerLogger . error ( msg ) return valid # check if all the links in transit shapes exist in the network # and transit is allowed shapes_df = shapes_df . astype ({ TransitNetwork . SHAPES_FOREIGN_KEY : int }) unique_shape_ids = shapes_df . shape_id . unique () . tolist () for id in unique_shape_ids : subset_shapes_df = shapes_df [ shapes_df [ \"shape_id\" ] == id ] subset_shapes_df = subset_shapes_df . sort_values ( by = [ \"shape_pt_sequence\" ]) subset_shapes_df = subset_shapes_df . add_suffix ( \"_1\" ) . join ( subset_shapes_df . shift ( - 1 ) . add_suffix ( \"_2\" ) ) subset_shapes_df = subset_shapes_df . dropna () merged_df = subset_shapes_df . merge ( links_df , how = \"left\" , left_on = [ TransitNetwork . SHAPES_FOREIGN_KEY + \"_1\" , TransitNetwork . SHAPES_FOREIGN_KEY + \"_2\" , ], right_on = [ \"A\" , \"B\" ], indicator = True , ) missing_links_df = merged_df . query ( '_merge == \"left_only\"' ) # there are shape links which does not exist in the roadway network if len ( missing_links_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which are missing in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) transit_not_allowed_df = merged_df . query ( '_merge == \"both\" & drive_access == 0 & bus_only == 0 & rail_only == 0' ) # there are shape links where transit is not allowed if len ( transit_not_allowed_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which does not allow transit in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) return valid validate_transit_stops () \u00b6 Validates that all transit stops are part of the roadway network. Returns: Type Description bool Boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def validate_transit_stops ( self ) -> bool : \"\"\" Validates that all transit stops are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) stops = self . feed . stops nodes = self . road_net . nodes_df valid = True stop_ids = [ int ( s ) for s in stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . to_list ()] node_ids = [ int ( n ) for n in nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( stop_ids ) . issubset ( node_ids ): valid = False missing_stops = list ( set ( stop_ids ) - set ( node_ids )) msg = \"Not all transit stops are part of the roadyway network. \" msg += \"Missing stops ( {} ) from the roadway nodes are {} .\" . format ( TransitNetwork . STOPS_FOREIGN_KEY , missing_stops ) WranglerLogger . error ( msg ) return valid write ( path = '.' , filename = None ) \u00b6 Writes a network in the transit network standard Parameters: Name Type Description Default path str the path were the output will be saved '.' filename str the name prefix of the transit files that will be generated None Source code in network_wrangler/transitnetwork.py 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the transit network standard Args: path: the path were the output will be saved filename: the name prefix of the transit files that will be generated \"\"\" WranglerLogger . info ( \"Writing transit to directory: {} \" . format ( path )) for node in self . config . nodes . keys (): df = self . feed . get ( node . replace ( \".txt\" , \"\" )) if not df . empty : if filename : outpath = os . path . join ( path , filename + \"_\" + node ) else : outpath = os . path . join ( path , node ) WranglerLogger . debug ( \"Writing file: {} \" . format ( outpath )) df . to_csv ( outpath , index = False ) Utils and Functions \u00b6 network_wrangler.utils \u00b6 create_line_string ( location_reference ) \u00b6 Creates a geometry as a LineString using location reference Source code in network_wrangler/utils.py 286 287 288 289 290 291 def create_line_string ( location_reference : list ): \"\"\" Creates a geometry as a LineString using location reference \"\"\" return LineString ([ location_reference [ 0 ][ \"point\" ], location_reference [ 1 ][ \"point\" ]]) create_location_reference_from_nodes ( node_a , node_b ) \u00b6 Creates a location reference using the node a and node b coordinates Source code in network_wrangler/utils.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def create_location_reference_from_nodes ( node_a , node_b ): \"\"\" Creates a location reference using the node a and node b coordinates Args: node_a: Node A as Series node_b: Node B as Series \"\"\" out_location_reference = [ { \"sequence\" : 1 , \"point\" : [ node_a [ \"X\" ], node_a [ \"Y\" ]]}, { \"sequence\" : 2 , \"point\" : [ node_b [ \"X\" ], node_b [ \"Y\" ]]}, ] return out_location_reference create_unique_shape_id ( line_string ) \u00b6 Creates a unique hash id using the coordinates of the geomtery Source code in network_wrangler/utils.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def create_unique_shape_id ( line_string : LineString ): \"\"\" Creates a unique hash id using the coordinates of the geomtery Args: line_string: Line Geometry as a LineString Returns: string \"\"\" x1 , y1 = list ( line_string . coords )[ 0 ] # first co-ordinate (A node) x2 , y2 = list ( line_string . coords )[ - 1 ] # last co-ordinate (B node) message = \"Geometry {} {} {} {} \" . format ( x1 , y1 , x2 , y2 ) unhashed = message . encode ( \"utf-8\" ) hash = hashlib . md5 ( unhashed ) . hexdigest () return hash get_bearing ( lat1 , lon1 , lat2 , lon2 ) \u00b6 calculate the bearing (forward azimuth) b/w the two points Source code in network_wrangler/utils.py 144 145 146 147 148 149 150 151 152 153 154 155 156 def get_bearing ( lat1 , lon1 , lat2 , lon2 ): \"\"\" calculate the bearing (forward azimuth) b/w the two points returns: bearing in radians \"\"\" # bearing in degrees brng = Geodesic . WGS84 . Inverse ( lat1 , lon1 , lat2 , lon2 )[ \"azi1\" ] # convert bearing to radians brng = math . radians ( brng ) return brng haversine_distance ( origin , destination ) \u00b6 Calculates haversine distance between two points Source code in network_wrangler/utils.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def haversine_distance ( origin : list , destination : list ): \"\"\" Calculates haversine distance between two points Args: origin: lat/lon for point A destination: lat/lon for point B Returns: string \"\"\" lon1 , lat1 = origin lon2 , lat2 = destination radius = 6378137 # meter dlat = math . radians ( lat2 - lat1 ) dlon = math . radians ( lon2 - lon1 ) a = math . sin ( dlat / 2 ) * math . sin ( dlat / 2 ) + math . cos ( math . radians ( lat1 ) ) * math . cos ( math . radians ( lat2 )) * math . sin ( dlon / 2 ) * math . sin ( dlon / 2 ) c = 2 * math . atan2 ( math . sqrt ( a ), math . sqrt ( 1 - a )) d = radius * c # meters d = d * 0.000621371 # miles return d link_df_to_json ( df , properties ) \u00b6 Export pandas dataframe as a json object. Modified from: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/ Parameters: Name Type Description Default df pd . DataFrame Dataframe to export required properties list list of properties to export required Source code in network_wrangler/utils.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def link_df_to_json ( df : pd . DataFrame , properties : list ): \"\"\" Export pandas dataframe as a json object. Modified from: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/ Args: df: Dataframe to export properties: list of properties to export \"\"\" # can't remember why we need this? if \"distance\" in properties : df [ \"distance\" ] . fillna ( 0 ) json = [] for _ , row in df . iterrows (): feature = {} for prop in properties : feature [ prop ] = row [ prop ] json . append ( feature ) return json make_slug ( text , delimiter = '_' ) \u00b6 makes a slug from text Source code in network_wrangler/utils.py 84 85 86 87 88 89 90 91 def make_slug ( text , delimiter : str = \"_\" ): \"\"\" makes a slug from text \"\"\" import re text = re . sub ( \"[,.;@#?!&$']+\" , \"\" , text . lower ()) return re . sub ( \"[\\ ]+\" , delimiter , text ) offset_location_reference ( location_reference , offset_meters = 10 ) \u00b6 Creates a new location reference using the node a and node b of given location reference, offseting it by 90 degree to the bearing of given location reference and distance equals to offset_meters Source code in network_wrangler/utils.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def offset_location_reference ( location_reference , offset_meters = 10 ): \"\"\" Creates a new location reference using the node a and node b of given location reference, offseting it by 90 degree to the bearing of given location reference and distance equals to offset_meters returns: new location_reference with offset \"\"\" lon_1 = location_reference [ 0 ][ \"point\" ][ 0 ] lat_1 = location_reference [ 0 ][ \"point\" ][ 1 ] lon_2 = location_reference [ 1 ][ \"point\" ][ 0 ] lat_2 = location_reference [ 1 ][ \"point\" ][ 1 ] bearing = get_bearing ( lat_1 , lon_1 , lat_2 , lon_2 ) # adding 90 degrees (1.57 radians) to the current bearing bearing = bearing + 1.57 new_lat_1 , new_lon_1 = offset_point_with_distance_and_bearing ( lat_1 , lon_1 , offset_meters , bearing ) new_lat_2 , new_lon_2 = offset_point_with_distance_and_bearing ( lat_2 , lon_2 , offset_meters , bearing ) out_location_reference = [ { \"sequence\" : 1 , \"point\" : [ new_lon_1 , new_lat_1 ]}, { \"sequence\" : 2 , \"point\" : [ new_lon_2 , new_lat_2 ]}, ] return out_location_reference offset_point_with_distance_and_bearing ( lat , lon , distance , bearing ) \u00b6 Get the new lat long (in degrees) given current point (lat/lon), distance and bearing Source code in network_wrangler/utils.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def offset_point_with_distance_and_bearing ( lat , lon , distance , bearing ): \"\"\" Get the new lat long (in degrees) given current point (lat/lon), distance and bearing returns: new lat/long \"\"\" # Earth's radius in meters radius = 6378137 # convert the lat long from degree to radians lat_radians = math . radians ( lat ) lon_radians = math . radians ( lon ) # calculate the new lat long in radians out_lat_radians = math . asin ( math . sin ( lat_radians ) * math . cos ( distance / radius ) + math . cos ( lat_radians ) * math . sin ( distance / radius ) * math . cos ( bearing ) ) out_lon_radians = lon_radians + math . atan2 ( math . sin ( bearing ) * math . sin ( distance / radius ) * math . cos ( lat_radians ), math . cos ( distance / radius ) - math . sin ( lat_radians ) * math . sin ( lat_radians ), ) # convert the new lat long back to degree out_lat = math . degrees ( out_lat_radians ) out_lon = math . degrees ( out_lon_radians ) return ( out_lat , out_lon ) parse_time_spans ( times ) \u00b6 parse time spans into tuples of seconds from midnight can also be used as an apply function for a pandas series Parameters times: tuple(string) or tuple(int) or list(string) or list(int) returns \u00b6 tuple(integer) time span as seconds from midnight Source code in network_wrangler/utils.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def parse_time_spans ( times ): \"\"\" parse time spans into tuples of seconds from midnight can also be used as an apply function for a pandas series Parameters ----------- times: tuple(string) or tuple(int) or list(string) or list(int) returns -------- tuple(integer) time span as seconds from midnight \"\"\" try : start_time , end_time = times except : msg = \"ERROR: times should be a tuple or list of two, got: {} \" . format ( times ) WranglerLogger . error ( msg ) raise ValueError ( msg ) # If times are strings, convert to int in seconds, else return as ints if isinstance ( start_time , str ) and isinstance ( end_time , str ): start_time = start_time . strip () end_time = end_time . strip () # If time is given without seconds, add 00 if len ( start_time ) <= 5 : start_time += \":00\" if len ( end_time ) <= 5 : end_time += \":00\" # Convert times to seconds from midnight (Partride's time storage) h0 , m0 , s0 = start_time . split ( \":\" ) start_time_sec = int ( h0 ) * 3600 + int ( m0 ) * 60 + int ( s0 ) h1 , m1 , s1 = end_time . split ( \":\" ) end_time_sec = int ( h1 ) * 3600 + int ( m1 ) * 60 + int ( s1 ) return ( start_time_sec , end_time_sec ) elif isinstance ( start_time , int ) and isinstance ( end_time , int ): return times else : WranglerLogger . error ( \"ERROR: times should be ints or strings\" ) raise ValueError () return ( start_time_sec , end_time_sec ) point_df_to_geojson ( df , properties ) \u00b6 Source code in network_wrangler/utils.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def point_df_to_geojson ( df : pd . DataFrame , properties : list ): \"\"\" Author: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/ \"\"\" from .roadwaynetwork import RoadwayNetwork geojson = { \"type\" : \"FeatureCollection\" , \"features\" : []} for _ , row in df . iterrows (): feature = { \"type\" : \"Feature\" , \"properties\" : {}, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : []}, } feature [ \"geometry\" ][ \"coordinates\" ] = [ row [ \"geometry\" ] . x , row [ \"geometry\" ] . y ] feature [ \"properties\" ][ RoadwayNetwork . NODE_FOREIGN_KEY ] = row . name for prop in properties : feature [ \"properties\" ][ prop ] = row [ prop ] geojson [ \"features\" ] . append ( feature ) return geojson topological_sort ( adjacency_list , visited_list ) \u00b6 Topological sorting for Acyclic Directed Graph Source code in network_wrangler/utils.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def topological_sort ( adjacency_list , visited_list ): \"\"\" Topological sorting for Acyclic Directed Graph \"\"\" output_stack = [] def _topology_sort_util ( vertex ): if not visited_list [ vertex ]: visited_list [ vertex ] = True for neighbor in adjacency_list [ vertex ]: _topology_sort_util ( neighbor ) output_stack . insert ( 0 , vertex ) for vertex in visited_list : _topology_sort_util ( vertex ) return output_stack network_wrangler.logger \u00b6 setupLogging ( level = None , log_filename = None , log_to_console = False ) \u00b6 Sets up the WranglerLogger w.r.t. the debug file location and if logging to console. Parameters: Name Type Description Default level int the level of logging that will be recorded None log_filename str the location of the log file that will get created to add the DEBUG log None log_to_console bool if True, logging will go to the console at INFO level False Source code in network_wrangler/logger.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def setupLogging ( level : int = None , log_filename : str = None , log_to_console : bool = False ): \"\"\" Sets up the WranglerLogger w.r.t. the debug file location and if logging to console. args: level: the level of logging that will be recorded log_filename: the location of the log file that will get created to add the DEBUG log log_to_console: if True, logging will go to the console at INFO level \"\"\" if level is None : WranglerLogger . setLevel ( logging . DEBUG ) else : WranglerLogger . setLevel ( level ) FORMAT = logging . Formatter ( \" %(asctime)-15s %(levelname)s : %(message)s \" , datefmt = \"%Y-%m- %d %H:%M:%S,\" ) if log_filename : file_handler = logging . FileHandler ( log_filename ) file_handler . setLevel ( logging . DEBUG ) file_handler . setFormatter ( FORMAT ) WranglerLogger . addHandler ( file_handler ) if log_to_console : console_handler = logging . StreamHandler ( sys . stdout ) console_handler . setLevel ( logging . INFO ) console_handler . setFormatter ( FORMAT ) WranglerLogger . addHandler ( console_handler )","title":"API Documentation"},{"location":"api/#api-documentation","text":"","title":"API Documentation"},{"location":"api/#base-classes","text":"","title":"Base Classes"},{"location":"api/#network_wrangler.ProjectCard","text":"Bases: object Representation of a Project Card Attributes: Name Type Description __dict__ Dictionary of project card attributes valid Boolean indicating if data conforms to project card data schema Source code in network_wrangler/projectcard.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 class ProjectCard ( object ): \"\"\" Representation of a Project Card Attributes: __dict__: Dictionary of project card attributes valid: Boolean indicating if data conforms to project card data schema \"\"\" TRANSIT_CATEGORIES = [ \"Transit Service Property Change\" ] # categories that may affect transit, but only as a secondary # effect of changing roadways SECONDARY_TRANSIT_CATEGORIES = [ \"Roadway Deletion\" , \"Parallel Managed Lanes\" ] ROADWAY_CATEGORIES = [ \"Roadway Property Change\" , \"Roadway Deletion\" , \"Parallel Managed lanes\" , \"Add New Roadway\" , \"Calculated Roadway\" , ] UNSPECIFIED_PROJECT_NAMES = [ \"\" , \"TO DO User Define\" , \"USER TO define\" ] def __init__ ( self , attribute_dictonary : dict ): \"\"\" Constructor args: attribute_dictonary: a nested dictionary of attributes \"\"\" # add these first so they are first on write out self . project = None self . tags = \"\" self . dependencies = \"\" self . __dict__ . update ( attribute_dictonary ) self . valid = False # todo more unstructuring of project card yaml def __str__ ( self ): s = [ \" {} : {} \" . format ( key , value ) for key , value in self . __dict__ . items ()] return \" \\n \" . join ( s ) @staticmethod def read ( path_to_card : str , validate : bool = True ): \"\"\" Reads and validates a Project card args: path_to_card: the path to the project card Returns a Project Card object \"\"\" card_suffix = path_to_card . split ( \".\" )[ - 1 ] . lower () if card_suffix in [ \"yaml\" , 'yml' ]: attribute_dictionary = ProjectCard . read_yml ( path_to_card ) elif card_suffix in [ \"wrangler\" , 'wr' ]: attribute_dictionary = ProjectCard . read_wrangler_card ( path_to_card ) else : msg = \"Card should have a suffix of yaml, yml, wrangler, or wr. Found suffix: {} \" . format ( card_suffix ) raise ValueError ( msg ) card = ProjectCard ( attribute_dictionary ) if card . project in ProjectCard . UNSPECIFIED_PROJECT_NAMES : msg = \"Card must have valid project name: {} \" . format ( path_to_card ) WranglerLogger . error ( msg ) raise ValueError ( msg ) card . valid = False if validate : card . valid = ProjectCard . validate_project_card_schema ( path_to_card ) return card @staticmethod def read_wrangler_card ( path_to_card : str ) -> dict : \"\"\" Reads wrangler project cards with YAML front matter and then python code. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading Wrangler-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : delim = cardfile . readline () WranglerLogger . debug ( \"Using delimiter: {} \" . format ( delim )) _yaml , _pycode = cardfile . read () . split ( delim ) WranglerLogger . debug ( \"_yaml: {} \\n _pycode: {} \" . format ( _yaml , _pycode )) attribute_dictionary = yaml . load ( _yaml ) attribute_dictionary [ \"file\" ] = path_to_card attribute_dictionary [ \"pycode\" ] = _pycode . lstrip ( \" \\n \" ) return attribute_dictionary @staticmethod def read_yml ( path_to_card : str ) -> dict : \"\"\" Reads \"normal\" wrangler project cards defined in YAML. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading YAML-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : attribute_dictionary = yaml . safe_load ( cardfile ) attribute_dictionary [ \"file\" ] = path_to_card return attribute_dictionary def write ( self , filename : str = None ): \"\"\" Writes project card dictionary to YAML file \"\"\" if not filename : from network_wrangler.utils import make_slug filename = make_slug ( self . project ) + \".yml\" # import collections # out_dict = collections.OrderedDict() out_dict = {} out_dict [ \"project\" ] = None out_dict [ \"tags\" ] = \"\" out_dict [ \"dependencies\" ] = \"\" out_dict . update ( self . __dict__ ) with open ( filename , \"w\" ) as outfile : yaml . dump ( out_dict , outfile , default_flow_style = False , sort_keys = False ) WranglerLogger . info ( \"Wrote project card to: {} \" . format ( filename )) @staticmethod def validate_project_card_schema ( card_file , card_schema_file : str = \"project_card.json\" ) -> bool : \"\"\" Tests project card schema validity by evaluating if it conforms to the schemas returns: boolean \"\"\" if not os . path . exists ( card_schema_file ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) card_schema_file = os . path . join ( base_path , card_schema_file ) with open ( card_schema_file ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( card_file , \"r\" ) as card : card_json = yaml . safe_load ( card ) try : validate ( card_json , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Project Card validation: Validation Error\" ) WranglerLogger . error ( \"Project Card File Loc: {} \" . format ( card_file )) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Failed Project Card schema validation: Schema Error\" ) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except yaml . YAMLError as exc : WranglerLogger . error ( exc . message ) @staticmethod def build_link_selection_query ( selection : dict , unique_model_link_identifiers : [], mode : List [ str ] = [ \"drive_access\" ], ignore = [], ): sel_query = \"(\" count = 0 selection_keys = [ k for l in selection [ \"link\" ] for k , v in l . items ()] num_unique_model_link_identifiers = len ( set ( unique_model_link_identifiers ) . intersection ( selection_keys ) ) unique_model_link_identifer_exist = num_unique_model_link_identifiers > 0 for l in selection [ \"link\" ]: for key , value in l . items (): if key in ignore : continue if ( unique_model_link_identifer_exist and key not in unique_model_link_identifiers ): continue count = count + 1 if isinstance ( value , list ): sel_query = sel_query + \"(\" v = 1 for i in value : # building an OR query with each element in list if isinstance ( i , str ): sel_query = sel_query + key + '.str.contains(\"' + i + '\")' else : sel_query = sel_query + key + \"==\" + str ( i ) if v != len ( value ): sel_query = sel_query + \" or \" v = v + 1 sel_query = sel_query + \")\" else : sel_query = sel_query + key + \"==\" + '\"' + str ( value ) + '\"' if not unique_model_link_identifer_exist and count != ( len ( selection [ \"link\" ]) - len ( ignore ) ): sel_query = sel_query + \" and \" if ( unique_model_link_identifer_exist and count != num_unique_model_link_identifiers ): sel_query = sel_query + \" and \" if not unique_model_link_identifer_exist : if count > 0 : sel_query = sel_query + \" and \" # add mode query mode_sel = \"(\" + \" or \" . join ( m + \"==1\" for m in mode ) + \")\" sel_query = sel_query + mode_sel sel_query = sel_query + \")\" return sel_query def roadway_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Roadway Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def new_roadway ( self , card : dict ): \"\"\" Probably delete. Reads a New Roadway card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def transit_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Transit Service Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def new_transit_right_of_way ( self , card : dict ): \"\"\" Probably delete. Reads a New Transit Dedicated Right of Way card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" )) def parallel_managed_lanes ( self , card : dict ): \"\"\" Probably delete. Reads a Parallel Managed lanes card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" ))","title":"ProjectCard"},{"location":"api/#network_wrangler.projectcard.ProjectCard.__init__","text":"Constructor Source code in network_wrangler/projectcard.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , attribute_dictonary : dict ): \"\"\" Constructor args: attribute_dictonary: a nested dictionary of attributes \"\"\" # add these first so they are first on write out self . project = None self . tags = \"\" self . dependencies = \"\" self . __dict__ . update ( attribute_dictonary ) self . valid = False","title":"__init__()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.new_roadway","text":"Probably delete. Reads a New Roadway card. Source code in network_wrangler/projectcard.py 275 276 277 278 279 280 281 282 283 def new_roadway ( self , card : dict ): \"\"\" Probably delete. Reads a New Roadway card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" ))","title":"new_roadway()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.new_transit_right_of_way","text":"Probably delete. Reads a New Transit Dedicated Right of Way card. Source code in network_wrangler/projectcard.py 295 296 297 298 299 300 301 302 303 def new_transit_right_of_way ( self , card : dict ): \"\"\" Probably delete. Reads a New Transit Dedicated Right of Way card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" ))","title":"new_transit_right_of_way()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.parallel_managed_lanes","text":"Probably delete. Reads a Parallel Managed lanes card. Source code in network_wrangler/projectcard.py 305 306 307 308 309 310 311 312 313 def parallel_managed_lanes ( self , card : dict ): \"\"\" Probably delete. Reads a Parallel Managed lanes card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" ))","title":"parallel_managed_lanes()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.read","text":"Reads and validates a Project card Returns a Project Card object Source code in network_wrangler/projectcard.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @staticmethod def read ( path_to_card : str , validate : bool = True ): \"\"\" Reads and validates a Project card args: path_to_card: the path to the project card Returns a Project Card object \"\"\" card_suffix = path_to_card . split ( \".\" )[ - 1 ] . lower () if card_suffix in [ \"yaml\" , 'yml' ]: attribute_dictionary = ProjectCard . read_yml ( path_to_card ) elif card_suffix in [ \"wrangler\" , 'wr' ]: attribute_dictionary = ProjectCard . read_wrangler_card ( path_to_card ) else : msg = \"Card should have a suffix of yaml, yml, wrangler, or wr. Found suffix: {} \" . format ( card_suffix ) raise ValueError ( msg ) card = ProjectCard ( attribute_dictionary ) if card . project in ProjectCard . UNSPECIFIED_PROJECT_NAMES : msg = \"Card must have valid project name: {} \" . format ( path_to_card ) WranglerLogger . error ( msg ) raise ValueError ( msg ) card . valid = False if validate : card . valid = ProjectCard . validate_project_card_schema ( path_to_card ) return card","title":"read()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.read_wrangler_card","text":"Reads wrangler project cards with YAML front matter and then python code. Parameters: Name Type Description Default path_to_card str where the project card is required Source code in network_wrangler/projectcard.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 @staticmethod def read_wrangler_card ( path_to_card : str ) -> dict : \"\"\" Reads wrangler project cards with YAML front matter and then python code. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading Wrangler-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : delim = cardfile . readline () WranglerLogger . debug ( \"Using delimiter: {} \" . format ( delim )) _yaml , _pycode = cardfile . read () . split ( delim ) WranglerLogger . debug ( \"_yaml: {} \\n _pycode: {} \" . format ( _yaml , _pycode )) attribute_dictionary = yaml . load ( _yaml ) attribute_dictionary [ \"file\" ] = path_to_card attribute_dictionary [ \"pycode\" ] = _pycode . lstrip ( \" \\n \" ) return attribute_dictionary","title":"read_wrangler_card()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.read_yml","text":"Reads \u201cnormal\u201d wrangler project cards defined in YAML. Parameters: Name Type Description Default path_to_card str where the project card is required Source code in network_wrangler/projectcard.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 @staticmethod def read_yml ( path_to_card : str ) -> dict : \"\"\" Reads \"normal\" wrangler project cards defined in YAML. Args: path_to_card: where the project card is Returns: Attribute Dictionary for Project Card \"\"\" WranglerLogger . debug ( \"Reading YAML-Style Project Card\" ) with open ( path_to_card , \"r\" ) as cardfile : attribute_dictionary = yaml . safe_load ( cardfile ) attribute_dictionary [ \"file\" ] = path_to_card return attribute_dictionary","title":"read_yml()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.roadway_attribute_change","text":"Probably delete. Reads a Roadway Attribute Change card. Source code in network_wrangler/projectcard.py 265 266 267 268 269 270 271 272 273 def roadway_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Roadway Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" ))","title":"roadway_attribute_change()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.transit_attribute_change","text":"Probably delete. Reads a Transit Service Attribute Change card. Source code in network_wrangler/projectcard.py 285 286 287 288 289 290 291 292 293 def transit_attribute_change ( self , card : dict ): \"\"\" Probably delete. Reads a Transit Service Attribute Change card. args: card: the project card stored in a dictionary \"\"\" WranglerLogger . info ( card . get ( \"Category\" ))","title":"transit_attribute_change()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.validate_project_card_schema","text":"Tests project card schema validity by evaluating if it conforms to the schemas Source code in network_wrangler/projectcard.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 @staticmethod def validate_project_card_schema ( card_file , card_schema_file : str = \"project_card.json\" ) -> bool : \"\"\" Tests project card schema validity by evaluating if it conforms to the schemas returns: boolean \"\"\" if not os . path . exists ( card_schema_file ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) card_schema_file = os . path . join ( base_path , card_schema_file ) with open ( card_schema_file ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( card_file , \"r\" ) as card : card_json = yaml . safe_load ( card ) try : validate ( card_json , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Project Card validation: Validation Error\" ) WranglerLogger . error ( \"Project Card File Loc: {} \" . format ( card_file )) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Failed Project Card schema validation: Schema Error\" ) WranglerLogger . error ( \"Project Card Schema Loc: {} \" . format ( card_schema_file )) WranglerLogger . error ( exc . message ) except yaml . YAMLError as exc : WranglerLogger . error ( exc . message )","title":"validate_project_card_schema()"},{"location":"api/#network_wrangler.projectcard.ProjectCard.write","text":"Writes project card dictionary to YAML file Source code in network_wrangler/projectcard.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def write ( self , filename : str = None ): \"\"\" Writes project card dictionary to YAML file \"\"\" if not filename : from network_wrangler.utils import make_slug filename = make_slug ( self . project ) + \".yml\" # import collections # out_dict = collections.OrderedDict() out_dict = {} out_dict [ \"project\" ] = None out_dict [ \"tags\" ] = \"\" out_dict [ \"dependencies\" ] = \"\" out_dict . update ( self . __dict__ ) with open ( filename , \"w\" ) as outfile : yaml . dump ( out_dict , outfile , default_flow_style = False , sort_keys = False ) WranglerLogger . info ( \"Wrote project card to: {} \" . format ( filename ))","title":"write()"},{"location":"api/#network_wrangler.Scenario","text":"Bases: object Holds information about a scenario. .. highlight:: python Typical usage example: :: my_base_scenario = { \u201croad_net\u201d: RoadwayNetwork.read( link_file=STPAUL_LINK_FILE, node_file=STPAUL_NODE_FILE, shape_file=STPAUL_SHAPE_FILE, fast=True, ), \u201ctransit_net\u201d: TransitNetwork.read(STPAUL_DIR), } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 card_filenames = [ \"3_multiple_roadway_attribute_change.yml\" , \"multiple_changes.yml\" , \"4_simple_managed_lane.yml\" , ] project_card_directory = os . path . join ( STPAUL_DIR , \"project_cards\" ) project_cards_list = [ ProjectCard . read ( os . path . join ( project_card_directory , filename ) , validate = False ) for filename in card_filenames ] my_scenario = Scenario . create_scenario ( base_scenario = my_base_scenario , project_cards_list = project_cards_list , ) my_scenario . check_scenario_requisites () my_scenario . apply_all_projects () my_scenario . scenario_summary () Attributes: Name Type Description base_scenario dictionary representation of a scenario project_cards Optional list of Project Card Instances road_net instance of RoadwayNetwork for the scenario transit_net instance of TransitNetwork for the scenario applied_projects list of project names that have been applied project_cards list of project card instances ordered_project_cards prerequisites dictionary storing prerequiste information corequisites dictionary storing corequisite information conflicts dictionary storing conflict information requisites_checked boolean indicating if the co- and pre-requisites have been checked in the project cards conflicts_checked boolean indicating if the project conflicts have been checked has_requisite_error boolean indicating if there is a conflict in the pre- or co-requisites of project cards has_conflict_error boolean indicating if there is are conflicting project cards prerequisites_sorted boolean indicating if the project cards have been sorted to make sure cards that are pre-requisites are applied first Source code in network_wrangler/scenario.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 class Scenario ( object ): \"\"\" Holds information about a scenario. .. highlight:: python Typical usage example: :: my_base_scenario = { \"road_net\": RoadwayNetwork.read( link_file=STPAUL_LINK_FILE, node_file=STPAUL_NODE_FILE, shape_file=STPAUL_SHAPE_FILE, fast=True, ), \"transit_net\": TransitNetwork.read(STPAUL_DIR), } card_filenames = [ \"3_multiple_roadway_attribute_change.yml\", \"multiple_changes.yml\", \"4_simple_managed_lane.yml\", ] project_card_directory = os.path.join(STPAUL_DIR, \"project_cards\") project_cards_list = [ ProjectCard.read(os.path.join(project_card_directory, filename), validate=False) for filename in card_filenames ] my_scenario = Scenario.create_scenario( base_scenario=my_base_scenario, project_cards_list=project_cards_list, ) my_scenario.check_scenario_requisites() my_scenario.apply_all_projects() my_scenario.scenario_summary() Attributes: base_scenario: dictionary representation of a scenario project_cards (Optional): list of Project Card Instances road_net: instance of RoadwayNetwork for the scenario transit_net: instance of TransitNetwork for the scenario applied_projects: list of project names that have been applied project_cards: list of project card instances ordered_project_cards: prerequisites: dictionary storing prerequiste information corequisites: dictionary storing corequisite information conflicts: dictionary storing conflict information requisites_checked: boolean indicating if the co- and pre-requisites have been checked in the project cards conflicts_checked: boolean indicating if the project conflicts have been checked has_requisite_error: boolean indicating if there is a conflict in the pre- or co-requisites of project cards has_conflict_error: boolean indicating if there is are conflicting project cards prerequisites_sorted: boolean indicating if the project cards have been sorted to make sure cards that are pre-requisites are applied first \"\"\" def __init__ ( self , base_scenario : dict , project_cards : [ ProjectCard ] = None ): \"\"\" Constructor args: base_scenario: dict the base scenario project_cards: list this scenario's project cards \"\"\" self . road_net = None self . transit_net = None self . base_scenario = base_scenario # if the base scenario had roadway or transit networks, use them as the basis. if self . base_scenario . get ( \"road_net\" ): self . road_net = copy . deepcopy ( self . base_scenario [ \"road_net\" ]) if self . base_scenario . get ( \"transit_net\" ): self . transit_net = copy . deepcopy ( self . base_scenario [ \"transit_net\" ]) # if the base scenario had applied projects, add them to the list of applied self . applied_projects = [] if self . base_scenario . get ( \"applied_projects\" ): self . applied_projects = base_scenario [ \"applied_projects\" ] self . project_cards = project_cards self . ordered_project_cards = OrderedDict () self . prerequisites = {} self . corequisites = {} self . conflicts = {} self . requisites_checked = False self . conflicts_checked = False self . has_requisite_error = False self . has_conflict_error = False self . prerequisites_sorted = False for card in self . project_cards : if not card . __dict__ . get ( \"dependencies\" ): continue if card . dependencies . get ( \"prerequisites\" ): self . prerequisites . update ( { card . project : card . dependencies [ \"prerequisites\" ]} ) if card . dependencies . get ( \"corequisites\" ): self . corequisites . update ( { card . project : card . dependencies [ \"corequisites\" ]} ) @staticmethod def create_base_scenario ( base_shape_name : str , base_link_name : str , base_node_name : str , roadway_dir : str = \"\" , transit_dir : str = \"\" , validate : bool = True , ) -> Scenario : \"\"\" args ----- roadway_dir: optional path to the base scenario roadway network files base_shape_name: filename of the base network shape base_link_name: filename of the base network link base_node_name: filename of the base network node transit_dir: optional path to base scenario transit files validate: boolean indicating whether to validate the base network or not \"\"\" if roadway_dir : base_network_shape_file = os . path . join ( roadway_dir , base_shape_name ) base_network_link_file = os . path . join ( roadway_dir , base_link_name ) base_network_node_file = os . path . join ( roadway_dir , base_node_name ) else : base_network_shape_file = base_shape_name base_network_link_file = base_link_name base_network_node_file = base_node_name road_net = RoadwayNetwork . read ( link_file = base_network_link_file , node_file = base_network_node_file , shape_file = base_network_shape_file , fast = not validate , ) if transit_dir : transit_net = TransitNetwork . read ( transit_dir ) else : transit_net = None WranglerLogger . info ( \"No transit directory specified, base scenario will have empty transit network.\" ) transit_net . set_roadnet ( road_net , validate_consistency = validate ) base_scenario = { \"road_net\" : road_net , \"transit_net\" : transit_net } return base_scenario @staticmethod def create_scenario ( base_scenario : dict = {}, card_directory : str = \"\" , tags : [ str ] = None , project_cards_list = [], glob_search = \"\" , validate_project_cards = True , ) -> Scenario : \"\"\" Validates project cards with a specific tag from the specified folder or list of user specified project cards and creates a scenario object with the valid project card. args ----- base_scenario: object dictionary for the base scenario (i.e. my_base_scenario.__dict__) tags: only project cards with these tags will be read/validated folder: the folder location where the project cards will be project_cards_list: list of project cards to be applied glob_search: \"\"\" WranglerLogger . info ( \"Creating Scenario\" ) if project_cards_list : WranglerLogger . debug ( \"Adding project cards from List. \\n {} \" . format ( \",\" . join ([ p . project for p in project_cards_list ]) ) ) scenario = Scenario ( base_scenario , project_cards = project_cards_list ) if card_directory and tags : WranglerLogger . debug ( \"Adding project cards from directory and tags. \\n Dir: {} \\n Tags: {} \" . format ( card_directory , \",\" . join ( tags ) ) ) scenario . add_project_cards_from_tags ( card_directory , tags = tags , glob_search = glob_search , validate = validate_project_cards , ) elif card_directory : WranglerLogger . debug ( \"Adding project cards from directory. \\n Dir: {} \" . format ( card_directory ) ) scenario . add_project_cards_from_directory ( card_directory , glob_search = glob_search , validate = validate_project_cards ) return scenario def add_project_card_from_file ( self , project_card_file : str , validate : bool = True , tags : list = [] ): WranglerLogger . debug ( \"Trying to add project card from file: {} \" . format ( project_card_file ) ) project_card = ProjectCard . read ( project_card_file , validate = validate ) if project_card == None : msg = \"project card not read: {} \" . format ( project_card_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if tags and set ( tags ) . isdisjoint ( project_card . tags ): WranglerLogger . debug ( \"Project card tags: {} don't match search tags: {} \" . format ( \",\" . join ( project_card . tags ), \",\" . join ( tags ) ) ) return if project_card . project in self . get_project_names (): msg = \"project card with name ' {} ' already in Scenario. Project names must be unique\" . format ( project_card . project ) WranglerLogger . error ( msg ) raise ValueError ( msg ) self . requisites_checked = False self . conflicts_checked = False self . prerequisites_sorted = False WranglerLogger . debug ( \"Adding project card to scenario: {} \" . format ( project_card . project ) ) self . project_cards . append ( project_card ) if not project_card . __dict__ . get ( \"dependencies\" ): return WranglerLogger . debug ( \"Adding project card dependencies\" ) if project_card . dependencies . get ( \"prerequisites\" ): self . prerequisites . update ( { project_card . project : project_card . dependencies [ \"prerequisites\" ]} ) if project_card . dependencies . get ( \"corequisites\" ): self . corequisites . update ( { project_card . project : project_card . dependencies [ \"corequisites\" ]} ) if project_card . dependencies . get ( \"conflicts\" ): self . conflicts . update ( { project_card . project : project_card . dependencies [ \"conflicts\" ]} ) def add_project_cards_from_directory ( self , folder : str , glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards and if applicable, a glob-style search. i.e. glob_search = 'road*.yml' args: folder: the folder location where the project cards will be glob_search: https://docs.python.org/2/library/glob.html \"\"\" if not os . path . exists ( folder ): msg = \"Cannot find specified directory to add project cards: {} \" . format ( folder ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if glob_search : WranglerLogger . debug ( \"Adding project cards using glob search: {} \" . format ( glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( file , validate = validate ) else : for file in os . listdir ( folder ): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( os . path . join ( folder , file ), validate = validate ) def add_project_cards_from_tags ( self , folder : str , tags : [ str ] = [], glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards that have a matching tag that is passed to the method. args: folder: the folder location where the project cards will be tags: only project cards with these tags will be validated and added to the returning scenario \"\"\" if glob_search : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} and \\n glob search: {} \" . format ( tags , glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): self . add_project_card_from_file ( file , tags = tags , validate = validate ) else : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} \" . format ( tags )) for file in os . listdir ( folder ): self . add_project_card_from_file ( file , tags = tags , validate = validate ) def __str__ ( self ): s = [ \" {} : {} \" . format ( key , value ) for key , value in self . __dict__ . items ()] return \" \\n \" . join ( s ) def get_project_names ( self ) -> list : \"\"\" Returns a list of project names \"\"\" return [ project_card . project for project_card in self . project_cards ] def check_scenario_conflicts ( self ) -> bool : \"\"\" Checks if there are any conflicting projects in the scenario Fail if the project A specifies that project B is a conflict and project B is included in the scenario Returns: boolean indicating if the check was successful or returned an error \"\"\" conflict_dict = self . conflicts scenario_projects = [ p . project for p in self . project_cards ] for project , conflicts in conflict_dict . items (): if conflicts : for name in conflicts : if name in scenario_projects : self . project_cards WranglerLogger . error ( \"Projects %s has %s as conflicting project\" % ( project , name ) ) self . has_conflict_error = True self . conflicts_checked = True return self . has_conflict_error def check_scenario_requisites ( self ) -> bool : \"\"\" Checks if there are any missing pre- or co-requisite projects in the scenario Fail if the project A specifies that project B is a pre- or co-requisite and project B is not included in the scenario Returns: boolean indicating if the checks were successful or returned an error \"\"\" corequisite_dict = self . corequisites prerequisite_dict = self . prerequisites scenario_projects = [ p . project for p in self . project_cards ] for project , coreq in corequisite_dict . items (): if coreq : for name in coreq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as corequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True for project , prereq in prerequisite_dict . items (): if prereq : for name in prereq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as prerequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True self . requisites_checked = True return self . has_requisite_error def order_project_cards ( self ): \"\"\" create a list of project cards such that they are in order based on pre-requisites Returns: ordered list of project cards to be applied to scenario \"\"\" scenario_projects = [ p . project . lower () for p in self . project_cards ] # build prereq (adjacency) list for topological sort adjacency_list = defaultdict ( list ) visited_list = defaultdict () for project in scenario_projects : visited_list [ project ] = False if not self . prerequisites . get ( project ): continue for prereq in self . prerequisites [ project ]: if ( prereq . lower () in scenario_projects ): # this will always be true, else would have been flagged in missing prerequsite check, but just in case adjacency_list [ prereq . lower ()] = [ project ] # sorted_project_names is topological sorted project card names (based on prerequsiite) sorted_project_names = topological_sort ( adjacency_list = adjacency_list , visited_list = visited_list ) # get the project card objects for these sorted project names project_card_and_name_dict = {} for project_card in self . project_cards : project_card_and_name_dict [ project_card . project . lower ()] = project_card sorted_project_cards = [ project_card_and_name_dict [ project_name ] for project_name in sorted_project_names ] try : assert len ( sorted_project_cards ) == len ( self . project_cards ) except : msg = \"Sorted project cards ( {} ) are not of same number as unsorted ( {} ).\" . format ( len ( sorted_project_cards ), len ( self . project_cards ) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) self . prerequisites_sorted = True self . ordered_project_cards = { project_name : project_card_and_name_dict [ project_name ] for project_name in sorted_project_names } WranglerLogger . debug ( \"Ordered Project Cards: {} \" . format ( self . ordered_project_cards ) ) self . project_cards = sorted_project_cards WranglerLogger . debug ( \"Project Cards: {} \" . format ( self . project_cards )) return sorted_project_cards def apply_all_projects ( self ): # Get everything in order if not self . requisites_checked : self . check_scenario_requisites () if not self . conflicts_checked : self . check_scenario_conflicts () if not self . prerequisites_sorted : self . order_project_cards () for p in self . project_cards : self . apply_project ( p . __dict__ ) def apply_project ( self , p ): if isinstance ( p , ProjectCard ): p = p . __dict__ if p . get ( \"project\" ): WranglerLogger . info ( \"Applying {} \" . format ( p [ \"project\" ])) if p . get ( \"changes\" ): part = 1 for pc in p [ \"changes\" ]: pc [ \"project\" ] = p [ \"project\" ] self . apply_project ( pc ) else : if p [ \"category\" ] in ProjectCard . ROADWAY_CATEGORIES : if not self . road_net : raise ( \"Missing Roadway Network\" ) self . road_net . apply ( p ) if p [ \"category\" ] in ProjectCard . TRANSIT_CATEGORIES : if not self . transit_net : raise ( \"Missing Transit Network\" ) self . transit_net . apply ( p ) if ( p [ \"category\" ] in ProjectCard . SECONDARY_TRANSIT_CATEGORIES and self . transit_net ): self . transit_net . apply ( p ) if p [ \"project\" ] not in self . applied_projects : self . applied_projects . append ( p [ \"project\" ]) def remove_all_projects ( self ): self . project_cards = [] def applied_project_card_summary ( self , project_card_dictionary : dict ) -> dict : \"\"\" Create a summary of applied project card and what they changed for the scenario. Args: project_card_dictionary: dictionary representation of the values of a project card (i.e. ProjectCard.__dict__ ) Returns: A dict of project summary change dictionaries for each change \"\"\" changes = project_card_dictionary . get ( \"changes\" , [ project_card_dictionary ]) summary = { \"project_card\" : project_card_dictionary [ \"file\" ], \"total_parts\" : len ( changes ), } def _summarize_change_roadway ( change : dict , change_summary : dict ): sel_key = RoadwayNetwork . build_selection_key ( self . road_net , change [ \"facility\" ] ) change_summary [ \"sel_idx\" ] = self . road_net . selections [ sel_key ][ \"selected_links\" ] . index . tolist () change_summary [ \"attributes\" ] = [ p [ \"property\" ] for p in change [ \"properties\" ]] if type ( sel_key ) == tuple : _ , A_id , B_id = sel_key else : A_id , B_id = ( None , None ) change_summary [ \"map\" ] = self . road_net . selection_map ( change_summary [ \"sel_idx\" ], A = A_id , B = B_id , candidate_link_idx = self . road_net . selections [ sel_key ] . get ( \"candidate_links\" , pd . DataFrame ([])) . index . tolist (), ) return change_summary def _summarize_add_roadway ( change : dict , change_summary : dict ): change_summary [ \"added_links\" ] = pd . DataFrame ( change . get ( \"links\" )) change_summary [ \"added_nodes\" ] = pd . DataFrame ( change . get ( \"nodes\" )) change_summary [ \"map\" ] = RoadwayNetwork . addition_map ( self . road_net , change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary def _summarize_deletion ( change : dict , change_summary : dict ): change_summary [ \"deleted_links\" ] = change . get ( \"links\" ) change_summary [ \"deleted_nodes\" ] = change . get ( \"nodes\" ) change_summary [ \"map\" ] = RoadwayNetwork . deletion_map ( self . base_scenario [ \"road_net\" ], change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary for i , change in enumerate ( changes ): WranglerLogger . debug ( \"Summarizing {} Part: {} \" . format ( project_card_dictionary [ \"project\" ], i + 1 ) ) change_summary = { \"project\" : project_card_dictionary [ \"project\" ] + \" \u2013 Part \" + str ( i + 1 ), \"category\" : change [ \"category\" ] . lower (), } if change [ \"category\" ] . lower () == \"roadway deletion\" : change_summary = _summarize_deletion ( change , change_summary ) elif change [ \"category\" ] . lower () == \"add new roadway\" : change_summary = _summarize_add_roadway ( change , change_summary ) elif change [ \"category\" ] . lower () in [ \"roadway property change\" , \"parallel managed lanes\" , ]: change_summary = _summarize_change_roadway ( change , change_summary ) summary [ \"Part \" + str ( i + 1 )] = change_summary return summary def scenario_summary ( self , project_detail : bool = True , outfile : str = \"\" , mode : str = \"a\" ) -> str : \"\"\" A high level summary of the created scenario. Args: project_detail: If True (default), will write out project card summaries. outfile: If specified, will write scenario summary to text file. mode: Outfile open mode. 'a' to append 'w' to overwrite. Returns: string of summary \"\"\" WranglerLogger . info ( \"Summarizing Scenario\" ) report_str = \"------------------------------ \\n \" report_str += \"Scenario created on {} \\n \" . format ( datetime . now ()) report_str += \"Base Scenario: \\n \" report_str += \"--Road Network: \\n \" report_str += \"----Link File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . link_file ) report_str += \"----Node File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . node_file ) report_str += \"----Shape File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . shape_file ) report_str += \"--Transit Network: \\n \" report_str += \"----Feed Path: {} \\n \" . format ( self . base_scenario [ \"transit_net\" ] . feed_path ) report_str += \" \\n Project Cards: \\n -\" report_str += \" \\n -\" . join ( p . file for p in self . project_cards ) report_str += \" \\n Applied Projects: \\n -\" report_str += \" \\n -\" . join ( self . applied_projects ) if project_detail : report_str += \" \\n ---Project Card Details--- \\n \" for p in self . project_cards : report_str += \" \\n {} \" . format ( pprint . pformat ( self . applied_project_card_summary ( p . __dict__ )) ) if outfile : with open ( outfile , mode ) as f : f . write ( report_str ) WranglerLogger . info ( \"Wrote Scenario Report to: {} \" . format ( outfile )) return report_str","title":"Scenario"},{"location":"api/#network_wrangler.scenario.Scenario.__init__","text":"Constructor Source code in network_wrangler/scenario.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def __init__ ( self , base_scenario : dict , project_cards : [ ProjectCard ] = None ): \"\"\" Constructor args: base_scenario: dict the base scenario project_cards: list this scenario's project cards \"\"\" self . road_net = None self . transit_net = None self . base_scenario = base_scenario # if the base scenario had roadway or transit networks, use them as the basis. if self . base_scenario . get ( \"road_net\" ): self . road_net = copy . deepcopy ( self . base_scenario [ \"road_net\" ]) if self . base_scenario . get ( \"transit_net\" ): self . transit_net = copy . deepcopy ( self . base_scenario [ \"transit_net\" ]) # if the base scenario had applied projects, add them to the list of applied self . applied_projects = [] if self . base_scenario . get ( \"applied_projects\" ): self . applied_projects = base_scenario [ \"applied_projects\" ] self . project_cards = project_cards self . ordered_project_cards = OrderedDict () self . prerequisites = {} self . corequisites = {} self . conflicts = {} self . requisites_checked = False self . conflicts_checked = False self . has_requisite_error = False self . has_conflict_error = False self . prerequisites_sorted = False for card in self . project_cards : if not card . __dict__ . get ( \"dependencies\" ): continue if card . dependencies . get ( \"prerequisites\" ): self . prerequisites . update ( { card . project : card . dependencies [ \"prerequisites\" ]} ) if card . dependencies . get ( \"corequisites\" ): self . corequisites . update ( { card . project : card . dependencies [ \"corequisites\" ]} )","title":"__init__()"},{"location":"api/#network_wrangler.scenario.Scenario.add_project_cards_from_directory","text":"Adds projects cards to the scenario. A folder is provided to look for project cards and if applicable, a glob-style search. i.e. glob_search = \u2018road*.yml\u2019 Source code in network_wrangler/scenario.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def add_project_cards_from_directory ( self , folder : str , glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards and if applicable, a glob-style search. i.e. glob_search = 'road*.yml' args: folder: the folder location where the project cards will be glob_search: https://docs.python.org/2/library/glob.html \"\"\" if not os . path . exists ( folder ): msg = \"Cannot find specified directory to add project cards: {} \" . format ( folder ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if glob_search : WranglerLogger . debug ( \"Adding project cards using glob search: {} \" . format ( glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( file , validate = validate ) else : for file in os . listdir ( folder ): if not file . endswith ( \".yml\" ) or file . endswith ( \".yaml\" ): continue else : self . add_project_card_from_file ( os . path . join ( folder , file ), validate = validate )","title":"add_project_cards_from_directory()"},{"location":"api/#network_wrangler.scenario.Scenario.add_project_cards_from_tags","text":"Adds projects cards to the scenario. A folder is provided to look for project cards that have a matching tag that is passed to the method. Source code in network_wrangler/scenario.py 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 def add_project_cards_from_tags ( self , folder : str , tags : [ str ] = [], glob_search = \"\" , validate = True ): \"\"\" Adds projects cards to the scenario. A folder is provided to look for project cards that have a matching tag that is passed to the method. args: folder: the folder location where the project cards will be tags: only project cards with these tags will be validated and added to the returning scenario \"\"\" if glob_search : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} and \\n glob search: {} \" . format ( tags , glob_search ) ) for file in glob . iglob ( os . path . join ( folder , glob_search )): self . add_project_card_from_file ( file , tags = tags , validate = validate ) else : WranglerLogger . debug ( \"Adding project cards using \\n -tags: {} \" . format ( tags )) for file in os . listdir ( folder ): self . add_project_card_from_file ( file , tags = tags , validate = validate )","title":"add_project_cards_from_tags()"},{"location":"api/#network_wrangler.scenario.Scenario.applied_project_card_summary","text":"Create a summary of applied project card and what they changed for the scenario. Parameters: Name Type Description Default project_card_dictionary dict dictionary representation of the values of a project card (i.e. ProjectCard. dict ) required Returns: Type Description dict A dict of project summary change dictionaries for each change Source code in network_wrangler/scenario.py 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 def applied_project_card_summary ( self , project_card_dictionary : dict ) -> dict : \"\"\" Create a summary of applied project card and what they changed for the scenario. Args: project_card_dictionary: dictionary representation of the values of a project card (i.e. ProjectCard.__dict__ ) Returns: A dict of project summary change dictionaries for each change \"\"\" changes = project_card_dictionary . get ( \"changes\" , [ project_card_dictionary ]) summary = { \"project_card\" : project_card_dictionary [ \"file\" ], \"total_parts\" : len ( changes ), } def _summarize_change_roadway ( change : dict , change_summary : dict ): sel_key = RoadwayNetwork . build_selection_key ( self . road_net , change [ \"facility\" ] ) change_summary [ \"sel_idx\" ] = self . road_net . selections [ sel_key ][ \"selected_links\" ] . index . tolist () change_summary [ \"attributes\" ] = [ p [ \"property\" ] for p in change [ \"properties\" ]] if type ( sel_key ) == tuple : _ , A_id , B_id = sel_key else : A_id , B_id = ( None , None ) change_summary [ \"map\" ] = self . road_net . selection_map ( change_summary [ \"sel_idx\" ], A = A_id , B = B_id , candidate_link_idx = self . road_net . selections [ sel_key ] . get ( \"candidate_links\" , pd . DataFrame ([])) . index . tolist (), ) return change_summary def _summarize_add_roadway ( change : dict , change_summary : dict ): change_summary [ \"added_links\" ] = pd . DataFrame ( change . get ( \"links\" )) change_summary [ \"added_nodes\" ] = pd . DataFrame ( change . get ( \"nodes\" )) change_summary [ \"map\" ] = RoadwayNetwork . addition_map ( self . road_net , change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary def _summarize_deletion ( change : dict , change_summary : dict ): change_summary [ \"deleted_links\" ] = change . get ( \"links\" ) change_summary [ \"deleted_nodes\" ] = change . get ( \"nodes\" ) change_summary [ \"map\" ] = RoadwayNetwork . deletion_map ( self . base_scenario [ \"road_net\" ], change . get ( \"links\" ), change . get ( \"nodes\" ), ) return change_summary for i , change in enumerate ( changes ): WranglerLogger . debug ( \"Summarizing {} Part: {} \" . format ( project_card_dictionary [ \"project\" ], i + 1 ) ) change_summary = { \"project\" : project_card_dictionary [ \"project\" ] + \" \u2013 Part \" + str ( i + 1 ), \"category\" : change [ \"category\" ] . lower (), } if change [ \"category\" ] . lower () == \"roadway deletion\" : change_summary = _summarize_deletion ( change , change_summary ) elif change [ \"category\" ] . lower () == \"add new roadway\" : change_summary = _summarize_add_roadway ( change , change_summary ) elif change [ \"category\" ] . lower () in [ \"roadway property change\" , \"parallel managed lanes\" , ]: change_summary = _summarize_change_roadway ( change , change_summary ) summary [ \"Part \" + str ( i + 1 )] = change_summary return summary","title":"applied_project_card_summary()"},{"location":"api/#network_wrangler.scenario.Scenario.check_scenario_conflicts","text":"Checks if there are any conflicting projects in the scenario Fail if the project A specifies that project B is a conflict and project B is included in the scenario Source code in network_wrangler/scenario.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 def check_scenario_conflicts ( self ) -> bool : \"\"\" Checks if there are any conflicting projects in the scenario Fail if the project A specifies that project B is a conflict and project B is included in the scenario Returns: boolean indicating if the check was successful or returned an error \"\"\" conflict_dict = self . conflicts scenario_projects = [ p . project for p in self . project_cards ] for project , conflicts in conflict_dict . items (): if conflicts : for name in conflicts : if name in scenario_projects : self . project_cards WranglerLogger . error ( \"Projects %s has %s as conflicting project\" % ( project , name ) ) self . has_conflict_error = True self . conflicts_checked = True return self . has_conflict_error","title":"check_scenario_conflicts()"},{"location":"api/#network_wrangler.scenario.Scenario.check_scenario_requisites","text":"Checks if there are any missing pre- or co-requisite projects in the scenario Fail if the project A specifies that project B is a pre- or co-requisite and project B is not included in the scenario Source code in network_wrangler/scenario.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 def check_scenario_requisites ( self ) -> bool : \"\"\" Checks if there are any missing pre- or co-requisite projects in the scenario Fail if the project A specifies that project B is a pre- or co-requisite and project B is not included in the scenario Returns: boolean indicating if the checks were successful or returned an error \"\"\" corequisite_dict = self . corequisites prerequisite_dict = self . prerequisites scenario_projects = [ p . project for p in self . project_cards ] for project , coreq in corequisite_dict . items (): if coreq : for name in coreq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as corequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True for project , prereq in prerequisite_dict . items (): if prereq : for name in prereq : if name not in scenario_projects : WranglerLogger . error ( \"Projects %s has %s as prerequisite project which is missing for the scenario\" % ( project , name ) ) self . has_requisite_error = True self . requisites_checked = True return self . has_requisite_error","title":"check_scenario_requisites()"},{"location":"api/#network_wrangler.scenario.Scenario.create_base_scenario","text":"","title":"create_base_scenario()"},{"location":"api/#network_wrangler.scenario.Scenario.create_base_scenario--args","text":"optional path to the base scenario roadway network files base_shape_name filename of the base network shape base_link_name filename of the base network link base_node_name filename of the base network node optional path to base scenario transit files validate boolean indicating whether to validate the base network or not Source code in network_wrangler/scenario.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 @staticmethod def create_base_scenario ( base_shape_name : str , base_link_name : str , base_node_name : str , roadway_dir : str = \"\" , transit_dir : str = \"\" , validate : bool = True , ) -> Scenario : \"\"\" args ----- roadway_dir: optional path to the base scenario roadway network files base_shape_name: filename of the base network shape base_link_name: filename of the base network link base_node_name: filename of the base network node transit_dir: optional path to base scenario transit files validate: boolean indicating whether to validate the base network or not \"\"\" if roadway_dir : base_network_shape_file = os . path . join ( roadway_dir , base_shape_name ) base_network_link_file = os . path . join ( roadway_dir , base_link_name ) base_network_node_file = os . path . join ( roadway_dir , base_node_name ) else : base_network_shape_file = base_shape_name base_network_link_file = base_link_name base_network_node_file = base_node_name road_net = RoadwayNetwork . read ( link_file = base_network_link_file , node_file = base_network_node_file , shape_file = base_network_shape_file , fast = not validate , ) if transit_dir : transit_net = TransitNetwork . read ( transit_dir ) else : transit_net = None WranglerLogger . info ( \"No transit directory specified, base scenario will have empty transit network.\" ) transit_net . set_roadnet ( road_net , validate_consistency = validate ) base_scenario = { \"road_net\" : road_net , \"transit_net\" : transit_net } return base_scenario","title":"args"},{"location":"api/#network_wrangler.scenario.Scenario.create_scenario","text":"Validates project cards with a specific tag from the specified folder or list of user specified project cards and creates a scenario object with the valid project card.","title":"create_scenario()"},{"location":"api/#network_wrangler.scenario.Scenario.create_scenario--args","text":"base_scenario object dictionary for the base scenario (i.e. my_base_scenario. dict ) tags only project cards with these tags will be read/validated folder the folder location where the project cards will be project_cards_list list of project cards to be applied Source code in network_wrangler/scenario.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 @staticmethod def create_scenario ( base_scenario : dict = {}, card_directory : str = \"\" , tags : [ str ] = None , project_cards_list = [], glob_search = \"\" , validate_project_cards = True , ) -> Scenario : \"\"\" Validates project cards with a specific tag from the specified folder or list of user specified project cards and creates a scenario object with the valid project card. args ----- base_scenario: object dictionary for the base scenario (i.e. my_base_scenario.__dict__) tags: only project cards with these tags will be read/validated folder: the folder location where the project cards will be project_cards_list: list of project cards to be applied glob_search: \"\"\" WranglerLogger . info ( \"Creating Scenario\" ) if project_cards_list : WranglerLogger . debug ( \"Adding project cards from List. \\n {} \" . format ( \",\" . join ([ p . project for p in project_cards_list ]) ) ) scenario = Scenario ( base_scenario , project_cards = project_cards_list ) if card_directory and tags : WranglerLogger . debug ( \"Adding project cards from directory and tags. \\n Dir: {} \\n Tags: {} \" . format ( card_directory , \",\" . join ( tags ) ) ) scenario . add_project_cards_from_tags ( card_directory , tags = tags , glob_search = glob_search , validate = validate_project_cards , ) elif card_directory : WranglerLogger . debug ( \"Adding project cards from directory. \\n Dir: {} \" . format ( card_directory ) ) scenario . add_project_cards_from_directory ( card_directory , glob_search = glob_search , validate = validate_project_cards ) return scenario","title":"args"},{"location":"api/#network_wrangler.scenario.Scenario.get_project_names","text":"Returns a list of project names Source code in network_wrangler/scenario.py 376 377 378 379 380 def get_project_names ( self ) -> list : \"\"\" Returns a list of project names \"\"\" return [ project_card . project for project_card in self . project_cards ]","title":"get_project_names()"},{"location":"api/#network_wrangler.scenario.Scenario.order_project_cards","text":"create a list of project cards such that they are in order based on pre-requisites Source code in network_wrangler/scenario.py 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def order_project_cards ( self ): \"\"\" create a list of project cards such that they are in order based on pre-requisites Returns: ordered list of project cards to be applied to scenario \"\"\" scenario_projects = [ p . project . lower () for p in self . project_cards ] # build prereq (adjacency) list for topological sort adjacency_list = defaultdict ( list ) visited_list = defaultdict () for project in scenario_projects : visited_list [ project ] = False if not self . prerequisites . get ( project ): continue for prereq in self . prerequisites [ project ]: if ( prereq . lower () in scenario_projects ): # this will always be true, else would have been flagged in missing prerequsite check, but just in case adjacency_list [ prereq . lower ()] = [ project ] # sorted_project_names is topological sorted project card names (based on prerequsiite) sorted_project_names = topological_sort ( adjacency_list = adjacency_list , visited_list = visited_list ) # get the project card objects for these sorted project names project_card_and_name_dict = {} for project_card in self . project_cards : project_card_and_name_dict [ project_card . project . lower ()] = project_card sorted_project_cards = [ project_card_and_name_dict [ project_name ] for project_name in sorted_project_names ] try : assert len ( sorted_project_cards ) == len ( self . project_cards ) except : msg = \"Sorted project cards ( {} ) are not of same number as unsorted ( {} ).\" . format ( len ( sorted_project_cards ), len ( self . project_cards ) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) self . prerequisites_sorted = True self . ordered_project_cards = { project_name : project_card_and_name_dict [ project_name ] for project_name in sorted_project_names } WranglerLogger . debug ( \"Ordered Project Cards: {} \" . format ( self . ordered_project_cards ) ) self . project_cards = sorted_project_cards WranglerLogger . debug ( \"Project Cards: {} \" . format ( self . project_cards )) return sorted_project_cards","title":"order_project_cards()"},{"location":"api/#network_wrangler.scenario.Scenario.scenario_summary","text":"A high level summary of the created scenario. Parameters: Name Type Description Default project_detail bool If True (default), will write out project card summaries. True outfile str If specified, will write scenario summary to text file. '' mode str Outfile open mode. \u2018a\u2019 to append \u2018w\u2019 to overwrite. 'a' Returns: Type Description str string of summary Source code in network_wrangler/scenario.py 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def scenario_summary ( self , project_detail : bool = True , outfile : str = \"\" , mode : str = \"a\" ) -> str : \"\"\" A high level summary of the created scenario. Args: project_detail: If True (default), will write out project card summaries. outfile: If specified, will write scenario summary to text file. mode: Outfile open mode. 'a' to append 'w' to overwrite. Returns: string of summary \"\"\" WranglerLogger . info ( \"Summarizing Scenario\" ) report_str = \"------------------------------ \\n \" report_str += \"Scenario created on {} \\n \" . format ( datetime . now ()) report_str += \"Base Scenario: \\n \" report_str += \"--Road Network: \\n \" report_str += \"----Link File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . link_file ) report_str += \"----Node File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . node_file ) report_str += \"----Shape File: {} \\n \" . format ( self . base_scenario [ \"road_net\" ] . shape_file ) report_str += \"--Transit Network: \\n \" report_str += \"----Feed Path: {} \\n \" . format ( self . base_scenario [ \"transit_net\" ] . feed_path ) report_str += \" \\n Project Cards: \\n -\" report_str += \" \\n -\" . join ( p . file for p in self . project_cards ) report_str += \" \\n Applied Projects: \\n -\" report_str += \" \\n -\" . join ( self . applied_projects ) if project_detail : report_str += \" \\n ---Project Card Details--- \\n \" for p in self . project_cards : report_str += \" \\n {} \" . format ( pprint . pformat ( self . applied_project_card_summary ( p . __dict__ )) ) if outfile : with open ( outfile , mode ) as f : f . write ( report_str ) WranglerLogger . info ( \"Wrote Scenario Report to: {} \" . format ( outfile )) return report_str","title":"scenario_summary()"},{"location":"api/#network_wrangler.RoadwayNetwork","text":"Bases: object Representation of a Roadway Network. Typical usage example: net = RoadwayNetwork . read ( link_file = MY_LINK_FILE , node_file = MY_NODE_FILE , shape_file = MY_SHAPE_FILE , ) my_selection = { \"link\" : [{ \"name\" : [ \"I 35E\" ]}], \"A\" : { \"osm_node_id\" : \"961117623\" }, # start searching for segments at A \"B\" : { \"osm_node_id\" : \"2564047368\" }, } net . select_roadway_features ( my_selection ) my_change = [ { 'property' : 'lanes' , 'existing' : 1 , 'set' : 2 , }, { 'property' : 'drive_access' , 'set' : 0 , }, ] my_net . apply_roadway_feature_change ( my_net . select_roadway_features ( my_selection ), my_change ) ml_net = net . create_managed_lane_network ( in_place = False ) ml_net . is_network_connected ( mode = \"drive\" )) _ , disconnected_nodes = ml_net . assess_connectivity ( mode = \"walk\" , ignore_end_nodes = True ) ml_net . write ( filename = my_out_prefix , path = my_dir ) Attributes: Name Type Description nodes_df GeoDataFrame node data links_df GeoDataFrame link data, including start and end nodes and associated shape shapes_df GeoDataFrame detailed shape data selections dict dictionary storing selections in case they are made repeatedly CRS str coordinate reference system in PROJ4 format. See https://proj.org/operations/projections/index.html# ESPG int integer representing coordinate system https://epsg.io/ NODE_FOREIGN_KEY str column in nodes_df associated with the LINK_FOREIGN_KEY LINK_FOREIGN_KEY list(str list of columns in link_df that represent the NODE_FOREIGN_KEY UNIQUE_LINK_KEY str column that is a unique key for links UNIQUE_NODE_KEY str column that is a unique key for nodes UNIQUE_SHAPE_KEY str column that is a unique shape key UNIQUE_MODEL_LINK_IDENTIFIERS list(str list of all unique identifiers for links, including the UNIQUE_LINK_KEY UNIQUE_NODE_IDENTIFIERS list(str list of all unique identifiers for nodes, including the UNIQUE_NODE_KEY SELECTION_REQUIRES list(str required attributes in the selection if a unique identifier is not used SEARCH_BREADTH int initial number of links from name-based selection that are traveresed before trying another shortest path when searching for paths between A and B node MAX_SEARCH_BREADTH int maximum number of links traversed between links that match the searched name when searching for paths between A and B node SP_WEIGHT_FACTOR Union(int, float penalty assigned for each degree of distance between a link and a link with the searched-for name when searching for paths between A and B node MANAGED_LANES_TO_NODE_ID_SCALAR int scalar value added to the general purpose lanes\u2019 model_node_id when creating an associated node for a parallel managed lane MANAGED_LANES_TO_LINK_ID_SCALAR int scalar value added to the general purpose lanes\u2019 model_link_id when creating an associated link for a parallel managed lane MANAGED_LANES_REQUIRED_ATTRIBUTES list(str list of attributes that must be provided in managed lanes KEEP_SAME_ATTRIBUTES_ML_AND_GP list(str list of attributes to copy from a general purpose lane to managed lane Source code in network_wrangler/roadwaynetwork.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 class RoadwayNetwork ( object ): \"\"\" Representation of a Roadway Network. Typical usage example: ``` py net = RoadwayNetwork.read( link_file=MY_LINK_FILE, node_file=MY_NODE_FILE, shape_file=MY_SHAPE_FILE, ) my_selection = { \"link\": [{\"name\": [\"I 35E\"]}], \"A\": {\"osm_node_id\": \"961117623\"}, # start searching for segments at A \"B\": {\"osm_node_id\": \"2564047368\"}, } net.select_roadway_features(my_selection) my_change = [ { 'property': 'lanes', 'existing': 1, 'set': 2, }, { 'property': 'drive_access', 'set': 0, }, ] my_net.apply_roadway_feature_change( my_net.select_roadway_features(my_selection), my_change ) ml_net = net.create_managed_lane_network(in_place=False) ml_net.is_network_connected(mode=\"drive\")) _, disconnected_nodes = ml_net.assess_connectivity(mode=\"walk\", ignore_end_nodes=True) ml_net.write(filename=my_out_prefix, path=my_dir) ``` Attributes: nodes_df (GeoDataFrame): node data links_df (GeoDataFrame): link data, including start and end nodes and associated shape shapes_df (GeoDataFrame): detailed shape data selections (dict): dictionary storing selections in case they are made repeatedly CRS (str): coordinate reference system in PROJ4 format. See https://proj.org/operations/projections/index.html# ESPG (int): integer representing coordinate system https://epsg.io/ NODE_FOREIGN_KEY (str): column in `nodes_df` associated with the LINK_FOREIGN_KEY LINK_FOREIGN_KEY (list(str)): list of columns in `link_df` that represent the NODE_FOREIGN_KEY UNIQUE_LINK_KEY (str): column that is a unique key for links UNIQUE_NODE_KEY (str): column that is a unique key for nodes UNIQUE_SHAPE_KEY (str): column that is a unique shape key UNIQUE_MODEL_LINK_IDENTIFIERS (list(str)): list of all unique identifiers for links, including the UNIQUE_LINK_KEY UNIQUE_NODE_IDENTIFIERS (list(str)): list of all unique identifiers for nodes, including the UNIQUE_NODE_KEY SELECTION_REQUIRES (list(str))): required attributes in the selection if a unique identifier is not used SEARCH_BREADTH (int): initial number of links from name-based selection that are traveresed before trying another shortest path when searching for paths between A and B node MAX_SEARCH_BREADTH (int): maximum number of links traversed between links that match the searched name when searching for paths between A and B node SP_WEIGHT_FACTOR (Union(int, float)): penalty assigned for each degree of distance between a link and a link with the searched-for name when searching for paths between A and B node MANAGED_LANES_TO_NODE_ID_SCALAR (int): scalar value added to the general purpose lanes' `model_node_id` when creating an associated node for a parallel managed lane MANAGED_LANES_TO_LINK_ID_SCALAR (int): scalar value added to the general purpose lanes' `model_link_id` when creating an associated link for a parallel managed lane MANAGED_LANES_REQUIRED_ATTRIBUTES (list(str)): list of attributes that must be provided in managed lanes KEEP_SAME_ATTRIBUTES_ML_AND_GP (list(str)): list of attributes to copy from a general purpose lane to managed lane \"\"\" # CRS = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\" CRS = 4326 # \"EPSG:4326\" NODE_FOREIGN_KEY = \"model_node_id\" LINK_FOREIGN_KEY = [ \"A\" , \"B\" ] SEARCH_BREADTH = 5 MAX_SEARCH_BREADTH = 10 SP_WEIGHT_FACTOR = 100 MANAGED_LANES_NODE_ID_SCALAR = 500000 MANAGED_LANES_LINK_ID_SCALAR = 1000000 SELECTION_REQUIRES = [ \"link\" ] UNIQUE_LINK_KEY = \"model_link_id\" UNIQUE_NODE_KEY = \"model_node_id\" UNIQUE_MODEL_LINK_IDENTIFIERS = [ \"model_link_id\" ] UNIQUE_NODE_IDENTIFIERS = [ \"model_node_id\" ] UNIQUE_SHAPE_KEY = \"shape_id\" MANAGED_LANES_REQUIRED_ATTRIBUTES = [ \"A\" , \"B\" , \"model_link_id\" , \"locationReferences\" , ] KEEP_SAME_ATTRIBUTES_ML_AND_GP = [ \"distance\" , \"bike_access\" , \"drive_access\" , \"transit_access\" , \"walk_access\" , \"maxspeed\" , \"name\" , \"oneway\" , \"ref\" , \"roadway\" , \"length\" , \"segment_id\" , ] MANAGED_LANES_SCALAR = 500000 MODES_TO_NETWORK_LINK_VARIABLES = { \"drive\" : [ \"drive_access\" ], \"bus\" : [ \"bus_only\" , \"drive_access\" ], \"rail\" : [ \"rail_only\" ], \"transit\" : [ \"bus_only\" , \"rail_only\" , \"drive_access\" ], \"walk\" : [ \"walk_access\" ], \"bike\" : [ \"bike_access\" ], } MODES_TO_NETWORK_NODE_VARIABLES = { \"drive\" : [ \"drive_node\" ], \"rail\" : [ \"rail_only\" , \"drive_node\" ], \"bus\" : [ \"bus_only\" , \"drive_node\" ], \"transit\" : [ \"bus_only\" , \"rail_only\" , \"drive_node\" ], \"walk\" : [ \"walk_node\" ], \"bike\" : [ \"bike_node\" ], } def __init__ ( self , nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Constructor \"\"\" if not RoadwayNetwork . validate_object_types ( nodes , links , shapes ): sys . exit ( \"RoadwayNetwork: Invalid constructor data type\" ) self . nodes_df = nodes self . links_df = links self . shapes_df = shapes self . link_file = None self . node_file = None self . shape_file = None # Add non-required fields if they aren't there. # for field, default_value in RoadwayNetwork.OPTIONAL_FIELDS: # if field not in self.links_df.columns: # self.links_df[field] = default_value if not self . validate_uniqueness (): raise ValueError ( \"IDs in network not unique\" ) self . selections = {} @staticmethod def read ( link_file : str , node_file : str , shape_file : str , fast : bool = True ) -> RoadwayNetwork : \"\"\" Reads a network from the roadway network standard Validates that it conforms to the schema args: link_file: full path to the link file node_file: full path to the node file shape_file: full path to the shape file fast: boolean that will skip validation to speed up read time Returns: a RoadwayNetwork instance .. todo:: Turn off fast=True as default \"\"\" WranglerLogger . info ( \"Reading from following files: \\n - {} \\n - {} \\n - {} .\" . format ( link_file , node_file , shape_file ) ) \"\"\" Validate Input \"\"\" if not os . path . exists ( link_file ): msg = \"Link file doesn't exist at: {} \" . format ( link_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( node_file ): msg = \"Node file doesn't exist at: {} \" . format ( node_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( shape_file ): msg = \"Shape file doesn't exist at: {} \" . format ( shape_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not fast : if not ( RoadwayNetwork . validate_node_schema ( node_file ) and RoadwayNetwork . validate_link_schema ( link_file ) and RoadwayNetwork . validate_shape_schema ( shape_file ) ): sys . exit ( \"RoadwayNetwork: Data doesn't conform to schema\" ) with open ( link_file ) as f : link_json = json . load ( f ) link_properties = pd . DataFrame ( link_json ) link_geometries = [ create_line_string ( g [ \"locationReferences\" ]) for g in link_json ] links_df = gpd . GeoDataFrame ( link_properties , geometry = link_geometries ) links_df . crs = RoadwayNetwork . CRS # coerce types for booleans which might not have a 1 and are therefore read in as intersection bool_columns = [ \"rail_only\" , \"bus_only\" , \"drive_access\" , \"bike_access\" , \"walk_access\" , \"truck_access\" , ] for bc in list ( set ( bool_columns ) & set ( links_df . columns )): links_df [ bc ] = links_df [ bc ] . astype ( bool ) shapes_df = gpd . read_file ( shape_file ) shapes_df . dropna ( subset = [ \"geometry\" , \"id\" ], inplace = True ) shapes_df . crs = RoadwayNetwork . CRS # geopandas uses fiona OGR drivers, which doesn't let you have # a list as a property type. Therefore, must read in node_properties # separately in a vanilla dataframe and then convert to geopandas with open ( node_file ) as f : node_geojson = json . load ( f ) node_properties = pd . DataFrame ( [ g [ \"properties\" ] for g in node_geojson [ \"features\" ]] ) node_geometries = [ Point ( g [ \"geometry\" ][ \"coordinates\" ]) for g in node_geojson [ \"features\" ] ] nodes_df = gpd . GeoDataFrame ( node_properties , geometry = node_geometries ) nodes_df . gdf_name = \"network_nodes\" # set a copy of the foreign key to be the index so that the # variable itself remains queryiable nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" ] = nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] nodes_df . set_index ( RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" , inplace = True ) nodes_df . crs = RoadwayNetwork . CRS nodes_df [ \"X\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) nodes_df [ \"Y\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) WranglerLogger . info ( \"Read %s links from %s \" % ( len ( links_df ), link_file )) WranglerLogger . info ( \"Read %s nodes from %s \" % ( len ( nodes_df ), node_file )) WranglerLogger . info ( \"Read %s shapes from %s \" % ( len ( shapes_df ), shape_file )) roadway_network = RoadwayNetwork ( nodes = nodes_df , links = links_df , shapes = shapes_df ) roadway_network . link_file = link_file roadway_network . node_file = node_file roadway_network . shape_file = shape_file return roadway_network def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the roadway network standard args: path: the path were the output will be saved filename: the name prefix of the roadway files that will be generated \"\"\" if not os . path . exists ( path ): WranglerLogger . debug ( \" \\n Path [ %s ] doesn't exist; creating.\" % path ) os . mkdir ( path ) if filename : links_file = os . path . join ( path , filename + \"_\" + \"link.json\" ) nodes_file = os . path . join ( path , filename + \"_\" + \"node.geojson\" ) shapes_file = os . path . join ( path , filename + \"_\" + \"shape.geojson\" ) else : links_file = os . path . join ( path , \"link.json\" ) nodes_file = os . path . join ( path , \"node.geojson\" ) shapes_file = os . path . join ( path , \"shape.geojson\" ) link_property_columns = self . links_df . columns . values . tolist () link_property_columns . remove ( \"geometry\" ) links_json = link_df_to_json ( self . links_df , link_property_columns ) with open ( links_file , \"w\" ) as f : json . dump ( links_json , f ) # geopandas wont let you write to geojson because # it uses fiona, which doesn't accept a list as one of the properties # so need to convert the df to geojson manually first property_columns = self . nodes_df . columns . values . tolist () property_columns . remove ( \"geometry\" ) nodes_geojson = point_df_to_geojson ( self . nodes_df , property_columns ) with open ( nodes_file , \"w\" ) as f : json . dump ( nodes_geojson , f ) self . shapes_df . to_file ( shapes_file , driver = \"GeoJSON\" ) @staticmethod def roadway_net_to_gdf ( roadway_net : RoadwayNetwork ) -> gpd . GeoDataFrame : \"\"\" Turn the roadway network into a GeoDataFrame args: roadway_net: the roadway network to export returns: shapes dataframe .. todo:: Make this much more sophisticated, for example attach link info to shapes \"\"\" return roadway_net . shapes_df def validate_uniqueness ( self ) -> Bool : \"\"\" Confirms that the unique identifiers are met. \"\"\" valid = True for c in RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain unique link identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . links_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network links\" . format ( c ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . LINK_FOREIGN_KEY : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain link foreign key identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) link_foreign_key = self . links_df [ RoadwayNetwork . LINK_FOREIGN_KEY ] . apply ( lambda x : \"-\" . join ( x . map ( str )), axis = 1 ) if not link_foreign_key . is_unique : valid = False msg = \"Foreign key: {} is not unique in network links\" . format ( RoadwayNetwork . LINK_FOREIGN_KEY ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . UNIQUE_NODE_IDENTIFIERS : if c not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain unique node identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . nodes_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network nodes\" . format ( c ) WranglerLogger . error ( msg ) if RoadwayNetwork . NODE_FOREIGN_KEY not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain node foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) elif not self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . is_unique : valid = False msg = \"Foreign key: {} is not unique in network nodes\" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) if RoadwayNetwork . UNIQUE_SHAPE_KEY not in self . shapes_df . columns : valid = False msg = \"Network doesn't contain unique shape id: {} \" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) elif not self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . is_unique : valid = False msg = \"Unique key: {} is not unique in network shapes\" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) return valid @staticmethod def validate_object_types ( nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Determines if the roadway network is being built with the right object types. Does not validate schemas. Args: nodes: nodes geodataframe links: link geodataframe shapes: shape geodataframe Returns: boolean \"\"\" errors = \"\" if not isinstance ( nodes , GeoDataFrame ): error_message = \"Incompatible nodes type: {} . Must provide a GeoDataFrame. \" . format ( type ( nodes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( links , GeoDataFrame ): error_message = \"Incompatible links type: {} . Must provide a GeoDataFrame. \" . format ( type ( links ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( shapes , GeoDataFrame ): error_message = \"Incompatible shapes type: {} . Must provide a GeoDataFrame. \" . format ( type ( shapes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if errors : return False return True @staticmethod def validate_node_schema ( node_file , schema_location : str = \"roadway_network_node.json\" ): \"\"\" Validate roadway network data node schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( node_file ) as node_json_file : json_data = json . load ( node_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Node schema validation: Validation Error\" ) WranglerLogger . error ( \"Node File Loc: {} \" . format ( node_file )) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Node Schema\" ) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False @staticmethod def validate_link_schema ( link_file , schema_location : str = \"roadway_network_link.json\" ): \"\"\" Validate roadway network data link schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( link_file ) as link_json_file : json_data = json . load ( link_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Link schema validation: Validation Error\" ) WranglerLogger . error ( \"Link File Loc: {} \" . format ( link_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Link Schema\" ) WranglerLogger . error ( \"Link Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False @staticmethod def validate_shape_schema ( shape_file , schema_location : str = \"roadway_network_shape.json\" ): \"\"\" Validate roadway network data shape schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( shape_file ) as shape_json_file : json_data = json . load ( shape_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Shape schema validation: Validation Error\" ) WranglerLogger . error ( \"Shape File Loc: {} \" . format ( shape_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Shape Schema\" ) WranglerLogger . error ( \"Shape Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False def validate_selection ( self , selection : dict ) -> Bool : \"\"\" Evaluate whetther the selection dictionary contains the minimum required values. Args: selection: selection dictionary to be evaluated Returns: boolean value as to whether the selection dictonary is valid. \"\"\" if not set ( RoadwayNetwork . SELECTION_REQUIRES ) . issubset ( selection ): err_msg = \"Project Card Selection requires: {} \" . format ( \",\" . join ( RoadwayNetwork . SELECTION_REQUIRES ) ) err_msg += \", but selection only contains: {} \" . format ( \",\" . join ( selection )) WranglerLogger . error ( err_msg ) raise KeyError ( err_msg ) err = [] for l in selection [ \"link\" ]: for k , v in l . items (): if k not in self . links_df . columns : err . append ( \" {} specified in link selection but not an attribute in network \\n \" . format ( k ) ) selection_keys = [ k for l in selection [ \"link\" ] for k , v in l . items ()] unique_link_id = bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) ) if not unique_link_id : for k , v in selection [ \"A\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in A node selection but not an attribute in network \\n \" . format ( k ) ) for k , v in selection [ \"B\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in B node selection but not an attribute in network \\n \" . format ( k ) ) if err : WranglerLogger . error ( \"ERROR: Selection variables in project card not found in network\" ) WranglerLogger . error ( \" \\n \" . join ( err )) WranglerLogger . error ( \"--existing node columns: {} \" . format ( \" \" . join ( self . nodes_df . columns )) ) WranglerLogger . error ( \"--existing link columns: {} \" . format ( \" \" . join ( self . links_df . columns )) ) raise ValueError () return False else : return True def orig_dest_nodes_foreign_key ( self , selection : dict , node_foreign_key : str = \"\" ) -> tuple : \"\"\" Returns the foreign key id (whatever is used in the u and v variables in the links file) for the AB nodes as a tuple. Args: selection : selection dictionary with A and B keys node_foreign_key: variable name for whatever is used by the u and v variable in the links_df file. If nothing is specified, assume whatever default is (usually osm_node_id) Returns: tuple of (A_id, B_id) \"\"\" if not node_foreign_key : node_foreign_key = RoadwayNetwork . NODE_FOREIGN_KEY if len ( selection [ \"A\" ]) > 1 : raise ( \"Selection A node dictionary should be of length 1\" ) if len ( selection [ \"B\" ]) > 1 : raise ( \"Selection B node dictionary should be of length 1\" ) A_node_key , A_id = next ( iter ( selection [ \"A\" ] . items ())) B_node_key , B_id = next ( iter ( selection [ \"B\" ] . items ())) if A_node_key != node_foreign_key : A_id = self . nodes_df [ self . nodes_df [ A_node_key ] == A_id ][ node_foreign_key ] . values [ 0 ] if B_node_key != node_foreign_key : B_id = self . nodes_df [ self . nodes_df [ B_node_key ] == B_id ][ node_foreign_key ] . values [ 0 ] return ( A_id , B_id ) @staticmethod def get_managed_lane_node_ids ( nodes_list ): return [ x + RoadwayNetwork . MANAGED_LANES_SCALAR for x in nodes_list ] @staticmethod def ox_graph ( nodes_df : GeoDataFrame , links_df : GeoDataFrame ): \"\"\" create an osmnx-flavored network graph osmnx doesn't like values that are arrays, so remove the variables that have arrays. osmnx also requires that certain variables be filled in, so do that too. Args: nodes_df : GeoDataFrame of nodes link_df : GeoDataFrame of links Returns: a networkx multidigraph \"\"\" WranglerLogger . debug ( \"starting ox_graph()\" ) graph_nodes = nodes_df . copy () . drop ( [ \"inboundReferenceIds\" , \"outboundReferenceIds\" ], axis = 1 ) graph_nodes . gdf_name = \"network_nodes\" WranglerLogger . debug ( \"GRAPH NODES: {} \" . format ( graph_nodes . columns )) graph_nodes [ \"id\" ] = graph_nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] graph_nodes [ \"x\" ] = graph_nodes [ \"X\" ] graph_nodes [ \"y\" ] = graph_nodes [ \"Y\" ] graph_links = links_df . copy () . drop ( [ \"osm_link_id\" , \"locationReferences\" ], axis = 1 ) # have to change this over into u,v b/c this is what osm-nx is expecting graph_links [ \"u\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 0 ]] graph_links [ \"v\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 1 ]] graph_links [ \"id\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] graph_links [ \"key\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] WranglerLogger . debug ( \"starting ox.gdfs_to_graph()\" ) try : G = ox . graph_from_gdfs ( graph_nodes , graph_links ) except : WranglerLogger . debug ( \"Please upgrade your OSMNX package. For now, using depricated osmnx.gdfs_to_graph because osmnx.graph_from_gdfs not found\" ) G = ox . gdfs_to_graph ( graph_nodes , graph_links ) WranglerLogger . debug ( \"finished ox.gdfs_to_graph()\" ) return G @staticmethod def selection_has_unique_link_id ( selection_dict : dict ) -> bool : \"\"\" Args: selection_dictionary: Dictionary representation of selection of roadway features, containing a \"link\" key. Returns: A boolean indicating if the selection dictionary contains a required unique link id. \"\"\" selection_keys = [ k for l in selection_dict [ \"link\" ] for k , v in l . items ()] return bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) ) def build_selection_key ( self , selection_dict : dict ) -> tuple : \"\"\" Selections are stored by a key combining the query and the A and B ids. This method combines the two for you based on the selection dictionary. Args: selection_dictonary: Selection Dictionary Returns: Tuple serving as the selection key. \"\"\" sel_query = ProjectCard . build_link_selection_query ( selection = selection_dict , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , ) if RoadwayNetwork . selection_has_unique_link_id ( selection_dict ): return sel_query A_id , B_id = self . orig_dest_nodes_foreign_key ( selection_dict ) return ( sel_query , A_id , B_id ) def select_roadway_features ( self , selection : dict , search_mode = \"drive\" , force_search = False ) -> GeoDataFrame : \"\"\" Selects roadway features that satisfy selection criteria Example usage: net.select_roadway_features( selection = [ { # a match condition for the from node using osm, # shared streets, or model node number 'from': {'osm_model_link_id': '1234'}, # a match for the to-node.. 'to': {'shstid': '4321'}, # a regex or match for facility condition # could be # of lanes, facility type, etc. 'facility': {'name':'Main St'}, }, ... ]) Args: selection : dictionary with keys for: A - from node B - to node link - which includes at least a variable for `name` Returns: a list of node foreign IDs on shortest path \"\"\" WranglerLogger . debug ( \"validating selection\" ) self . validate_selection ( selection ) # create a unique key for the selection so that we can cache it sel_key = self . build_selection_key ( selection ) WranglerLogger . debug ( \"Selection Key: {} \" . format ( sel_key )) # if this selection has been queried before, just return the # previously selected links if sel_key in self . selections and not force_search : if self . selections [ sel_key ][ \"selection_found\" ]: return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : msg = \"Selection previously queried but no selection found\" WranglerLogger . error ( msg ) raise Exception ( msg ) self . selections [ sel_key ] = {} self . selections [ sel_key ][ \"selection_found\" ] = False unique_model_link_identifer_in_selection = RoadwayNetwork . selection_has_unique_link_id ( selection ) if not unique_model_link_identifer_in_selection : A_id , B_id = self . orig_dest_nodes_foreign_key ( selection ) # identify candidate links which match the initial query # assign them as iteration = 0 # subsequent iterations that didn't match the query will be # assigned a heigher weight in the shortest path WranglerLogger . debug ( \"Building selection query\" ) # build a selection query based on the selection dictionary sel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ) WranglerLogger . debug ( \"Selecting features: \\n {} \" . format ( sel_query )) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) WranglerLogger . debug ( \"Completed query\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] # b/c too long to keep that way candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 and unique_model_link_identifer_in_selection : msg = \"No links found based on unique link identifiers. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if len ( candidate_links . index ) == 0 : WranglerLogger . debug ( \"No candidate links in initial search. \\n Retrying query using 'ref' instead of 'name'\" ) # if the query doesn't come back with something from 'name' # try it again with 'ref' instead selection_has_name_key = any ( \"name\" in d for d in selection [ \"link\" ]) if not selection_has_name_key : msg = \"Not able to complete search using 'ref' instead of 'name' because 'name' not in search.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if not \"ref\" in self . links_df . columns : msg = \"Not able to complete search using 'ref' because 'ref' not in network.\" WranglerLogger . error ( msg ) raise Exception ( msg ) WranglerLogger . debug ( \"Trying selection query replacing 'name' with 'ref'\" ) sel_query = sel_query . replace ( \"name\" , \"ref\" ) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 : msg = \"No candidate links in search using either 'name' or 'ref' in query. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) def _add_breadth ( candidate_links : DataFrame , nodes : Data , links , i ): \"\"\" Add outbound and inbound reference IDs to candidate links from existing nodes Args: candidate_links : GeoDataFrame df with the links from the previous iteration that we want to add on to nodes : GeoDataFrame df of all nodes in the full network links : GeoDataFrame df of all links in the full network i : int iteration of adding breadth Returns: candidate_links : GeoDataFrame updated df with one more degree of added breadth node_list_foreign_keys : list list of foreign key ids for nodes in the updated candidate links to test if the A and B nodes are in there. ..todo:: Make unique ID for links in the settings \"\"\" WranglerLogger . debug ( \"-Adding Breadth-\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = nodes . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"Candidate Nodes: {} \" . format ( len ( candidate_nodes ))) links_shstRefId_to_add = list ( set ( sum ( candidate_nodes [ \"outboundReferenceIds\" ] . tolist (), []) + sum ( candidate_nodes [ \"inboundReferenceIds\" ] . tolist (), []) ) - set ( candidate_links [ \"shstReferenceId\" ] . tolist ()) - set ([ \"\" ]) ) ##TODO make unique ID for links in the settings # print(\"Link IDs to add: {}\".format(links_shstRefId_to_add)) # print(\"Links: \", links_id_to_add) links_to_add = links [ links . shstReferenceId . isin ( links_shstRefId_to_add )] # print(\"Adding Links:\",links_to_add) WranglerLogger . debug ( \"Adding {} links.\" . format ( links_to_add . shape [ 0 ])) links [ links . model_link_id . isin ( links_shstRefId_to_add )][ \"i\" ] = i candidate_links = candidate_links . append ( links_to_add ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) return candidate_links , node_list_foreign_keys def _shortest_path (): WranglerLogger . debug ( \"_shortest_path(): calculating shortest path from graph\" ) candidate_links . loc [:, \"weight\" ] = 1 + ( candidate_links [ \"i\" ] * RoadwayNetwork . SP_WEIGHT_FACTOR ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"creating network graph\" ) G = RoadwayNetwork . ox_graph ( candidate_nodes , candidate_links ) self . selections [ sel_key ][ \"graph\" ] = G self . selections [ sel_key ][ \"candidate_links\" ] = candidate_links try : WranglerLogger . debug ( \"Calculating NX shortest path from A_id: {} to B_id: {} \" . format ( A_id , B_id ) ) sp_route = nx . shortest_path ( G , A_id , B_id , weight = \"weight\" ) WranglerLogger . debug ( \"Shortest path successfully routed\" ) except nx . NetworkXNoPath : return False sp_links = candidate_links [ candidate_links [ \"A\" ] . isin ( sp_route ) & candidate_links [ \"B\" ] . isin ( sp_route ) ] self . selections [ sel_key ][ \"route\" ] = sp_route self . selections [ sel_key ][ \"links\" ] = sp_links return True if not unique_model_link_identifer_in_selection : # find the node ids for the candidate links WranglerLogger . debug ( \"Not a unique ID selection, conduct search\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) WranglerLogger . debug ( \"Foreign key list: {} \" . format ( node_list_foreign_keys )) i = 0 max_i = RoadwayNetwork . SEARCH_BREADTH while ( A_id not in node_list_foreign_keys and B_id not in node_list_foreign_keys and i <= max_i ): WranglerLogger . debug ( \"Adding breadth, no shortest path. i: {} , Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) WranglerLogger . debug ( \"calculating shortest path from graph\" ) sp_found = _shortest_path () if not sp_found : WranglerLogger . info ( \"No shortest path found with {} , trying greater breadth until SP found\" . format ( i ) ) while not sp_found and i <= RoadwayNetwork . MAX_SEARCH_BREADTH : WranglerLogger . debug ( \"Adding breadth, with shortest path iteration. i: {} Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) sp_found = _shortest_path () if sp_found : # reselect from the links in the shortest path, the ones with # the desired values....ignoring name. if len ( selection [ \"link\" ]) > 1 : resel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ignore = [ \"name\" ], ) WranglerLogger . info ( \"Reselecting features: \\n {} \" . format ( resel_query )) self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] . query ( resel_query , engine = \"python\" ) else : self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True # Return pandas.Series of links_ids return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : WranglerLogger . error ( \"Couldn't find path from {} to {} \" . format ( A_id , B_id ) ) raise ValueError else : # unique identifier exists and no need to go through big search self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"candidate_links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () def validate_properties ( self , properties : dict , ignore_existing : bool = False , require_existing_for_change : bool = False , ) -> bool : \"\"\" If there are change or existing commands, make sure that that property exists in the network. Args: properties : properties dictionary to be evaluated ignore_existing: If True, will only warn about properties that specify an \"existing\" value. If False, will fail. require_existing_for_change: If True, will fail if there isn't a specified value in theproject card for existing when a change is specified. Returns: boolean value as to whether the properties dictonary is valid. \"\"\" validation_error_message = [] for p in properties : if p [ \"property\" ] not in self . links_df . columns : if p . get ( \"change\" ): validation_error_message . append ( '\"Change\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"existing\" ) and not ignore_existing : validation_error_message . append ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) elif p . get ( \"existing\" ): WranglerLogger . warning ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"change\" ) and not p . get ( \"existing\" ): if require_existing_for_change : validation_error_message . append ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n To proceed, run with the setting require_existing_for_change=False' . format ( p [ \"property\" ] ) ) else : WranglerLogger . warning ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n ' . format ( p [ \"property\" ] ) ) if validation_error_message : WranglerLogger . error ( \" \" . join ( validation_error_message )) raise ValueError () def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a roadway network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Roadway Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if project_dictionary [ \"category\" ] . lower () == \"roadway property change\" : self . apply_roadway_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : self . apply_managed_lane_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"add new roadway\" : self . add_new_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : self . delete_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"calculated roadway\" : self . apply_python_calculation ( project_dictionary [ 'pycode' ] ) else : raise ( BaseException ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary ) def apply_python_calculation ( self , pycode : str , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes roadway network object by executing pycode. Args: pycode: python code which changes values in the roadway network object in_place: update self or return a new roadway network object \"\"\" exec ( pycode ) def apply_roadway_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes the roadway attributes for the selected features based on the project card information passed Args: link_idx : list lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean update self or return a new roadway network object \"\"\" # check if there are change or existing commands that that property # exists in the network # if there is a set command, add that property to network self . validate_properties ( properties ) for i , p in enumerate ( properties ): attribute = p [ \"property\" ] # if project card specifies an existing value in the network # check and see if the existing value in the network matches if p . get ( \"existing\" ): network_values = self . links_df . loc [ link_idx , attribute ] . tolist () if not set ( network_values ) . issubset ([ p . get ( \"existing\" )]): WranglerLogger . warning ( \"Existing value defined for {} in project card does \" \"not match the value in the roadway network for the \" \"selected links\" . format ( attribute ) ) if in_place : if \"set\" in p . keys (): self . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : self . links_df . loc [ link_idx , attribute ] = ( self . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) else : if i == 0 : updated_network = copy . deepcopy ( self ) if \"set\" in p . keys (): updated_network . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : updated_network . links_df . loc [ link_idx , attribute ] = ( updated_network . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) if i == len ( properties ) - 1 : return updated_network def apply_managed_lane_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Apply the managed lane feature changes to the roadway network Args: link_idx : list of lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean to indicate whether to update self or return a new roadway network object .. todo:: decide on connectors info when they are more specific in project card \"\"\" # add ML flag if \"managed\" in self . links_df . columns : self . links_df . loc [ link_idx , \"managed\" ] = 1 else : self . links_df [ \"managed\" ] = 0 self . links_df . loc [ link_idx , \"managed\" ] = 1 for p in properties : attribute = p [ \"property\" ] if \"group\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for g in p [ \"group\" ]: category = g [ \"category\" ] for tod in g [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"category\" : category , \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ], } ) elif \"timeofday\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for tod in p [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ]} ) elif \"set\" in p . keys (): attr_value = p [ \"set\" ] else : attr_value = \"\" # TODO: decide on connectors info when they are more specific in project card if attribute == \"ML_ACCESS\" and attr_value == \"all\" : attr_value = 1 if attribute == \"ML_EGRESS\" and attr_value == \"all\" : attr_value = 1 if in_place : if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object self . links_df [ attribute ] = self . links_df [ attribute ] . astype ( object ) if attribute not in self . links_df . columns : # if it is a new attribute then initiate with NaN values self . links_df [ attribute ] = \"NaN\" for idx in link_idx : self . links_df . at [ idx , attribute ] = attr_value else : if i == 0 : updated_network = copy . deepcopy ( self ) if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object updated_network . links_df [ attribute ] = updated_network . links_df [ attribute ] . astype ( object ) if attribute not in updated_network . links_df . columns : # if it is a new attribute then initiate with NaN values updated_network . links_df [ attribute ] = \"NaN\" for idx in link_idx : updated_network . links_df . at [ idx , attribute ] = attr_value if i == len ( properties ) - 1 : return updated_network def add_new_roadway_feature_change ( self , links : dict , nodes : dict ) -> None : \"\"\" add the new roadway features defined in the project card. new shapes are also added for the new roadway links. args: links : list of dictionaries nodes : list of dictionaries returns: None .. todo:: validate links and nodes dictionary \"\"\" def _add_dict_to_df ( df , new_dict ): df_column_names = df . columns new_row_to_add = {} # add the fields from project card that are in the network for property in df_column_names : if property in new_dict . keys (): if df [ property ] . dtype == np . float64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"float\" ) elif df [ property ] . dtype == np . int64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"integer\" ) else : value = str ( new_dict [ property ]) else : value = \"\" new_row_to_add [ property ] = value # add the fields from project card that are NOT in the network for key , value in new_dict . items (): if key not in df_column_names : new_row_to_add [ key ] = new_dict [ key ] out_df = df . append ( new_row_to_add , ignore_index = True ) return out_df if nodes is not None : for node in nodes : if node . get ( RoadwayNetwork . NODE_FOREIGN_KEY ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) raise ValueError ( msg ) node_query = ( RoadwayNetwork . UNIQUE_NODE_KEY + \" == \" + str ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ]) ) if not self . nodes_df . query ( node_query , engine = \"python\" ) . empty : msg = \"Node with id = {} already exist in the network\" . format ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for node in nodes : self . nodes_df = _add_dict_to_df ( self . nodes_df , node ) if links is not None : for link in links : for key in RoadwayNetwork . LINK_FOREIGN_KEY : if link . get ( key ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( key ) WranglerLogger . error ( msg ) raise ValueError ( msg ) ab_query = \"A == \" + str ( link [ \"A\" ]) + \" and B == \" + str ( link [ \"B\" ]) if not self . links_df . query ( ab_query , engine = \"python\" ) . empty : msg = \"Link with A = {} and B = {} already exist in the network\" . format ( link [ \"A\" ], link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"A\" ] ] . empty : msg = \"New link to add has A node = {} but the node does not exist in the network\" . format ( link [ \"A\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"B\" ] ] . empty : msg = \"New link to add has B node = {} but the node does not exist in the network\" . format ( link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for link in links : link [ \"new_link\" ] = 1 self . links_df = _add_dict_to_df ( self . links_df , link ) # add location reference and geometry for new links self . links_df [ \"locationReferences\" ] = self . links_df . apply ( lambda x : create_location_reference_from_nodes ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"A\" ] ] . squeeze (), self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"B\" ] ] . squeeze (), ) if x [ \"new_link\" ] == 1 else x [ \"locationReferences\" ], axis = 1 , ) self . links_df [ \"geometry\" ] = self . links_df . apply ( lambda x : create_line_string ( x [ \"locationReferences\" ]) if x [ \"new_link\" ] == 1 else x [ \"geometry\" ], axis = 1 , ) self . links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = self . links_df . apply ( lambda x : create_unique_shape_id ( x [ \"geometry\" ]) if x [ \"new_link\" ] == 1 else x [ RoadwayNetwork . UNIQUE_SHAPE_KEY ], axis = 1 , ) # add new shapes added_links = self . links_df [ self . links_df [ \"new_link\" ] == 1 ] added_shapes_df = pd . DataFrame ({ \"geometry\" : added_links [ \"geometry\" ]}) added_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = added_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) self . shapes_df = self . shapes_df . append ( added_shapes_df ) self . links_df . drop ([ \"new_link\" ], axis = 1 , inplace = True ) def delete_roadway_feature_change ( self , links : dict , nodes : dict , ignore_missing = True ) -> None : \"\"\" delete the roadway features defined in the project card. valid links and nodes defined in the project gets deleted and shapes corresponding to the deleted links are also deleted. Args: links : dict list of dictionaries nodes : dict list of dictionaries ignore_missing: bool If True, will only warn about links/nodes that are missing from network but specified to \"delete\" in project card If False, will fail. \"\"\" missing_error_message = [] if links is not None : shapes_to_delete = [] for key , val in links . items (): missing_links = [ v for v in val if v not in self . links_df [ key ] . tolist ()] if missing_links : message = \"Links attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] shapes_to_delete . extend ( deleted_links [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . tolist () ) self . links_df . drop ( self . links_df . index [ self . links_df [ key ] . isin ( val )], inplace = True ) self . shapes_df . drop ( self . shapes_df . index [ self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . isin ( shapes_to_delete ) ], inplace = True , ) if nodes is not None : for key , val in nodes . items (): missing_nodes = [ v for v in val if v not in self . nodes_df [ key ] . tolist ()] if missing_nodes : message = \"Nodes attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) self . nodes_df = self . nodes_df [ ~ self . nodes_df [ key ] . isin ( val )] if missing_error_message : WranglerLogger . error ( \" \" . join ( missing_error_message )) raise ValueError () def get_property_by_time_period_and_group ( self , property , time_period = None , category = None ): \"\"\" Return a series for the properties with a specific group or time period. args ------ property: str the variable that you want from network time_period: list(str) the time period that you are querying for i.e. ['16:00', '19:00'] category: str or list(str)(Optional) the group category i.e. \"sov\" or list of group categories in order of search, i.e. [\"hov3\",\"hov2\"] returns -------- pandas series \"\"\" def _get_property ( v , time_spans = None , category = None , return_partial_match : bool = False , partial_match_minutes : int = 60 , ): \"\"\" .. todo:: return the time period with the largest overlap \"\"\" if category and not time_spans : WranglerLogger . error ( \" \\n Shouldn't have a category group without time spans\" ) raise ValueError ( \"Shouldn't have a category group without time spans\" ) # simple case if type ( v ) in ( int , float , str ): return v if not category : category = [ \"default\" ] elif isinstance ( category , str ): category = [ category ] search_cats = [ c . lower () for c in category ] # if no time or group specified, but it is a complex link situation if not time_spans : if \"default\" in v . keys (): return v [ \"default\" ] else : WranglerLogger . debug ( \"variable: \" . format ( v )) msg = \"Variable {} is more complex in network than query\" . format ( v ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if v . get ( \"timeofday\" ): categories = [] for tg in v [ \"timeofday\" ]: if ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ] ): if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", time_spans, category, tg[\"value\"] # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] # if there isn't a fully matched time period, see if there is an overlapping one # right now just return the first overlapping ones # TODO return the time period with the largest overlap if ( ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 0 ] <= tg [ \"time\" ][ 1 ]) ) or ( ( time_spans [ 1 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ]) ): overlap_minutes = max ( 0 , min ( tg [ \"time\" ][ 1 ], time_spans [ 1 ]) - max ( time_spans [ 0 ], tg [ \"time\" ][ 0 ]), ) # print(\"OLM\",overlap_minutes) if not return_partial_match and overlap_minutes > 0 : WranglerLogger . debug ( \"Couldn't find time period consistent with {} , but found a partial match: {} . Consider allowing partial matches using 'return_partial_match' keyword or updating query.\" . format ( time_spans , tg [ \"time\" ] ) ) elif ( overlap_minutes < partial_match_minutes and overlap_minutes > 0 ): WranglerLogger . debug ( \"Time period: {} overlapped less than the minimum number of minutes ( {} < {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) elif overlap_minutes > 0 : WranglerLogger . debug ( \"Returning a partial time period match. Time period: {} overlapped the minimum number of minutes ( {} >= {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", # time_spans, # category, # tg[\"value\"], # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] \"\"\" WranglerLogger.debug( \"\\nCouldn't find time period for {}, returning default\".format( str(time_spans) ) ) \"\"\" if \"default\" in v . keys (): # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, v[\"default\"]) return v [ \"default\" ] else : # print(\"Var:\", v) WranglerLogger . error ( \" \\n Can't find default; must specify a category in {} \" . format ( str ( categories ) ) ) raise ValueError ( \"Can't find default, must specify a category in: {} \" . format ( str ( categories ) ) ) time_spans = parse_time_spans ( time_period ) return self . links_df [ property ] . apply ( _get_property , time_spans = time_spans , category = category ) def create_dummy_connector_links ( gp_df : GeoDataFrame , ml_df : GeoDataFrame ): \"\"\" create dummy connector links between the general purpose and managed lanes args: gp_df : GeoDataFrame dataframe of general purpose links (where managed lane also exists) ml_df : GeoDataFrame dataframe of corresponding managed lane links \"\"\" gp_ml_links_df = pd . concat ( [ gp_df , ml_df . add_prefix ( \"ML_\" )], axis = 1 , join = \"inner\" ) access_df = gp_df . iloc [ 0 : 0 , :] . copy () egress_df = gp_df . iloc [ 0 : 0 , :] . copy () def _get_connector_references ( ref_1 : list , ref_2 : list , type : str ): if type == \"access\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_1 [ 0 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_2 [ 0 ][ \"point\" ]}, ] if type == \"egress\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_2 [ 1 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_1 [ 1 ][ \"point\" ]}, ] return out_location_reference for index , row in gp_ml_links_df . iterrows (): access_row = {} access_row [ \"A\" ] = row [ \"A\" ] access_row [ \"B\" ] = row [ \"ML_A\" ] access_row [ \"lanes\" ] = 1 access_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 1 ) access_row [ \"access\" ] = row [ \"ML_access\" ] access_row [ \"drive_access\" ] = row [ \"drive_access\" ] access_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"access\" ) access_row [ \"distance\" ] = haversine_distance ( access_row [ \"locationReferences\" ][ 0 ][ \"point\" ], access_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) access_row [ \"roadway\" ] = \"ml_access\" access_row [ \"name\" ] = \"Access Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : access_row [ \"ref\" ] = row [ \"ref\" ] else : access_row [ \"ref\" ] = \"\" access_df = access_df . append ( access_row , ignore_index = True ) egress_row = {} egress_row [ \"A\" ] = row [ \"ML_B\" ] egress_row [ \"B\" ] = row [ \"B\" ] egress_row [ \"lanes\" ] = 1 egress_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 2 ) egress_row [ \"access\" ] = row [ \"ML_access\" ] egress_row [ \"drive_access\" ] = row [ \"drive_access\" ] egress_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"egress\" ) egress_row [ \"distance\" ] = haversine_distance ( egress_row [ \"locationReferences\" ][ 0 ][ \"point\" ], egress_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) egress_row [ \"roadway\" ] = \"ml_egress\" egress_row [ \"name\" ] = \"Egress Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : egress_row [ \"ref\" ] = row [ \"ref\" ] else : egress_row [ \"ref\" ] = \"\" egress_df = egress_df . append ( egress_row , ignore_index = True ) return ( access_df , egress_df ) def create_managed_lane_network ( self , in_place : bool = False ) -> RoadwayNetwork : \"\"\" Create a roadway network with managed lanes links separated out. Add new parallel managed lane links, access/egress links, and add shapes corresponding to the new links args: in_place: update self or return a new roadway network object returns: A RoadwayNetwork instance .. todo:: make this a more rigorous test \"\"\" WranglerLogger . info ( \"Creating network with duplicated managed lanes\" ) if \"ml_access\" in self . links_df [ \"roadway\" ] . tolist (): msg = \"managed lane access links already exist in network; shouldn't be running create managed lane network. Returning network as-is.\" WranglerLogger . error ( msg ) if in_place : return else : return copy . deepcopy ( self ) link_attributes = self . links_df . columns . values . tolist () ml_attributes = [ i for i in link_attributes if i . startswith ( \"ML_\" )] # non_ml_links are links in the network where there is no managed lane. # gp_links are the gp lanes and ml_links are ml lanes respectively for the ML roadways. non_ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 0 ] non_ml_links_df = non_ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 1 ] gp_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) for attr in link_attributes : if attr == \"name\" : ml_links_df [ \"name\" ] = \"Managed Lane \" + gp_links_df [ \"name\" ] elif attr in ml_attributes and attr not in [ \"ML_ACCESS\" , \"ML_EGRESS\" ]: gp_attr = attr . split ( \"_\" , 1 )[ 1 ] ml_links_df . loc [:, gp_attr ] = ml_links_df [ attr ] if ( attr not in RoadwayNetwork . KEEP_SAME_ATTRIBUTES_ML_AND_GP and attr not in RoadwayNetwork . MANAGED_LANES_REQUIRED_ATTRIBUTES ): ml_links_df [ attr ] = \"\" ml_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df [ \"managed\" ] = 1 gp_links_df [ \"managed\" ] = 0 def _update_location_reference ( location_reference : list ): out_location_reference = copy . deepcopy ( location_reference ) out_location_reference [ 0 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 0 ][ \"point\" ] ) out_location_reference [ 1 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 1 ][ \"point\" ] ) return out_location_reference ml_links_df [ \"A\" ] = ( ml_links_df [ \"A\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ \"B\" ] = ( ml_links_df [ \"B\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] = ( ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] + RoadwayNetwork . MANAGED_LANES_LINK_ID_SCALAR ) ml_links_df [ \"locationReferences\" ] = ml_links_df [ \"locationReferences\" ] . apply ( # lambda x: _update_location_reference(x) lambda x : offset_location_reference ( x ) ) ml_links_df [ \"geometry\" ] = ml_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) ml_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = ml_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x ) ) access_links_df , egress_links_df = RoadwayNetwork . create_dummy_connector_links ( gp_links_df , ml_links_df ) access_links_df [ \"geometry\" ] = access_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) egress_links_df [ \"geometry\" ] = egress_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) access_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = access_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) egress_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = egress_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_links_df = gp_links_df . append ( ml_links_df ) out_links_df = out_links_df . append ( access_links_df ) out_links_df = out_links_df . append ( egress_links_df ) out_links_df = out_links_df . append ( non_ml_links_df ) # only the ml_links_df has the new nodes added added_a_nodes = ml_links_df [ \"A\" ] added_b_nodes = ml_links_df [ \"B\" ] out_nodes_df = self . nodes_df for a_node in added_a_nodes : out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : a_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"A\" ] == a_node ] . iloc [ 0 ][ \"locationReferences\" ][ 0 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) for b_node in added_b_nodes : if b_node not in out_nodes_df [ \"model_node_id\" ] . tolist (): out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : b_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"B\" ] == b_node ] . iloc [ 0 ][ \"locationReferences\" ][ 1 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) out_nodes_df [ \"X\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) out_nodes_df [ \"Y\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) out_shapes_df = self . shapes_df # managed lanes, access and egress connectors are new geometry new_shapes_df = pd . DataFrame ( { \"geometry\" : ml_links_df [ \"geometry\" ] . append ( access_links_df [ \"geometry\" ]) . append ( egress_links_df [ \"geometry\" ]) } ) new_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = new_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_shapes_df = out_shapes_df . append ( new_shapes_df ) out_links_df = out_links_df . reset_index () out_nodes_df = out_nodes_df . reset_index () out_shapes_df = out_shapes_df . reset_index () if in_place : self . links_df = out_links_df self . nodes_df = out_nodes_df self . shapes_df = out_shapes_df else : out_network = copy . deepcopy ( self ) out_network . links_df = out_links_df out_network . nodes_df = out_nodes_df out_network . shapes_df = out_shapes_df return out_network @staticmethod def get_modal_links_nodes ( links_df : DataFrame , nodes_df : DataFrame , modes : list [ str ] = None ) -> tuple ( DataFrame , DataFrame ): \"\"\"Returns nodes and link dataframes for specific mode. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes modes: list of the modes of the network to be kept, must be in `drive`,`transit`,`rail`,`bus`, `walk`, `bike`. For example, if bike and walk are selected, both bike and walk links will be kept. Returns: tuple of DataFrames for links, nodes filtered by mode .. todo:: Right now we don't filter the nodes because transit-only links with walk access are not marked as having walk access Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] \"\"\" for mode in modes : if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} , got {} \" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()), mode , ) WranglerLogger . error ( msg ) raise ValueError ( msg ) mode_link_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ mode ] ] ) ) mode_node_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_NODE_VARIABLES [ mode ] ] ) ) if not set ( mode_link_variables ) . issubset ( set ( links_df . columns )): msg = \" {} not in provided links_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_link_variables ) - set ( links_df . columns ), links_df . columns ) WranglerLogger . error ( msg ) if not set ( mode_node_variables ) . issubset ( set ( nodes_df . columns )): msg = \" {} not in provided nodes_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_node_variables ) - set ( nodes_df . columns ), nodes_df . columns ) WranglerLogger . error ( msg ) modal_links_df = links_df . loc [ links_df [ mode_link_variables ] . any ( axis = 1 )] ##TODO right now we don't filter the nodes because transit-only # links with walk access are not marked as having walk access # Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 # modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] modal_nodes_df = nodes_df return modal_links_df , modal_nodes_df @staticmethod def get_modal_graph ( links_df : DataFrame , nodes_df : DataFrame , mode : str = None ): \"\"\"Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` Returns: networkx: osmnx: DiGraph of network \"\"\" if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} .\" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( links_df , nodes_df , modes = [ mode ], ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) return G def is_network_connected ( self , mode : str = None , links_df : DataFrame = None , nodes_df : DataFrame = None ): \"\"\" Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes Returns: boolean .. todo:: Consider caching graphs if they take a long time. \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) # TODO: consider caching graphs if they start to take forever # and we are calling them more than once. G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) is_connected = nx . is_strongly_connected ( G ) return is_connected def assess_connectivity ( self , mode : str = \"\" , ignore_end_nodes : bool = True , links_df : DataFrame = None , nodes_df : DataFrame = None , ): \"\"\"Returns a network graph and list of disconnected subgraphs as described by a list of their member nodes. Args: mode: list of modes of the network, one of `drive`,`transit`, `walk`, `bike` ignore_end_nodes: if True, ignores stray singleton nodes links_df: if specified, will assess connectivity of this links list rather than self.links_df nodes_df: if specified, will assess connectivity of this nodes list rather than self.nodes_df Returns: Tuple of Network Graph (osmnx flavored networkX DiGraph) List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`) \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) # sub_graphs = [s for s in sorted(nx.strongly_connected_component_subgraphs(G), key=len, reverse=True)] sub_graphs = [ s for s in sorted ( ( G . subgraph ( c ) for c in nx . strongly_connected_components ( G )), key = len , reverse = True , ) ] sub_graph_nodes = [ list ( s ) for s in sorted ( nx . strongly_connected_components ( G ), key = len , reverse = True ) ] # sorted on decreasing length, dropping the main sub-graph disconnected_sub_graph_nodes = sub_graph_nodes [ 1 :] # dropping the sub-graphs with only 1 node if ignore_end_nodes : disconnected_sub_graph_nodes = [ list ( s ) for s in disconnected_sub_graph_nodes if len ( s ) > 1 ] WranglerLogger . info ( \" {} for disconnected networks for mode = {} : \\n {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY , mode , \" \\n \" . join ( list ( map ( str , disconnected_sub_graph_nodes ))), ) ) return G , disconnected_sub_graph_nodes @staticmethod def network_connection_plot ( G , disconnected_subgraph_nodes : list ): \"\"\"Plot a graph to check for network connection. Args: G: OSMNX flavored networkX graph. disconnected_subgraph_nodes: List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`). returns: fig, ax : tuple \"\"\" colors = [] for i in range ( len ( disconnected_subgraph_nodes )): colors . append ( \"# %06X \" % randint ( 0 , 0xFFFFFF )) fig , ax = ox . plot_graph ( G , figsize = ( 16 , 16 ), show = False , close = True , edge_color = \"black\" , edge_alpha = 0.1 , node_color = \"black\" , node_alpha = 0.5 , node_size = 10 , ) i = 0 for nodes in disconnected_subgraph_nodes : for n in nodes : size = 100 ax . scatter ( G . nodes [ n ][ \"X\" ], G . nodes [ n ][ \"Y\" ], c = colors [ i ], s = size ) i = i + 1 return fig , ax def selection_map ( self , selected_link_idx : list , A : Optional [ Any ] = None , B : Optional [ Any ] = None , candidate_link_idx : Optional [ List ] = [], ): \"\"\" Shows which links are selected for roadway property change or parallel managed lanes category of roadway projects. Args: selected_links_idx: list of selected link indices candidate_links_idx: optional list of candidate link indices to also include in map A: optional foreign key of starting node of a route selection B: optional foreign key of ending node of a route selection \"\"\" WranglerLogger . debug ( \"Selected Links: {} \\n Candidate Links: {} \\n \" . format ( selected_link_idx , candidate_link_idx ) ) graph_link_idx = list ( set ( selected_link_idx + candidate_link_idx )) graph_links = self . links_df . loc [ graph_link_idx ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( graph_links [ fk ]) ] ) ) graph_nodes = self . nodes_df . loc [ node_list_foreign_keys ] G = RoadwayNetwork . ox_graph ( graph_nodes , graph_links ) # base map plot with whole graph m = ox . plot_graph_folium ( G , edge_color = None , tiles = \"cartodbpositron\" , width = \"300px\" , height = \"250px\" ) # plot selection selected_links = self . links_df . loc [ selected_link_idx ] for _ , row in selected_links . iterrows (): pl = ox . folium . _make_folium_polyline ( edge = row , edge_color = \"blue\" , edge_width = 5 , edge_opacity = 0.8 ) pl . add_to ( m ) # if have A and B node add them to base map def _folium_node ( node_row , color = \"white\" , icon = \"\" ): node_marker = folium . Marker ( location = [ node_row [ \"Y\" ], node_row [ \"X\" ]], icon = folium . Icon ( icon = icon , color = color ), ) return node_marker if A : # WranglerLogger.debug(\"A: {}\\n{}\".format(A,self.nodes_df[self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY] == A])) _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == A ], color = \"green\" , icon = \"play\" , ) . add_to ( m ) if B : _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == B ], color = \"red\" , icon = \"star\" , ) . add_to ( m ) return m def deletion_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are deleted from the roadway network \"\"\" # deleted_links = None # deleted_nodes = None missing_error_message = [] if links is not None : for key , val in links . items (): deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( deleted_links [ fk ]) ] ) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] else : deleted_links = None if nodes is not None : for key , val in nodes . items (): deleted_nodes = self . nodes_df [ self . nodes_df [ key ] . isin ( val )] else : deleted_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , deleted_links ) m = ox . plot_graph_folium ( G , edge_color = \"red\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if deleted_nodes is not None : for _ , row in deleted_nodes . iterrows (): _folium_node ( row , color = \"red\" ) . add_to ( m ) return m def addition_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are added to the roadway network \"\"\" if links is not None : link_ids = [] for link in links : link_ids . append ( link . get ( RoadwayNetwork . UNIQUE_LINK_KEY )) added_links = self . links_df [ self . links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] . isin ( link_ids ) ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( added_links [ fk ]) ] ) ) try : candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] except : return None if nodes is not None : node_ids = [] for node in nodes : node_ids . append ( node . get ( RoadwayNetwork . UNIQUE_NODE_KEY )) added_nodes = self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] . isin ( node_ids ) ] else : added_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , added_links ) m = ox . plot_graph_folium ( G , edge_color = \"green\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if added_nodes is not None : for _ , row in added_nodes . iterrows (): _folium_node ( row , color = \"green\" ) . add_to ( m ) return m","title":"RoadwayNetwork"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.__init__","text":"Constructor Source code in network_wrangler/roadwaynetwork.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def __init__ ( self , nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Constructor \"\"\" if not RoadwayNetwork . validate_object_types ( nodes , links , shapes ): sys . exit ( \"RoadwayNetwork: Invalid constructor data type\" ) self . nodes_df = nodes self . links_df = links self . shapes_df = shapes self . link_file = None self . node_file = None self . shape_file = None # Add non-required fields if they aren't there. # for field, default_value in RoadwayNetwork.OPTIONAL_FIELDS: # if field not in self.links_df.columns: # self.links_df[field] = default_value if not self . validate_uniqueness (): raise ValueError ( \"IDs in network not unique\" ) self . selections = {}","title":"__init__()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.add_new_roadway_feature_change","text":"add the new roadway features defined in the project card. new shapes are also added for the new roadway links. Parameters: Name Type Description Default links list of dictionaries required nodes list of dictionaries required .. todo:: validate links and nodes dictionary Source code in network_wrangler/roadwaynetwork.py 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 def add_new_roadway_feature_change ( self , links : dict , nodes : dict ) -> None : \"\"\" add the new roadway features defined in the project card. new shapes are also added for the new roadway links. args: links : list of dictionaries nodes : list of dictionaries returns: None .. todo:: validate links and nodes dictionary \"\"\" def _add_dict_to_df ( df , new_dict ): df_column_names = df . columns new_row_to_add = {} # add the fields from project card that are in the network for property in df_column_names : if property in new_dict . keys (): if df [ property ] . dtype == np . float64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"float\" ) elif df [ property ] . dtype == np . int64 : value = pd . to_numeric ( new_dict [ property ], downcast = \"integer\" ) else : value = str ( new_dict [ property ]) else : value = \"\" new_row_to_add [ property ] = value # add the fields from project card that are NOT in the network for key , value in new_dict . items (): if key not in df_column_names : new_row_to_add [ key ] = new_dict [ key ] out_df = df . append ( new_row_to_add , ignore_index = True ) return out_df if nodes is not None : for node in nodes : if node . get ( RoadwayNetwork . NODE_FOREIGN_KEY ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) raise ValueError ( msg ) node_query = ( RoadwayNetwork . UNIQUE_NODE_KEY + \" == \" + str ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ]) ) if not self . nodes_df . query ( node_query , engine = \"python\" ) . empty : msg = \"Node with id = {} already exist in the network\" . format ( node [ RoadwayNetwork . NODE_FOREIGN_KEY ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for node in nodes : self . nodes_df = _add_dict_to_df ( self . nodes_df , node ) if links is not None : for link in links : for key in RoadwayNetwork . LINK_FOREIGN_KEY : if link . get ( key ) is None : msg = \"New link to add doesn't contain link foreign key identifier: {} \" . format ( key ) WranglerLogger . error ( msg ) raise ValueError ( msg ) ab_query = \"A == \" + str ( link [ \"A\" ]) + \" and B == \" + str ( link [ \"B\" ]) if not self . links_df . query ( ab_query , engine = \"python\" ) . empty : msg = \"Link with A = {} and B = {} already exist in the network\" . format ( link [ \"A\" ], link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"A\" ] ] . empty : msg = \"New link to add has A node = {} but the node does not exist in the network\" . format ( link [ \"A\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] == link [ \"B\" ] ] . empty : msg = \"New link to add has B node = {} but the node does not exist in the network\" . format ( link [ \"B\" ] ) WranglerLogger . error ( msg ) raise ValueError ( msg ) for link in links : link [ \"new_link\" ] = 1 self . links_df = _add_dict_to_df ( self . links_df , link ) # add location reference and geometry for new links self . links_df [ \"locationReferences\" ] = self . links_df . apply ( lambda x : create_location_reference_from_nodes ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"A\" ] ] . squeeze (), self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == x [ \"B\" ] ] . squeeze (), ) if x [ \"new_link\" ] == 1 else x [ \"locationReferences\" ], axis = 1 , ) self . links_df [ \"geometry\" ] = self . links_df . apply ( lambda x : create_line_string ( x [ \"locationReferences\" ]) if x [ \"new_link\" ] == 1 else x [ \"geometry\" ], axis = 1 , ) self . links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = self . links_df . apply ( lambda x : create_unique_shape_id ( x [ \"geometry\" ]) if x [ \"new_link\" ] == 1 else x [ RoadwayNetwork . UNIQUE_SHAPE_KEY ], axis = 1 , ) # add new shapes added_links = self . links_df [ self . links_df [ \"new_link\" ] == 1 ] added_shapes_df = pd . DataFrame ({ \"geometry\" : added_links [ \"geometry\" ]}) added_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = added_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) self . shapes_df = self . shapes_df . append ( added_shapes_df ) self . links_df . drop ([ \"new_link\" ], axis = 1 , inplace = True )","title":"add_new_roadway_feature_change()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.addition_map","text":"Shows which links and nodes are added to the roadway network Source code in network_wrangler/roadwaynetwork.py 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 def addition_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are added to the roadway network \"\"\" if links is not None : link_ids = [] for link in links : link_ids . append ( link . get ( RoadwayNetwork . UNIQUE_LINK_KEY )) added_links = self . links_df [ self . links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] . isin ( link_ids ) ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( added_links [ fk ]) ] ) ) try : candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] except : return None if nodes is not None : node_ids = [] for node in nodes : node_ids . append ( node . get ( RoadwayNetwork . UNIQUE_NODE_KEY )) added_nodes = self . nodes_df [ self . nodes_df [ RoadwayNetwork . UNIQUE_NODE_KEY ] . isin ( node_ids ) ] else : added_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , added_links ) m = ox . plot_graph_folium ( G , edge_color = \"green\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if added_nodes is not None : for _ , row in added_nodes . iterrows (): _folium_node ( row , color = \"green\" ) . add_to ( m ) return m","title":"addition_map()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply","text":"Wrapper method to apply a project to a roadway network. Parameters: Name Type Description Default project_card_dictionary dict dict a dictionary of the project card object required Source code in network_wrangler/roadwaynetwork.py 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a roadway network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Roadway Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if project_dictionary [ \"category\" ] . lower () == \"roadway property change\" : self . apply_roadway_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : self . apply_managed_lane_feature_change ( self . select_roadway_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"add new roadway\" : self . add_new_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : self . delete_roadway_feature_change ( project_dictionary . get ( \"links\" ), project_dictionary . get ( \"nodes\" ) ) elif project_dictionary [ \"category\" ] . lower () == \"calculated roadway\" : self . apply_python_calculation ( project_dictionary [ 'pycode' ] ) else : raise ( BaseException ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary )","title":"apply()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply_managed_lane_feature_change","text":"Apply the managed lane feature changes to the roadway network Parameters: Name Type Description Default link_idx list of lndices of all links to apply change to required properties list of dictionarys roadway properties to change required in_place bool boolean to indicate whether to update self or return a new roadway network object True .. todo:: decide on connectors info when they are more specific in project card Source code in network_wrangler/roadwaynetwork.py 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 def apply_managed_lane_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Apply the managed lane feature changes to the roadway network Args: link_idx : list of lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean to indicate whether to update self or return a new roadway network object .. todo:: decide on connectors info when they are more specific in project card \"\"\" # add ML flag if \"managed\" in self . links_df . columns : self . links_df . loc [ link_idx , \"managed\" ] = 1 else : self . links_df [ \"managed\" ] = 0 self . links_df . loc [ link_idx , \"managed\" ] = 1 for p in properties : attribute = p [ \"property\" ] if \"group\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for g in p [ \"group\" ]: category = g [ \"category\" ] for tod in g [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"category\" : category , \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ], } ) elif \"timeofday\" in p . keys (): attr_value = {} attr_value [ \"default\" ] = p [ \"set\" ] attr_value [ \"timeofday\" ] = [] for tod in p [ \"timeofday\" ]: attr_value [ \"timeofday\" ] . append ( { \"time\" : parse_time_spans ( tod [ \"time\" ]), \"value\" : tod [ \"set\" ]} ) elif \"set\" in p . keys (): attr_value = p [ \"set\" ] else : attr_value = \"\" # TODO: decide on connectors info when they are more specific in project card if attribute == \"ML_ACCESS\" and attr_value == \"all\" : attr_value = 1 if attribute == \"ML_EGRESS\" and attr_value == \"all\" : attr_value = 1 if in_place : if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object self . links_df [ attribute ] = self . links_df [ attribute ] . astype ( object ) if attribute not in self . links_df . columns : # if it is a new attribute then initiate with NaN values self . links_df [ attribute ] = \"NaN\" for idx in link_idx : self . links_df . at [ idx , attribute ] = attr_value else : if i == 0 : updated_network = copy . deepcopy ( self ) if attribute in self . links_df . columns and not isinstance ( attr_value , numbers . Number ): # if the attribute already exists # and the attr value we are trying to set is not numeric # then change the attribute type to object updated_network . links_df [ attribute ] = updated_network . links_df [ attribute ] . astype ( object ) if attribute not in updated_network . links_df . columns : # if it is a new attribute then initiate with NaN values updated_network . links_df [ attribute ] = \"NaN\" for idx in link_idx : updated_network . links_df . at [ idx , attribute ] = attr_value if i == len ( properties ) - 1 : return updated_network","title":"apply_managed_lane_feature_change()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply_python_calculation","text":"Changes roadway network object by executing pycode. Parameters: Name Type Description Default pycode str python code which changes values in the roadway network object required in_place bool update self or return a new roadway network object True Source code in network_wrangler/roadwaynetwork.py 1255 1256 1257 1258 1259 1260 1261 1262 1263 def apply_python_calculation ( self , pycode : str , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes roadway network object by executing pycode. Args: pycode: python code which changes values in the roadway network object in_place: update self or return a new roadway network object \"\"\" exec ( pycode )","title":"apply_python_calculation()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.apply_roadway_feature_change","text":"Changes the roadway attributes for the selected features based on the project card information passed Parameters: Name Type Description Default link_idx list lndices of all links to apply change to required properties list of dictionarys roadway properties to change required in_place bool boolean update self or return a new roadway network object True Source code in network_wrangler/roadwaynetwork.py 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 def apply_roadway_feature_change ( self , link_idx : list , properties : dict , in_place : bool = True ) -> Union ( None , RoadwayNetwork ): \"\"\" Changes the roadway attributes for the selected features based on the project card information passed Args: link_idx : list lndices of all links to apply change to properties : list of dictionarys roadway properties to change in_place: boolean update self or return a new roadway network object \"\"\" # check if there are change or existing commands that that property # exists in the network # if there is a set command, add that property to network self . validate_properties ( properties ) for i , p in enumerate ( properties ): attribute = p [ \"property\" ] # if project card specifies an existing value in the network # check and see if the existing value in the network matches if p . get ( \"existing\" ): network_values = self . links_df . loc [ link_idx , attribute ] . tolist () if not set ( network_values ) . issubset ([ p . get ( \"existing\" )]): WranglerLogger . warning ( \"Existing value defined for {} in project card does \" \"not match the value in the roadway network for the \" \"selected links\" . format ( attribute ) ) if in_place : if \"set\" in p . keys (): self . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : self . links_df . loc [ link_idx , attribute ] = ( self . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) else : if i == 0 : updated_network = copy . deepcopy ( self ) if \"set\" in p . keys (): updated_network . links_df . loc [ link_idx , attribute ] = p [ \"set\" ] else : updated_network . links_df . loc [ link_idx , attribute ] = ( updated_network . links_df . loc [ link_idx , attribute ] + p [ \"change\" ] ) if i == len ( properties ) - 1 : return updated_network","title":"apply_roadway_feature_change()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.assess_connectivity","text":"Returns a network graph and list of disconnected subgraphs as described by a list of their member nodes. Parameters: Name Type Description Default mode str list of modes of the network, one of drive , transit , walk , bike '' ignore_end_nodes bool if True, ignores stray singleton nodes True links_df DataFrame if specified, will assess connectivity of this links list rather than self.links_df None nodes_df DataFrame if specified, will assess connectivity of this nodes list rather than self.nodes_df None Tuple of Type Description Network Graph (osmnx flavored networkX DiGraph) List of disconnected subgraphs described by the list of their member nodes (as described by their model_node_id ) Source code in network_wrangler/roadwaynetwork.py 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 def assess_connectivity ( self , mode : str = \"\" , ignore_end_nodes : bool = True , links_df : DataFrame = None , nodes_df : DataFrame = None , ): \"\"\"Returns a network graph and list of disconnected subgraphs as described by a list of their member nodes. Args: mode: list of modes of the network, one of `drive`,`transit`, `walk`, `bike` ignore_end_nodes: if True, ignores stray singleton nodes links_df: if specified, will assess connectivity of this links list rather than self.links_df nodes_df: if specified, will assess connectivity of this nodes list rather than self.nodes_df Returns: Tuple of Network Graph (osmnx flavored networkX DiGraph) List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`) \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) # sub_graphs = [s for s in sorted(nx.strongly_connected_component_subgraphs(G), key=len, reverse=True)] sub_graphs = [ s for s in sorted ( ( G . subgraph ( c ) for c in nx . strongly_connected_components ( G )), key = len , reverse = True , ) ] sub_graph_nodes = [ list ( s ) for s in sorted ( nx . strongly_connected_components ( G ), key = len , reverse = True ) ] # sorted on decreasing length, dropping the main sub-graph disconnected_sub_graph_nodes = sub_graph_nodes [ 1 :] # dropping the sub-graphs with only 1 node if ignore_end_nodes : disconnected_sub_graph_nodes = [ list ( s ) for s in disconnected_sub_graph_nodes if len ( s ) > 1 ] WranglerLogger . info ( \" {} for disconnected networks for mode = {} : \\n {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY , mode , \" \\n \" . join ( list ( map ( str , disconnected_sub_graph_nodes ))), ) ) return G , disconnected_sub_graph_nodes","title":"assess_connectivity()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.build_selection_key","text":"Selections are stored by a key combining the query and the A and B ids. This method combines the two for you based on the selection dictionary. Parameters: Name Type Description Default selection_dictonary Selection Dictionary required Source code in network_wrangler/roadwaynetwork.py 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 def build_selection_key ( self , selection_dict : dict ) -> tuple : \"\"\" Selections are stored by a key combining the query and the A and B ids. This method combines the two for you based on the selection dictionary. Args: selection_dictonary: Selection Dictionary Returns: Tuple serving as the selection key. \"\"\" sel_query = ProjectCard . build_link_selection_query ( selection = selection_dict , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , ) if RoadwayNetwork . selection_has_unique_link_id ( selection_dict ): return sel_query A_id , B_id = self . orig_dest_nodes_foreign_key ( selection_dict ) return ( sel_query , A_id , B_id )","title":"build_selection_key()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.create_dummy_connector_links","text":"create dummy connector links between the general purpose and managed lanes Parameters: Name Type Description Default gp_df GeoDataFrame dataframe of general purpose links (where managed lane also exists) required ml_df GeoDataFrame dataframe of corresponding managed lane links required Source code in network_wrangler/roadwaynetwork.py 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 def create_dummy_connector_links ( gp_df : GeoDataFrame , ml_df : GeoDataFrame ): \"\"\" create dummy connector links between the general purpose and managed lanes args: gp_df : GeoDataFrame dataframe of general purpose links (where managed lane also exists) ml_df : GeoDataFrame dataframe of corresponding managed lane links \"\"\" gp_ml_links_df = pd . concat ( [ gp_df , ml_df . add_prefix ( \"ML_\" )], axis = 1 , join = \"inner\" ) access_df = gp_df . iloc [ 0 : 0 , :] . copy () egress_df = gp_df . iloc [ 0 : 0 , :] . copy () def _get_connector_references ( ref_1 : list , ref_2 : list , type : str ): if type == \"access\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_1 [ 0 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_2 [ 0 ][ \"point\" ]}, ] if type == \"egress\" : out_location_reference = [ { \"sequence\" : 1 , \"point\" : ref_2 [ 1 ][ \"point\" ]}, { \"sequence\" : 2 , \"point\" : ref_1 [ 1 ][ \"point\" ]}, ] return out_location_reference for index , row in gp_ml_links_df . iterrows (): access_row = {} access_row [ \"A\" ] = row [ \"A\" ] access_row [ \"B\" ] = row [ \"ML_A\" ] access_row [ \"lanes\" ] = 1 access_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 1 ) access_row [ \"access\" ] = row [ \"ML_access\" ] access_row [ \"drive_access\" ] = row [ \"drive_access\" ] access_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"access\" ) access_row [ \"distance\" ] = haversine_distance ( access_row [ \"locationReferences\" ][ 0 ][ \"point\" ], access_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) access_row [ \"roadway\" ] = \"ml_access\" access_row [ \"name\" ] = \"Access Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : access_row [ \"ref\" ] = row [ \"ref\" ] else : access_row [ \"ref\" ] = \"\" access_df = access_df . append ( access_row , ignore_index = True ) egress_row = {} egress_row [ \"A\" ] = row [ \"ML_B\" ] egress_row [ \"B\" ] = row [ \"B\" ] egress_row [ \"lanes\" ] = 1 egress_row [ \"model_link_id\" ] = ( row [ \"model_link_id\" ] + row [ \"ML_model_link_id\" ] + 2 ) egress_row [ \"access\" ] = row [ \"ML_access\" ] egress_row [ \"drive_access\" ] = row [ \"drive_access\" ] egress_row [ \"locationReferences\" ] = _get_connector_references ( row [ \"locationReferences\" ], row [ \"ML_locationReferences\" ], \"egress\" ) egress_row [ \"distance\" ] = haversine_distance ( egress_row [ \"locationReferences\" ][ 0 ][ \"point\" ], egress_row [ \"locationReferences\" ][ 1 ][ \"point\" ], ) egress_row [ \"roadway\" ] = \"ml_egress\" egress_row [ \"name\" ] = \"Egress Dummy \" + row [ \"name\" ] # ref is not a *required* attribute, so make conditional: if \"ref\" in gp_ml_links_df . columns : egress_row [ \"ref\" ] = row [ \"ref\" ] else : egress_row [ \"ref\" ] = \"\" egress_df = egress_df . append ( egress_row , ignore_index = True ) return ( access_df , egress_df )","title":"create_dummy_connector_links()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.create_managed_lane_network","text":"Create a roadway network with managed lanes links separated out. Add new parallel managed lane links, access/egress links, and add shapes corresponding to the new links Parameters: Name Type Description Default in_place bool update self or return a new roadway network object False .. todo:: make this a more rigorous test Source code in network_wrangler/roadwaynetwork.py 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 def create_managed_lane_network ( self , in_place : bool = False ) -> RoadwayNetwork : \"\"\" Create a roadway network with managed lanes links separated out. Add new parallel managed lane links, access/egress links, and add shapes corresponding to the new links args: in_place: update self or return a new roadway network object returns: A RoadwayNetwork instance .. todo:: make this a more rigorous test \"\"\" WranglerLogger . info ( \"Creating network with duplicated managed lanes\" ) if \"ml_access\" in self . links_df [ \"roadway\" ] . tolist (): msg = \"managed lane access links already exist in network; shouldn't be running create managed lane network. Returning network as-is.\" WranglerLogger . error ( msg ) if in_place : return else : return copy . deepcopy ( self ) link_attributes = self . links_df . columns . values . tolist () ml_attributes = [ i for i in link_attributes if i . startswith ( \"ML_\" )] # non_ml_links are links in the network where there is no managed lane. # gp_links are the gp lanes and ml_links are ml lanes respectively for the ML roadways. non_ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 0 ] non_ml_links_df = non_ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df = self . links_df [ self . links_df [ \"managed\" ] == 1 ] gp_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) for attr in link_attributes : if attr == \"name\" : ml_links_df [ \"name\" ] = \"Managed Lane \" + gp_links_df [ \"name\" ] elif attr in ml_attributes and attr not in [ \"ML_ACCESS\" , \"ML_EGRESS\" ]: gp_attr = attr . split ( \"_\" , 1 )[ 1 ] ml_links_df . loc [:, gp_attr ] = ml_links_df [ attr ] if ( attr not in RoadwayNetwork . KEEP_SAME_ATTRIBUTES_ML_AND_GP and attr not in RoadwayNetwork . MANAGED_LANES_REQUIRED_ATTRIBUTES ): ml_links_df [ attr ] = \"\" ml_links_df = ml_links_df . drop ( ml_attributes , axis = 1 ) ml_links_df [ \"managed\" ] = 1 gp_links_df [ \"managed\" ] = 0 def _update_location_reference ( location_reference : list ): out_location_reference = copy . deepcopy ( location_reference ) out_location_reference [ 0 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 0 ][ \"point\" ] ) out_location_reference [ 1 ][ \"point\" ] = offset_lat_lon ( out_location_reference [ 1 ][ \"point\" ] ) return out_location_reference ml_links_df [ \"A\" ] = ( ml_links_df [ \"A\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ \"B\" ] = ( ml_links_df [ \"B\" ] + RoadwayNetwork . MANAGED_LANES_NODE_ID_SCALAR ) ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] = ( ml_links_df [ RoadwayNetwork . UNIQUE_LINK_KEY ] + RoadwayNetwork . MANAGED_LANES_LINK_ID_SCALAR ) ml_links_df [ \"locationReferences\" ] = ml_links_df [ \"locationReferences\" ] . apply ( # lambda x: _update_location_reference(x) lambda x : offset_location_reference ( x ) ) ml_links_df [ \"geometry\" ] = ml_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) ml_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = ml_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x ) ) access_links_df , egress_links_df = RoadwayNetwork . create_dummy_connector_links ( gp_links_df , ml_links_df ) access_links_df [ \"geometry\" ] = access_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) egress_links_df [ \"geometry\" ] = egress_links_df [ \"locationReferences\" ] . apply ( lambda x : create_line_string ( x ) ) access_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = access_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) egress_links_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = egress_links_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_links_df = gp_links_df . append ( ml_links_df ) out_links_df = out_links_df . append ( access_links_df ) out_links_df = out_links_df . append ( egress_links_df ) out_links_df = out_links_df . append ( non_ml_links_df ) # only the ml_links_df has the new nodes added added_a_nodes = ml_links_df [ \"A\" ] added_b_nodes = ml_links_df [ \"B\" ] out_nodes_df = self . nodes_df for a_node in added_a_nodes : out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : a_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"A\" ] == a_node ] . iloc [ 0 ][ \"locationReferences\" ][ 0 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) for b_node in added_b_nodes : if b_node not in out_nodes_df [ \"model_node_id\" ] . tolist (): out_nodes_df = out_nodes_df . append ( { \"model_node_id\" : b_node , \"geometry\" : Point ( out_links_df [ out_links_df [ \"B\" ] == b_node ] . iloc [ 0 ][ \"locationReferences\" ][ 1 ][ \"point\" ] ), \"drive_node\" : 1 , }, ignore_index = True , ) out_nodes_df [ \"X\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) out_nodes_df [ \"Y\" ] = out_nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) out_shapes_df = self . shapes_df # managed lanes, access and egress connectors are new geometry new_shapes_df = pd . DataFrame ( { \"geometry\" : ml_links_df [ \"geometry\" ] . append ( access_links_df [ \"geometry\" ]) . append ( egress_links_df [ \"geometry\" ]) } ) new_shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] = new_shapes_df [ \"geometry\" ] . apply ( lambda x : create_unique_shape_id ( x )) out_shapes_df = out_shapes_df . append ( new_shapes_df ) out_links_df = out_links_df . reset_index () out_nodes_df = out_nodes_df . reset_index () out_shapes_df = out_shapes_df . reset_index () if in_place : self . links_df = out_links_df self . nodes_df = out_nodes_df self . shapes_df = out_shapes_df else : out_network = copy . deepcopy ( self ) out_network . links_df = out_links_df out_network . nodes_df = out_nodes_df out_network . shapes_df = out_shapes_df return out_network","title":"create_managed_lane_network()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.delete_roadway_feature_change","text":"delete the roadway features defined in the project card. valid links and nodes defined in the project gets deleted and shapes corresponding to the deleted links are also deleted. Parameters: Name Type Description Default links dict list of dictionaries required nodes dict list of dictionaries required ignore_missing bool If True, will only warn about links/nodes that are missing from network but specified to \u201cdelete\u201d in project card If False, will fail. True Source code in network_wrangler/roadwaynetwork.py 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 def delete_roadway_feature_change ( self , links : dict , nodes : dict , ignore_missing = True ) -> None : \"\"\" delete the roadway features defined in the project card. valid links and nodes defined in the project gets deleted and shapes corresponding to the deleted links are also deleted. Args: links : dict list of dictionaries nodes : dict list of dictionaries ignore_missing: bool If True, will only warn about links/nodes that are missing from network but specified to \"delete\" in project card If False, will fail. \"\"\" missing_error_message = [] if links is not None : shapes_to_delete = [] for key , val in links . items (): missing_links = [ v for v in val if v not in self . links_df [ key ] . tolist ()] if missing_links : message = \"Links attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] shapes_to_delete . extend ( deleted_links [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . tolist () ) self . links_df . drop ( self . links_df . index [ self . links_df [ key ] . isin ( val )], inplace = True ) self . shapes_df . drop ( self . shapes_df . index [ self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . isin ( shapes_to_delete ) ], inplace = True , ) if nodes is not None : for key , val in nodes . items (): missing_nodes = [ v for v in val if v not in self . nodes_df [ key ] . tolist ()] if missing_nodes : message = \"Nodes attribute {} with values as {} does not exist in the network \\n \" . format ( key , missing_links ) if ignore_missing : WranglerLogger . warning ( message ) else : missing_error_message . append ( message ) self . nodes_df = self . nodes_df [ ~ self . nodes_df [ key ] . isin ( val )] if missing_error_message : WranglerLogger . error ( \" \" . join ( missing_error_message )) raise ValueError ()","title":"delete_roadway_feature_change()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.deletion_map","text":"Shows which links and nodes are deleted from the roadway network Source code in network_wrangler/roadwaynetwork.py 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 def deletion_map ( self , links : dict , nodes : dict ): \"\"\" Shows which links and nodes are deleted from the roadway network \"\"\" # deleted_links = None # deleted_nodes = None missing_error_message = [] if links is not None : for key , val in links . items (): deleted_links = self . links_df [ self . links_df [ key ] . isin ( val )] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( deleted_links [ fk ]) ] ) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] else : deleted_links = None if nodes is not None : for key , val in nodes . items (): deleted_nodes = self . nodes_df [ self . nodes_df [ key ] . isin ( val )] else : deleted_nodes = None G = RoadwayNetwork . ox_graph ( candidate_nodes , deleted_links ) m = ox . plot_graph_folium ( G , edge_color = \"red\" , tiles = \"cartodbpositron\" ) def _folium_node ( node , color = \"white\" , icon = \"\" ): node_circle = folium . Circle ( location = [ node [ \"Y\" ], node [ \"X\" ]], radius = 2 , fill = True , color = color , fill_opacity = 0.8 , ) return node_circle if deleted_nodes is not None : for _ , row in deleted_nodes . iterrows (): _folium_node ( row , color = \"red\" ) . add_to ( m ) return m","title":"deletion_map()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_modal_graph","text":"Determines if the network graph is \u201cstrongly\u201d connected A graph is strongly connected if each vertex is reachable from every other vertex. Parameters: Name Type Description Default links_df DataFrame DataFrame of standard network links required nodes_df DataFrame DataFrame of standard network nodes required mode str mode of the network, one of drive , transit , walk , bike None Source code in network_wrangler/roadwaynetwork.py 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 @staticmethod def get_modal_graph ( links_df : DataFrame , nodes_df : DataFrame , mode : str = None ): \"\"\"Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` Returns: networkx: osmnx: DiGraph of network \"\"\" if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} .\" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()) ) WranglerLogger . error ( msg ) raise ValueError ( msg ) _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( links_df , nodes_df , modes = [ mode ], ) G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) return G","title":"get_modal_graph()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_modal_links_nodes","text":"Returns nodes and link dataframes for specific mode. Parameters: Name Type Description Default links_df DataFrame DataFrame of standard network links required nodes_df DataFrame DataFrame of standard network nodes required modes list [ str ] list of the modes of the network to be kept, must be in drive , transit , rail , bus , walk , bike . For example, if bike and walk are selected, both bike and walk links will be kept. None .. todo:: Right now we don\u2019t filter the nodes because transit-only links with walk access are not marked as having walk access Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] Source code in network_wrangler/roadwaynetwork.py 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 @staticmethod def get_modal_links_nodes ( links_df : DataFrame , nodes_df : DataFrame , modes : list [ str ] = None ) -> tuple ( DataFrame , DataFrame ): \"\"\"Returns nodes and link dataframes for specific mode. Args: links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes modes: list of the modes of the network to be kept, must be in `drive`,`transit`,`rail`,`bus`, `walk`, `bike`. For example, if bike and walk are selected, both bike and walk links will be kept. Returns: tuple of DataFrames for links, nodes filtered by mode .. todo:: Right now we don't filter the nodes because transit-only links with walk access are not marked as having walk access Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] \"\"\" for mode in modes : if mode not in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys (): msg = \"mode value should be one of {} , got {} \" . format ( list ( RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES . keys ()), mode , ) WranglerLogger . error ( msg ) raise ValueError ( msg ) mode_link_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ mode ] ] ) ) mode_node_variables = list ( set ( [ mode for mode in modes for mode in RoadwayNetwork . MODES_TO_NETWORK_NODE_VARIABLES [ mode ] ] ) ) if not set ( mode_link_variables ) . issubset ( set ( links_df . columns )): msg = \" {} not in provided links_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_link_variables ) - set ( links_df . columns ), links_df . columns ) WranglerLogger . error ( msg ) if not set ( mode_node_variables ) . issubset ( set ( nodes_df . columns )): msg = \" {} not in provided nodes_df list of columns. Available columns are: \\n {} \" . format ( set ( mode_node_variables ) - set ( nodes_df . columns ), nodes_df . columns ) WranglerLogger . error ( msg ) modal_links_df = links_df . loc [ links_df [ mode_link_variables ] . any ( axis = 1 )] ##TODO right now we don't filter the nodes because transit-only # links with walk access are not marked as having walk access # Issue discussed in https://github.com/wsp-sag/network_wrangler/issues/145 # modal_nodes_df = nodes_df[nodes_df[mode_node_variable] == 1] modal_nodes_df = nodes_df return modal_links_df , modal_nodes_df","title":"get_modal_links_nodes()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_property_by_time_period_and_group","text":"Return a series for the properties with a specific group or time period.","title":"get_property_by_time_period_and_group()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_property_by_time_period_and_group--args","text":"str the variable that you want from network list(str) the time period that you are querying for i.e. [\u201816:00\u2019, \u201819:00\u2019] str or list(str)(Optional) the group category i.e. \u201csov\u201d or list of group categories in order of search, i.e. [\u201chov3\u201d,\u201dhov2\u201d]","title":"args"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.get_property_by_time_period_and_group--returns","text":"pandas series Source code in network_wrangler/roadwaynetwork.py 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 def get_property_by_time_period_and_group ( self , property , time_period = None , category = None ): \"\"\" Return a series for the properties with a specific group or time period. args ------ property: str the variable that you want from network time_period: list(str) the time period that you are querying for i.e. ['16:00', '19:00'] category: str or list(str)(Optional) the group category i.e. \"sov\" or list of group categories in order of search, i.e. [\"hov3\",\"hov2\"] returns -------- pandas series \"\"\" def _get_property ( v , time_spans = None , category = None , return_partial_match : bool = False , partial_match_minutes : int = 60 , ): \"\"\" .. todo:: return the time period with the largest overlap \"\"\" if category and not time_spans : WranglerLogger . error ( \" \\n Shouldn't have a category group without time spans\" ) raise ValueError ( \"Shouldn't have a category group without time spans\" ) # simple case if type ( v ) in ( int , float , str ): return v if not category : category = [ \"default\" ] elif isinstance ( category , str ): category = [ category ] search_cats = [ c . lower () for c in category ] # if no time or group specified, but it is a complex link situation if not time_spans : if \"default\" in v . keys (): return v [ \"default\" ] else : WranglerLogger . debug ( \"variable: \" . format ( v )) msg = \"Variable {} is more complex in network than query\" . format ( v ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if v . get ( \"timeofday\" ): categories = [] for tg in v [ \"timeofday\" ]: if ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ] ): if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", time_spans, category, tg[\"value\"] # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] # if there isn't a fully matched time period, see if there is an overlapping one # right now just return the first overlapping ones # TODO return the time period with the largest overlap if ( ( time_spans [ 0 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 0 ] <= tg [ \"time\" ][ 1 ]) ) or ( ( time_spans [ 1 ] >= tg [ \"time\" ][ 0 ]) and ( time_spans [ 1 ] <= tg [ \"time\" ][ 1 ]) ): overlap_minutes = max ( 0 , min ( tg [ \"time\" ][ 1 ], time_spans [ 1 ]) - max ( time_spans [ 0 ], tg [ \"time\" ][ 0 ]), ) # print(\"OLM\",overlap_minutes) if not return_partial_match and overlap_minutes > 0 : WranglerLogger . debug ( \"Couldn't find time period consistent with {} , but found a partial match: {} . Consider allowing partial matches using 'return_partial_match' keyword or updating query.\" . format ( time_spans , tg [ \"time\" ] ) ) elif ( overlap_minutes < partial_match_minutes and overlap_minutes > 0 ): WranglerLogger . debug ( \"Time period: {} overlapped less than the minimum number of minutes ( {} < {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) elif overlap_minutes > 0 : WranglerLogger . debug ( \"Returning a partial time period match. Time period: {} overlapped the minimum number of minutes ( {} >= {} ) to be considered a match with time period in network: {} .\" . format ( time_spans , overlap_minutes , partial_match_minutes , tg [ \"time\" ], ) ) if tg . get ( \"category\" ): categories += tg [ \"category\" ] for c in search_cats : print ( \"CAT:\" , c , tg [ \"category\" ]) if c in tg [ \"category\" ]: # print(\"Var:\", v) # print( # \"RETURNING:\", # time_spans, # category, # tg[\"value\"], # ) return tg [ \"value\" ] else : # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, category, tg[\"value\"]) return tg [ \"value\" ] \"\"\" WranglerLogger.debug( \"\\nCouldn't find time period for {}, returning default\".format( str(time_spans) ) ) \"\"\" if \"default\" in v . keys (): # print(\"Var:\", v) # print(\"RETURNING:\", time_spans, v[\"default\"]) return v [ \"default\" ] else : # print(\"Var:\", v) WranglerLogger . error ( \" \\n Can't find default; must specify a category in {} \" . format ( str ( categories ) ) ) raise ValueError ( \"Can't find default, must specify a category in: {} \" . format ( str ( categories ) ) ) time_spans = parse_time_spans ( time_period ) return self . links_df [ property ] . apply ( _get_property , time_spans = time_spans , category = category )","title":"returns"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.is_network_connected","text":"Determines if the network graph is \u201cstrongly\u201d connected A graph is strongly connected if each vertex is reachable from every other vertex. Parameters: Name Type Description Default mode str mode of the network, one of drive , transit , walk , bike None links_df DataFrame DataFrame of standard network links None nodes_df DataFrame DataFrame of standard network nodes None .. todo:: Consider caching graphs if they take a long time. Source code in network_wrangler/roadwaynetwork.py 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 def is_network_connected ( self , mode : str = None , links_df : DataFrame = None , nodes_df : DataFrame = None ): \"\"\" Determines if the network graph is \"strongly\" connected A graph is strongly connected if each vertex is reachable from every other vertex. Args: mode: mode of the network, one of `drive`,`transit`, `walk`, `bike` links_df: DataFrame of standard network links nodes_df: DataFrame of standard network nodes Returns: boolean .. todo:: Consider caching graphs if they take a long time. \"\"\" _nodes_df = nodes_df if nodes_df else self . nodes_df _links_df = links_df if links_df else self . links_df if mode : _links_df , _nodes_df = RoadwayNetwork . get_modal_links_nodes ( _links_df , _nodes_df , modes = [ mode ], ) else : WranglerLogger . info ( \"Assessing connectivity without a mode \\ specified. This may have limited value in interpretation. \\ To add mode specificity, add the keyword `mode =` to calling \\ this method\" ) # TODO: consider caching graphs if they start to take forever # and we are calling them more than once. G = RoadwayNetwork . ox_graph ( _nodes_df , _links_df ) is_connected = nx . is_strongly_connected ( G ) return is_connected","title":"is_network_connected()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.network_connection_plot","text":"Plot a graph to check for network connection. Parameters: Name Type Description Default G OSMNX flavored networkX graph. required disconnected_subgraph_nodes list List of disconnected subgraphs described by the list of their member nodes (as described by their model_node_id ). required Source code in network_wrangler/roadwaynetwork.py 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 @staticmethod def network_connection_plot ( G , disconnected_subgraph_nodes : list ): \"\"\"Plot a graph to check for network connection. Args: G: OSMNX flavored networkX graph. disconnected_subgraph_nodes: List of disconnected subgraphs described by the list of their member nodes (as described by their `model_node_id`). returns: fig, ax : tuple \"\"\" colors = [] for i in range ( len ( disconnected_subgraph_nodes )): colors . append ( \"# %06X \" % randint ( 0 , 0xFFFFFF )) fig , ax = ox . plot_graph ( G , figsize = ( 16 , 16 ), show = False , close = True , edge_color = \"black\" , edge_alpha = 0.1 , node_color = \"black\" , node_alpha = 0.5 , node_size = 10 , ) i = 0 for nodes in disconnected_subgraph_nodes : for n in nodes : size = 100 ax . scatter ( G . nodes [ n ][ \"X\" ], G . nodes [ n ][ \"Y\" ], c = colors [ i ], s = size ) i = i + 1 return fig , ax","title":"network_connection_plot()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.orig_dest_nodes_foreign_key","text":"Returns the foreign key id (whatever is used in the u and v variables in the links file) for the AB nodes as a tuple. Parameters: Name Type Description Default selection selection dictionary with A and B keys required node_foreign_key str variable name for whatever is used by the u and v variable '' Source code in network_wrangler/roadwaynetwork.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 def orig_dest_nodes_foreign_key ( self , selection : dict , node_foreign_key : str = \"\" ) -> tuple : \"\"\" Returns the foreign key id (whatever is used in the u and v variables in the links file) for the AB nodes as a tuple. Args: selection : selection dictionary with A and B keys node_foreign_key: variable name for whatever is used by the u and v variable in the links_df file. If nothing is specified, assume whatever default is (usually osm_node_id) Returns: tuple of (A_id, B_id) \"\"\" if not node_foreign_key : node_foreign_key = RoadwayNetwork . NODE_FOREIGN_KEY if len ( selection [ \"A\" ]) > 1 : raise ( \"Selection A node dictionary should be of length 1\" ) if len ( selection [ \"B\" ]) > 1 : raise ( \"Selection B node dictionary should be of length 1\" ) A_node_key , A_id = next ( iter ( selection [ \"A\" ] . items ())) B_node_key , B_id = next ( iter ( selection [ \"B\" ] . items ())) if A_node_key != node_foreign_key : A_id = self . nodes_df [ self . nodes_df [ A_node_key ] == A_id ][ node_foreign_key ] . values [ 0 ] if B_node_key != node_foreign_key : B_id = self . nodes_df [ self . nodes_df [ B_node_key ] == B_id ][ node_foreign_key ] . values [ 0 ] return ( A_id , B_id )","title":"orig_dest_nodes_foreign_key()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.ox_graph","text":"create an osmnx-flavored network graph osmnx doesn\u2019t like values that are arrays, so remove the variables that have arrays. osmnx also requires that certain variables be filled in, so do that too. Parameters: Name Type Description Default nodes_df GeoDataFrame of nodes required link_df GeoDataFrame of links required Source code in network_wrangler/roadwaynetwork.py 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 @staticmethod def ox_graph ( nodes_df : GeoDataFrame , links_df : GeoDataFrame ): \"\"\" create an osmnx-flavored network graph osmnx doesn't like values that are arrays, so remove the variables that have arrays. osmnx also requires that certain variables be filled in, so do that too. Args: nodes_df : GeoDataFrame of nodes link_df : GeoDataFrame of links Returns: a networkx multidigraph \"\"\" WranglerLogger . debug ( \"starting ox_graph()\" ) graph_nodes = nodes_df . copy () . drop ( [ \"inboundReferenceIds\" , \"outboundReferenceIds\" ], axis = 1 ) graph_nodes . gdf_name = \"network_nodes\" WranglerLogger . debug ( \"GRAPH NODES: {} \" . format ( graph_nodes . columns )) graph_nodes [ \"id\" ] = graph_nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] graph_nodes [ \"x\" ] = graph_nodes [ \"X\" ] graph_nodes [ \"y\" ] = graph_nodes [ \"Y\" ] graph_links = links_df . copy () . drop ( [ \"osm_link_id\" , \"locationReferences\" ], axis = 1 ) # have to change this over into u,v b/c this is what osm-nx is expecting graph_links [ \"u\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 0 ]] graph_links [ \"v\" ] = graph_links [ RoadwayNetwork . LINK_FOREIGN_KEY [ 1 ]] graph_links [ \"id\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] graph_links [ \"key\" ] = graph_links [ RoadwayNetwork . UNIQUE_LINK_KEY ] WranglerLogger . debug ( \"starting ox.gdfs_to_graph()\" ) try : G = ox . graph_from_gdfs ( graph_nodes , graph_links ) except : WranglerLogger . debug ( \"Please upgrade your OSMNX package. For now, using depricated osmnx.gdfs_to_graph because osmnx.graph_from_gdfs not found\" ) G = ox . gdfs_to_graph ( graph_nodes , graph_links ) WranglerLogger . debug ( \"finished ox.gdfs_to_graph()\" ) return G","title":"ox_graph()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.read","text":"Reads a network from the roadway network standard Validates that it conforms to the schema Parameters: Name Type Description Default link_file str full path to the link file required node_file str full path to the node file required shape_file str full path to the shape file required fast bool boolean that will skip validation to speed up read time True .. todo:: Turn off fast=True as default Source code in network_wrangler/roadwaynetwork.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 @staticmethod def read ( link_file : str , node_file : str , shape_file : str , fast : bool = True ) -> RoadwayNetwork : \"\"\" Reads a network from the roadway network standard Validates that it conforms to the schema args: link_file: full path to the link file node_file: full path to the node file shape_file: full path to the shape file fast: boolean that will skip validation to speed up read time Returns: a RoadwayNetwork instance .. todo:: Turn off fast=True as default \"\"\" WranglerLogger . info ( \"Reading from following files: \\n - {} \\n - {} \\n - {} .\" . format ( link_file , node_file , shape_file ) ) \"\"\" Validate Input \"\"\" if not os . path . exists ( link_file ): msg = \"Link file doesn't exist at: {} \" . format ( link_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( node_file ): msg = \"Node file doesn't exist at: {} \" . format ( node_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not os . path . exists ( shape_file ): msg = \"Shape file doesn't exist at: {} \" . format ( shape_file ) WranglerLogger . error ( msg ) raise ValueError ( msg ) if not fast : if not ( RoadwayNetwork . validate_node_schema ( node_file ) and RoadwayNetwork . validate_link_schema ( link_file ) and RoadwayNetwork . validate_shape_schema ( shape_file ) ): sys . exit ( \"RoadwayNetwork: Data doesn't conform to schema\" ) with open ( link_file ) as f : link_json = json . load ( f ) link_properties = pd . DataFrame ( link_json ) link_geometries = [ create_line_string ( g [ \"locationReferences\" ]) for g in link_json ] links_df = gpd . GeoDataFrame ( link_properties , geometry = link_geometries ) links_df . crs = RoadwayNetwork . CRS # coerce types for booleans which might not have a 1 and are therefore read in as intersection bool_columns = [ \"rail_only\" , \"bus_only\" , \"drive_access\" , \"bike_access\" , \"walk_access\" , \"truck_access\" , ] for bc in list ( set ( bool_columns ) & set ( links_df . columns )): links_df [ bc ] = links_df [ bc ] . astype ( bool ) shapes_df = gpd . read_file ( shape_file ) shapes_df . dropna ( subset = [ \"geometry\" , \"id\" ], inplace = True ) shapes_df . crs = RoadwayNetwork . CRS # geopandas uses fiona OGR drivers, which doesn't let you have # a list as a property type. Therefore, must read in node_properties # separately in a vanilla dataframe and then convert to geopandas with open ( node_file ) as f : node_geojson = json . load ( f ) node_properties = pd . DataFrame ( [ g [ \"properties\" ] for g in node_geojson [ \"features\" ]] ) node_geometries = [ Point ( g [ \"geometry\" ][ \"coordinates\" ]) for g in node_geojson [ \"features\" ] ] nodes_df = gpd . GeoDataFrame ( node_properties , geometry = node_geometries ) nodes_df . gdf_name = \"network_nodes\" # set a copy of the foreign key to be the index so that the # variable itself remains queryiable nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" ] = nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] nodes_df . set_index ( RoadwayNetwork . NODE_FOREIGN_KEY + \"_idx\" , inplace = True ) nodes_df . crs = RoadwayNetwork . CRS nodes_df [ \"X\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . x ) nodes_df [ \"Y\" ] = nodes_df [ \"geometry\" ] . apply ( lambda g : g . y ) WranglerLogger . info ( \"Read %s links from %s \" % ( len ( links_df ), link_file )) WranglerLogger . info ( \"Read %s nodes from %s \" % ( len ( nodes_df ), node_file )) WranglerLogger . info ( \"Read %s shapes from %s \" % ( len ( shapes_df ), shape_file )) roadway_network = RoadwayNetwork ( nodes = nodes_df , links = links_df , shapes = shapes_df ) roadway_network . link_file = link_file roadway_network . node_file = node_file roadway_network . shape_file = shape_file return roadway_network","title":"read()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.roadway_net_to_gdf","text":"Turn the roadway network into a GeoDataFrame Parameters: Name Type Description Default roadway_net RoadwayNetwork the roadway network to export required .. todo:: Make this much more sophisticated, for example attach link info to shapes Source code in network_wrangler/roadwaynetwork.py 390 391 392 393 394 395 396 397 398 399 400 401 @staticmethod def roadway_net_to_gdf ( roadway_net : RoadwayNetwork ) -> gpd . GeoDataFrame : \"\"\" Turn the roadway network into a GeoDataFrame args: roadway_net: the roadway network to export returns: shapes dataframe .. todo:: Make this much more sophisticated, for example attach link info to shapes \"\"\" return roadway_net . shapes_df","title":"roadway_net_to_gdf()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.select_roadway_features","text":"Selects roadway features that satisfy selection criteria Example usage net.select_roadway_features( selection = [ { # a match condition for the from node using osm, # shared streets, or model node number \u2018from\u2019: {\u2018osm_model_link_id\u2019: \u20181234\u2019}, # a match for the to-node.. \u2018to\u2019: {\u2018shstid\u2019: \u20184321\u2019}, # a regex or match for facility condition # could be # of lanes, facility type, etc. \u2018facility\u2019: {\u2018name\u2019:\u2019Main St\u2019}, }, \u2026 ]) Parameters: Name Type Description Default selection dictionary with keys for: A - from node B - to node link - which includes at least a variable for name required Source code in network_wrangler/roadwaynetwork.py 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 def select_roadway_features ( self , selection : dict , search_mode = \"drive\" , force_search = False ) -> GeoDataFrame : \"\"\" Selects roadway features that satisfy selection criteria Example usage: net.select_roadway_features( selection = [ { # a match condition for the from node using osm, # shared streets, or model node number 'from': {'osm_model_link_id': '1234'}, # a match for the to-node.. 'to': {'shstid': '4321'}, # a regex or match for facility condition # could be # of lanes, facility type, etc. 'facility': {'name':'Main St'}, }, ... ]) Args: selection : dictionary with keys for: A - from node B - to node link - which includes at least a variable for `name` Returns: a list of node foreign IDs on shortest path \"\"\" WranglerLogger . debug ( \"validating selection\" ) self . validate_selection ( selection ) # create a unique key for the selection so that we can cache it sel_key = self . build_selection_key ( selection ) WranglerLogger . debug ( \"Selection Key: {} \" . format ( sel_key )) # if this selection has been queried before, just return the # previously selected links if sel_key in self . selections and not force_search : if self . selections [ sel_key ][ \"selection_found\" ]: return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : msg = \"Selection previously queried but no selection found\" WranglerLogger . error ( msg ) raise Exception ( msg ) self . selections [ sel_key ] = {} self . selections [ sel_key ][ \"selection_found\" ] = False unique_model_link_identifer_in_selection = RoadwayNetwork . selection_has_unique_link_id ( selection ) if not unique_model_link_identifer_in_selection : A_id , B_id = self . orig_dest_nodes_foreign_key ( selection ) # identify candidate links which match the initial query # assign them as iteration = 0 # subsequent iterations that didn't match the query will be # assigned a heigher weight in the shortest path WranglerLogger . debug ( \"Building selection query\" ) # build a selection query based on the selection dictionary sel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ) WranglerLogger . debug ( \"Selecting features: \\n {} \" . format ( sel_query )) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) WranglerLogger . debug ( \"Completed query\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] # b/c too long to keep that way candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 and unique_model_link_identifer_in_selection : msg = \"No links found based on unique link identifiers. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if len ( candidate_links . index ) == 0 : WranglerLogger . debug ( \"No candidate links in initial search. \\n Retrying query using 'ref' instead of 'name'\" ) # if the query doesn't come back with something from 'name' # try it again with 'ref' instead selection_has_name_key = any ( \"name\" in d for d in selection [ \"link\" ]) if not selection_has_name_key : msg = \"Not able to complete search using 'ref' instead of 'name' because 'name' not in search.\" WranglerLogger . error ( msg ) raise Exception ( msg ) if not \"ref\" in self . links_df . columns : msg = \"Not able to complete search using 'ref' because 'ref' not in network.\" WranglerLogger . error ( msg ) raise Exception ( msg ) WranglerLogger . debug ( \"Trying selection query replacing 'name' with 'ref'\" ) sel_query = sel_query . replace ( \"name\" , \"ref\" ) self . selections [ sel_key ][ \"candidate_links\" ] = self . links_df . query ( sel_query , engine = \"python\" ) candidate_links = self . selections [ sel_key ][ \"candidate_links\" ] candidate_links [ \"i\" ] = 0 if len ( candidate_links . index ) == 0 : msg = \"No candidate links in search using either 'name' or 'ref' in query. \\n Selection Failed.\" WranglerLogger . error ( msg ) raise Exception ( msg ) def _add_breadth ( candidate_links : DataFrame , nodes : Data , links , i ): \"\"\" Add outbound and inbound reference IDs to candidate links from existing nodes Args: candidate_links : GeoDataFrame df with the links from the previous iteration that we want to add on to nodes : GeoDataFrame df of all nodes in the full network links : GeoDataFrame df of all links in the full network i : int iteration of adding breadth Returns: candidate_links : GeoDataFrame updated df with one more degree of added breadth node_list_foreign_keys : list list of foreign key ids for nodes in the updated candidate links to test if the A and B nodes are in there. ..todo:: Make unique ID for links in the settings \"\"\" WranglerLogger . debug ( \"-Adding Breadth-\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = nodes . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"Candidate Nodes: {} \" . format ( len ( candidate_nodes ))) links_shstRefId_to_add = list ( set ( sum ( candidate_nodes [ \"outboundReferenceIds\" ] . tolist (), []) + sum ( candidate_nodes [ \"inboundReferenceIds\" ] . tolist (), []) ) - set ( candidate_links [ \"shstReferenceId\" ] . tolist ()) - set ([ \"\" ]) ) ##TODO make unique ID for links in the settings # print(\"Link IDs to add: {}\".format(links_shstRefId_to_add)) # print(\"Links: \", links_id_to_add) links_to_add = links [ links . shstReferenceId . isin ( links_shstRefId_to_add )] # print(\"Adding Links:\",links_to_add) WranglerLogger . debug ( \"Adding {} links.\" . format ( links_to_add . shape [ 0 ])) links [ links . model_link_id . isin ( links_shstRefId_to_add )][ \"i\" ] = i candidate_links = candidate_links . append ( links_to_add ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) return candidate_links , node_list_foreign_keys def _shortest_path (): WranglerLogger . debug ( \"_shortest_path(): calculating shortest path from graph\" ) candidate_links . loc [:, \"weight\" ] = 1 + ( candidate_links [ \"i\" ] * RoadwayNetwork . SP_WEIGHT_FACTOR ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) candidate_nodes = self . nodes_df . loc [ node_list_foreign_keys ] WranglerLogger . debug ( \"creating network graph\" ) G = RoadwayNetwork . ox_graph ( candidate_nodes , candidate_links ) self . selections [ sel_key ][ \"graph\" ] = G self . selections [ sel_key ][ \"candidate_links\" ] = candidate_links try : WranglerLogger . debug ( \"Calculating NX shortest path from A_id: {} to B_id: {} \" . format ( A_id , B_id ) ) sp_route = nx . shortest_path ( G , A_id , B_id , weight = \"weight\" ) WranglerLogger . debug ( \"Shortest path successfully routed\" ) except nx . NetworkXNoPath : return False sp_links = candidate_links [ candidate_links [ \"A\" ] . isin ( sp_route ) & candidate_links [ \"B\" ] . isin ( sp_route ) ] self . selections [ sel_key ][ \"route\" ] = sp_route self . selections [ sel_key ][ \"links\" ] = sp_links return True if not unique_model_link_identifer_in_selection : # find the node ids for the candidate links WranglerLogger . debug ( \"Not a unique ID selection, conduct search\" ) node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( candidate_links [ fk ]) ] ) # set(list(candidate_links[\"u\"]) + list(candidate_links[\"v\"])) ) WranglerLogger . debug ( \"Foreign key list: {} \" . format ( node_list_foreign_keys )) i = 0 max_i = RoadwayNetwork . SEARCH_BREADTH while ( A_id not in node_list_foreign_keys and B_id not in node_list_foreign_keys and i <= max_i ): WranglerLogger . debug ( \"Adding breadth, no shortest path. i: {} , Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) WranglerLogger . debug ( \"calculating shortest path from graph\" ) sp_found = _shortest_path () if not sp_found : WranglerLogger . info ( \"No shortest path found with {} , trying greater breadth until SP found\" . format ( i ) ) while not sp_found and i <= RoadwayNetwork . MAX_SEARCH_BREADTH : WranglerLogger . debug ( \"Adding breadth, with shortest path iteration. i: {} Max i: {} \" . format ( i , max_i ) ) i += 1 candidate_links , node_list_foreign_keys = _add_breadth ( candidate_links , self . nodes_df , self . links_df , i ) sp_found = _shortest_path () if sp_found : # reselect from the links in the shortest path, the ones with # the desired values....ignoring name. if len ( selection [ \"link\" ]) > 1 : resel_query = ProjectCard . build_link_selection_query ( selection = selection , unique_model_link_identifiers = RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS , mode = RoadwayNetwork . MODES_TO_NETWORK_LINK_VARIABLES [ search_mode ], ignore = [ \"name\" ], ) WranglerLogger . info ( \"Reselecting features: \\n {} \" . format ( resel_query )) self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] . query ( resel_query , engine = \"python\" ) else : self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True # Return pandas.Series of links_ids return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist () else : WranglerLogger . error ( \"Couldn't find path from {} to {} \" . format ( A_id , B_id ) ) raise ValueError else : # unique identifier exists and no need to go through big search self . selections [ sel_key ][ \"selected_links\" ] = self . selections [ sel_key ][ \"candidate_links\" ] self . selections [ sel_key ][ \"selection_found\" ] = True return self . selections [ sel_key ][ \"selected_links\" ] . index . tolist ()","title":"select_roadway_features()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.selection_has_unique_link_id","text":"Parameters: Name Type Description Default selection_dictionary Dictionary representation of selection of roadway features, containing a \u201clink\u201d key. required A boolean indicating if the selection dictionary contains Type Description bool a required unique link id. Source code in network_wrangler/roadwaynetwork.py 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 @staticmethod def selection_has_unique_link_id ( selection_dict : dict ) -> bool : \"\"\" Args: selection_dictionary: Dictionary representation of selection of roadway features, containing a \"link\" key. Returns: A boolean indicating if the selection dictionary contains a required unique link id. \"\"\" selection_keys = [ k for l in selection_dict [ \"link\" ] for k , v in l . items ()] return bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) )","title":"selection_has_unique_link_id()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.selection_map","text":"Shows which links are selected for roadway property change or parallel managed lanes category of roadway projects. Parameters: Name Type Description Default selected_links_idx list of selected link indices required candidate_links_idx optional list of candidate link indices to also include in map required A Optional [ Any ] optional foreign key of starting node of a route selection None B Optional [ Any ] optional foreign key of ending node of a route selection None Source code in network_wrangler/roadwaynetwork.py 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 def selection_map ( self , selected_link_idx : list , A : Optional [ Any ] = None , B : Optional [ Any ] = None , candidate_link_idx : Optional [ List ] = [], ): \"\"\" Shows which links are selected for roadway property change or parallel managed lanes category of roadway projects. Args: selected_links_idx: list of selected link indices candidate_links_idx: optional list of candidate link indices to also include in map A: optional foreign key of starting node of a route selection B: optional foreign key of ending node of a route selection \"\"\" WranglerLogger . debug ( \"Selected Links: {} \\n Candidate Links: {} \\n \" . format ( selected_link_idx , candidate_link_idx ) ) graph_link_idx = list ( set ( selected_link_idx + candidate_link_idx )) graph_links = self . links_df . loc [ graph_link_idx ] node_list_foreign_keys = list ( set ( [ i for fk in RoadwayNetwork . LINK_FOREIGN_KEY for i in list ( graph_links [ fk ]) ] ) ) graph_nodes = self . nodes_df . loc [ node_list_foreign_keys ] G = RoadwayNetwork . ox_graph ( graph_nodes , graph_links ) # base map plot with whole graph m = ox . plot_graph_folium ( G , edge_color = None , tiles = \"cartodbpositron\" , width = \"300px\" , height = \"250px\" ) # plot selection selected_links = self . links_df . loc [ selected_link_idx ] for _ , row in selected_links . iterrows (): pl = ox . folium . _make_folium_polyline ( edge = row , edge_color = \"blue\" , edge_width = 5 , edge_opacity = 0.8 ) pl . add_to ( m ) # if have A and B node add them to base map def _folium_node ( node_row , color = \"white\" , icon = \"\" ): node_marker = folium . Marker ( location = [ node_row [ \"Y\" ], node_row [ \"X\" ]], icon = folium . Icon ( icon = icon , color = color ), ) return node_marker if A : # WranglerLogger.debug(\"A: {}\\n{}\".format(A,self.nodes_df[self.nodes_df[RoadwayNetwork.NODE_FOREIGN_KEY] == A])) _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == A ], color = \"green\" , icon = \"play\" , ) . add_to ( m ) if B : _folium_node ( self . nodes_df [ self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] == B ], color = \"red\" , icon = \"star\" , ) . add_to ( m ) return m","title":"selection_map()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_link_schema","text":"Validate roadway network data link schema and output a boolean Source code in network_wrangler/roadwaynetwork.py 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 @staticmethod def validate_link_schema ( link_file , schema_location : str = \"roadway_network_link.json\" ): \"\"\" Validate roadway network data link schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( link_file ) as link_json_file : json_data = json . load ( link_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Link schema validation: Validation Error\" ) WranglerLogger . error ( \"Link File Loc: {} \" . format ( link_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Link Schema\" ) WranglerLogger . error ( \"Link Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False","title":"validate_link_schema()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_node_schema","text":"Validate roadway network data node schema and output a boolean Source code in network_wrangler/roadwaynetwork.py 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 @staticmethod def validate_node_schema ( node_file , schema_location : str = \"roadway_network_node.json\" ): \"\"\" Validate roadway network data node schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( node_file ) as node_json_file : json_data = json . load ( node_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Node schema validation: Validation Error\" ) WranglerLogger . error ( \"Node File Loc: {} \" . format ( node_file )) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Node Schema\" ) WranglerLogger . error ( \"Node Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False","title":"validate_node_schema()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_object_types","text":"Determines if the roadway network is being built with the right object types. Does not validate schemas. Parameters: Name Type Description Default nodes GeoDataFrame nodes geodataframe required links GeoDataFrame link geodataframe required shapes GeoDataFrame shape geodataframe required Source code in network_wrangler/roadwaynetwork.py 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 @staticmethod def validate_object_types ( nodes : GeoDataFrame , links : GeoDataFrame , shapes : GeoDataFrame ): \"\"\" Determines if the roadway network is being built with the right object types. Does not validate schemas. Args: nodes: nodes geodataframe links: link geodataframe shapes: shape geodataframe Returns: boolean \"\"\" errors = \"\" if not isinstance ( nodes , GeoDataFrame ): error_message = \"Incompatible nodes type: {} . Must provide a GeoDataFrame. \" . format ( type ( nodes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( links , GeoDataFrame ): error_message = \"Incompatible links type: {} . Must provide a GeoDataFrame. \" . format ( type ( links ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if not isinstance ( shapes , GeoDataFrame ): error_message = \"Incompatible shapes type: {} . Must provide a GeoDataFrame. \" . format ( type ( shapes ) ) WranglerLogger . error ( error_message ) errors . append ( error_message ) if errors : return False return True","title":"validate_object_types()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_properties","text":"If there are change or existing commands, make sure that that property exists in the network. Parameters: Name Type Description Default properties properties dictionary to be evaluated required ignore_existing bool If True, will only warn about properties that specify an \u201cexisting\u201d value. If False, will fail. False require_existing_for_change bool If True, will fail if there isn\u2019t a specified value in theproject card for existing when a change is specified. False Source code in network_wrangler/roadwaynetwork.py 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 def validate_properties ( self , properties : dict , ignore_existing : bool = False , require_existing_for_change : bool = False , ) -> bool : \"\"\" If there are change or existing commands, make sure that that property exists in the network. Args: properties : properties dictionary to be evaluated ignore_existing: If True, will only warn about properties that specify an \"existing\" value. If False, will fail. require_existing_for_change: If True, will fail if there isn't a specified value in theproject card for existing when a change is specified. Returns: boolean value as to whether the properties dictonary is valid. \"\"\" validation_error_message = [] for p in properties : if p [ \"property\" ] not in self . links_df . columns : if p . get ( \"change\" ): validation_error_message . append ( '\"Change\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"existing\" ) and not ignore_existing : validation_error_message . append ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) elif p . get ( \"existing\" ): WranglerLogger . warning ( '\"Existing\" is specified for attribute {} , but doesn \\' t exist in base network \\n ' . format ( p [ \"property\" ] ) ) if p . get ( \"change\" ) and not p . get ( \"existing\" ): if require_existing_for_change : validation_error_message . append ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n To proceed, run with the setting require_existing_for_change=False' . format ( p [ \"property\" ] ) ) else : WranglerLogger . warning ( '\"Change\" is specified for attribute {} , but there isn \\' t a value for existing. \\n ' . format ( p [ \"property\" ] ) ) if validation_error_message : WranglerLogger . error ( \" \" . join ( validation_error_message )) raise ValueError ()","title":"validate_properties()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_selection","text":"Evaluate whetther the selection dictionary contains the minimum required values. Parameters: Name Type Description Default selection dict selection dictionary to be evaluated required Source code in network_wrangler/roadwaynetwork.py 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 def validate_selection ( self , selection : dict ) -> Bool : \"\"\" Evaluate whetther the selection dictionary contains the minimum required values. Args: selection: selection dictionary to be evaluated Returns: boolean value as to whether the selection dictonary is valid. \"\"\" if not set ( RoadwayNetwork . SELECTION_REQUIRES ) . issubset ( selection ): err_msg = \"Project Card Selection requires: {} \" . format ( \",\" . join ( RoadwayNetwork . SELECTION_REQUIRES ) ) err_msg += \", but selection only contains: {} \" . format ( \",\" . join ( selection )) WranglerLogger . error ( err_msg ) raise KeyError ( err_msg ) err = [] for l in selection [ \"link\" ]: for k , v in l . items (): if k not in self . links_df . columns : err . append ( \" {} specified in link selection but not an attribute in network \\n \" . format ( k ) ) selection_keys = [ k for l in selection [ \"link\" ] for k , v in l . items ()] unique_link_id = bool ( set ( RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS ) . intersection ( set ( selection_keys ) ) ) if not unique_link_id : for k , v in selection [ \"A\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in A node selection but not an attribute in network \\n \" . format ( k ) ) for k , v in selection [ \"B\" ] . items (): if ( k not in self . nodes_df . columns and k != RoadwayNetwork . NODE_FOREIGN_KEY ): err . append ( \" {} specified in B node selection but not an attribute in network \\n \" . format ( k ) ) if err : WranglerLogger . error ( \"ERROR: Selection variables in project card not found in network\" ) WranglerLogger . error ( \" \\n \" . join ( err )) WranglerLogger . error ( \"--existing node columns: {} \" . format ( \" \" . join ( self . nodes_df . columns )) ) WranglerLogger . error ( \"--existing link columns: {} \" . format ( \" \" . join ( self . links_df . columns )) ) raise ValueError () return False else : return True","title":"validate_selection()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_shape_schema","text":"Validate roadway network data shape schema and output a boolean Source code in network_wrangler/roadwaynetwork.py 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 @staticmethod def validate_shape_schema ( shape_file , schema_location : str = \"roadway_network_shape.json\" ): \"\"\" Validate roadway network data shape schema and output a boolean \"\"\" if not os . path . exists ( schema_location ): base_path = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ )), \"schemas\" ) schema_location = os . path . join ( base_path , schema_location ) with open ( schema_location ) as schema_json_file : schema = json . load ( schema_json_file ) with open ( shape_file ) as shape_json_file : json_data = json . load ( shape_json_file ) try : validate ( json_data , schema ) return True except ValidationError as exc : WranglerLogger . error ( \"Failed Shape schema validation: Validation Error\" ) WranglerLogger . error ( \"Shape File Loc: {} \" . format ( shape_file )) WranglerLogger . error ( \"Path: {} \" . format ( exc . path )) WranglerLogger . error ( exc . message ) except SchemaError as exc : WranglerLogger . error ( \"Invalid Shape Schema\" ) WranglerLogger . error ( \"Shape Schema Loc: {} \" . format ( schema_location )) WranglerLogger . error ( json . dumps ( exc . message , indent = 2 )) return False","title":"validate_shape_schema()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.validate_uniqueness","text":"Confirms that the unique identifiers are met. Source code in network_wrangler/roadwaynetwork.py 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 def validate_uniqueness ( self ) -> Bool : \"\"\" Confirms that the unique identifiers are met. \"\"\" valid = True for c in RoadwayNetwork . UNIQUE_MODEL_LINK_IDENTIFIERS : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain unique link identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . links_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network links\" . format ( c ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . LINK_FOREIGN_KEY : if c not in self . links_df . columns : valid = False msg = \"Network doesn't contain link foreign key identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) link_foreign_key = self . links_df [ RoadwayNetwork . LINK_FOREIGN_KEY ] . apply ( lambda x : \"-\" . join ( x . map ( str )), axis = 1 ) if not link_foreign_key . is_unique : valid = False msg = \"Foreign key: {} is not unique in network links\" . format ( RoadwayNetwork . LINK_FOREIGN_KEY ) WranglerLogger . error ( msg ) for c in RoadwayNetwork . UNIQUE_NODE_IDENTIFIERS : if c not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain unique node identifier: {} \" . format ( c ) WranglerLogger . error ( msg ) if not self . nodes_df [ c ] . is_unique : valid = False msg = \"Unique identifier {} is not unique in network nodes\" . format ( c ) WranglerLogger . error ( msg ) if RoadwayNetwork . NODE_FOREIGN_KEY not in self . nodes_df . columns : valid = False msg = \"Network doesn't contain node foreign key identifier: {} \" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) elif not self . nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . is_unique : valid = False msg = \"Foreign key: {} is not unique in network nodes\" . format ( RoadwayNetwork . NODE_FOREIGN_KEY ) WranglerLogger . error ( msg ) if RoadwayNetwork . UNIQUE_SHAPE_KEY not in self . shapes_df . columns : valid = False msg = \"Network doesn't contain unique shape id: {} \" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) elif not self . shapes_df [ RoadwayNetwork . UNIQUE_SHAPE_KEY ] . is_unique : valid = False msg = \"Unique key: {} is not unique in network shapes\" . format ( RoadwayNetwork . UNIQUE_SHAPE_KEY ) WranglerLogger . error ( msg ) return valid","title":"validate_uniqueness()"},{"location":"api/#network_wrangler.roadwaynetwork.RoadwayNetwork.write","text":"Writes a network in the roadway network standard Parameters: Name Type Description Default path str the path were the output will be saved '.' filename str the name prefix of the roadway files that will be generated None Source code in network_wrangler/roadwaynetwork.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the roadway network standard args: path: the path were the output will be saved filename: the name prefix of the roadway files that will be generated \"\"\" if not os . path . exists ( path ): WranglerLogger . debug ( \" \\n Path [ %s ] doesn't exist; creating.\" % path ) os . mkdir ( path ) if filename : links_file = os . path . join ( path , filename + \"_\" + \"link.json\" ) nodes_file = os . path . join ( path , filename + \"_\" + \"node.geojson\" ) shapes_file = os . path . join ( path , filename + \"_\" + \"shape.geojson\" ) else : links_file = os . path . join ( path , \"link.json\" ) nodes_file = os . path . join ( path , \"node.geojson\" ) shapes_file = os . path . join ( path , \"shape.geojson\" ) link_property_columns = self . links_df . columns . values . tolist () link_property_columns . remove ( \"geometry\" ) links_json = link_df_to_json ( self . links_df , link_property_columns ) with open ( links_file , \"w\" ) as f : json . dump ( links_json , f ) # geopandas wont let you write to geojson because # it uses fiona, which doesn't accept a list as one of the properties # so need to convert the df to geojson manually first property_columns = self . nodes_df . columns . values . tolist () property_columns . remove ( \"geometry\" ) nodes_geojson = point_df_to_geojson ( self . nodes_df , property_columns ) with open ( nodes_file , \"w\" ) as f : json . dump ( nodes_geojson , f ) self . shapes_df . to_file ( shapes_file , driver = \"GeoJSON\" )","title":"write()"},{"location":"api/#network_wrangler.TransitNetwork","text":"Bases: object Representation of a Transit Network. Typical usage example: import network_wrangler as wr stpaul = r '/home/jovyan/work/example/stpaul' tc = wr . TransitNetwork . read ( path = stpaul ) Attributes: Name Type Description feed DotDict Partridge feed mapping dataframes. config nx . DiGraph Partridge config road_net RoadwayNetwork Associated roadway network object. graph nx . MultiDiGraph Graph for associated roadway network object. feed_path str Where the feed was read in from. validated_frequencies bool The frequencies have been validated. validated_road_network_consistency The network has been validated against the road network. SHAPES_FOREIGN_KEY str foreign key between shapes dataframe and roadway network nodes STOPS_FOREIGN_KEY str foreign key between stops dataframe and roadway network nodes ID_SCALAR int scalar value added to create new IDs when necessary. REQUIRED_FILES list [ str ] list of files that the transit network requires. .. todo:: investigate consolidating scalars this with RoadwayNetwork consolidate thes foreign key constants into one if possible Source code in network_wrangler/transitnetwork.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 class TransitNetwork ( object ): \"\"\" Representation of a Transit Network. Typical usage example: ``` py import network_wrangler as wr stpaul = r'/home/jovyan/work/example/stpaul' tc=wr.TransitNetwork.read(path=stpaul) ``` Attributes: feed (DotDict): Partridge feed mapping dataframes. config (nx.DiGraph): Partridge config road_net (RoadwayNetwork): Associated roadway network object. graph (nx.MultiDiGraph): Graph for associated roadway network object. feed_path (str): Where the feed was read in from. validated_frequencies (bool): The frequencies have been validated. validated_road_network_consistency (): The network has been validated against the road network. SHAPES_FOREIGN_KEY (str): foreign key between shapes dataframe and roadway network nodes STOPS_FOREIGN_KEY (str): foreign key between stops dataframe and roadway network nodes ID_SCALAR (int): scalar value added to create new IDs when necessary. REQUIRED_FILES (list[str]): list of files that the transit network requires. .. todo:: investigate consolidating scalars this with RoadwayNetwork consolidate thes foreign key constants into one if possible \"\"\" # PK = primary key, FK = foreign key SHAPES_FOREIGN_KEY = \"shape_model_node_id\" STOPS_FOREIGN_KEY = \"model_node_id\" ##TODO consolidate these two ^^^ constants if possible ID_SCALAR = 100000000 ##TODO investigate consolidating this with RoadwayNetwork REQUIRED_FILES = [ \"agency.txt\" , \"frequencies.txt\" , \"routes.txt\" , \"shapes.txt\" , \"stop_times.txt\" , \"stops.txt\" , \"trips.txt\" , ] def __init__ ( self , feed : DotDict = None , config : nx . DiGraph = None ): \"\"\" Constructor .. todo:: Make graph a reference to associated RoadwayNetwork's graph, not its own thing. \"\"\" self . feed : DotDict = feed self . config : nx . DiGraph = config self . road_net : RoadwayNetwork = None self . graph : nx . MultiDiGraph = None self . feed_path = None self . validated_frequencies = False self . validated_road_network_consistency = False if not self . validate_frequencies (): raise ValueError ( \"Transit lines with non-positive frequencies exist in the network\" ) @staticmethod def empty () -> TransitNetwork : \"\"\" Create an empty transit network instance using the default config. .. todo:: fill out this method \"\"\" ##TODO msg = \"TransitNetwork.empty is not implemented.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg ) @staticmethod def read ( feed_path : str ) -> TransitNetwork : \"\"\" Read GTFS feed from folder and TransitNetwork object Args: feed_path: where to read transit network files from Returns: a TransitNetwork object. \"\"\" config = default_config () feed = ptg . load_feed ( feed_path , config = config ) WranglerLogger . info ( \"Read in transit feed from: {} \" . format ( feed_path )) updated_config = TransitNetwork . validate_feed ( feed , config ) # Read in each feed so we can write over them editable_feed = DotDict () for node in updated_config . nodes . keys (): # Load (initiate Partridge's lazy load) editable_feed [ node . replace ( \".txt\" , \"\" )] = feed . get ( node ) transit_network = TransitNetwork ( feed = editable_feed , config = updated_config ) transit_network . feed_path = feed_path return transit_network @staticmethod def validate_feed ( feed : DotDict , config : nx . DiGraph ) -> bool : \"\"\" Since Partridge lazily loads the df, load each file to make sure it actually works. Partridge uses a DiGraph from the networkx library to represent the relationships between GTFS files. Each file is a 'node', and the relationship between files are 'edges'. Args: feed: partridge feed config: partridge config \"\"\" updated_config = copy . deepcopy ( config ) files_not_found = [] for node in config . nodes . keys (): n = feed . get ( node ) WranglerLogger . debug ( \"... {} : \\n {} \" . format ( node , n [: 10 ])) if n . shape [ 0 ] == 0 : WranglerLogger . info ( \"Removing {} from transit network config because file not found\" . format ( node ) ) updated_config . remove_node ( node ) if node in TransitNetwork . REQUIRED_FILES : files_not_found . append ( node ) if files_not_found : msg = \"Required files not found or valid: {} \" . format ( \",\" . join ( files_not_found ) ) WranglerLogger . error ( msg ) raise AttributeError ( msg ) return False TransitNetwork . validate_network_keys ( feed ) return updated_config def validate_frequencies ( self ) -> bool : \"\"\" Validates that there are no transit trips in the feed with zero frequencies. Changes state of self.validated_frequencies boolean based on outcome. Returns: boolean indicating if valid or not. \"\"\" _valid = True zero_freq = self . feed . frequencies [ self . feed . frequencies . headway_secs <= 0 ] if len ( zero_freq . index ) > 0 : _valid = False msg = \"Transit lines {} have non-positive frequencies\" . format ( zero_freq . trip_id . to_list () ) WranglerLogger . error ( msg ) self . validated_frequencies = True return _valid def validate_road_network_consistencies ( self ) -> bool : \"\"\" Validates transit network against the road network for both stops and shapes. Returns: boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) valid = True valid_stops = self . validate_transit_stops () valid_shapes = self . validate_transit_shapes () self . validated_road_network_consistency = True if not valid_stops or not valid_shapes : valid = False raise ValueError ( \"Transit network is not consistent with road network.\" ) return valid def validate_transit_stops ( self ) -> bool : \"\"\" Validates that all transit stops are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) stops = self . feed . stops nodes = self . road_net . nodes_df valid = True stop_ids = [ int ( s ) for s in stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . to_list ()] node_ids = [ int ( n ) for n in nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( stop_ids ) . issubset ( node_ids ): valid = False missing_stops = list ( set ( stop_ids ) - set ( node_ids )) msg = \"Not all transit stops are part of the roadyway network. \" msg += \"Missing stops ( {} ) from the roadway nodes are {} .\" . format ( TransitNetwork . STOPS_FOREIGN_KEY , missing_stops ) WranglerLogger . error ( msg ) return valid def validate_transit_shapes ( self ) -> bool : \"\"\" Validates that all transit shapes are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) shapes_df = self . feed . shapes nodes_df = self . road_net . nodes_df links_df = self . road_net . links_df valid = True # check if all the node ids exist in the network shape_ids = [ int ( s ) for s in shapes_df [ TransitNetwork . SHAPES_FOREIGN_KEY ] . to_list () ] node_ids = [ int ( n ) for n in nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( shape_ids ) . issubset ( node_ids ): valid = False missing_shapes = list ( set ( shape_ids ) - set ( node_ids )) msg = \"Not all transit shapes are part of the roadyway network. \" msg += \"Missing shapes ( {} ) from the roadway network are {} .\" . format ( TransitNetwork . SHAPES_FOREIGN_KEY , missing_shapes ) WranglerLogger . error ( msg ) return valid # check if all the links in transit shapes exist in the network # and transit is allowed shapes_df = shapes_df . astype ({ TransitNetwork . SHAPES_FOREIGN_KEY : int }) unique_shape_ids = shapes_df . shape_id . unique () . tolist () for id in unique_shape_ids : subset_shapes_df = shapes_df [ shapes_df [ \"shape_id\" ] == id ] subset_shapes_df = subset_shapes_df . sort_values ( by = [ \"shape_pt_sequence\" ]) subset_shapes_df = subset_shapes_df . add_suffix ( \"_1\" ) . join ( subset_shapes_df . shift ( - 1 ) . add_suffix ( \"_2\" ) ) subset_shapes_df = subset_shapes_df . dropna () merged_df = subset_shapes_df . merge ( links_df , how = \"left\" , left_on = [ TransitNetwork . SHAPES_FOREIGN_KEY + \"_1\" , TransitNetwork . SHAPES_FOREIGN_KEY + \"_2\" , ], right_on = [ \"A\" , \"B\" ], indicator = True , ) missing_links_df = merged_df . query ( '_merge == \"left_only\"' ) # there are shape links which does not exist in the roadway network if len ( missing_links_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which are missing in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) transit_not_allowed_df = merged_df . query ( '_merge == \"both\" & drive_access == 0 & bus_only == 0 & rail_only == 0' ) # there are shape links where transit is not allowed if len ( transit_not_allowed_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which does not allow transit in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) return valid @staticmethod def route_ids_in_routestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever route_id occurs, make sure it is in routes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" route_ids_routestxt = set ( feed . routes . route_id . tolist ()) route_ids_referenced = set ( feed . trips . route_id . tolist ()) missing_routes = route_ids_referenced - route_ids_routestxt if missing_routes : WranglerLogger . warning ( \"The following route_ids are referenced but missing from routes.txt: {} \" . format ( list ( missing_routes ) ) ) return False return True @staticmethod def trip_ids_in_tripstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever trip_id occurs, make sure it is in trips.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" trip_ids_tripstxt = set ( feed . trips . trip_id . tolist ()) trip_ids_referenced = set ( feed . stop_times . trip_id . tolist () + feed . frequencies . trip_id . tolist () ) missing_trips = trip_ids_referenced - trip_ids_tripstxt if missing_trips : WranglerLogger . warning ( \"The following trip_ids are referenced but missing from trips.txt: {} \" . format ( list ( missing_trips ) ) ) return False return True @staticmethod def shape_ids_in_shapestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever shape_id occurs, make sure it is in shapes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" shape_ids_shapestxt = set ( feed . shapes . shape_id . tolist ()) shape_ids_referenced = set ( feed . trips . shape_id . tolist ()) missing_shapes = shape_ids_referenced - shape_ids_shapestxt if missing_shapes : WranglerLogger . warning ( \"The following shape_ids from trips.txt are missing from shapes.txt: {} \" . format ( list ( missing_shapes ) ) ) return False return True @staticmethod def stop_ids_in_stopstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever stop_id occurs, make sure it is in stops.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" stop_ids_stopstxt = set ( feed . stops . stop_id . tolist ()) stop_ids_referenced = [] # STOP_TIMES stop_ids_referenced . extend ( feed . stop_times . stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . stops . parent_station . dropna () . tolist ()) # TRANSFERS if feed . get ( \"transfers.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . transfers . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . transfers . to_stop_id . dropna () . tolist ()) # PATHWAYS if feed . get ( \"pathways.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . pathways . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . pathways . to_stop_id . dropna () . tolist ()) stop_ids_referenced = set ( stop_ids_referenced ) missing_stops = stop_ids_referenced - stop_ids_stopstxt if missing_stops : WranglerLogger . warning ( \"The following stop_ids from are referenced but missing from stops.txt: {} \" . format ( list ( missing_stops ) ) ) return False return True @staticmethod def validate_network_keys ( feed : DotDict ) -> Bool : \"\"\" Validates foreign keys are present in all connecting feed files. Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" result = True result = result and TransitNetwork . route_ids_in_routestxt ( feed ) result = result and TransitNetwork . trip_ids_in_tripstxt ( feed ) result = result and TransitNetwork . shape_ids_in_shapestxt ( feed ) result = result and TransitNetwork . stop_ids_in_stopstxt ( feed ) return result def set_roadnet ( self , road_net : RoadwayNetwork , graph_shapes : bool = False , graph_stops : bool = False , validate_consistency : bool = True , ) -> None : self . road_net : RoadwayNetwork = road_net self . graph : nx . MultiDiGraph = RoadwayNetwork . ox_graph ( road_net . nodes_df , road_net . links_df ) if graph_shapes : self . _graph_shapes () if graph_stops : self . _graph_stops () if validate_consistency : self . validate_road_network_consistencies () def _graph_shapes ( self ) -> None : \"\"\" .. todo:: Fill out this method. \"\"\" existing_shapes = self . feed . shapes msg = \"_graph_shapes() not implemented yet.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg ) # graphed_shapes = pd.DataFrame() # for shape_id in shapes: # TODO traverse point by point, mapping shortest path on graph, # then append to a list # return total list of all link ids # rebuild rows in shapes dataframe and add to graphed_shapes # make graphed_shapes a GeoDataFrame # self.feed.shapes = graphed_shapes def _graph_stops ( self ) -> None : \"\"\" .. todo:: Fill out this method. \"\"\" existing_stops = self . feed . stops msg = \"_graph_stops() not implemented yet.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg ) # graphed_stops = pd.DataFrame() # for stop_id in stops: # TODO # self.feed.stops = graphed_stops def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the transit network standard Args: path: the path were the output will be saved filename: the name prefix of the transit files that will be generated \"\"\" WranglerLogger . info ( \"Writing transit to directory: {} \" . format ( path )) for node in self . config . nodes . keys (): df = self . feed . get ( node . replace ( \".txt\" , \"\" )) if not df . empty : if filename : outpath = os . path . join ( path , filename + \"_\" + node ) else : outpath = os . path . join ( path , node ) WranglerLogger . debug ( \"Writing file: {} \" . format ( outpath )) df . to_csv ( outpath , index = False ) @staticmethod def transit_net_to_gdf ( transit : Union ( TransitNetwork , pd . DataFrame )): \"\"\" Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame. Args: transit: either a TransitNetwork or a Shapes GeoDataFrame .. todo:: Make more sophisticated. \"\"\" from partridge import geo if type ( transit ) is pd . DataFrame : shapes = transit else : shapes = transit . feed . shapes transit_gdf = geo . build_shapes ( shapes ) return transit_gdf def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a transit network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Transit Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if ( project_dictionary [ \"category\" ] . lower () == \"transit service property change\" ): self . apply_transit_feature_change ( self . select_transit_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : # Grab the list of nodes in the facility from road_net # It should be cached because managed lane projects are # processed by RoadwayNetwork first via # Scenario.apply_all_projects try : managed_lane_nodes = self . road_net . selections ( self . road_net . build_selection_key ( project_dictionary [ \"facility\" ] ) )[ \"route\" ] except ValueError : WranglerLogger . error ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) # Reroute any transit using these nodes self . apply_transit_managed_lane ( self . select_transit_features_by_nodes ( managed_lane_nodes ), managed_lane_nodes , ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : WranglerLogger . warning ( \"Roadway Deletion not yet implemented in Transit; ignoring\" ) else : msg = \" {} not implemented yet in TransitNetwork; can't apply.\" . format ( project_dictionary [ \"category\" ] ) WranglerLogger . error ( msg ) raise ( msg ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary ) def select_transit_features ( self , selection : dict ) -> pd . Series : \"\"\" Selects transit features that satisfy selection criteria Args: selection : selection dictionary Returns: trip identifiers : list of GTFS trip IDs in the selection \"\"\" trips = self . feed . trips routes = self . feed . routes freq = self . feed . frequencies # Turn selection's values into lists if they are not already for key in selection . keys (): if type ( selection [ key ]) not in [ list , tuple ]: selection [ key ] = [ selection [ key ]] # Based on the key in selection, filter trips if \"trip_id\" in selection : trips = trips [ trips . trip_id . isin ( selection [ \"trip_id\" ])] elif \"route_id\" in selection : trips = trips [ trips . route_id . isin ( selection [ \"route_id\" ])] elif \"route_short_name\" in selection : routes = routes [ routes . route_short_name . isin ( selection [ \"route_short_name\" ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] elif \"route_long_name\" in selection : matches = [] for sel in selection [ \"route_long_name\" ]: for route_long_name in routes [ \"route_long_name\" ]: x = re . search ( sel , route_long_name ) if x is not None : matches . append ( route_long_name ) routes = routes [ routes . route_long_name . isin ( matches )] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , selection . keys ()) raise ValueError # If a time key exists, filter trips using frequency table if selection . get ( \"time\" ): selection [ \"time\" ] = parse_time_spans ( selection [ \"time\" ]) elif selection . get ( \"start_time\" ) and selection . get ( \"end_time\" ): selection [ \"time\" ] = parse_time_spans ( [ selection [ \"start_time\" ], selection [ \"end_time\" ]] ) # Filter freq to trips in selection freq = freq [ freq . trip_id . isin ( trips [ \"trip_id\" ])] freq = freq [ freq . start_time == selection [ \"time\" ][ 0 ]] freq = freq [ freq . end_time == selection [ \"time\" ][ 1 ]] # Filter trips table to those still in freq table trips = trips [ trips . trip_id . isin ( freq [ \"trip_id\" ])] # If any other key exists, filter routes or trips accordingly for key in selection . keys (): if key not in [ \"trip_id\" , \"route_id\" , \"route_short_name\" , \"route_long_name\" , \"time\" , ]: if key in trips : trips = trips [ trips [ key ] . isin ( selection [ key ])] elif key in routes : routes = routes [ routes [ key ] . isin ( selection [ key ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , key ) raise ValueError # Check that there is at least one trip in trips table or raise error if len ( trips ) < 1 : WranglerLogger . error ( \"Selection returned zero trips\" ) raise ValueError # Return pandas.Series of trip_ids return trips [ \"trip_id\" ] def select_transit_features_by_nodes ( self , node_ids : list , require_all : bool = False ) -> pd . Series : \"\"\" Selects transit features that use any one of a list of node_ids Args: node_ids: list (generally coming from nx.shortest_path) require_all : bool if True, the returned trip_ids must traverse all of the nodes (default = False) Returns: trip identifiers list of GTFS trip IDs in the selection \"\"\" # If require_all, the returned trip_ids must traverse all of the nodes # Else, filter any shapes that use any one of the nodes in node_ids if require_all : shape_ids = ( self . feed . shapes . groupby ( \"shape_id\" ) . filter ( lambda x : all ( i in x [ TransitNetwork . SHAPES_FOREIGN_KEY ] . tolist () for i in node_ids ) ) ) . shape_id . drop_duplicates () else : shape_ids = self . feed . shapes [ self . feed . shapes [ TransitNetwork . SHAPES_FOREIGN_KEY ] . isin ( node_ids ) ] . shape_id . drop_duplicates () # Return pandas.Series of trip_ids return self . feed . trips [ self . feed . trips . shape_id . isin ( shape_ids )] . trip_id def apply_transit_feature_change ( self , trip_ids : pd . Series , properties : list , in_place : bool = True ) -> Union ( None , TransitNetwork ): \"\"\" Changes the transit attributes for the selected features based on the project card information passed Args: trip_ids : pd.Series all trip_ids to apply change to properties : list of dictionaries transit properties to change in_place : bool whether to apply changes in place or return a new network Returns: None \"\"\" for i in properties : if i [ \"property\" ] in [ \"headway_secs\" ]: self . _apply_transit_feature_change_frequencies ( trip_ids , i , in_place ) elif i [ \"property\" ] in [ \"routing\" ]: self . _apply_transit_feature_change_routing ( trip_ids , i , in_place ) def _apply_transit_feature_change_routing ( self , trip_ids : pd . Series , properties : dict , in_place : bool = True ) -> Union ( None , TransitNetwork ): shapes = self . feed . shapes . copy () stop_times = self . feed . stop_times . copy () stops = self . feed . stops . copy () # A negative sign in \"set\" indicates a traversed node without a stop # If any positive numbers, stops have changed stops_change = False if any ( x > 0 for x in properties [ \"set\" ]): # Simplify \"set\" and \"existing\" to only stops properties [ \"set_stops\" ] = [ str ( i ) for i in properties [ \"set\" ] if i > 0 ] if properties . get ( \"existing\" ) is not None : properties [ \"existing_stops\" ] = [ str ( i ) for i in properties [ \"existing\" ] if i > 0 ] stops_change = True # Convert ints to objects properties [ \"set_shapes\" ] = [ str ( abs ( i )) for i in properties [ \"set\" ]] if properties . get ( \"existing\" ) is not None : properties [ \"existing_shapes\" ] = [ str ( abs ( i )) for i in properties [ \"existing\" ] ] # Replace shapes records trips = self . feed . trips # create pointer rather than a copy shape_ids = trips [ trips [ \"trip_id\" ] . isin ( trip_ids )] . shape_id for shape_id in shape_ids : # Check if `shape_id` is used by trips that are not in # parameter `trip_ids` trips_using_shape_id = trips . loc [ trips [ \"shape_id\" ] == shape_id , [ \"trip_id\" ]] if not all ( trips_using_shape_id . isin ( trip_ids )[ \"trip_id\" ]): # In this case, we need to create a new shape_id so as to leave # the trips not part of the query alone WranglerLogger . warning ( \"Trips that were not in your query selection use the \" \"same `shape_id` as trips that are in your query. Only \" \"the trips' shape in your query will be changed.\" ) old_shape_id = shape_id shape_id = str ( int ( shape_id ) + TransitNetwork . ID_SCALAR ) if shape_id in shapes [ \"shape_id\" ] . tolist (): WranglerLogger . error ( \"Cannot create a unique new shape_id.\" ) dup_shape = shapes [ shapes . shape_id == old_shape_id ] . copy () dup_shape [ \"shape_id\" ] = shape_id shapes = pd . concat ([ shapes , dup_shape ], ignore_index = True ) # Pop the rows that match shape_id this_shape = shapes [ shapes . shape_id == shape_id ] # Make sure they are ordered by shape_pt_sequence this_shape = this_shape . sort_values ( by = [ \"shape_pt_sequence\" ]) # Build a pd.DataFrame of new shape records new_shape_rows = pd . DataFrame ( { \"shape_id\" : shape_id , \"shape_pt_lat\" : None , # FIXME Populate from self.road_net? \"shape_pt_lon\" : None , # FIXME \"shape_osm_node_id\" : None , # FIXME \"shape_pt_sequence\" : None , TransitNetwork . SHAPES_FOREIGN_KEY : properties [ \"set_shapes\" ], } ) # If \"existing\" is specified, replace only that segment # Else, replace the whole thing if properties . get ( \"existing\" ) is not None : # Match list nodes = this_shape [ TransitNetwork . SHAPES_FOREIGN_KEY ] . tolist () index_replacement_starts = nodes . index ( properties [ \"existing_shapes\" ][ 0 ]) index_replacement_ends = nodes . index ( properties [ \"existing_shapes\" ][ - 1 ]) this_shape = pd . concat ( [ this_shape . iloc [: index_replacement_starts ], new_shape_rows , this_shape . iloc [ index_replacement_ends + 1 :], ], ignore_index = True , sort = False , ) else : this_shape = new_shape_rows # Renumber shape_pt_sequence this_shape [ \"shape_pt_sequence\" ] = np . arange ( len ( this_shape )) # Add rows back into shapes shapes = pd . concat ( [ shapes [ shapes . shape_id != shape_id ], this_shape ], ignore_index = True , sort = False , ) # Replace stop_times and stops records (if required) if stops_change : # If node IDs in properties[\"set_stops\"] are not already # in stops.txt, create a new stop_id for them in stops existing_fk_ids = set ( stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . tolist ()) nodes_df = self . road_net . nodes_df . loc [ :, [ TransitNetwork . STOPS_FOREIGN_KEY , \"X\" , \"Y\" ] ] for fk_i in properties [ \"set_stops\" ]: if fk_i not in existing_fk_ids : WranglerLogger . info ( \"Creating a new stop in stops.txt for node ID: {} \" . format ( fk_i ) ) # Add new row to stops new_stop_id = str ( int ( fk_i ) + TransitNetwork . ID_SCALAR ) if stop_id in stops [ \"stop_id\" ] . tolist (): WranglerLogger . error ( \"Cannot create a unique new stop_id.\" ) stops . loc [ len ( stops . index ) + 1 , [ \"stop_id\" , \"stop_lat\" , \"stop_lon\" , TransitNetwork . STOPS_FOREIGN_KEY , ], ] = [ new_stop_id , nodes_df . loc [ int ( fk_i ), \"Y\" ], nodes_df . loc [ int ( fk_i ), \"X\" ], fk_i , ] # Loop through all the trip_ids for trip_id in trip_ids : # Pop the rows that match trip_id this_stoptime = stop_times [ stop_times . trip_id == trip_id ] # Merge on node IDs using stop_id (one node ID per stop_id) this_stoptime = this_stoptime . merge ( stops [[ \"stop_id\" , TransitNetwork . STOPS_FOREIGN_KEY ]], how = \"left\" , on = \"stop_id\" , ) # Make sure the stop_times are ordered by stop_sequence this_stoptime = this_stoptime . sort_values ( by = [ \"stop_sequence\" ]) # Build a pd.DataFrame of new shape records from properties new_stoptime_rows = pd . DataFrame ( { \"trip_id\" : trip_id , \"arrival_time\" : None , \"departure_time\" : None , \"pickup_type\" : None , \"drop_off_type\" : None , \"stop_distance\" : None , \"timepoint\" : None , \"stop_is_skipped\" : None , TransitNetwork . STOPS_FOREIGN_KEY : properties [ \"set_stops\" ], } ) # Merge on stop_id using node IDs (many stop_id per node ID) new_stoptime_rows = ( new_stoptime_rows . merge ( stops [[ \"stop_id\" , TransitNetwork . STOPS_FOREIGN_KEY ]], how = \"left\" , on = TransitNetwork . STOPS_FOREIGN_KEY , ) . groupby ([ TransitNetwork . STOPS_FOREIGN_KEY ]) . head ( 1 ) ) # pick first # If \"existing\" is specified, replace only that segment # Else, replace the whole thing if properties . get ( \"existing\" ) is not None : # Match list (remember stops are passed in with node IDs) nodes = this_stoptime [ TransitNetwork . STOPS_FOREIGN_KEY ] . tolist () index_replacement_starts = nodes . index ( properties [ \"existing_stops\" ][ 0 ] ) index_replacement_ends = nodes . index ( properties [ \"existing_stops\" ][ - 1 ] ) this_stoptime = pd . concat ( [ this_stoptime . iloc [: index_replacement_starts ], new_stoptime_rows , this_stoptime . iloc [ index_replacement_ends + 1 :], ], ignore_index = True , sort = False , ) else : this_stoptime = new_stoptime_rows # Remove node ID del this_stoptime [ TransitNetwork . STOPS_FOREIGN_KEY ] # Renumber stop_sequence this_stoptime [ \"stop_sequence\" ] = np . arange ( len ( this_stoptime )) # Add rows back into stoptime stop_times = pd . concat ( [ stop_times [ stop_times . trip_id != trip_id ], this_stoptime ], ignore_index = True , sort = False , ) # Replace self if in_place, else return if in_place : self . feed . shapes = shapes self . feed . stops = stops self . feed . stop_times = stop_times else : updated_network = copy . deepcopy ( self ) updated_network . feed . shapes = shapes updated_network . feed . stops = stops updated_network . feed . stop_times = stop_times return updated_network def _apply_transit_feature_change_frequencies ( self , trip_ids : pd . Series , properties : dict , in_place : bool = True ) -> Union ( None , TransitNetwork ): freq = self . feed . frequencies . copy () # Grab only those records matching trip_ids (aka selection) freq = freq [ freq . trip_id . isin ( trip_ids )] # Check all `existing` properties if given if properties . get ( \"existing\" ) is not None : if not all ( freq . headway_secs == properties [ \"existing\" ]): WranglerLogger . error ( \"Existing does not match for at least \" \"1 trip in: \\n {} \" . format ( trip_ids . to_string ()) ) raise ValueError # Calculate build value if properties . get ( \"set\" ) is not None : build_value = properties [ \"set\" ] else : build_value = [ i + properties [ \"change\" ] for i in freq . headway_secs ] # Update self or return a new object q = self . feed . frequencies . trip_id . isin ( freq [ \"trip_id\" ]) if in_place : self . feed . frequencies . loc [ q , properties [ \"property\" ]] = build_value else : updated_network = copy . deepcopy ( self ) updated_network . loc [ q , properties [ \"property\" ]] = build_value return updated_network def apply_transit_managed_lane ( self , trip_ids : pd . Series , node_ids : list , in_place : bool = True ) -> Union ( None , TransitNetwork ): # Traversed nodes without a stop should be negative integers all_stops = self . feed . stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . tolist () node_ids = [ int ( x ) if str ( x ) in all_stops else int ( x ) * - 1 for x in node_ids ] self . _apply_transit_feature_change_routing ( trip_ids = trip_ids , properties = { \"existing\" : node_ids , \"set\" : RoadwayNetwork . get_managed_lane_node_ids ( node_ids ), }, in_place = in_place , )","title":"TransitNetwork"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.__init__","text":"Constructor .. todo:: Make graph a reference to associated RoadwayNetwork\u2019s graph, not its own thing. Source code in network_wrangler/transitnetwork.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def __init__ ( self , feed : DotDict = None , config : nx . DiGraph = None ): \"\"\" Constructor .. todo:: Make graph a reference to associated RoadwayNetwork's graph, not its own thing. \"\"\" self . feed : DotDict = feed self . config : nx . DiGraph = config self . road_net : RoadwayNetwork = None self . graph : nx . MultiDiGraph = None self . feed_path = None self . validated_frequencies = False self . validated_road_network_consistency = False if not self . validate_frequencies (): raise ValueError ( \"Transit lines with non-positive frequencies exist in the network\" )","title":"__init__()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.apply","text":"Wrapper method to apply a project to a transit network. Parameters: Name Type Description Default project_card_dictionary dict dict a dictionary of the project card object required Source code in network_wrangler/transitnetwork.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 def apply ( self , project_card_dictionary : dict ): \"\"\" Wrapper method to apply a project to a transit network. Args: project_card_dictionary: dict a dictionary of the project card object \"\"\" WranglerLogger . info ( \"Applying Project to Transit Network: {} \" . format ( project_card_dictionary [ \"project\" ] ) ) def _apply_individual_change ( project_dictionary : dict ): if ( project_dictionary [ \"category\" ] . lower () == \"transit service property change\" ): self . apply_transit_feature_change ( self . select_transit_features ( project_dictionary [ \"facility\" ]), project_dictionary [ \"properties\" ], ) elif project_dictionary [ \"category\" ] . lower () == \"parallel managed lanes\" : # Grab the list of nodes in the facility from road_net # It should be cached because managed lane projects are # processed by RoadwayNetwork first via # Scenario.apply_all_projects try : managed_lane_nodes = self . road_net . selections ( self . road_net . build_selection_key ( project_dictionary [ \"facility\" ] ) )[ \"route\" ] except ValueError : WranglerLogger . error ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) # Reroute any transit using these nodes self . apply_transit_managed_lane ( self . select_transit_features_by_nodes ( managed_lane_nodes ), managed_lane_nodes , ) elif project_dictionary [ \"category\" ] . lower () == \"roadway deletion\" : WranglerLogger . warning ( \"Roadway Deletion not yet implemented in Transit; ignoring\" ) else : msg = \" {} not implemented yet in TransitNetwork; can't apply.\" . format ( project_dictionary [ \"category\" ] ) WranglerLogger . error ( msg ) raise ( msg ) if project_card_dictionary . get ( \"changes\" ): for project_dictionary in project_card_dictionary [ \"changes\" ]: _apply_individual_change ( project_dictionary ) else : _apply_individual_change ( project_card_dictionary )","title":"apply()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.apply_transit_feature_change","text":"Changes the transit attributes for the selected features based on the project card information passed Parameters: Name Type Description Default trip_ids pd.Series all trip_ids to apply change to required properties list of dictionaries transit properties to change required in_place bool whether to apply changes in place or return a new network True Returns: Type Description Union (None, TransitNetwork ) None Source code in network_wrangler/transitnetwork.py 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 def apply_transit_feature_change ( self , trip_ids : pd . Series , properties : list , in_place : bool = True ) -> Union ( None , TransitNetwork ): \"\"\" Changes the transit attributes for the selected features based on the project card information passed Args: trip_ids : pd.Series all trip_ids to apply change to properties : list of dictionaries transit properties to change in_place : bool whether to apply changes in place or return a new network Returns: None \"\"\" for i in properties : if i [ \"property\" ] in [ \"headway_secs\" ]: self . _apply_transit_feature_change_frequencies ( trip_ids , i , in_place ) elif i [ \"property\" ] in [ \"routing\" ]: self . _apply_transit_feature_change_routing ( trip_ids , i , in_place )","title":"apply_transit_feature_change()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.empty","text":"Create an empty transit network instance using the default config. .. todo:: fill out this method Source code in network_wrangler/transitnetwork.py 91 92 93 94 95 96 97 98 99 100 101 102 @staticmethod def empty () -> TransitNetwork : \"\"\" Create an empty transit network instance using the default config. .. todo:: fill out this method \"\"\" ##TODO msg = \"TransitNetwork.empty is not implemented.\" WranglerLogger . error ( msg ) raise NotImplemented ( msg )","title":"empty()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.read","text":"Read GTFS feed from folder and TransitNetwork object Parameters: Name Type Description Default feed_path str where to read transit network files from required Source code in network_wrangler/transitnetwork.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @staticmethod def read ( feed_path : str ) -> TransitNetwork : \"\"\" Read GTFS feed from folder and TransitNetwork object Args: feed_path: where to read transit network files from Returns: a TransitNetwork object. \"\"\" config = default_config () feed = ptg . load_feed ( feed_path , config = config ) WranglerLogger . info ( \"Read in transit feed from: {} \" . format ( feed_path )) updated_config = TransitNetwork . validate_feed ( feed , config ) # Read in each feed so we can write over them editable_feed = DotDict () for node in updated_config . nodes . keys (): # Load (initiate Partridge's lazy load) editable_feed [ node . replace ( \".txt\" , \"\" )] = feed . get ( node ) transit_network = TransitNetwork ( feed = editable_feed , config = updated_config ) transit_network . feed_path = feed_path return transit_network","title":"read()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.route_ids_in_routestxt","text":"Wherever route_id occurs, make sure it is in routes.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 @staticmethod def route_ids_in_routestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever route_id occurs, make sure it is in routes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" route_ids_routestxt = set ( feed . routes . route_id . tolist ()) route_ids_referenced = set ( feed . trips . route_id . tolist ()) missing_routes = route_ids_referenced - route_ids_routestxt if missing_routes : WranglerLogger . warning ( \"The following route_ids are referenced but missing from routes.txt: {} \" . format ( list ( missing_routes ) ) ) return False return True","title":"route_ids_in_routestxt()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.select_transit_features","text":"Selects transit features that satisfy selection criteria Parameters: Name Type Description Default selection selection dictionary required Source code in network_wrangler/transitnetwork.py 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 def select_transit_features ( self , selection : dict ) -> pd . Series : \"\"\" Selects transit features that satisfy selection criteria Args: selection : selection dictionary Returns: trip identifiers : list of GTFS trip IDs in the selection \"\"\" trips = self . feed . trips routes = self . feed . routes freq = self . feed . frequencies # Turn selection's values into lists if they are not already for key in selection . keys (): if type ( selection [ key ]) not in [ list , tuple ]: selection [ key ] = [ selection [ key ]] # Based on the key in selection, filter trips if \"trip_id\" in selection : trips = trips [ trips . trip_id . isin ( selection [ \"trip_id\" ])] elif \"route_id\" in selection : trips = trips [ trips . route_id . isin ( selection [ \"route_id\" ])] elif \"route_short_name\" in selection : routes = routes [ routes . route_short_name . isin ( selection [ \"route_short_name\" ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] elif \"route_long_name\" in selection : matches = [] for sel in selection [ \"route_long_name\" ]: for route_long_name in routes [ \"route_long_name\" ]: x = re . search ( sel , route_long_name ) if x is not None : matches . append ( route_long_name ) routes = routes [ routes . route_long_name . isin ( matches )] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , selection . keys ()) raise ValueError # If a time key exists, filter trips using frequency table if selection . get ( \"time\" ): selection [ \"time\" ] = parse_time_spans ( selection [ \"time\" ]) elif selection . get ( \"start_time\" ) and selection . get ( \"end_time\" ): selection [ \"time\" ] = parse_time_spans ( [ selection [ \"start_time\" ], selection [ \"end_time\" ]] ) # Filter freq to trips in selection freq = freq [ freq . trip_id . isin ( trips [ \"trip_id\" ])] freq = freq [ freq . start_time == selection [ \"time\" ][ 0 ]] freq = freq [ freq . end_time == selection [ \"time\" ][ 1 ]] # Filter trips table to those still in freq table trips = trips [ trips . trip_id . isin ( freq [ \"trip_id\" ])] # If any other key exists, filter routes or trips accordingly for key in selection . keys (): if key not in [ \"trip_id\" , \"route_id\" , \"route_short_name\" , \"route_long_name\" , \"time\" , ]: if key in trips : trips = trips [ trips [ key ] . isin ( selection [ key ])] elif key in routes : routes = routes [ routes [ key ] . isin ( selection [ key ])] trips = trips [ trips . route_id . isin ( routes [ \"route_id\" ])] else : WranglerLogger . error ( \"Selection not supported %s \" , key ) raise ValueError # Check that there is at least one trip in trips table or raise error if len ( trips ) < 1 : WranglerLogger . error ( \"Selection returned zero trips\" ) raise ValueError # Return pandas.Series of trip_ids return trips [ \"trip_id\" ]","title":"select_transit_features()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.select_transit_features_by_nodes","text":"Selects transit features that use any one of a list of node_ids Parameters: Name Type Description Default node_ids list list (generally coming from nx.shortest_path) required require_all bool if True, the returned trip_ids must traverse all of the nodes (default = False) False Returns: Type Description pd . Series trip identifiers list of GTFS trip IDs in the selection Source code in network_wrangler/transitnetwork.py 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 def select_transit_features_by_nodes ( self , node_ids : list , require_all : bool = False ) -> pd . Series : \"\"\" Selects transit features that use any one of a list of node_ids Args: node_ids: list (generally coming from nx.shortest_path) require_all : bool if True, the returned trip_ids must traverse all of the nodes (default = False) Returns: trip identifiers list of GTFS trip IDs in the selection \"\"\" # If require_all, the returned trip_ids must traverse all of the nodes # Else, filter any shapes that use any one of the nodes in node_ids if require_all : shape_ids = ( self . feed . shapes . groupby ( \"shape_id\" ) . filter ( lambda x : all ( i in x [ TransitNetwork . SHAPES_FOREIGN_KEY ] . tolist () for i in node_ids ) ) ) . shape_id . drop_duplicates () else : shape_ids = self . feed . shapes [ self . feed . shapes [ TransitNetwork . SHAPES_FOREIGN_KEY ] . isin ( node_ids ) ] . shape_id . drop_duplicates () # Return pandas.Series of trip_ids return self . feed . trips [ self . feed . trips . shape_id . isin ( shape_ids )] . trip_id","title":"select_transit_features_by_nodes()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.shape_ids_in_shapestxt","text":"Wherever shape_id occurs, make sure it is in shapes.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 @staticmethod def shape_ids_in_shapestxt ( feed : DotDict ) -> Bool : \"\"\" Wherever shape_id occurs, make sure it is in shapes.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" shape_ids_shapestxt = set ( feed . shapes . shape_id . tolist ()) shape_ids_referenced = set ( feed . trips . shape_id . tolist ()) missing_shapes = shape_ids_referenced - shape_ids_shapestxt if missing_shapes : WranglerLogger . warning ( \"The following shape_ids from trips.txt are missing from shapes.txt: {} \" . format ( list ( missing_shapes ) ) ) return False return True","title":"shape_ids_in_shapestxt()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.stop_ids_in_stopstxt","text":"Wherever stop_id occurs, make sure it is in stops.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 @staticmethod def stop_ids_in_stopstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever stop_id occurs, make sure it is in stops.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" stop_ids_stopstxt = set ( feed . stops . stop_id . tolist ()) stop_ids_referenced = [] # STOP_TIMES stop_ids_referenced . extend ( feed . stop_times . stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . stops . parent_station . dropna () . tolist ()) # TRANSFERS if feed . get ( \"transfers.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . transfers . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . transfers . to_stop_id . dropna () . tolist ()) # PATHWAYS if feed . get ( \"pathways.txt\" ) . shape [ 0 ] > 0 : stop_ids_referenced . extend ( feed . pathways . from_stop_id . dropna () . tolist ()) stop_ids_referenced . extend ( feed . pathways . to_stop_id . dropna () . tolist ()) stop_ids_referenced = set ( stop_ids_referenced ) missing_stops = stop_ids_referenced - stop_ids_stopstxt if missing_stops : WranglerLogger . warning ( \"The following stop_ids from are referenced but missing from stops.txt: {} \" . format ( list ( missing_stops ) ) ) return False return True","title":"stop_ids_in_stopstxt()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.transit_net_to_gdf","text":"Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame. Parameters: Name Type Description Default transit Union ( TransitNetwork , pd . DataFrame ) either a TransitNetwork or a Shapes GeoDataFrame required .. todo:: Make more sophisticated. Source code in network_wrangler/transitnetwork.py 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 @staticmethod def transit_net_to_gdf ( transit : Union ( TransitNetwork , pd . DataFrame )): \"\"\" Returns a geodataframe given a TransitNetwork or a valid Shapes DataFrame. Args: transit: either a TransitNetwork or a Shapes GeoDataFrame .. todo:: Make more sophisticated. \"\"\" from partridge import geo if type ( transit ) is pd . DataFrame : shapes = transit else : shapes = transit . feed . shapes transit_gdf = geo . build_shapes ( shapes ) return transit_gdf","title":"transit_net_to_gdf()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.trip_ids_in_tripstxt","text":"Wherever trip_id occurs, make sure it is in trips.txt Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 @staticmethod def trip_ids_in_tripstxt ( feed : DotDict ) -> Bool : \"\"\" Wherever trip_id occurs, make sure it is in trips.txt Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" trip_ids_tripstxt = set ( feed . trips . trip_id . tolist ()) trip_ids_referenced = set ( feed . stop_times . trip_id . tolist () + feed . frequencies . trip_id . tolist () ) missing_trips = trip_ids_referenced - trip_ids_tripstxt if missing_trips : WranglerLogger . warning ( \"The following trip_ids are referenced but missing from trips.txt: {} \" . format ( list ( missing_trips ) ) ) return False return True","title":"trip_ids_in_tripstxt()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_feed","text":"Since Partridge lazily loads the df, load each file to make sure it actually works. Partridge uses a DiGraph from the networkx library to represent the relationships between GTFS files. Each file is a \u2018node\u2019, and the relationship between files are \u2018edges\u2019. Parameters: Name Type Description Default feed DotDict partridge feed required config nx . DiGraph partridge config required Source code in network_wrangler/transitnetwork.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @staticmethod def validate_feed ( feed : DotDict , config : nx . DiGraph ) -> bool : \"\"\" Since Partridge lazily loads the df, load each file to make sure it actually works. Partridge uses a DiGraph from the networkx library to represent the relationships between GTFS files. Each file is a 'node', and the relationship between files are 'edges'. Args: feed: partridge feed config: partridge config \"\"\" updated_config = copy . deepcopy ( config ) files_not_found = [] for node in config . nodes . keys (): n = feed . get ( node ) WranglerLogger . debug ( \"... {} : \\n {} \" . format ( node , n [: 10 ])) if n . shape [ 0 ] == 0 : WranglerLogger . info ( \"Removing {} from transit network config because file not found\" . format ( node ) ) updated_config . remove_node ( node ) if node in TransitNetwork . REQUIRED_FILES : files_not_found . append ( node ) if files_not_found : msg = \"Required files not found or valid: {} \" . format ( \",\" . join ( files_not_found ) ) WranglerLogger . error ( msg ) raise AttributeError ( msg ) return False TransitNetwork . validate_network_keys ( feed ) return updated_config","title":"validate_feed()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_frequencies","text":"Validates that there are no transit trips in the feed with zero frequencies. Changes state of self.validated_frequencies boolean based on outcome. Returns: Type Description bool boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def validate_frequencies ( self ) -> bool : \"\"\" Validates that there are no transit trips in the feed with zero frequencies. Changes state of self.validated_frequencies boolean based on outcome. Returns: boolean indicating if valid or not. \"\"\" _valid = True zero_freq = self . feed . frequencies [ self . feed . frequencies . headway_secs <= 0 ] if len ( zero_freq . index ) > 0 : _valid = False msg = \"Transit lines {} have non-positive frequencies\" . format ( zero_freq . trip_id . to_list () ) WranglerLogger . error ( msg ) self . validated_frequencies = True return _valid","title":"validate_frequencies()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_network_keys","text":"Validates foreign keys are present in all connecting feed files. Parameters: Name Type Description Default feed DotDict partridge feed object required Returns: Type Description Bool Boolean indicating if feed is okay. Source code in network_wrangler/transitnetwork.py 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 @staticmethod def validate_network_keys ( feed : DotDict ) -> Bool : \"\"\" Validates foreign keys are present in all connecting feed files. Args: feed: partridge feed object Returns: Boolean indicating if feed is okay. \"\"\" result = True result = result and TransitNetwork . route_ids_in_routestxt ( feed ) result = result and TransitNetwork . trip_ids_in_tripstxt ( feed ) result = result and TransitNetwork . shape_ids_in_shapestxt ( feed ) result = result and TransitNetwork . stop_ids_in_stopstxt ( feed ) return result","title":"validate_network_keys()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_road_network_consistencies","text":"Validates transit network against the road network for both stops and shapes. Returns: Type Description bool boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def validate_road_network_consistencies ( self ) -> bool : \"\"\" Validates transit network against the road network for both stops and shapes. Returns: boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) valid = True valid_stops = self . validate_transit_stops () valid_shapes = self . validate_transit_shapes () self . validated_road_network_consistency = True if not valid_stops or not valid_shapes : valid = False raise ValueError ( \"Transit network is not consistent with road network.\" ) return valid","title":"validate_road_network_consistencies()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_transit_shapes","text":"Validates that all transit shapes are part of the roadway network. Returns: Type Description bool Boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 def validate_transit_shapes ( self ) -> bool : \"\"\" Validates that all transit shapes are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) shapes_df = self . feed . shapes nodes_df = self . road_net . nodes_df links_df = self . road_net . links_df valid = True # check if all the node ids exist in the network shape_ids = [ int ( s ) for s in shapes_df [ TransitNetwork . SHAPES_FOREIGN_KEY ] . to_list () ] node_ids = [ int ( n ) for n in nodes_df [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( shape_ids ) . issubset ( node_ids ): valid = False missing_shapes = list ( set ( shape_ids ) - set ( node_ids )) msg = \"Not all transit shapes are part of the roadyway network. \" msg += \"Missing shapes ( {} ) from the roadway network are {} .\" . format ( TransitNetwork . SHAPES_FOREIGN_KEY , missing_shapes ) WranglerLogger . error ( msg ) return valid # check if all the links in transit shapes exist in the network # and transit is allowed shapes_df = shapes_df . astype ({ TransitNetwork . SHAPES_FOREIGN_KEY : int }) unique_shape_ids = shapes_df . shape_id . unique () . tolist () for id in unique_shape_ids : subset_shapes_df = shapes_df [ shapes_df [ \"shape_id\" ] == id ] subset_shapes_df = subset_shapes_df . sort_values ( by = [ \"shape_pt_sequence\" ]) subset_shapes_df = subset_shapes_df . add_suffix ( \"_1\" ) . join ( subset_shapes_df . shift ( - 1 ) . add_suffix ( \"_2\" ) ) subset_shapes_df = subset_shapes_df . dropna () merged_df = subset_shapes_df . merge ( links_df , how = \"left\" , left_on = [ TransitNetwork . SHAPES_FOREIGN_KEY + \"_1\" , TransitNetwork . SHAPES_FOREIGN_KEY + \"_2\" , ], right_on = [ \"A\" , \"B\" ], indicator = True , ) missing_links_df = merged_df . query ( '_merge == \"left_only\"' ) # there are shape links which does not exist in the roadway network if len ( missing_links_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which are missing in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) transit_not_allowed_df = merged_df . query ( '_merge == \"both\" & drive_access == 0 & bus_only == 0 & rail_only == 0' ) # there are shape links where transit is not allowed if len ( transit_not_allowed_df . index ) > 0 : valid = False msg = \"There are links for shape id {} which does not allow transit in the roadway network.\" . format ( id ) WranglerLogger . error ( msg ) return valid","title":"validate_transit_shapes()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.validate_transit_stops","text":"Validates that all transit stops are part of the roadway network. Returns: Type Description bool Boolean indicating if valid or not. Source code in network_wrangler/transitnetwork.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def validate_transit_stops ( self ) -> bool : \"\"\" Validates that all transit stops are part of the roadway network. Returns: Boolean indicating if valid or not. \"\"\" if self . road_net is None : raise ValueError ( \"RoadwayNetwork not set yet, see TransitNetwork.set_roadnet()\" ) stops = self . feed . stops nodes = self . road_net . nodes_df valid = True stop_ids = [ int ( s ) for s in stops [ TransitNetwork . STOPS_FOREIGN_KEY ] . to_list ()] node_ids = [ int ( n ) for n in nodes [ RoadwayNetwork . NODE_FOREIGN_KEY ] . to_list ()] if not set ( stop_ids ) . issubset ( node_ids ): valid = False missing_stops = list ( set ( stop_ids ) - set ( node_ids )) msg = \"Not all transit stops are part of the roadyway network. \" msg += \"Missing stops ( {} ) from the roadway nodes are {} .\" . format ( TransitNetwork . STOPS_FOREIGN_KEY , missing_stops ) WranglerLogger . error ( msg ) return valid","title":"validate_transit_stops()"},{"location":"api/#network_wrangler.transitnetwork.TransitNetwork.write","text":"Writes a network in the transit network standard Parameters: Name Type Description Default path str the path were the output will be saved '.' filename str the name prefix of the transit files that will be generated None Source code in network_wrangler/transitnetwork.py 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 def write ( self , path : str = \".\" , filename : str = None ) -> None : \"\"\" Writes a network in the transit network standard Args: path: the path were the output will be saved filename: the name prefix of the transit files that will be generated \"\"\" WranglerLogger . info ( \"Writing transit to directory: {} \" . format ( path )) for node in self . config . nodes . keys (): df = self . feed . get ( node . replace ( \".txt\" , \"\" )) if not df . empty : if filename : outpath = os . path . join ( path , filename + \"_\" + node ) else : outpath = os . path . join ( path , node ) WranglerLogger . debug ( \"Writing file: {} \" . format ( outpath )) df . to_csv ( outpath , index = False )","title":"write()"},{"location":"api/#utils-and-functions","text":"","title":"Utils and Functions"},{"location":"api/#network_wrangler.utils","text":"","title":"utils"},{"location":"api/#network_wrangler.utils.create_line_string","text":"Creates a geometry as a LineString using location reference Source code in network_wrangler/utils.py 286 287 288 289 290 291 def create_line_string ( location_reference : list ): \"\"\" Creates a geometry as a LineString using location reference \"\"\" return LineString ([ location_reference [ 0 ][ \"point\" ], location_reference [ 1 ][ \"point\" ]])","title":"create_line_string()"},{"location":"api/#network_wrangler.utils.create_location_reference_from_nodes","text":"Creates a location reference using the node a and node b coordinates Source code in network_wrangler/utils.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def create_location_reference_from_nodes ( node_a , node_b ): \"\"\" Creates a location reference using the node a and node b coordinates Args: node_a: Node A as Series node_b: Node B as Series \"\"\" out_location_reference = [ { \"sequence\" : 1 , \"point\" : [ node_a [ \"X\" ], node_a [ \"Y\" ]]}, { \"sequence\" : 2 , \"point\" : [ node_b [ \"X\" ], node_b [ \"Y\" ]]}, ] return out_location_reference","title":"create_location_reference_from_nodes()"},{"location":"api/#network_wrangler.utils.create_unique_shape_id","text":"Creates a unique hash id using the coordinates of the geomtery Source code in network_wrangler/utils.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def create_unique_shape_id ( line_string : LineString ): \"\"\" Creates a unique hash id using the coordinates of the geomtery Args: line_string: Line Geometry as a LineString Returns: string \"\"\" x1 , y1 = list ( line_string . coords )[ 0 ] # first co-ordinate (A node) x2 , y2 = list ( line_string . coords )[ - 1 ] # last co-ordinate (B node) message = \"Geometry {} {} {} {} \" . format ( x1 , y1 , x2 , y2 ) unhashed = message . encode ( \"utf-8\" ) hash = hashlib . md5 ( unhashed ) . hexdigest () return hash","title":"create_unique_shape_id()"},{"location":"api/#network_wrangler.utils.get_bearing","text":"calculate the bearing (forward azimuth) b/w the two points Source code in network_wrangler/utils.py 144 145 146 147 148 149 150 151 152 153 154 155 156 def get_bearing ( lat1 , lon1 , lat2 , lon2 ): \"\"\" calculate the bearing (forward azimuth) b/w the two points returns: bearing in radians \"\"\" # bearing in degrees brng = Geodesic . WGS84 . Inverse ( lat1 , lon1 , lat2 , lon2 )[ \"azi1\" ] # convert bearing to radians brng = math . radians ( brng ) return brng","title":"get_bearing()"},{"location":"api/#network_wrangler.utils.haversine_distance","text":"Calculates haversine distance between two points Source code in network_wrangler/utils.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def haversine_distance ( origin : list , destination : list ): \"\"\" Calculates haversine distance between two points Args: origin: lat/lon for point A destination: lat/lon for point B Returns: string \"\"\" lon1 , lat1 = origin lon2 , lat2 = destination radius = 6378137 # meter dlat = math . radians ( lat2 - lat1 ) dlon = math . radians ( lon2 - lon1 ) a = math . sin ( dlat / 2 ) * math . sin ( dlat / 2 ) + math . cos ( math . radians ( lat1 ) ) * math . cos ( math . radians ( lat2 )) * math . sin ( dlon / 2 ) * math . sin ( dlon / 2 ) c = 2 * math . atan2 ( math . sqrt ( a ), math . sqrt ( 1 - a )) d = radius * c # meters d = d * 0.000621371 # miles return d","title":"haversine_distance()"},{"location":"api/#network_wrangler.utils.link_df_to_json","text":"Export pandas dataframe as a json object. Modified from: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/ Parameters: Name Type Description Default df pd . DataFrame Dataframe to export required properties list list of properties to export required Source code in network_wrangler/utils.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def link_df_to_json ( df : pd . DataFrame , properties : list ): \"\"\" Export pandas dataframe as a json object. Modified from: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/ Args: df: Dataframe to export properties: list of properties to export \"\"\" # can't remember why we need this? if \"distance\" in properties : df [ \"distance\" ] . fillna ( 0 ) json = [] for _ , row in df . iterrows (): feature = {} for prop in properties : feature [ prop ] = row [ prop ] json . append ( feature ) return json","title":"link_df_to_json()"},{"location":"api/#network_wrangler.utils.make_slug","text":"makes a slug from text Source code in network_wrangler/utils.py 84 85 86 87 88 89 90 91 def make_slug ( text , delimiter : str = \"_\" ): \"\"\" makes a slug from text \"\"\" import re text = re . sub ( \"[,.;@#?!&$']+\" , \"\" , text . lower ()) return re . sub ( \"[\\ ]+\" , delimiter , text )","title":"make_slug()"},{"location":"api/#network_wrangler.utils.offset_location_reference","text":"Creates a new location reference using the node a and node b of given location reference, offseting it by 90 degree to the bearing of given location reference and distance equals to offset_meters Source code in network_wrangler/utils.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def offset_location_reference ( location_reference , offset_meters = 10 ): \"\"\" Creates a new location reference using the node a and node b of given location reference, offseting it by 90 degree to the bearing of given location reference and distance equals to offset_meters returns: new location_reference with offset \"\"\" lon_1 = location_reference [ 0 ][ \"point\" ][ 0 ] lat_1 = location_reference [ 0 ][ \"point\" ][ 1 ] lon_2 = location_reference [ 1 ][ \"point\" ][ 0 ] lat_2 = location_reference [ 1 ][ \"point\" ][ 1 ] bearing = get_bearing ( lat_1 , lon_1 , lat_2 , lon_2 ) # adding 90 degrees (1.57 radians) to the current bearing bearing = bearing + 1.57 new_lat_1 , new_lon_1 = offset_point_with_distance_and_bearing ( lat_1 , lon_1 , offset_meters , bearing ) new_lat_2 , new_lon_2 = offset_point_with_distance_and_bearing ( lat_2 , lon_2 , offset_meters , bearing ) out_location_reference = [ { \"sequence\" : 1 , \"point\" : [ new_lon_1 , new_lat_1 ]}, { \"sequence\" : 2 , \"point\" : [ new_lon_2 , new_lat_2 ]}, ] return out_location_reference","title":"offset_location_reference()"},{"location":"api/#network_wrangler.utils.offset_point_with_distance_and_bearing","text":"Get the new lat long (in degrees) given current point (lat/lon), distance and bearing Source code in network_wrangler/utils.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def offset_point_with_distance_and_bearing ( lat , lon , distance , bearing ): \"\"\" Get the new lat long (in degrees) given current point (lat/lon), distance and bearing returns: new lat/long \"\"\" # Earth's radius in meters radius = 6378137 # convert the lat long from degree to radians lat_radians = math . radians ( lat ) lon_radians = math . radians ( lon ) # calculate the new lat long in radians out_lat_radians = math . asin ( math . sin ( lat_radians ) * math . cos ( distance / radius ) + math . cos ( lat_radians ) * math . sin ( distance / radius ) * math . cos ( bearing ) ) out_lon_radians = lon_radians + math . atan2 ( math . sin ( bearing ) * math . sin ( distance / radius ) * math . cos ( lat_radians ), math . cos ( distance / radius ) - math . sin ( lat_radians ) * math . sin ( lat_radians ), ) # convert the new lat long back to degree out_lat = math . degrees ( out_lat_radians ) out_lon = math . degrees ( out_lon_radians ) return ( out_lat , out_lon )","title":"offset_point_with_distance_and_bearing()"},{"location":"api/#network_wrangler.utils.parse_time_spans","text":"parse time spans into tuples of seconds from midnight can also be used as an apply function for a pandas series Parameters times: tuple(string) or tuple(int) or list(string) or list(int)","title":"parse_time_spans()"},{"location":"api/#network_wrangler.utils.parse_time_spans--returns","text":"tuple(integer) time span as seconds from midnight Source code in network_wrangler/utils.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def parse_time_spans ( times ): \"\"\" parse time spans into tuples of seconds from midnight can also be used as an apply function for a pandas series Parameters ----------- times: tuple(string) or tuple(int) or list(string) or list(int) returns -------- tuple(integer) time span as seconds from midnight \"\"\" try : start_time , end_time = times except : msg = \"ERROR: times should be a tuple or list of two, got: {} \" . format ( times ) WranglerLogger . error ( msg ) raise ValueError ( msg ) # If times are strings, convert to int in seconds, else return as ints if isinstance ( start_time , str ) and isinstance ( end_time , str ): start_time = start_time . strip () end_time = end_time . strip () # If time is given without seconds, add 00 if len ( start_time ) <= 5 : start_time += \":00\" if len ( end_time ) <= 5 : end_time += \":00\" # Convert times to seconds from midnight (Partride's time storage) h0 , m0 , s0 = start_time . split ( \":\" ) start_time_sec = int ( h0 ) * 3600 + int ( m0 ) * 60 + int ( s0 ) h1 , m1 , s1 = end_time . split ( \":\" ) end_time_sec = int ( h1 ) * 3600 + int ( m1 ) * 60 + int ( s1 ) return ( start_time_sec , end_time_sec ) elif isinstance ( start_time , int ) and isinstance ( end_time , int ): return times else : WranglerLogger . error ( \"ERROR: times should be ints or strings\" ) raise ValueError () return ( start_time_sec , end_time_sec )","title":"returns"},{"location":"api/#network_wrangler.utils.point_df_to_geojson","text":"Source code in network_wrangler/utils.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def point_df_to_geojson ( df : pd . DataFrame , properties : list ): \"\"\" Author: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/ \"\"\" from .roadwaynetwork import RoadwayNetwork geojson = { \"type\" : \"FeatureCollection\" , \"features\" : []} for _ , row in df . iterrows (): feature = { \"type\" : \"Feature\" , \"properties\" : {}, \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : []}, } feature [ \"geometry\" ][ \"coordinates\" ] = [ row [ \"geometry\" ] . x , row [ \"geometry\" ] . y ] feature [ \"properties\" ][ RoadwayNetwork . NODE_FOREIGN_KEY ] = row . name for prop in properties : feature [ \"properties\" ][ prop ] = row [ prop ] geojson [ \"features\" ] . append ( feature ) return geojson","title":"point_df_to_geojson()"},{"location":"api/#network_wrangler.utils.topological_sort","text":"Topological sorting for Acyclic Directed Graph Source code in network_wrangler/utils.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def topological_sort ( adjacency_list , visited_list ): \"\"\" Topological sorting for Acyclic Directed Graph \"\"\" output_stack = [] def _topology_sort_util ( vertex ): if not visited_list [ vertex ]: visited_list [ vertex ] = True for neighbor in adjacency_list [ vertex ]: _topology_sort_util ( neighbor ) output_stack . insert ( 0 , vertex ) for vertex in visited_list : _topology_sort_util ( vertex ) return output_stack","title":"topological_sort()"},{"location":"api/#network_wrangler.logger","text":"","title":"logger"},{"location":"api/#network_wrangler.logger.setupLogging","text":"Sets up the WranglerLogger w.r.t. the debug file location and if logging to console. Parameters: Name Type Description Default level int the level of logging that will be recorded None log_filename str the location of the log file that will get created to add the DEBUG log None log_to_console bool if True, logging will go to the console at INFO level False Source code in network_wrangler/logger.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def setupLogging ( level : int = None , log_filename : str = None , log_to_console : bool = False ): \"\"\" Sets up the WranglerLogger w.r.t. the debug file location and if logging to console. args: level: the level of logging that will be recorded log_filename: the location of the log file that will get created to add the DEBUG log log_to_console: if True, logging will go to the console at INFO level \"\"\" if level is None : WranglerLogger . setLevel ( logging . DEBUG ) else : WranglerLogger . setLevel ( level ) FORMAT = logging . Formatter ( \" %(asctime)-15s %(levelname)s : %(message)s \" , datefmt = \"%Y-%m- %d %H:%M:%S,\" ) if log_filename : file_handler = logging . FileHandler ( log_filename ) file_handler . setLevel ( logging . DEBUG ) file_handler . setFormatter ( FORMAT ) WranglerLogger . addHandler ( file_handler ) if log_to_console : console_handler = logging . StreamHandler ( sys . stdout ) console_handler . setLevel ( logging . INFO ) console_handler . setFormatter ( FORMAT ) WranglerLogger . addHandler ( console_handler )","title":"setupLogging()"},{"location":"design/","text":"Design \u00b6 Atomic Parts \u00b6 NetworkWrangler deals with four primary atomic parts: 1. Scenario objects describe a Roadway Network, Transit Network, and collection of Projects. Scenarios manage the addition and construction of projects on the network via projct cards. Scenarios can be based on or tiered from other scenarios. 2. RoadwayNetwork objects stores information about roadway nodes, directed links between nodes, and the shapes of links (note that the same shape can be shared between two or more links). Network Wrangler reads/writes roadway network objects from/to three files: links.json , shapes.geojson , and nodes.geojson . Their data is stored as GeoDataFrames in the object. 3. TransitNetwork objects contain information about stops, routes, trips, shapes, stoptimes, and frequencies. Network Wrangler reads/writes transit network information from/to gtfs csv files and stores them as DataFrames within a Partridge feed object. Transit networks can be associated with Roadway networks. 4. ProjectCard objects store infromation (including metadata) about changes to the network. Network Wtanglr reads project cards from .yml files validates them, and manages them within a Scenario object.","title":"Design"},{"location":"design/#design","text":"","title":"Design"},{"location":"design/#atomic-parts","text":"NetworkWrangler deals with four primary atomic parts: 1. Scenario objects describe a Roadway Network, Transit Network, and collection of Projects. Scenarios manage the addition and construction of projects on the network via projct cards. Scenarios can be based on or tiered from other scenarios. 2. RoadwayNetwork objects stores information about roadway nodes, directed links between nodes, and the shapes of links (note that the same shape can be shared between two or more links). Network Wrangler reads/writes roadway network objects from/to three files: links.json , shapes.geojson , and nodes.geojson . Their data is stored as GeoDataFrames in the object. 3. TransitNetwork objects contain information about stops, routes, trips, shapes, stoptimes, and frequencies. Network Wrangler reads/writes transit network information from/to gtfs csv files and stores them as DataFrames within a Partridge feed object. Transit networks can be associated with Roadway networks. 4. ProjectCard objects store infromation (including metadata) about changes to the network. Network Wtanglr reads project cards from .yml files validates them, and manages them within a Scenario object.","title":"Atomic Parts"},{"location":"development/","text":"Development \u00b6 Contributing to Network Wrangler \u00b6 Roles \u00b6 How to Contribute \u00b6 Setup \u00b6 Make sure you have a GitHub account. Make sure you have git , a terminal (e.g. Mac Terminal, CygWin, etc.), and a text editor installed on your local machine. Optionally, you will likely find it easier to use GitHub Desktop , an IDE instead of a simple text editor like VSCode , Eclipse , Sublime Text , etc. Fork the repository into your own GitHub account and clone it locally . Install your network_wrangler clone in development mode: pip install . -e Install development requirements: pip install -r dev-requirements.txt Install documentation requirements: pip install -r requirements.docs.txt [Optional] Install act to run github actions locally. Development Workflow \u00b6 Create an issue for any features/bugs that you are working on. Create a branch to work on a new issue (or checkout an existing one where the issue is being worked on). Develop comprehensive tests in the /tests folder. Modify code including inline documentation such that it passes all tests (not just your new ones) Lint code using pre-commit run --all-files Fill out information in the pull request template Submit all pull requests to the develop branch. Core developer will review your pull request and suggest changes. After requested changes are complete, core developer will sign off on pull-request merge. !tip: Keep pull requests small and focused. One issue is best. !tip: Don\u2019t forget to update any associated #documentation as well! Documentation \u00b6 Documentation is produced by mkdocs: mkdocs build : builds documentation mkdocs serve : builds and serves documentation to review locally in browswer Documentation is built and deployed using the mike package and Github Actions configured in .github/workflows/ for each \u201cref\u201d (i.e. branch) in the network_wrangler repository. Testing and Continuous Integration \u00b6 Tests and test data reside in the /tests directory: pytest : runs all tests Continuous Integration is managed by Github Actions in .github/workflows . All tests other than those with the decorator @pytest.mark.skipci will be run. Project Governance \u00b6 The project is currently governed by representatives of its two major organizational contributors: Metropolitan Council (MN) Metropolitan Transportation Commission (California) Code of Conduct \u00b6 Contributors to the Network Wrangler Project are expected to read and follow the CODE_OF_CONDUCT for the project. Contributors \u00b6 Lisa Zorn - initial Network Wrangler implementation at SFCTA Billy Charlton Elizabeh Sall Sijia Wang David Ory Ashish K. !Note: There are likely more contributors - feel free to add your name if we missed it!","title":"Development"},{"location":"development/#development","text":"","title":"Development"},{"location":"development/#contributing-to-network-wrangler","text":"","title":"Contributing to Network Wrangler"},{"location":"development/#roles","text":"","title":"Roles"},{"location":"development/#how-to-contribute","text":"","title":"How to Contribute"},{"location":"development/#setup","text":"Make sure you have a GitHub account. Make sure you have git , a terminal (e.g. Mac Terminal, CygWin, etc.), and a text editor installed on your local machine. Optionally, you will likely find it easier to use GitHub Desktop , an IDE instead of a simple text editor like VSCode , Eclipse , Sublime Text , etc. Fork the repository into your own GitHub account and clone it locally . Install your network_wrangler clone in development mode: pip install . -e Install development requirements: pip install -r dev-requirements.txt Install documentation requirements: pip install -r requirements.docs.txt [Optional] Install act to run github actions locally.","title":"Setup"},{"location":"development/#development-workflow","text":"Create an issue for any features/bugs that you are working on. Create a branch to work on a new issue (or checkout an existing one where the issue is being worked on). Develop comprehensive tests in the /tests folder. Modify code including inline documentation such that it passes all tests (not just your new ones) Lint code using pre-commit run --all-files Fill out information in the pull request template Submit all pull requests to the develop branch. Core developer will review your pull request and suggest changes. After requested changes are complete, core developer will sign off on pull-request merge. !tip: Keep pull requests small and focused. One issue is best. !tip: Don\u2019t forget to update any associated #documentation as well!","title":"Development Workflow"},{"location":"development/#documentation","text":"Documentation is produced by mkdocs: mkdocs build : builds documentation mkdocs serve : builds and serves documentation to review locally in browswer Documentation is built and deployed using the mike package and Github Actions configured in .github/workflows/ for each \u201cref\u201d (i.e. branch) in the network_wrangler repository.","title":"Documentation"},{"location":"development/#testing-and-continuous-integration","text":"Tests and test data reside in the /tests directory: pytest : runs all tests Continuous Integration is managed by Github Actions in .github/workflows . All tests other than those with the decorator @pytest.mark.skipci will be run.","title":"Testing and Continuous Integration"},{"location":"development/#project-governance","text":"The project is currently governed by representatives of its two major organizational contributors: Metropolitan Council (MN) Metropolitan Transportation Commission (California)","title":"Project Governance"},{"location":"development/#code-of-conduct","text":"Contributors to the Network Wrangler Project are expected to read and follow the CODE_OF_CONDUCT for the project.","title":"Code of Conduct"},{"location":"development/#contributors","text":"Lisa Zorn - initial Network Wrangler implementation at SFCTA Billy Charlton Elizabeh Sall Sijia Wang David Ory Ashish K. !Note: There are likely more contributors - feel free to add your name if we missed it!","title":"Contributors"}]}