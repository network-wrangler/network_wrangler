{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Network Wrangler is a Python library for managing travel model network scenarios.</p>"},{"location":"#system-requirements","title":"System Requirements","text":"<p>Network Wrangler should be operating system agonistic and has been tested on Ubuntu and Mac OS.</p> <p>Network Wrangler does require Python 3.9+.  If you have a different version of Python installed (e.g. from ArcGIS), <code>conda</code> or a similar virtual environment manager can care of installing it for you in the installation instructions below.</p> <p>installing conda</p> <p>In order to assist in installation, its helpful to have miniconda or another virtual environment manager installed to make sure the network wrangler dependencies don\u2019t interfer with any other package requirements you have. If you don\u2019t have any of these already, we recommend starting with Miniconda as it has the smallest footprint. <code>conda</code> is the environment manager that is contained within both the Anaconda and mini-conda applications.</p> installing conda or Anaconda (the GUI version) for the first time on computer with Cube or ArcGIS?<p>For ArcGIS / Cube users - Recommend Install conda by leaving boxes unchecked for advanced options \u2013 system path and register anaconda. On some systems, checking these boxes will break Cube and ArcGis systems.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#create-and-activate-virtual-environment","title":"Create and Activate Virtual Environment","text":"<p>Create and/or activate the virtual environment where you want to install Network Wrangler.</p> <p>Option 1. Create a new conda environment for wrangler using conda</p> <pre><code>conda config --add channels conda-forge\nconda create python=3.11 -n wrangler #if you don't already have a virtual environment\nconda activate wrangler\n</code></pre> <p>Option 2. Use pre-packaged conda-environment with all dependencies</p> <p>Network wrangler comes packaged with a conda environment that already has all the required dependencies.  This can be helpful if you are having trouble with different versions of requirements since <code>conda</code> can be better at sorting through them than <code>pip</code>.</p> <pre><code>conda config --add channels conda-forge\nconda env create -f environments/conda/environment.yml\nconda activate wrangler\n</code></pre>"},{"location":"#step-2-consider-which-dependencies-you-want","title":"Step 2. Consider which Dependencies you want","text":"<p>The core requirements for network wrangler are specified in <code>pyproject.toml</code> and will be automatically checked and installed when you install network wrangler.</p> <p>Additional, optional libraries are specified in separate requirements files to reduce the bloat of the minimum installation.</p> File pip Option Code Purpose <code>requirements.viz.txt</code> <code>viz</code> Requirements for running visualizations. <code>requirements.docs.txt</code> <code>docs</code> Requirements for building documentation. <code>requirements.tests.txt</code> <code>tests</code> Requirements for running tests. <p>If you want to view your networks or use jupyter notebooks, will likely want to install at least the visualization dependencies, which you can always do later as follows:</p> <pre><code>conda activate wrangler\npip install -r requirements.viz.txt\n</code></pre> <p>install additional dependencies using pip</p> <p>You don\u2019t have to separately install these dependencies. You can also install them when you install network wrangler itself using command like follows using the respective pip option code or a list of them:</p> <pre><code>conda activate wrangler\npip install network-wrangler[viz]\n</code></pre> <p>tricky dependencies</p> <p><code>rtree</code>, <code>geopandas</code> and <code>osmnx</code> can have some tricky co-dependencies.  If don\u2019t already have an up-to-date installation of them, we\u2019ve had the best success installing them using conda (as opposed to pip).</p> <pre><code>conda install rtree geopandas osmnx\n</code></pre>"},{"location":"#step-3-install-wrangler","title":"Step 3. Install Wrangler","text":"Latest ReleaseFrom GitHub <pre><code>pip install network-wrangler\n</code></pre> <p>Only necessary if you want to test features before they have released as official versions.</p> <pre><code>pip install git+https://github.com/wsp-sag/network_wrangler.git@develop#egg=network_wrangler\n</code></pre> <p>Tip</p> <p>If you wanted to install from a specific tag/version number or branch, replace <code>@develop</code> with <code>@&lt;branchname&gt;</code>  or <code>@tag</code></p>"},{"location":"#common-installation-issues","title":"Common Installation Issues","text":"libstdc++ is deprecated <p>clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]`</p> <p>If you are using MacOS, you might need to update your xcode command line tools and headers</p> libspatialindex_c or Missing GEOS module <p>\u201cOSError: Could not find libspatialindex_c library file</p> <p>or</p> <p>Shapely, a pre-requisite, doesn\u2019t install propertly because it is missing GEOS module</p> <p>Try installing them using conda.</p> <pre><code>conda uninstall geopandas rtree shapely\nconda install rtree shapely geopandas\n</code></pre> Conda is unable to install a library or to update to a specific library version<p>Add libraries from conda-forge</p> <pre><code>conda install -c conda-forge *library*\n</code></pre> User does not have permission to install in directories<p>Try running Anaconda as an administrator, even if you are an admin on your machine.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>To get a feel for the API and using project cards, please refer to the \u201cWrangler Quickstart\u201d jupyter notebook.</p> <p>To start the notebook, open a command line in the network_wrangler top-level directory and type:</p> <p><code>jupyter notebook</code></p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import network_wrangler\n\n##todo this is just an example for now\n\nnetwork_wrangler.setup_logging()\n\n## Network Manipulation\nmy_network = network_wrangler.read_roadway_network(...) # returns\nmy_network.apply_project_card(...) # returns\nmy_network.write_roadway_network(...) # returns\n\n## Scenario Building\nmy_scenario = network_wrangler.create_scenario(\n        base_scenario=my_base_scenario,\n        card_search_dir=project_card_directory,\n        tags = [\"baseline-2050\"]\n        )\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/baseline\", \"baseline-2050\")\nmy_scenario.summarize(outfile=\"scenario_summary_baseline.txt\")\n\nmy_scenario.add_projects_from_files(list_of_build_project_card_files)\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/build\", \"baseline\")\n</code></pre>"},{"location":"#attribution","title":"Attribution","text":"<p>NetworkWrangler was developed using resources from the Metropolitan Transportation Commission, Metropolitan Council MN, and in-kind time from UrbanLabs LLC and WSP.  It is currently maintained using in-kind time\u2026so please be patient.</p> <p>This project is built upon the ideas and concepts implemented in the network wrangler project by the San Francisco County Transportation Authority and expanded upon by the Metropolitan Transportation Commission.</p> <p>While Network Wrangler as written here is based on these concepts, the code is distinct and builds upon other packages such as <code>geopandas</code> and <code>pydantic</code> which hadn\u2019t been implemented when networkwrangler 1.0 was developed.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome. Please review contributing guidelines and instructions.</p>"},{"location":"#companion-software","title":"Companion Software","text":"<p>ProjectCard: Initially part of NetworkWrangler, the functionality for reading, writing and validating ProjectCard objects was pulled out into a separate project so that it could be used by other entities without necessitating NetworkWrangler.</p>"},{"location":"#having-an-issue","title":"Having an issue?","text":"<p>\ud83e\udeb2 NetworkWrangler may contain bugs.</p> <p>\ud83e\udd14 Also, since it has primarily been used by its developers, the documentation may contain some omissions or not be entirely clear.</p> <p>But we\u2019d love to make it better! Please report bugs or incorrect/unclear/missing documentation with a GitHub Issue -  or fix them yourself with a pull request!</p>"},{"location":"#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"#release-history","title":"Release History","text":""},{"location":"#changelog","title":"Changelog","text":"<p>Notable changes and version history.</p> Version Date Comment v1.0-beta-2 20204-10-15 Bug fixes in scenario loading, projectcard API and compatibility of transit net with roadway deletions. Some additional performance improvements. v1.0-beta-1 20204-10-9 Feature-complete for 1.0 v1.0-alpha-2 2024-10-8 Testing for Met Council v1.0-alpha-1 2024-07-17 Full refactor v0.2.0-alpha 2020-09-16 - v0.1.0-alpha 2020-09-09 - 0.0.2 2020-02-05 -"},{"location":"api/","title":"API Documentation","text":""},{"location":"api/#common-usage","title":"Common Usage","text":""},{"location":"api/#base-objects","title":"Base Objects","text":"<p>Scenario objects manage how a collection of projects is applied to the networks.</p> <p>Scenarios are built from a base scenario and a list of project cards.</p> <p>A project card is a YAML file (or similar) that describes a change to the network. The project card can contain multiple changes, each of which is applied to the network in sequence.</p> <p>Roadway Network class and functions for Network Wrangler.</p> <p>Used to represent a roadway network and perform operations on it.</p> <p>Usage:</p> <pre><code>from network_wrangler import load_roadway_from_dir, write_roadway\n\nnet = load_roadway_from_dir(\"my_dir\")\nnet.get_selection({\"links\": [{\"name\": [\"I 35E\"]}]})\nnet.apply(\"my_project_card.yml\")\n\nwrite_roadway(net, \"my_out_prefix\", \"my_dir\", file_format=\"parquet\")\n</code></pre> <p>TransitNetwork class for representing a transit network.</p> <p>Transit Networks are represented as a Wrangler-flavored GTFS Feed and optionally mapped to a RoadwayNetwork object. The TransitNetwork object is the primary object for managing transit networks in Wrangler.</p> <p>Usage:</p> <pre><code>```python\nimport network_wrangler as wr\n\nt = wr.load_transit(stpaul_gtfs)\nt.road_net = wr.load_roadway(stpaul_roadway)\nt = t.apply(project_card)\nwrite_transit(t, \"output_dir\")\n```\n</code></pre>"},{"location":"api/#network_wrangler.scenario--create-a-scenario","title":"Create a Scenario","text":"<p>Instantiate a scenario by seeding it with a base scenario and optionally some project cards.</p> <pre><code>from network_wrangler import create_scenario\n\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags=[\"baseline2050\"],\n)\n</code></pre> <p>A <code>base_year_scenario</code> is a dictionary representation of key components of a scenario:</p> <ul> <li><code>road_net</code>: RoadwayNetwork instance</li> <li><code>transit_net</code>: TransitNetwork instance</li> <li><code>applied_projects</code>: list of projects that have been applied to the base scenario so that the     scenario knows if there will be conflicts with future projects or if a future project\u2019s     pre-requisite is satisfied.</li> <li><code>conflicts</code>: dictionary of conflicts for project that have been applied to the base scenario so     that the scenario knows if there will be conflicts with future projects.</li> </ul> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_from_roadway_dir(STPAUL_DIR),\n    \"transit_net\": load_transit(STPAUL_DIR),\n    \"applied_projects\": [],\n    \"conflicts\": {},\n}\n</code></pre>"},{"location":"api/#network_wrangler.scenario--add-projects-to-a-scenario","title":"Add Projects to a Scenario","text":"<p>In addition to adding projects when you create the scenario, project cards can be added to a scenario using the <code>add_project_cards</code> method.</p> <pre><code>from projectcard import read_cards\n\nproject_card_dict = read_cards(card_location, filter_tags=[\"Baseline2030\"], recursive=True)\nmy_scenario.add_project_cards(project_card_dict.values())\n</code></pre> <p>Where <code>card_location</code> can be a single path, list of paths, a directory, or a glob pattern.</p>"},{"location":"api/#network_wrangler.scenario--apply-projects-to-a-scenario","title":"Apply Projects to a Scenario","text":"<p>Projects can be applied to a scenario using the <code>apply_all_projects</code> method. Before applying projects, the scenario will check that all pre-requisites are satisfied, that there are no conflicts, and that the projects are in the planned projects list.</p> <p>If you want to check the order of projects before applying them, you can use the <code>queued_projects</code> prooperty.</p> <pre><code>my_scenario.queued_projects\nmy_scenario.apply_all_projects()\n</code></pre> <p>You can review the resulting scenario, roadway network, and transit networks.</p> <pre><code>my_scenario.applied_projects\nmy_scenario.road_net.links_gdf.explore()\nmy_scenario.transit_net.feed.shapes_gdf.explore()\n</code></pre>"},{"location":"api/#network_wrangler.scenario--write-a-scenario-to-disk","title":"Write a Scenario to Disk","text":"<p>Scenarios (and their networks) can be written to disk using the <code>write</code> method which in addition to writing out roadway and transit networks, will serialize the scenario to a yaml-like file and can also write out the project cards that have been applied.</p> <pre><code>my_scenario.write(\n    \"output_dir\",\n    \"scenario_name_to_use\",\n    overwrite=True,\n    projects_write=True,\n    file_format=\"parquet\",\n)\n</code></pre> Example Serialized Scenario File<pre><code>applied_projects: &amp;id001\n- project a\n- project b\nbase_scenario:\napplied_projects: *id001\nroadway:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\n    file_format: geojson\ntransit:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\nconfig:\nCPU:\n    EST_PD_READ_SPEED:\n    csv: 0.03\n    geojson: 0.03\n    json: 0.15\n    parquet: 0.005\n    txt: 0.04\nIDS:\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: &amp;id002 !!python/tuple\n    - 950000\n    - 999999\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: *id002\n    ML_NODE_ID_SCALAR: 15000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\nMODEL_ROADWAY:\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\n    ML_OFFSET_METERS: -10\nconflicts: {}\ncorequisites: {}\nname: first_scenario\nprerequisites: {}\nroadway:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/roadway\nfile_format: parquet\ntransit:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/transit\nfile_format: txt\n</code></pre>"},{"location":"api/#network_wrangler.scenario--load-a-scenario-from-disk","title":"Load a scenario from disk","text":"<p>And if you want to reload scenario that you \u201cwrote\u201d, you can use the <code>load_scenario</code> function.</p> <pre><code>from network_wrangler import load_scenario\n\nmy_scenario = load_scenario(\"output_dir/scenario_name_to_use_scenario.yml\")\n</code></pre>"},{"location":"api/#network_wrangler.scenario.BASE_SCENARIO_SUGGESTED_PROPS","title":"<code>BASE_SCENARIO_SUGGESTED_PROPS: list[str] = ['road_net', 'transit_net', 'applied_projects', 'conflicts']</code>  <code>module-attribute</code>","text":"<p>List of card types that that will be applied to the transit network.</p>"},{"location":"api/#network_wrangler.scenario.ROADWAY_CARD_TYPES","title":"<code>ROADWAY_CARD_TYPES: list[str] = ['roadway_property_change', 'roadway_deletion', 'roadway_addition', 'pycode']</code>  <code>module-attribute</code>","text":"<p>List of card types that that will be applied to the transit network AFTER being applied to the roadway network.</p>"},{"location":"api/#network_wrangler.scenario.TRANSIT_CARD_TYPES","title":"<code>TRANSIT_CARD_TYPES: list[str] = ['transit_property_change', 'transit_routing_change', 'transit_route_addition', 'transit_service_deletion']</code>  <code>module-attribute</code>","text":"<p>List of card types that that will be applied to the roadway network.</p>"},{"location":"api/#network_wrangler.scenario.Scenario","title":"<code>Scenario</code>","text":"<p>Holds information about a scenario.</p> <p>Typical usage example:</p> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_roadway(\n        links_file=STPAUL_LINK_FILE,\n        nodes_file=STPAUL_NODE_FILE,\n        shapes_file=STPAUL_SHAPE_FILE,\n    ),\n    \"transit_net\": load_transit(STPAUL_DIR),\n}\n\n# create a future baseline scenario from base by searching for all cards in dir w/ baseline tag\nproject_card_directory = Path(STPAUL_DIR) / \"project_cards\"\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags=[\"baseline2050\"],\n)\n\n# check project card queue and then apply the projects\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\n\n# check applied projects, write it out, and create a summary report.\nmy_scenario.applied_projects\nmy_scenario.write(\"baseline\")\nmy_scenario.summary\n\n# Add some projects to create a build scenario based on a list of files.\nbuild_card_filenames = [\n    \"3_multiple_roadway_attribute_change.yml\",\n    \"road.prop_changes.segment.yml\",\n    \"4_simple_managed_lane.yml\",\n]\nmy_scenario.add_projects_from_files(build_card_filenames)\nmy_scenario.write(\"build2050\")\nmy_scenario.summary\n</code></pre> <p>Attributes:</p> Name Type Description <code>base_scenario</code> <code>dict</code> <p>dictionary representation of a scenario</p> <code>road_net</code> <code>Optional[RoadwayNetwork]</code> <p>instance of RoadwayNetwork for the scenario</p> <code>transit_net</code> <code>Optional[TransitNetwork]</code> <p>instance of TransitNetwork for the scenario</p> <code>project_cards</code> <code>dict[str, ProjectCard]</code> <p>Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.</p> <code>queued_projects</code> <p>Projects which are \u201cshovel ready\u201d - have had pre-requisits checked and done any required re-ordering. Similar to a git staging, project cards aren\u2019t recognized in this collecton once they are moved to applied.</p> <code>applied_projects</code> <code>list[str]</code> <p>list of project names that have been applied</p> <code>projects</code> <p>list of all projects either planned, queued, or applied</p> <code>prerequisites</code> <code>dict[str, list[str]]</code> <p>dictionary storing prerequiste info as <code>projectA: [prereqs-for-projectA]</code></p> <code>corequisites</code> <code>dict[str, list[str]]</code> <p>dictionary storing corequisite info as<code>projectA: [coreqs-for-projectA]</code></p> <code>conflicts</code> <code>dict[str, list[str]]</code> <p>dictionary storing conflict info as <code>projectA: [conflicts-for-projectA]</code></p> <code>config</code> <p>WranglerConfig instance.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class Scenario:\n    \"\"\"Holds information about a scenario.\n\n    Typical usage example:\n\n    ```python\n    my_base_year_scenario = {\n        \"road_net\": load_roadway(\n            links_file=STPAUL_LINK_FILE,\n            nodes_file=STPAUL_NODE_FILE,\n            shapes_file=STPAUL_SHAPE_FILE,\n        ),\n        \"transit_net\": load_transit(STPAUL_DIR),\n    }\n\n    # create a future baseline scenario from base by searching for all cards in dir w/ baseline tag\n    project_card_directory = Path(STPAUL_DIR) / \"project_cards\"\n    my_scenario = create_scenario(\n        base_scenario=my_base_year_scenario,\n        card_search_dir=project_card_directory,\n        filter_tags=[\"baseline2050\"],\n    )\n\n    # check project card queue and then apply the projects\n    my_scenario.queued_projects\n    my_scenario.apply_all_projects()\n\n    # check applied projects, write it out, and create a summary report.\n    my_scenario.applied_projects\n    my_scenario.write(\"baseline\")\n    my_scenario.summary\n\n    # Add some projects to create a build scenario based on a list of files.\n    build_card_filenames = [\n        \"3_multiple_roadway_attribute_change.yml\",\n        \"road.prop_changes.segment.yml\",\n        \"4_simple_managed_lane.yml\",\n    ]\n    my_scenario.add_projects_from_files(build_card_filenames)\n    my_scenario.write(\"build2050\")\n    my_scenario.summary\n    ```\n\n    Attributes:\n        base_scenario: dictionary representation of a scenario\n        road_net: instance of RoadwayNetwork for the scenario\n        transit_net: instance of TransitNetwork for the scenario\n        project_cards: Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.\n        queued_projects: Projects which are \"shovel ready\" - have had pre-requisits checked and\n            done any required re-ordering. Similar to a git staging, project cards aren't\n            recognized in this collecton once they are moved to applied.\n        applied_projects: list of project names that have been applied\n        projects: list of all projects either planned, queued, or applied\n        prerequisites:  dictionary storing prerequiste info as `projectA: [prereqs-for-projectA]`\n        corequisites:  dictionary storing corequisite info as`projectA: [coreqs-for-projectA]`\n        conflicts: dictionary storing conflict info as `projectA: [conflicts-for-projectA]`\n        config: WranglerConfig instance.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_scenario: Union[Scenario, dict],\n        project_card_list: Optional[list[ProjectCard]] = None,\n        config: Optional[Union[WranglerConfig, dict, Path, list[Path]]] = None,\n        name: str = \"\",\n    ):\n        \"\"\"Constructor.\n\n        Args:\n            base_scenario: A base scenario object to base this isntance off of, or a dict which\n                describes the scenario attributes including applied projects and respective\n                conflicts. `{\"applied_projects\": [],\"conflicts\":{...}}`\n            project_card_list: Optional list of ProjectCard instances to add to planned projects.\n                Defaults to None.\n            config: WranglerConfig instance or a dictionary of configuration settings or a path to\n                one or more configuration files. Configurations that are not explicity set will\n                default to the values in the default configuration in\n                `/configs/wrangler/default.yml`.\n            name: Optional name for the scenario.\n        \"\"\"\n        WranglerLogger.info(\"Creating Scenario\")\n        self.config = load_wrangler_config(config)\n\n        if project_card_list is None:\n            project_card_list = []\n\n        if isinstance(base_scenario, Scenario):\n            base_scenario = base_scenario.__dict__\n\n        self.base_scenario: dict = extract_base_scenario_metadata(base_scenario)\n\n        if not set(BASE_SCENARIO_SUGGESTED_PROPS) &lt;= set(base_scenario.keys()):\n            WranglerLogger.warning(\n                f\"Base_scenario doesn't contain {BASE_SCENARIO_SUGGESTED_PROPS}\"\n            )\n        self.name: str = name\n        # if the base scenario had roadway or transit networks, use them as the basis.\n        self.road_net: Optional[RoadwayNetwork] = copy.deepcopy(\n            base_scenario.pop(\"road_net\", None)\n        )\n\n        self.transit_net: Optional[TransitNetwork] = copy.deepcopy(\n            base_scenario.pop(\"transit_net\", None)\n        )\n        if self.road_net and self.transit_net:\n            self.transit_net.road_net = self.road_net\n\n        # Set configs for networks to be the same as scenario.\n        if isinstance(self.road_net, RoadwayNetwork):\n            self.road_net.config = self.config\n        if isinstance(self.transit_net, TransitNetwork):\n            self.transit_net.config = self.config\n\n        self.project_cards: dict[str, ProjectCard] = {}\n        self._planned_projects: list[str] = []\n        self._queued_projects = None\n        self.applied_projects: list[str] = base_scenario.pop(\"applied_projects\", [])\n\n        self.prerequisites: dict[str, list[str]] = base_scenario.pop(\"prerequisites\", {})\n        self.corequisites: dict[str, list[str]] = base_scenario.pop(\"corequisites\", {})\n        self.conflicts: dict[str, list[str]] = base_scenario.pop(\"conflicts\", {})\n\n        for p in project_card_list:\n            self._add_project(p)\n\n    @property\n    def projects(self):\n        \"\"\"Returns a list of all projects in the scenario: applied and planned.\"\"\"\n        return self.applied_projects + self._planned_projects\n\n    @property\n    def queued_projects(self):\n        \"\"\"Returns a list version of _queued_projects queue.\n\n        Queued projects are thos that have been planned, have all pre-requisites satisfied, and\n        have been ordered based on pre-requisites.\n\n        If no queued projects, will dynamically generate from planned projects based on\n        pre-requisites and return the queue.\n        \"\"\"\n        if not self._queued_projects:\n            self._check_projects_requirements_satisfied(self._planned_projects)\n            self._queued_projects = self.order_projects(self._planned_projects)\n        return list(self._queued_projects)\n\n    def __str__(self):\n        \"\"\"String representation of the Scenario object.\"\"\"\n        s = [f\"{key}: {value}\" for key, value in self.__dict__.items()]\n        return \"\\n\".join(s)\n\n    def _add_dependencies(self, project_name, dependencies: dict) -&gt; None:\n        \"\"\"Add dependencies from a project card to relevant scenario variables.\n\n        Updates existing \"prerequisites\", \"corequisites\" and \"conflicts\".\n        Lowercases everything to enable string matching.\n\n        Args:\n            project_name: name of project you are adding dependencies for.\n            dependencies: Dictionary of depndencies by dependency type and list of associated\n                projects.\n        \"\"\"\n        project_name = project_name.lower()\n\n        for d, v in dependencies.items():\n            _dep = list(map(str.lower, v))\n            WranglerLogger.debug(f\"Adding {_dep} to {project_name} dependency table.\")\n            self.__dict__[d].update({project_name: _dep})\n\n    def _add_project(\n        self,\n        project_card: ProjectCard,\n        validate: bool = True,\n        filter_tags: Optional[list[str]] = None,\n    ) -&gt; None:\n        \"\"\"Adds a single ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Resets scenario queued_projects.\n\n        Args:\n            project_card (ProjectCard): ProjectCard instance to add to scenario.\n            validate (bool, optional): If True, will validate the projectcard before\n                being adding it to the scenario. Defaults to True.\n            filter_tags: If used, will only add the project card if\n                its tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n\n        \"\"\"\n        filter_tags = filter_tags or []\n        project_name = project_card.project.lower()\n        filter_tags = list(map(str.lower, filter_tags))\n\n        if project_name in self.projects:\n            msg = f\"Names not unique from existing scenario projects: {project_card.project}\"\n            raise ProjectCardError(msg)\n\n        if filter_tags and set(project_card.tags).isdisjoint(set(filter_tags)):\n            WranglerLogger.debug(\n                f\"Skipping {project_name} - no overlapping tags with {filter_tags}.\"\n            )\n            return\n\n        if validate:\n            project_card.validate()\n\n        WranglerLogger.info(f\"Adding {project_name} to scenario.\")\n        self.project_cards[project_name] = project_card\n        self._planned_projects.append(project_name)\n        self._queued_projects = None\n        self._add_dependencies(project_name, project_card.dependencies)\n\n    def add_project_cards(\n        self,\n        project_card_list: list[ProjectCard],\n        validate: bool = True,\n        filter_tags: Optional[list[str]] = None,\n    ) -&gt; None:\n        \"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Args:\n            project_card_list: List of ProjectCard instances to add to\n                scenario.\n            validate (bool, optional): If True, will require each ProjectCard is validated before\n                being added to scenario. Defaults to True.\n            filter_tags: If used, will filter ProjectCard instances\n                and only add those whose tags match one or more of these filter_tags.\n                Defaults to [] - which means no tag-filtering will occur.\n        \"\"\"\n        filter_tags = filter_tags or []\n        for p in project_card_list:\n            self._add_project(p, validate=validate, filter_tags=filter_tags)\n\n    def _check_projects_requirements_satisfied(self, project_list: list[str]):\n        \"\"\"Checks all requirements are satisified to apply this specific set of projects.\n\n        Including:\n        1. has an associaed project card\n        2. is in scenario's planned projects\n        3. pre-requisites satisfied\n        4. co-requisies satisfied by applied or co-applied projects\n        5. no conflicing applied or co-applied projects\n\n        Args:\n            project_list: list of projects to check requirements for.\n        \"\"\"\n        self._check_projects_planned(project_list)\n        self._check_projects_have_project_cards(project_list)\n        self._check_projects_prerequisites(project_list)\n        self._check_projects_corequisites(project_list)\n        self._check_projects_conflicts(project_list)\n\n    def _check_projects_planned(self, project_names: list[str]) -&gt; None:\n        \"\"\"Checks that a list of projects are in the scenario's planned projects.\"\"\"\n        _missing_ps = [p for p in project_names if p not in self._planned_projects]\n        if _missing_ps:\n            msg = f\"Projects are not in planned projects: \\n {_missing_ps}. \\\n                Add them by using add_project_cards().\"\n            WranglerLogger.debug(msg)\n            raise ValueError(msg)\n\n    def _check_projects_have_project_cards(self, project_list: list[str]) -&gt; bool:\n        \"\"\"Checks that a list of projects has an associated project card in the scenario.\"\"\"\n        _missing = [p for p in project_list if p not in self.project_cards]\n        if _missing:\n            WranglerLogger.error(\n                f\"Projects referenced which are missing project cards: {_missing}\"\n            )\n            return False\n        return True\n\n    def _check_projects_prerequisites(self, project_names: list[str]) -&gt; None:\n        \"\"\"Check a list of projects' pre-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.prerequisites.keys())):\n            return\n        _prereqs = []\n        for p in project_names:\n            _prereqs += self.prerequisites.get(p, [])\n        _projects_applied = self.applied_projects + project_names\n        _missing = list(set(_prereqs) - set(_projects_applied))\n        if _missing:\n            WranglerLogger.debug(\n                f\"project_names: {project_names}\\nprojects_have_or_will_be_applied: \\\n                    {_projects_applied}\\nmissing: {_missing}\"\n            )\n            msg = f\"Missing {len(_missing)} pre-requisites.\"\n            raise ScenarioPrerequisiteError(msg)\n\n    def _check_projects_corequisites(self, project_names: list[str]) -&gt; None:\n        \"\"\"Check a list of projects' co-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.corequisites.keys())):\n            return\n        _coreqs = []\n        for p in project_names:\n            _coreqs += self.corequisites.get(p, [])\n        _projects_applied = self.applied_projects + project_names\n        _missing = list(set(_coreqs) - set(_projects_applied))\n        if _missing:\n            WranglerLogger.debug(\n                f\"project_names: {project_names}\\nprojects_have_or_will_be_applied: \\\n                    {_projects_applied}\\nmissing: {_missing}\"\n            )\n            msg = f\"Missing {len(_missing)} corequisites.\"\n            raise ScenarioCorequisiteError(msg)\n\n    def _check_projects_conflicts(self, project_names: list[str]) -&gt; None:\n        \"\"\"Checks that list of projects' conflicts have not been or will be applied to scenario.\"\"\"\n        # WranglerLogger.debug(\"Checking Conflicts...\")\n        projects_to_check = project_names + self.applied_projects\n        # WranglerLogger.debug(f\"\\nprojects_to_check:{projects_to_check}\\nprojects_with_conflicts:{set(self.conflicts.keys())}\")\n        if set(projects_to_check).isdisjoint(set(self.conflicts.keys())):\n            # WranglerLogger.debug(\"Projects have no conflicts to check\")\n            return\n        _conflicts = []\n        for p in project_names:\n            _conflicts += self.conflicts.get(p, [])\n        _conflict_problems = [p for p in _conflicts if p in projects_to_check]\n        if _conflict_problems:\n            WranglerLogger.warning(f\"Conflict Problems: \\n{_conflict_problems}\")\n            _conf_dict = {\n                k: v\n                for k, v in self.conflicts.items()\n                if k in projects_to_check and not set(v).isdisjoint(set(_conflict_problems))\n            }\n            WranglerLogger.debug(f\"Problematic Conflicts: \\n{_conf_dict}\")\n            msg = f\"Found {len(_conflict_problems)} conflicts: {_conflict_problems}\"\n            raise ScenarioConflictError(msg)\n\n    def order_projects(self, project_list: list[str]) -&gt; deque:\n        \"\"\"Orders a list of projects based on moving up pre-requisites into a deque.\n\n        Args:\n            project_list: list of projects to order\n\n        Returns: deque for applying projects.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n        assert self._check_projects_have_project_cards(project_list)\n\n        # build prereq (adjacency) list for topological sort\n        adjacency_list: dict[str, list] = defaultdict(list)\n        visited_list: dict[str, bool] = defaultdict(bool)\n\n        for project in project_list:\n            visited_list[project] = False\n            if not self.prerequisites.get(project):\n                continue\n            for prereq in self.prerequisites[project]:\n                # this will always be true, else would have been flagged in missing \\\n                # prerequsite check, but just in case\n                if prereq.lower() in project_list:\n                    if adjacency_list.get(prereq.lower()):\n                        adjacency_list[prereq.lower()].append(project)\n                    else:\n                        adjacency_list[prereq.lower()] = [project]\n\n        # sorted_project_names is topological sorted project card names (based on prerequsiite)\n        _ordered_projects = topological_sort(\n            adjacency_list=adjacency_list, visited_list=visited_list\n        )\n\n        if set(_ordered_projects) != set(project_list):\n            _missing = list(set(project_list) - set(_ordered_projects))\n            msg = f\"Project sort resulted in missing projects: {_missing}\"\n            raise ValueError(msg)\n\n        project_deque = deque(_ordered_projects)\n\n        WranglerLogger.debug(f\"Ordered Projects: \\n{project_deque}\")\n\n        return project_deque\n\n    def apply_all_projects(self):\n        \"\"\"Applies all planned projects in the queue.\"\"\"\n        # Call this to make sure projects are appropriately queued in hidden variable.\n        self.queued_projects  # noqa: B018\n\n        # Use hidden variable.\n        while self._queued_projects:\n            self._apply_project(self._queued_projects.popleft())\n\n        # set this so it will trigger re-queuing any more projects.\n        self._queued_projects = None\n\n    def _apply_change(self, change: Union[ProjectCard, SubProject]) -&gt; None:\n        \"\"\"Applies a specific change specified in a project card.\n\n        Change type must be in at least one of:\n        - ROADWAY_CARD_TYPES\n        - TRANSIT_CARD_TYPES\n\n        Args:\n            change: a project card or subproject card\n        \"\"\"\n        if change.change_type in ROADWAY_CARD_TYPES:\n            if not self.road_net:\n                msg = \"Missing Roadway Network\"\n                raise ValueError(msg)\n            if change.change_type in SECONDARY_TRANSIT_CARD_TYPES and self.transit_net:\n                self.road_net.apply(change, transit_net=self.transit_net)\n            else:\n                self.road_net.apply(change)\n        if change.change_type in TRANSIT_CARD_TYPES:\n            if not self.transit_net:\n                msg = \"Missing Transit Network\"\n                raise ValueError(msg)\n            self.transit_net.apply(change)\n\n        if change.change_type not in ROADWAY_CARD_TYPES + TRANSIT_CARD_TYPES:\n            msg = f\"Project {change.project}: Don't understand project cat: {change.change_type}\"\n            raise ProjectCardError(msg)\n\n    def _apply_project(self, project_name: str) -&gt; None:\n        \"\"\"Applies project card to scenario.\n\n        If a list of changes is specified in referenced project card, iterates through each change.\n\n        Args:\n            project_name (str): name of project to be applied.\n        \"\"\"\n        project_name = project_name.lower()\n\n        WranglerLogger.info(f\"Applying {project_name} from file:\\\n                            {self.project_cards[project_name].file}\")\n\n        p = self.project_cards[project_name]\n        WranglerLogger.debug(f\"types: {p.change_types}\")\n        WranglerLogger.debug(f\"type: {p.change_type}\")\n        if p._sub_projects:\n            for sp in p._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp)\n\n        else:\n            self._apply_change(p)\n\n        self._planned_projects.remove(project_name)\n        self.applied_projects.append(project_name)\n\n    def apply_projects(self, project_list: list[str]):\n        \"\"\"Applies a specific list of projects from the planned project queue.\n\n        Will order the list of projects based on pre-requisites.\n\n        NOTE: does not check co-requisites b/c that isn't possible when applying a single project.\n\n        Args:\n            project_list: List of projects to be applied. All need to be in the planned project\n                queue.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n\n        self._check_projects_requirements_satisfied(project_list)\n        ordered_project_queue = self.order_projects(project_list)\n\n        while ordered_project_queue:\n            self._apply_project(ordered_project_queue.popleft())\n\n        # Set so that when called again it will retrigger queueing from planned projects.\n        self._ordered_projects = None\n\n    def write(\n        self,\n        path: Path,\n        name: str,\n        overwrite: bool = True,\n        roadway_write: bool = True,\n        transit_write: bool = True,\n        projects_write: bool = True,\n        roadway_convert_complex_link_properties_to_single_field: bool = False,\n        roadway_out_dir: Optional[Path] = None,\n        roadway_prefix: Optional[str] = None,\n        roadway_file_format: RoadwayFileTypes = \"parquet\",\n        roadway_true_shape: bool = False,\n        transit_out_dir: Optional[Path] = None,\n        transit_prefix: Optional[str] = None,\n        transit_file_format: TransitFileTypes = \"txt\",\n        projects_out_dir: Optional[Path] = None,\n    ) -&gt; Path:\n        \"\"\"Writes scenario networks and summary to disk and returns path to scenario file.\n\n        Args:\n            path: Path to write scenario networks and scenario summary to.\n            name: Name to use.\n            overwrite: If True, will overwrite the files if they already exist.\n            roadway_write: If True, will write out the roadway network.\n            transit_write: If True, will write out the transit network.\n            projects_write: If True, will write out the project cards.\n            roadway_convert_complex_link_properties_to_single_field: If True, will convert complex\n                link properties to a single field.\n            roadway_out_dir: Path to write the roadway network files to.\n            roadway_prefix: Prefix to add to the file name.\n            roadway_file_format: File format to write the roadway network to\n            roadway_true_shape: If True, will write the true shape of the roadway network\n            transit_out_dir: Path to write the transit network files to.\n            transit_prefix: Prefix to add to the file name.\n            transit_file_format: File format to write the transit network to\n            projects_out_dir: Path to write the project cards to.\n        \"\"\"\n        path = Path(path)\n        path.mkdir(parents=True, exist_ok=True)\n\n        if self.road_net and roadway_write:\n            if roadway_out_dir is None:\n                roadway_out_dir = path / \"roadway\"\n            roadway_out_dir.mkdir(parents=True, exist_ok=True)\n\n            write_roadway(\n                net=self.road_net,\n                out_dir=roadway_out_dir,\n                prefix=roadway_prefix or name,\n                convert_complex_link_properties_to_single_field=roadway_convert_complex_link_properties_to_single_field,\n                file_format=roadway_file_format,\n                true_shape=roadway_true_shape,\n                overwrite=overwrite,\n            )\n        if self.transit_net and transit_write:\n            if transit_out_dir is None:\n                transit_out_dir = path / \"transit\"\n            transit_out_dir.mkdir(parents=True, exist_ok=True)\n            write_transit(\n                self.transit_net,\n                out_dir=transit_out_dir,\n                prefix=transit_prefix or name,\n                file_format=transit_file_format,\n                overwrite=overwrite,\n            )\n        if projects_write:\n            if projects_out_dir is None:\n                projects_out_dir = path / \"projects\"\n            write_applied_projects(\n                self,\n                out_dir=projects_out_dir,\n                overwrite=overwrite,\n            )\n\n        scenario_data = self.summary\n        if transit_write:\n            scenario_data[\"transit\"] = {\n                \"dir\": str(transit_out_dir),\n                \"file_format\": transit_file_format,\n            }\n        if roadway_write:\n            scenario_data[\"roadway\"] = {\n                \"dir\": str(roadway_out_dir),\n                \"file_format\": roadway_file_format,\n            }\n        if projects_write:\n            scenario_data[\"project_cards\"] = {\"dir\": str(projects_out_dir)}\n        scenario_file_path = Path(path) / f\"{name}_scenario.yml\"\n        with scenario_file_path.open(\"w\") as f:\n            yaml.dump(scenario_data, f, default_flow_style=False, allow_unicode=True)\n        return scenario_file_path\n\n    @property\n    def summary(self) -&gt; dict:\n        \"\"\"A high level summary of the created scenario and public attributes.\"\"\"\n        skip = [\"road_net\", \"base_scenario\", \"transit_net\", \"project_cards\", \"config\"]\n        summary_dict = {\n            k: v for k, v in self.__dict__.items() if not k.startswith(\"_\") and k not in skip\n        }\n        summary_dict[\"config\"] = self.config.to_dict()\n\n        \"\"\"\n        # Handle nested dictionary for \"base_scenario\"\n        skip_base = [\"project_cards\"]\n        if \"base_scenario\" in self.__dict__:\n            base_summary_dict = {\n                k: v\n                for k, v in self.base_scenario.items()\n                if not k.startswith(\"_\") and k not in skip_base\n            }\n            summary_dict[\"base_scenario\"] = base_summary_dict\n        \"\"\"\n\n        return summary_dict\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.projects","title":"<code>projects</code>  <code>property</code>","text":"<p>Returns a list of all projects in the scenario: applied and planned.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.queued_projects","title":"<code>queued_projects</code>  <code>property</code>","text":"<p>Returns a list version of _queued_projects queue.</p> <p>Queued projects are thos that have been planned, have all pre-requisites satisfied, and have been ordered based on pre-requisites.</p> <p>If no queued projects, will dynamically generate from planned projects based on pre-requisites and return the queue.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.summary","title":"<code>summary: dict</code>  <code>property</code>","text":"<p>A high level summary of the created scenario and public attributes.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.__init__","title":"<code>__init__(base_scenario, project_card_list=None, config=None, name='')</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>base_scenario</code> <code>Union[Scenario, dict]</code> <p>A base scenario object to base this isntance off of, or a dict which describes the scenario attributes including applied projects and respective conflicts. <code>{\"applied_projects\": [],\"conflicts\":{...}}</code></p> required <code>project_card_list</code> <code>Optional[list[ProjectCard]]</code> <p>Optional list of ProjectCard instances to add to planned projects. Defaults to None.</p> <code>None</code> <code>config</code> <code>Optional[Union[WranglerConfig, dict, Path, list[Path]]]</code> <p>WranglerConfig instance or a dictionary of configuration settings or a path to one or more configuration files. Configurations that are not explicity set will default to the values in the default configuration in <code>/configs/wrangler/default.yml</code>.</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional name for the scenario.</p> <code>''</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_scenario: Union[Scenario, dict],\n    project_card_list: Optional[list[ProjectCard]] = None,\n    config: Optional[Union[WranglerConfig, dict, Path, list[Path]]] = None,\n    name: str = \"\",\n):\n    \"\"\"Constructor.\n\n    Args:\n        base_scenario: A base scenario object to base this isntance off of, or a dict which\n            describes the scenario attributes including applied projects and respective\n            conflicts. `{\"applied_projects\": [],\"conflicts\":{...}}`\n        project_card_list: Optional list of ProjectCard instances to add to planned projects.\n            Defaults to None.\n        config: WranglerConfig instance or a dictionary of configuration settings or a path to\n            one or more configuration files. Configurations that are not explicity set will\n            default to the values in the default configuration in\n            `/configs/wrangler/default.yml`.\n        name: Optional name for the scenario.\n    \"\"\"\n    WranglerLogger.info(\"Creating Scenario\")\n    self.config = load_wrangler_config(config)\n\n    if project_card_list is None:\n        project_card_list = []\n\n    if isinstance(base_scenario, Scenario):\n        base_scenario = base_scenario.__dict__\n\n    self.base_scenario: dict = extract_base_scenario_metadata(base_scenario)\n\n    if not set(BASE_SCENARIO_SUGGESTED_PROPS) &lt;= set(base_scenario.keys()):\n        WranglerLogger.warning(\n            f\"Base_scenario doesn't contain {BASE_SCENARIO_SUGGESTED_PROPS}\"\n        )\n    self.name: str = name\n    # if the base scenario had roadway or transit networks, use them as the basis.\n    self.road_net: Optional[RoadwayNetwork] = copy.deepcopy(\n        base_scenario.pop(\"road_net\", None)\n    )\n\n    self.transit_net: Optional[TransitNetwork] = copy.deepcopy(\n        base_scenario.pop(\"transit_net\", None)\n    )\n    if self.road_net and self.transit_net:\n        self.transit_net.road_net = self.road_net\n\n    # Set configs for networks to be the same as scenario.\n    if isinstance(self.road_net, RoadwayNetwork):\n        self.road_net.config = self.config\n    if isinstance(self.transit_net, TransitNetwork):\n        self.transit_net.config = self.config\n\n    self.project_cards: dict[str, ProjectCard] = {}\n    self._planned_projects: list[str] = []\n    self._queued_projects = None\n    self.applied_projects: list[str] = base_scenario.pop(\"applied_projects\", [])\n\n    self.prerequisites: dict[str, list[str]] = base_scenario.pop(\"prerequisites\", {})\n    self.corequisites: dict[str, list[str]] = base_scenario.pop(\"corequisites\", {})\n    self.conflicts: dict[str, list[str]] = base_scenario.pop(\"conflicts\", {})\n\n    for p in project_card_list:\n        self._add_project(p)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the Scenario object.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def __str__(self):\n    \"\"\"String representation of the Scenario object.\"\"\"\n    s = [f\"{key}: {value}\" for key, value in self.__dict__.items()]\n    return \"\\n\".join(s)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.add_project_cards","title":"<code>add_project_cards(project_card_list, validate=True, filter_tags=None)</code>","text":"<p>Adds a list of ProjectCard instances to the Scenario.</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>project_card_list</code> <code>list[ProjectCard]</code> <p>List of ProjectCard instances to add to scenario.</p> required <code>validate</code> <code>bool</code> <p>If True, will require each ProjectCard is validated before being added to scenario. Defaults to True.</p> <code>True</code> <code>filter_tags</code> <code>Optional[list[str]]</code> <p>If used, will filter ProjectCard instances and only add those whose tags match one or more of these filter_tags. Defaults to [] - which means no tag-filtering will occur.</p> <code>None</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def add_project_cards(\n    self,\n    project_card_list: list[ProjectCard],\n    validate: bool = True,\n    filter_tags: Optional[list[str]] = None,\n) -&gt; None:\n    \"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        project_card_list: List of ProjectCard instances to add to\n            scenario.\n        validate (bool, optional): If True, will require each ProjectCard is validated before\n            being added to scenario. Defaults to True.\n        filter_tags: If used, will filter ProjectCard instances\n            and only add those whose tags match one or more of these filter_tags.\n            Defaults to [] - which means no tag-filtering will occur.\n    \"\"\"\n    filter_tags = filter_tags or []\n    for p in project_card_list:\n        self._add_project(p, validate=validate, filter_tags=filter_tags)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_all_projects","title":"<code>apply_all_projects()</code>","text":"<p>Applies all planned projects in the queue.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_all_projects(self):\n    \"\"\"Applies all planned projects in the queue.\"\"\"\n    # Call this to make sure projects are appropriately queued in hidden variable.\n    self.queued_projects  # noqa: B018\n\n    # Use hidden variable.\n    while self._queued_projects:\n        self._apply_project(self._queued_projects.popleft())\n\n    # set this so it will trigger re-queuing any more projects.\n    self._queued_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_projects","title":"<code>apply_projects(project_list)</code>","text":"<p>Applies a specific list of projects from the planned project queue.</p> <p>Will order the list of projects based on pre-requisites.</p> <p>NOTE: does not check co-requisites b/c that isn\u2019t possible when applying a single project.</p> <p>Parameters:</p> Name Type Description Default <code>project_list</code> <code>list[str]</code> <p>List of projects to be applied. All need to be in the planned project queue.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_projects(self, project_list: list[str]):\n    \"\"\"Applies a specific list of projects from the planned project queue.\n\n    Will order the list of projects based on pre-requisites.\n\n    NOTE: does not check co-requisites b/c that isn't possible when applying a single project.\n\n    Args:\n        project_list: List of projects to be applied. All need to be in the planned project\n            queue.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n\n    self._check_projects_requirements_satisfied(project_list)\n    ordered_project_queue = self.order_projects(project_list)\n\n    while ordered_project_queue:\n        self._apply_project(ordered_project_queue.popleft())\n\n    # Set so that when called again it will retrigger queueing from planned projects.\n    self._ordered_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.order_projects","title":"<code>order_projects(project_list)</code>","text":"<p>Orders a list of projects based on moving up pre-requisites into a deque.</p> <p>Parameters:</p> Name Type Description Default <code>project_list</code> <code>list[str]</code> <p>list of projects to order</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def order_projects(self, project_list: list[str]) -&gt; deque:\n    \"\"\"Orders a list of projects based on moving up pre-requisites into a deque.\n\n    Args:\n        project_list: list of projects to order\n\n    Returns: deque for applying projects.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n    assert self._check_projects_have_project_cards(project_list)\n\n    # build prereq (adjacency) list for topological sort\n    adjacency_list: dict[str, list] = defaultdict(list)\n    visited_list: dict[str, bool] = defaultdict(bool)\n\n    for project in project_list:\n        visited_list[project] = False\n        if not self.prerequisites.get(project):\n            continue\n        for prereq in self.prerequisites[project]:\n            # this will always be true, else would have been flagged in missing \\\n            # prerequsite check, but just in case\n            if prereq.lower() in project_list:\n                if adjacency_list.get(prereq.lower()):\n                    adjacency_list[prereq.lower()].append(project)\n                else:\n                    adjacency_list[prereq.lower()] = [project]\n\n    # sorted_project_names is topological sorted project card names (based on prerequsiite)\n    _ordered_projects = topological_sort(\n        adjacency_list=adjacency_list, visited_list=visited_list\n    )\n\n    if set(_ordered_projects) != set(project_list):\n        _missing = list(set(project_list) - set(_ordered_projects))\n        msg = f\"Project sort resulted in missing projects: {_missing}\"\n        raise ValueError(msg)\n\n    project_deque = deque(_ordered_projects)\n\n    WranglerLogger.debug(f\"Ordered Projects: \\n{project_deque}\")\n\n    return project_deque\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.write","title":"<code>write(path, name, overwrite=True, roadway_write=True, transit_write=True, projects_write=True, roadway_convert_complex_link_properties_to_single_field=False, roadway_out_dir=None, roadway_prefix=None, roadway_file_format='parquet', roadway_true_shape=False, transit_out_dir=None, transit_prefix=None, transit_file_format='txt', projects_out_dir=None)</code>","text":"<p>Writes scenario networks and summary to disk and returns path to scenario file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to write scenario networks and scenario summary to.</p> required <code>name</code> <code>str</code> <p>Name to use.</p> required <code>overwrite</code> <code>bool</code> <p>If True, will overwrite the files if they already exist.</p> <code>True</code> <code>roadway_write</code> <code>bool</code> <p>If True, will write out the roadway network.</p> <code>True</code> <code>transit_write</code> <code>bool</code> <p>If True, will write out the transit network.</p> <code>True</code> <code>projects_write</code> <code>bool</code> <p>If True, will write out the project cards.</p> <code>True</code> <code>roadway_convert_complex_link_properties_to_single_field</code> <code>bool</code> <p>If True, will convert complex link properties to a single field.</p> <code>False</code> <code>roadway_out_dir</code> <code>Optional[Path]</code> <p>Path to write the roadway network files to.</p> <code>None</code> <code>roadway_prefix</code> <code>Optional[str]</code> <p>Prefix to add to the file name.</p> <code>None</code> <code>roadway_file_format</code> <code>RoadwayFileTypes</code> <p>File format to write the roadway network to</p> <code>'parquet'</code> <code>roadway_true_shape</code> <code>bool</code> <p>If True, will write the true shape of the roadway network</p> <code>False</code> <code>transit_out_dir</code> <code>Optional[Path]</code> <p>Path to write the transit network files to.</p> <code>None</code> <code>transit_prefix</code> <code>Optional[str]</code> <p>Prefix to add to the file name.</p> <code>None</code> <code>transit_file_format</code> <code>TransitFileTypes</code> <p>File format to write the transit network to</p> <code>'txt'</code> <code>projects_out_dir</code> <code>Optional[Path]</code> <p>Path to write the project cards to.</p> <code>None</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def write(\n    self,\n    path: Path,\n    name: str,\n    overwrite: bool = True,\n    roadway_write: bool = True,\n    transit_write: bool = True,\n    projects_write: bool = True,\n    roadway_convert_complex_link_properties_to_single_field: bool = False,\n    roadway_out_dir: Optional[Path] = None,\n    roadway_prefix: Optional[str] = None,\n    roadway_file_format: RoadwayFileTypes = \"parquet\",\n    roadway_true_shape: bool = False,\n    transit_out_dir: Optional[Path] = None,\n    transit_prefix: Optional[str] = None,\n    transit_file_format: TransitFileTypes = \"txt\",\n    projects_out_dir: Optional[Path] = None,\n) -&gt; Path:\n    \"\"\"Writes scenario networks and summary to disk and returns path to scenario file.\n\n    Args:\n        path: Path to write scenario networks and scenario summary to.\n        name: Name to use.\n        overwrite: If True, will overwrite the files if they already exist.\n        roadway_write: If True, will write out the roadway network.\n        transit_write: If True, will write out the transit network.\n        projects_write: If True, will write out the project cards.\n        roadway_convert_complex_link_properties_to_single_field: If True, will convert complex\n            link properties to a single field.\n        roadway_out_dir: Path to write the roadway network files to.\n        roadway_prefix: Prefix to add to the file name.\n        roadway_file_format: File format to write the roadway network to\n        roadway_true_shape: If True, will write the true shape of the roadway network\n        transit_out_dir: Path to write the transit network files to.\n        transit_prefix: Prefix to add to the file name.\n        transit_file_format: File format to write the transit network to\n        projects_out_dir: Path to write the project cards to.\n    \"\"\"\n    path = Path(path)\n    path.mkdir(parents=True, exist_ok=True)\n\n    if self.road_net and roadway_write:\n        if roadway_out_dir is None:\n            roadway_out_dir = path / \"roadway\"\n        roadway_out_dir.mkdir(parents=True, exist_ok=True)\n\n        write_roadway(\n            net=self.road_net,\n            out_dir=roadway_out_dir,\n            prefix=roadway_prefix or name,\n            convert_complex_link_properties_to_single_field=roadway_convert_complex_link_properties_to_single_field,\n            file_format=roadway_file_format,\n            true_shape=roadway_true_shape,\n            overwrite=overwrite,\n        )\n    if self.transit_net and transit_write:\n        if transit_out_dir is None:\n            transit_out_dir = path / \"transit\"\n        transit_out_dir.mkdir(parents=True, exist_ok=True)\n        write_transit(\n            self.transit_net,\n            out_dir=transit_out_dir,\n            prefix=transit_prefix or name,\n            file_format=transit_file_format,\n            overwrite=overwrite,\n        )\n    if projects_write:\n        if projects_out_dir is None:\n            projects_out_dir = path / \"projects\"\n        write_applied_projects(\n            self,\n            out_dir=projects_out_dir,\n            overwrite=overwrite,\n        )\n\n    scenario_data = self.summary\n    if transit_write:\n        scenario_data[\"transit\"] = {\n            \"dir\": str(transit_out_dir),\n            \"file_format\": transit_file_format,\n        }\n    if roadway_write:\n        scenario_data[\"roadway\"] = {\n            \"dir\": str(roadway_out_dir),\n            \"file_format\": roadway_file_format,\n        }\n    if projects_write:\n        scenario_data[\"project_cards\"] = {\"dir\": str(projects_out_dir)}\n    scenario_file_path = Path(path) / f\"{name}_scenario.yml\"\n    with scenario_file_path.open(\"w\") as f:\n        yaml.dump(scenario_data, f, default_flow_style=False, allow_unicode=True)\n    return scenario_file_path\n</code></pre>"},{"location":"api/#network_wrangler.scenario.build_scenario_from_config","title":"<code>build_scenario_from_config(scenario_config)</code>","text":"<p>Builds a scenario from a dictionary configuration.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_config</code> <code>Union[Path, list[Path], ScenarioConfig, dict]</code> <p>Path to a configuration file, list of paths, or a dictionary of configuration.</p> required Source code in <code>network_wrangler/scenario.py</code> <pre><code>def build_scenario_from_config(\n    scenario_config: Union[Path, list[Path], ScenarioConfig, dict],\n) -&gt; Scenario:\n    \"\"\"Builds a scenario from a dictionary configuration.\n\n    Args:\n        scenario_config: Path to a configuration file, list of paths, or a dictionary of\n            configuration.\n    \"\"\"\n    WranglerLogger.info(f\"Building Scenario from Configuration: {scenario_config}\")\n    scenario_config = load_scenario_config(scenario_config)\n    WranglerLogger.debug(f\"{pprint.pformat(scenario_config)}\")\n\n    base_scenario = create_base_scenario(\n        **scenario_config.base_scenario.to_dict(), config=scenario_config.wrangler_config\n    )\n\n    my_scenario = create_scenario(\n        base_scenario=base_scenario,\n        config=scenario_config.wrangler_config,\n        **scenario_config.projects.to_dict(),\n    )\n\n    my_scenario.apply_all_projects()\n\n    write_args = _scenario_output_config_to_scenario_write(scenario_config.output_scenario)\n    my_scenario.write(**write_args, name=scenario_config.name)\n    return my_scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.create_base_scenario","title":"<code>create_base_scenario(roadway=None, transit=None, applied_projects=None, conflicts=None, config=DefaultConfig)</code>","text":"<p>Creates a base scenario dictionary from roadway and transit network files.</p> <p>Parameters:</p> Name Type Description Default <code>roadway</code> <code>Optional[dict]</code> <p>kwargs for load_roadway_from_dir</p> <code>None</code> <code>transit</code> <code>Optional[dict]</code> <p>kwargs for load_transit from dir</p> <code>None</code> <code>applied_projects</code> <code>Optional[list]</code> <p>list of projects that have been applied to the base scenario.</p> <code>None</code> <code>conflicts</code> <code>Optional[dict]</code> <p>dictionary of conflicts that have been identified in the base scenario. Takes the format of <code>{\"projectA\": [\"projectB\", \"projectC\"]}</code> showing that projectA, which has been applied, conflicts with projectB and projectC and so they shouldn\u2019t be applied in the future.</p> <code>None</code> <code>config</code> <code>WranglerConfig</code> <p>WranglerConfig instance.</p> <code>DefaultConfig</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def create_base_scenario(\n    roadway: Optional[dict] = None,\n    transit: Optional[dict] = None,\n    applied_projects: Optional[list] = None,\n    conflicts: Optional[dict] = None,\n    config: WranglerConfig = DefaultConfig,\n) -&gt; dict:\n    \"\"\"Creates a base scenario dictionary from roadway and transit network files.\n\n    Args:\n        roadway: kwargs for load_roadway_from_dir\n        transit: kwargs for load_transit from dir\n        applied_projects: list of projects that have been applied to the base scenario.\n        conflicts: dictionary of conflicts that have been identified in the base scenario.\n            Takes the format of `{\"projectA\": [\"projectB\", \"projectC\"]}` showing that projectA,\n            which has been applied, conflicts with projectB and projectC and so they shouldn't be\n            applied in the future.\n        config: WranglerConfig instance.\n    \"\"\"\n    applied_projects = applied_projects or []\n    conflicts = conflicts or {}\n    if roadway:\n        road_net = load_roadway_from_dir(**roadway, config=config)\n    else:\n        road_net = None\n        WranglerLogger.info(\n            \"No roadway directory specified, base scenario will have empty roadway network.\"\n        )\n\n    if transit:\n        transit_net = load_transit(**transit, config=config)\n        if roadway:\n            transit_net.road_net = road_net\n    else:\n        transit_net = None\n        WranglerLogger.info(\n            \"No transit directory specified, base scenario will have empty transit network.\"\n        )\n\n    base_scenario = {\n        \"road_net\": road_net,\n        \"transit_net\": transit_net,\n        \"applied_projects\": applied_projects,\n        \"conflicts\": conflicts,\n    }\n\n    return base_scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.create_scenario","title":"<code>create_scenario(base_scenario=None, name=datetime.now().strftime('%Y%m%d%H%M%S'), project_card_list=None, project_card_filepath=None, filter_tags=None, config=None)</code>","text":"<p>Creates scenario from a base scenario and adds project cards.</p> <p>Project cards can be added using any/all of the following methods: 1. List of ProjectCard instances 2. List of ProjectCard files 3. Directory and optional glob search to find project card files in</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> Name Type Description Default <code>base_scenario</code> <code>Optional[Union[Scenario, dict]]</code> <p>base Scenario scenario instances of dictionary of attributes.</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional name for the scenario. Defaults to current datetime.</p> <code>strftime('%Y%m%d%H%M%S')</code> <code>project_card_list</code> <p>List of ProjectCard instances to create Scenario from. Defaults to [].</p> <code>None</code> <code>project_card_filepath</code> <code>Optional[Union[list[Path], Path]]</code> <p>where the project card is.  A single path, list of paths,</p> <code>None</code> <code>filter_tags</code> <code>Optional[list[str]]</code> <p>If used, will only add the project card if its tags match one or more of these filter_tags. Defaults to [] which means no tag-filtering will occur.</p> <code>None</code> <code>config</code> <code>Optional[Union[dict, Path, list[Path], WranglerConfig]]</code> <p>Optional wrangler configuration file or dictionary or instance. Defaults to default config.</p> <code>None</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def create_scenario(\n    base_scenario: Optional[Union[Scenario, dict]] = None,\n    name: str = datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n    project_card_list=None,\n    project_card_filepath: Optional[Union[list[Path], Path]] = None,\n    filter_tags: Optional[list[str]] = None,\n    config: Optional[Union[dict, Path, list[Path], WranglerConfig]] = None,\n) -&gt; Scenario:\n    \"\"\"Creates scenario from a base scenario and adds project cards.\n\n    Project cards can be added using any/all of the following methods:\n    1. List of ProjectCard instances\n    2. List of ProjectCard files\n    3. Directory and optional glob search to find project card files in\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        base_scenario: base Scenario scenario instances of dictionary of attributes.\n        name: Optional name for the scenario. Defaults to current datetime.\n        project_card_list: List of ProjectCard instances to create Scenario from. Defaults\n            to [].\n        project_card_filepath: where the project card is.  A single path, list of paths,\n        a directory, or a glob pattern. Defaults to None.\n        filter_tags: If used, will only add the project card if\n            its tags match one or more of these filter_tags. Defaults to []\n            which means no tag-filtering will occur.\n        config: Optional wrangler configuration file or dictionary or instance. Defaults to\n            default config.\n    \"\"\"\n    base_scenario = base_scenario or {}\n    project_card_list = project_card_list or []\n    filter_tags = filter_tags or []\n\n    scenario = Scenario(base_scenario, config=config, name=name)\n\n    if project_card_filepath:\n        project_card_list += list(\n            read_cards(project_card_filepath, filter_tags=filter_tags).values()\n        )\n\n    if project_card_list:\n        scenario.add_project_cards(project_card_list, filter_tags=filter_tags)\n\n    return scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.extract_base_scenario_metadata","title":"<code>extract_base_scenario_metadata(base_scenario)</code>","text":"<p>Extract metadata from base scenario rather than keeping all of big files.</p> <p>Useful for summarizing a scenario.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def extract_base_scenario_metadata(base_scenario: dict) -&gt; dict:\n    \"\"\"Extract metadata from base scenario rather than keeping all of big files.\n\n    Useful for summarizing a scenario.\n    \"\"\"\n    _skip_copy = [\"road_net\", \"transit_net\", \"config\"]\n    out_dict = {k: v for k, v in base_scenario.items() if k not in _skip_copy}\n    if isinstance(base_scenario.get(\"road_net\"), RoadwayNetwork):\n        nodes_file_path = base_scenario[\"road_net\"].nodes_df.attrs.get(\"source_file\", None)\n        if nodes_file_path is not None:\n            out_dict[\"roadway\"] = {\n                \"dir\": str(Path(nodes_file_path).parent),\n                \"file_format\": str(nodes_file_path.suffix).lstrip(\".\"),\n            }\n    if isinstance(base_scenario.get(\"transit_net\"), TransitNetwork):\n        feed_path = base_scenario[\"transit_net\"].feed.feed_path\n        if feed_path is not None:\n            out_dict[\"transit\"] = {\"dir\": str(feed_path)}\n    return out_dict\n</code></pre>"},{"location":"api/#network_wrangler.scenario.load_scenario","title":"<code>load_scenario(scenario_data, name=datetime.now().strftime('%Y%m%d%H%M%S'))</code>","text":"<p>Loads a scenario from a file written by Scenario.write() as the base scenario.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_data</code> <code>Union[dict, Path]</code> <p>Scenario data as a dict or path to scenario data file</p> required <code>name</code> <code>str</code> <p>Optional name for the scenario. Defaults to current datetime.</p> <code>strftime('%Y%m%d%H%M%S')</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def load_scenario(\n    scenario_data: Union[dict, Path],\n    name: str = datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n) -&gt; Scenario:\n    \"\"\"Loads a scenario from a file written by Scenario.write() as the base scenario.\n\n    Args:\n        scenario_data: Scenario data as a dict or path to scenario data file\n        name: Optional name for the scenario. Defaults to current datetime.\n    \"\"\"\n    if not isinstance(scenario_data, dict):\n        WranglerLogger.debug(f\"Loading Scenario from file: {scenario_data}\")\n        scenario_data = load_dict(scenario_data)\n    else:\n        WranglerLogger.debug(\"Loading Scenario from dict.\")\n\n    base_scenario_data = {\n        \"roadway\": scenario_data.get(\"roadway\"),\n        \"transit\": scenario_data.get(\"transit\"),\n        \"applied_projects\": scenario_data.get(\"applied_projects\", []),\n        \"conflicts\": scenario_data.get(\"conflicts\", {}),\n    }\n    base_scenario = _load_base_scenario_from_config(\n        base_scenario_data, config=scenario_data[\"config\"]\n    )\n    my_scenario = create_scenario(\n        base_scenario=base_scenario, name=name, config=scenario_data[\"config\"]\n    )\n    return my_scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.write_applied_projects","title":"<code>write_applied_projects(scenario, out_dir, overwrite=True)</code>","text":"<p>Summarizes all projects in a scenario to folder.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>Scenario</code> <p>Scenario instance to summarize.</p> required <code>out_dir</code> <code>Path</code> <p>Path to write the project cards.</p> required <code>overwrite</code> <code>bool</code> <p>If True, will overwrite the files if they already exist.</p> <code>True</code> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def write_applied_projects(scenario: Scenario, out_dir: Path, overwrite: bool = True) -&gt; None:\n    \"\"\"Summarizes all projects in a scenario to folder.\n\n    Args:\n        scenario: Scenario instance to summarize.\n        out_dir: Path to write the project cards.\n        overwrite: If True, will overwrite the files if they already exist.\n    \"\"\"\n    outdir = Path(out_dir)\n    prep_dir(out_dir, overwrite=overwrite)\n\n    for p in scenario.applied_projects:\n        if p in scenario.project_cards:\n            card = scenario.project_cards[p]\n        elif p in scenario.base_scenario[\"project_cards\"]:\n            card = scenario.base_scenario[\"project_cards\"][p]\n        else:\n            continue\n        filename = Path(card.__dict__.get(\"file\", f\"{p}.yml\")).name\n        outpath = outdir / filename\n        write_card(card, outpath)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork","title":"<code>RoadwayNetwork</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Representation of a Roadway Network.</p> <p>Typical usage example:</p> <pre><code>net = load_roadway(\n    links_file=MY_LINK_FILE,\n    nodes_file=MY_NODE_FILE,\n    shapes_file=MY_SHAPE_FILE,\n)\nmy_selection = {\n    \"link\": [{\"name\": [\"I 35E\"]}],\n    \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n    \"B\": {\"osm_node_id\": \"2564047368\"},\n}\nnet.get_selection(my_selection)\n\nmy_change = [\n    {\n        'property': 'lanes',\n        'existing': 1,\n        'set': 2,\n    },\n    {\n        'property': 'drive_access',\n        'set': 0,\n    },\n]\n\nmy_net.apply_roadway_feature_change(\n    my_net.get_selection(my_selection),\n    my_change\n)\n\n    net.model_net\n    net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n    _, disconnected_nodes = net.assess_connectivity(\n        mode=\"walk\",\n        ignore_end_nodes=True,\n        nodes=self.m_nodes_df,\n        links=self.m_links_df\n    )\n    write_roadway(net,filename=my_out_prefix, path=my_dir, for_model = True)\n</code></pre> <p>Attributes:</p> Name Type Description <code>nodes_df</code> <code>RoadNodesTable</code> <p>dataframe of of node records.</p> <code>links_df</code> <code>RoadLinksTable</code> <p>dataframe of link records and associated properties.</p> <code>shapes_df</code> <code>RoadShapestable</code> <p>data from of detailed shape records  This is lazily created iff it is called because shapes files can be expensive to read.</p> <code>_selections</code> <code>dict</code> <p>dictionary of stored roadway selection objects, mapped by <code>RoadwayLinkSelection.sel_key</code> or <code>RoadwayNodeSelection.sel_key</code> in case they are     made repeatedly.</p> <code>network_hash</code> <code>str</code> <p>dynamic property of the hashed value of links_df and nodes_df. Used for quickly identifying if a network has changed since various expensive operations have taken place (i.e. generating a ModelRoadwayNetwork or a network graph)</p> <code>model_net</code> <code>ModelRoadwayNetwork</code> <p>referenced <code>ModelRoadwayNetwork</code> object which will be lazily created if None or if the <code>network_hash</code> has changed.</p> <code>config</code> <code>WranglerConfig</code> <p>wrangler configuration object</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>class RoadwayNetwork(BaseModel):\n    \"\"\"Representation of a Roadway Network.\n\n    Typical usage example:\n\n    ```py\n    net = load_roadway(\n        links_file=MY_LINK_FILE,\n        nodes_file=MY_NODE_FILE,\n        shapes_file=MY_SHAPE_FILE,\n    )\n    my_selection = {\n        \"link\": [{\"name\": [\"I 35E\"]}],\n        \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n        \"B\": {\"osm_node_id\": \"2564047368\"},\n    }\n    net.get_selection(my_selection)\n\n    my_change = [\n        {\n            'property': 'lanes',\n            'existing': 1,\n            'set': 2,\n        },\n        {\n            'property': 'drive_access',\n            'set': 0,\n        },\n    ]\n\n    my_net.apply_roadway_feature_change(\n        my_net.get_selection(my_selection),\n        my_change\n    )\n\n        net.model_net\n        net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n        _, disconnected_nodes = net.assess_connectivity(\n            mode=\"walk\",\n            ignore_end_nodes=True,\n            nodes=self.m_nodes_df,\n            links=self.m_links_df\n        )\n        write_roadway(net,filename=my_out_prefix, path=my_dir, for_model = True)\n    ```\n\n    Attributes:\n        nodes_df (RoadNodesTable): dataframe of of node records.\n        links_df (RoadLinksTable): dataframe of link records and associated properties.\n        shapes_df (RoadShapestable): data from of detailed shape records  This is lazily\n            created iff it is called because shapes files can be expensive to read.\n        _selections (dict): dictionary of stored roadway selection objects, mapped by\n            `RoadwayLinkSelection.sel_key` or `RoadwayNodeSelection.sel_key` in case they are\n                made repeatedly.\n        network_hash: dynamic property of the hashed value of links_df and nodes_df. Used for\n            quickly identifying if a network has changed since various expensive operations have\n            taken place (i.e. generating a ModelRoadwayNetwork or a network graph)\n        model_net (ModelRoadwayNetwork): referenced `ModelRoadwayNetwork` object which will be\n            lazily created if None or if the `network_hash` has changed.\n        config (WranglerConfig): wrangler configuration object\n    \"\"\"\n\n    nodes_df: DataFrame[RoadNodesTable]\n    links_df: DataFrame[RoadLinksTable]\n    _shapes_df: Optional[DataFrame[RoadShapesTable]] = None\n\n    _links_file: Optional[Path] = None\n    _nodes_file: Optional[Path] = None\n    _shapes_file: Optional[Path] = None\n\n    config: WranglerConfig = DefaultConfig\n\n    _model_net: Optional[ModelRoadwayNetwork] = None\n    _selections: dict[str, Selections] = {}\n    _modal_graphs: dict[str, dict] = defaultdict(lambda: {\"graph\": None, \"hash\": None})\n\n    @field_validator(\"config\")\n    def validate_config(cls, v):\n        \"\"\"Validate config.\"\"\"\n        return load_wrangler_config(v)\n\n    @field_validator(\"nodes_df\", \"links_df\")\n    def coerce_crs(cls, v):\n        \"\"\"Coerce crs of nodes_df and links_df to LAT_LON_CRS.\"\"\"\n        if v.crs != LAT_LON_CRS:\n            WranglerLogger.warning(\n                f\"CRS of links_df ({v.crs}) doesn't match network crs {LAT_LON_CRS}. \\\n                    Changing to network crs.\"\n            )\n            v.to_crs(LAT_LON_CRS)\n        return v\n\n    @property\n    def shapes_df(self) -&gt; DataFrame[RoadShapesTable]:\n        \"\"\"Load and return RoadShapesTable.\n\n        If not already loaded, will read from shapes_file and return. If shapes_file is None,\n        will return an empty dataframe with the right schema. If shapes_df is already set, will\n        return that.\n        \"\"\"\n        if (self._shapes_df is None or self._shapes_df.empty) and self._shapes_file is not None:\n            self._shapes_df = read_shapes(\n                self._shapes_file,\n                filter_to_shape_ids=self.links_df.shape_id.to_list(),\n                config=self.config,\n            )\n        # if there is NONE, then at least create an empty dataframe with right schema\n        elif self._shapes_df is None:\n            self._shapes_df = empty_df_from_datamodel(RoadShapesTable)\n            self._shapes_df.set_index(\"shape_id_idx\", inplace=True)\n\n        return self._shapes_df\n\n    @shapes_df.setter\n    def shapes_df(self, value):\n        self._shapes_df = df_to_shapes_df(value, config=self.config)\n\n    @property\n    def network_hash(self) -&gt; str:\n        \"\"\"Hash of the links and nodes dataframes.\"\"\"\n        _value = str.encode(self.links_df.df_hash() + \"-\" + self.nodes_df.df_hash())\n\n        _hash = hashlib.sha256(_value).hexdigest()\n        return _hash\n\n    @property\n    def model_net(self) -&gt; ModelRoadwayNetwork:\n        \"\"\"Return a ModelRoadwayNetwork object for this network.\"\"\"\n        if self._model_net is None or self._model_net._net_hash != self.network_hash:\n            self._model_net = ModelRoadwayNetwork(self)\n        return self._model_net\n\n    @property\n    def summary(self) -&gt; dict:\n        \"\"\"Quick summary dictionary of number of links, nodes.\"\"\"\n        d = {\n            \"links\": len(self.links_df),\n            \"nodes\": len(self.nodes_df),\n        }\n        return d\n\n    @property\n    def link_shapes_df(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Add shape geometry to links if available.\n\n        returns: shapes merged to links dataframe\n        \"\"\"\n        _links_df = copy.deepcopy(self.links_df)\n        link_shapes_df = _links_df.merge(\n            self.shapes_df,\n            left_on=\"shape_id\",\n            right_on=\"shape_id\",\n            how=\"left\",\n        )\n        link_shapes_df[\"geometry\"] = link_shapes_df[\"geometry_y\"].combine_first(\n            link_shapes_df[\"geometry_x\"]\n        )\n        link_shapes_df = link_shapes_df.drop(columns=[\"geometry_x\", \"geometry_y\"])\n        link_shapes_df = link_shapes_df.set_geometry(\"geometry\")\n        return link_shapes_df\n\n    def get_property_by_timespan_and_group(\n        self,\n        link_property: str,\n        category: Optional[Union[str, int]] = DEFAULT_CATEGORY,\n        timespan: Optional[TimespanString] = DEFAULT_TIMESPAN,\n        strict_timespan_match: bool = False,\n        min_overlap_minutes: int = 60,\n    ) -&gt; Any:\n        \"\"\"Returns a new dataframe with model_link_id and link property by category and timespan.\n\n        Convenience method for backward compatability.\n\n        Args:\n            link_property: link property to query\n            category: category to query or a list of categories. Defaults to DEFAULT_CATEGORY.\n            timespan: timespan to query in the form of [\"HH:MM\",\"HH:MM\"].\n                Defaults to DEFAULT_TIMESPAN.\n            strict_timespan_match: If True, will only return links that match the timespan exactly.\n                Defaults to False.\n            min_overlap_minutes: If strict_timespan_match is False, will return links that overlap\n                with the timespan by at least this many minutes. Defaults to 60.\n        \"\"\"\n        from .links.scopes import prop_for_scope\n\n        return prop_for_scope(\n            self.links_df,\n            link_property,\n            timespan=timespan,\n            category=category,\n            strict_timespan_match=strict_timespan_match,\n            min_overlap_minutes=min_overlap_minutes,\n        )\n\n    def get_selection(\n        self,\n        selection_dict: Union[dict, SelectFacility],\n        overwrite: bool = False,\n    ) -&gt; Union[RoadwayNodeSelection, RoadwayLinkSelection]:\n        \"\"\"Return selection if it already exists, otherwise performs selection.\n\n        Args:\n            selection_dict (dict): SelectFacility dictionary.\n            overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n        \"\"\"\n        key = _create_selection_key(selection_dict)\n        if (key in self._selections) and not overwrite:\n            WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n            return self._selections[key]\n\n        if isinstance(selection_dict, SelectFacility):\n            selection_data = selection_dict\n        elif isinstance(selection_dict, SelectLinksDict):\n            selection_data = SelectFacility(links=selection_dict)\n        elif isinstance(selection_dict, SelectNodesDict):\n            selection_data = SelectFacility(nodes=selection_dict)\n        elif isinstance(selection_dict, dict):\n            selection_data = SelectFacility(**selection_dict)\n        else:\n            msg = \"selection_dict arg must be a dictionary or SelectFacility model.\"\n            WranglerLogger.error(\n                msg + f\" Received: {selection_dict} of type {type(selection_dict)}\"\n            )\n            raise SelectionError(msg)\n\n        WranglerLogger.debug(f\"Getting selection from key: {key}\")\n        if \"links\" in selection_data.fields:\n            return RoadwayLinkSelection(self, selection_dict)\n        if \"nodes\" in selection_data.fields:\n            return RoadwayNodeSelection(self, selection_dict)\n        msg = \"Selection data should have either 'links' or 'nodes'.\"\n        WranglerLogger.error(msg + f\" Received: {selection_dict}\")\n        raise SelectionError(msg)\n\n    def modal_graph_hash(self, mode) -&gt; str:\n        \"\"\"Hash of the links in order to detect a network change from when graph created.\"\"\"\n        _value = str.encode(self.links_df.df_hash() + \"-\" + mode)\n        _hash = hashlib.sha256(_value).hexdigest()\n\n        return _hash\n\n    def get_modal_graph(self, mode) -&gt; MultiDiGraph:\n        \"\"\"Return a networkx graph of the network for a specific mode.\n\n        Args:\n            mode: mode of the network, one of `drive`,`transit`,`walk`, `bike`\n        \"\"\"\n        from .graph import net_to_graph\n\n        if self._modal_graphs[mode][\"hash\"] != self.modal_graph_hash(mode):\n            self._modal_graphs[mode][\"graph\"] = net_to_graph(self, mode)\n\n        return self._modal_graphs[mode][\"graph\"]\n\n    def apply(\n        self,\n        project_card: Union[ProjectCard, dict],\n        transit_net: Optional[TransitNetwork] = None,\n        **kwargs,\n    ) -&gt; RoadwayNetwork:\n        \"\"\"Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n        Args:\n            project_card: either a dictionary of the project card object or ProjectCard instance\n            transit_net: optional transit network which will be used to if project requires as\n                noted in `SECONDARY_TRANSIT_CARD_TYPES`.  If no transit network is provided, will\n                skip anything related to transit network.\n            **kwargs: keyword arguments to pass to project application\n        \"\"\"\n        if not (isinstance(project_card, (ProjectCard, SubProject))):\n            project_card = ProjectCard(project_card)\n\n        # project_card.validate()\n        if not project_card.valid:\n            msg = f\"Project card {project_card.project} not valid.\"\n            WranglerLogger.error(msg)\n            raise ProjectCardError(msg)\n\n        if project_card._sub_projects:\n            for sp in project_card._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp, transit_net=transit_net, **kwargs)\n            return self\n        return self._apply_change(project_card, transit_net=transit_net, **kwargs)\n\n    def _apply_change(\n        self,\n        change: Union[ProjectCard, SubProject],\n        transit_net: Optional[TransitNetwork] = None,\n    ) -&gt; RoadwayNetwork:\n        \"\"\"Apply a single change: a single-project project or a sub-project.\"\"\"\n        if not isinstance(change, SubProject):\n            WranglerLogger.info(f\"Applying Project to Roadway Network: {change.project}\")\n\n        if change.change_type == \"roadway_property_change\":\n            return apply_roadway_property_change(\n                self,\n                self.get_selection(change.roadway_property_change[\"facility\"]),\n                change.roadway_property_change[\"property_changes\"],\n                project_name=change.project,\n            )\n\n        if change.change_type == \"roadway_addition\":\n            return apply_new_roadway(\n                self,\n                change.roadway_addition,\n                project_name=change.project,\n            )\n\n        if change.change_type == \"roadway_deletion\":\n            return apply_roadway_deletion(\n                self,\n                change.roadway_deletion,\n                transit_net=transit_net,\n            )\n\n        if change.change_type == \"pycode\":\n            return apply_calculated_roadway(self, change.pycode)\n        WranglerLogger.error(f\"Couldn't find project in: \\n{change.__dict__}\")\n        msg = f\"Invalid Project Card Category: {change.change_type}\"\n        raise ProjectCardError(msg)\n\n    def links_with_link_ids(self, link_ids: list[int]) -&gt; DataFrame[RoadLinksTable]:\n        \"\"\"Return subset of links_df based on link_ids list.\"\"\"\n        return filter_links_to_ids(self.links_df, link_ids)\n\n    def links_with_nodes(self, node_ids: list[int]) -&gt; DataFrame[RoadLinksTable]:\n        \"\"\"Return subset of links_df based on node_ids list.\"\"\"\n        return filter_links_to_node_ids(self.links_df, node_ids)\n\n    def nodes_in_links(self) -&gt; DataFrame[RoadNodesTable]:\n        \"\"\"Returns subset of self.nodes_df that are in self.links_df.\"\"\"\n        return filter_nodes_to_links(self.links_df, self.nodes_df)\n\n    def node_coords(self, model_node_id: int) -&gt; tuple:\n        \"\"\"Return coordinates (x, y) of a node based on model_node_id.\"\"\"\n        try:\n            node = self.nodes_df[self.nodes_df.model_node_id == model_node_id]\n        except ValueError as err:\n            msg = f\"Node with model_node_id {model_node_id} not found.\"\n            WranglerLogger.error(msg)\n            raise NodeNotFoundError(msg) from err\n        return node.geometry.x.values[0], node.geometry.y.values[0]\n\n    def add_links(\n        self,\n        add_links_df: Union[pd.DataFrame, DataFrame[RoadLinksTable]],\n        in_crs: int = LAT_LON_CRS,\n    ):\n        \"\"\"Validate combined links_df with LinksSchema before adding to self.links_df.\n\n        Args:\n            add_links_df: Dataframe of additional links to add.\n            in_crs: crs of input data. Defaults to LAT_LON_CRS.\n        \"\"\"\n        dupe_recs = self.links_df.model_link_id.isin(add_links_df.model_link_id)\n\n        if dupe_recs.any():\n            dupe_ids = self.links_df.loc[dupe_recs, \"model_link_id\"]\n            WranglerLogger.error(\n                f\"Cannot add links with model_link_id already in network: {dupe_ids}\"\n            )\n            msg = \"Cannot add links with model_link_id already in network.\"\n            raise LinkAddError(msg)\n\n        if add_links_df.attrs.get(\"name\") != \"road_links\":\n            add_links_df = data_to_links_df(add_links_df, nodes_df=self.nodes_df, in_crs=in_crs)\n        self.links_df = validate_df_to_model(\n            concat_with_attr([self.links_df, add_links_df], axis=0), RoadLinksTable\n        )\n\n    def add_nodes(\n        self,\n        add_nodes_df: Union[pd.DataFrame, DataFrame[RoadNodesTable]],\n        in_crs: int = LAT_LON_CRS,\n    ):\n        \"\"\"Validate combined nodes_df with NodesSchema before adding to self.nodes_df.\n\n        Args:\n            add_nodes_df: Dataframe of additional nodes to add.\n            in_crs: crs of input data. Defaults to LAT_LON_CRS.\n        \"\"\"\n        dupe_ids = self.nodes_df.model_node_id.isin(add_nodes_df.model_node_id)\n        if dupe_ids.any():\n            WranglerLogger.error(\n                f\"Cannot add nodes with model_node_id already in network: {dupe_ids}\"\n            )\n            msg = \"Cannot add nodes with model_node_id already in network.\"\n            raise NodeAddError(msg)\n\n        if add_nodes_df.attrs.get(\"name\") != \"road_nodes\":\n            add_nodes_df = data_to_nodes_df(add_nodes_df, in_crs=in_crs, config=self.config)\n        self.nodes_df = validate_df_to_model(\n            concat_with_attr([self.nodes_df, add_nodes_df], axis=0), RoadNodesTable\n        )\n        if self.nodes_df.attrs.get(\"name\") != \"road_nodes\":\n            msg = f\"Expected nodes_df to have name 'road_nodes', got {self.nodes_df.attrs.get('name')}\"\n            raise NotNodesError(msg)\n\n    def add_shapes(\n        self,\n        add_shapes_df: Union[pd.DataFrame, DataFrame[RoadShapesTable]],\n        in_crs: int = LAT_LON_CRS,\n    ):\n        \"\"\"Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.\n\n        Args:\n            add_shapes_df: Dataframe of additional shapes to add.\n            in_crs: crs of input data. Defaults to LAT_LON_CRS.\n        \"\"\"\n        dupe_ids = self.shapes_df.shape_id.isin(add_shapes_df.shape_id)\n        if dupe_ids.any():\n            msg = \"Cannot add shapes with shape_id already in network.\"\n            WranglerLogger.error(msg + f\"\\nDuplicates: {dupe_ids}\")\n            raise ShapeAddError(msg)\n\n        if add_shapes_df.attrs.get(\"name\") != \"road_shapes\":\n            add_shapes_df = df_to_shapes_df(add_shapes_df, in_crs=in_crs, config=self.config)\n\n        WranglerLogger.debug(f\"add_shapes_df: \\n{add_shapes_df}\")\n        WranglerLogger.debug(f\"self.shapes_df: \\n{self.shapes_df}\")\n\n        self.shapes_df = validate_df_to_model(\n            concat_with_attr([self.shapes_df, add_shapes_df], axis=0), RoadShapesTable\n        )\n\n    def delete_links(\n        self,\n        selection_dict: Union[dict, SelectLinksDict],\n        clean_nodes: bool = False,\n        clean_shapes: bool = False,\n        transit_net: Optional[TransitNetwork] = None,\n    ):\n        \"\"\"Deletes links based on selection dictionary and optionally associated nodes and shapes.\n\n        Args:\n            selection_dict (SelectLinks): Dictionary describing link selections as follows:\n                `all`: Optional[bool] = False. If true, will select all.\n                `name`: Optional[list[str]]\n                `ref`: Optional[list[str]]\n                `osm_link_id`:Optional[list[str]]\n                `model_link_id`: Optional[list[int]]\n                `modes`: Optional[list[str]]. Defaults to \"any\"\n                `ignore_missing`: if true, will not error when defaults to True.\n                ...plus any other link property to select on top of these.\n            clean_nodes (bool, optional): If True, will clean nodes uniquely associated with\n                deleted links. Defaults to False.\n            clean_shapes (bool, optional): If True, will clean nodes uniquely associated with\n                deleted links. Defaults to False.\n            transit_net (TransitNetwork, optional): If provided, will check TransitNetwork and\n                warn if deletion breaks transit shapes. Defaults to None.\n        \"\"\"\n        if not isinstance(selection_dict, SelectLinksDict):\n            selection_dict = SelectLinksDict(**selection_dict)\n        selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n        selection = self.get_selection({\"links\": selection_dict})\n        if isinstance(selection, RoadwayNodeSelection):\n            msg = \"Selection should be for links, but got nodes.\"\n            raise SelectionError(msg)\n        if clean_nodes:\n            node_ids_to_delete = node_ids_unique_to_link_ids(\n                selection.selected_links, selection.selected_links_df, self.nodes_df\n            )\n            WranglerLogger.debug(\n                f\"Dropping nodes associated with dropped links: \\n{node_ids_to_delete}\"\n            )\n            self.nodes_df = delete_nodes_by_ids(self.nodes_df, del_node_ids=node_ids_to_delete)\n\n        if clean_shapes:\n            shape_ids_to_delete = shape_ids_unique_to_link_ids(\n                selection.selected_links, selection.selected_links_df, self.shapes_df\n            )\n            WranglerLogger.debug(\n                f\"Dropping shapes associated with dropped links: \\n{shape_ids_to_delete}\"\n            )\n            self.shapes_df = delete_shapes_by_ids(\n                self.shapes_df, del_shape_ids=shape_ids_to_delete\n            )\n\n        self.links_df = delete_links_by_ids(\n            self.links_df,\n            selection.selected_links,\n            ignore_missing=selection.ignore_missing,\n            transit_net=transit_net,\n        )\n\n    def delete_nodes(\n        self,\n        selection_dict: Union[dict, SelectNodesDict],\n        remove_links: bool = False,\n    ) -&gt; None:\n        \"\"\"Deletes nodes from roadway network. Wont delete nodes used by links in network.\n\n        Args:\n            selection_dict: dictionary of node selection criteria in the form of a SelectNodesDict.\n            remove_links: if True, will remove any links that are associated with the nodes.\n                If False, will only remove nodes if they are not associated with any links.\n                Defaults to False.\n\n        raises:\n            NodeDeletionError: If not ignore_missing and selected nodes to delete aren't in network\n        \"\"\"\n        if not isinstance(selection_dict, SelectNodesDict):\n            selection_dict = SelectNodesDict(**selection_dict)\n        selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n        _selection = self.get_selection({\"nodes\": selection_dict})\n        assert isinstance(_selection, RoadwayNodeSelection)  # for mypy\n        selection: RoadwayNodeSelection = _selection\n        if remove_links:\n            del_node_ids = selection.selected_nodes\n            link_ids = self.links_with_nodes(selection.selected_nodes).model_link_id.to_list()\n            WranglerLogger.info(f\"Removing {len(link_ids)} links associated with nodes.\")\n            self.delete_links({\"model_link_id\": link_ids})\n        else:\n            unused_node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n            del_node_ids = list(set(selection.selected_nodes).intersection(unused_node_ids))\n\n        self.nodes_df = delete_nodes_by_ids(\n            self.nodes_df, del_node_ids, ignore_missing=selection.ignore_missing\n        )\n\n    def clean_unused_shapes(self):\n        \"\"\"Removes any unused shapes from network that aren't referenced by links_df.\"\"\"\n        from .shapes.shapes import shape_ids_without_links\n\n        del_shape_ids = shape_ids_without_links(self.shapes_df, self.links_df)\n        self.shapes_df = self.shapes_df.drop(del_shape_ids)\n\n    def clean_unused_nodes(self):\n        \"\"\"Removes any unused nodes from network that aren't referenced by links_df.\n\n        NOTE: does not check if these nodes are used by transit, so use with caution.\n        \"\"\"\n        from .nodes.nodes import node_ids_without_links\n\n        node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n        self.nodes_df = self.nodes_df.drop(node_ids)\n\n    def move_nodes(\n        self,\n        node_geometry_change_table: DataFrame[NodeGeometryChangeTable],\n    ):\n        \"\"\"Moves nodes based on updated geometry along with associated links and shape geometry.\n\n        Args:\n            node_geometry_change_table: a table with model_node_id, X, Y, and CRS.\n        \"\"\"\n        node_geometry_change_table = NodeGeometryChangeTable(node_geometry_change_table)\n        node_ids = node_geometry_change_table.model_node_id.to_list()\n        WranglerLogger.debug(f\"Moving nodes: {node_ids}\")\n        self.nodes_df = edit_node_geometry(self.nodes_df, node_geometry_change_table)\n        self.links_df = edit_link_geometry_from_nodes(self.links_df, self.nodes_df, node_ids)\n        self.shapes_df = edit_shape_geometry_from_nodes(\n            self.shapes_df, self.links_df, self.nodes_df, node_ids\n        )\n\n    def has_node(self, model_node_id: int) -&gt; bool:\n        \"\"\"Queries if network has node based on model_node_id.\n\n        Args:\n            model_node_id: model_node_id to check for.\n        \"\"\"\n        has_node = self.nodes_df[self.nodes_df.model_node_id].isin([model_node_id]).any()\n\n        return has_node\n\n    def has_link(self, ab: tuple) -&gt; bool:\n        \"\"\"Returns true if network has links with AB values.\n\n        Args:\n            ab: Tuple of values corresponding with A and B.\n        \"\"\"\n        sel_a, sel_b = ab\n        has_link = (\n            self.links_df[self.links_df[[\"A\", \"B\"]]].isin_dict({\"A\": sel_a, \"B\": sel_b}).any()\n        )\n        return has_link\n\n    def is_connected(self, mode: str) -&gt; bool:\n        \"\"\"Determines if the network graph is \"strongly\" connected.\n\n        A graph is strongly connected if each vertex is reachable from every other vertex.\n\n        Args:\n            mode:  mode of the network, one of `drive`,`transit`,`walk`, `bike`\n        \"\"\"\n        is_connected = nx.is_strongly_connected(self.get_modal_graph(mode))\n\n        return is_connected\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.link_shapes_df","title":"<code>link_shapes_df: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Add shape geometry to links if available.</p> <p>returns: shapes merged to links dataframe</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.model_net","title":"<code>model_net: ModelRoadwayNetwork</code>  <code>property</code>","text":"<p>Return a ModelRoadwayNetwork object for this network.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.network_hash","title":"<code>network_hash: str</code>  <code>property</code>","text":"<p>Hash of the links and nodes dataframes.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.shapes_df","title":"<code>shapes_df: DataFrame[RoadShapesTable]</code>  <code>property</code> <code>writable</code>","text":"<p>Load and return RoadShapesTable.</p> <p>If not already loaded, will read from shapes_file and return. If shapes_file is None, will return an empty dataframe with the right schema. If shapes_df is already set, will return that.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.summary","title":"<code>summary: dict</code>  <code>property</code>","text":"<p>Quick summary dictionary of number of links, nodes.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_links","title":"<code>add_links(add_links_df, in_crs=LAT_LON_CRS)</code>","text":"<p>Validate combined links_df with LinksSchema before adding to self.links_df.</p> <p>Parameters:</p> Name Type Description Default <code>add_links_df</code> <code>Union[DataFrame, DataFrame[RoadLinksTable]]</code> <p>Dataframe of additional links to add.</p> required <code>in_crs</code> <code>int</code> <p>crs of input data. Defaults to LAT_LON_CRS.</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_links(\n    self,\n    add_links_df: Union[pd.DataFrame, DataFrame[RoadLinksTable]],\n    in_crs: int = LAT_LON_CRS,\n):\n    \"\"\"Validate combined links_df with LinksSchema before adding to self.links_df.\n\n    Args:\n        add_links_df: Dataframe of additional links to add.\n        in_crs: crs of input data. Defaults to LAT_LON_CRS.\n    \"\"\"\n    dupe_recs = self.links_df.model_link_id.isin(add_links_df.model_link_id)\n\n    if dupe_recs.any():\n        dupe_ids = self.links_df.loc[dupe_recs, \"model_link_id\"]\n        WranglerLogger.error(\n            f\"Cannot add links with model_link_id already in network: {dupe_ids}\"\n        )\n        msg = \"Cannot add links with model_link_id already in network.\"\n        raise LinkAddError(msg)\n\n    if add_links_df.attrs.get(\"name\") != \"road_links\":\n        add_links_df = data_to_links_df(add_links_df, nodes_df=self.nodes_df, in_crs=in_crs)\n    self.links_df = validate_df_to_model(\n        concat_with_attr([self.links_df, add_links_df], axis=0), RoadLinksTable\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_nodes","title":"<code>add_nodes(add_nodes_df, in_crs=LAT_LON_CRS)</code>","text":"<p>Validate combined nodes_df with NodesSchema before adding to self.nodes_df.</p> <p>Parameters:</p> Name Type Description Default <code>add_nodes_df</code> <code>Union[DataFrame, DataFrame[RoadNodesTable]]</code> <p>Dataframe of additional nodes to add.</p> required <code>in_crs</code> <code>int</code> <p>crs of input data. Defaults to LAT_LON_CRS.</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_nodes(\n    self,\n    add_nodes_df: Union[pd.DataFrame, DataFrame[RoadNodesTable]],\n    in_crs: int = LAT_LON_CRS,\n):\n    \"\"\"Validate combined nodes_df with NodesSchema before adding to self.nodes_df.\n\n    Args:\n        add_nodes_df: Dataframe of additional nodes to add.\n        in_crs: crs of input data. Defaults to LAT_LON_CRS.\n    \"\"\"\n    dupe_ids = self.nodes_df.model_node_id.isin(add_nodes_df.model_node_id)\n    if dupe_ids.any():\n        WranglerLogger.error(\n            f\"Cannot add nodes with model_node_id already in network: {dupe_ids}\"\n        )\n        msg = \"Cannot add nodes with model_node_id already in network.\"\n        raise NodeAddError(msg)\n\n    if add_nodes_df.attrs.get(\"name\") != \"road_nodes\":\n        add_nodes_df = data_to_nodes_df(add_nodes_df, in_crs=in_crs, config=self.config)\n    self.nodes_df = validate_df_to_model(\n        concat_with_attr([self.nodes_df, add_nodes_df], axis=0), RoadNodesTable\n    )\n    if self.nodes_df.attrs.get(\"name\") != \"road_nodes\":\n        msg = f\"Expected nodes_df to have name 'road_nodes', got {self.nodes_df.attrs.get('name')}\"\n        raise NotNodesError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_shapes","title":"<code>add_shapes(add_shapes_df, in_crs=LAT_LON_CRS)</code>","text":"<p>Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.</p> <p>Parameters:</p> Name Type Description Default <code>add_shapes_df</code> <code>Union[DataFrame, DataFrame[RoadShapesTable]]</code> <p>Dataframe of additional shapes to add.</p> required <code>in_crs</code> <code>int</code> <p>crs of input data. Defaults to LAT_LON_CRS.</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_shapes(\n    self,\n    add_shapes_df: Union[pd.DataFrame, DataFrame[RoadShapesTable]],\n    in_crs: int = LAT_LON_CRS,\n):\n    \"\"\"Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.\n\n    Args:\n        add_shapes_df: Dataframe of additional shapes to add.\n        in_crs: crs of input data. Defaults to LAT_LON_CRS.\n    \"\"\"\n    dupe_ids = self.shapes_df.shape_id.isin(add_shapes_df.shape_id)\n    if dupe_ids.any():\n        msg = \"Cannot add shapes with shape_id already in network.\"\n        WranglerLogger.error(msg + f\"\\nDuplicates: {dupe_ids}\")\n        raise ShapeAddError(msg)\n\n    if add_shapes_df.attrs.get(\"name\") != \"road_shapes\":\n        add_shapes_df = df_to_shapes_df(add_shapes_df, in_crs=in_crs, config=self.config)\n\n    WranglerLogger.debug(f\"add_shapes_df: \\n{add_shapes_df}\")\n    WranglerLogger.debug(f\"self.shapes_df: \\n{self.shapes_df}\")\n\n    self.shapes_df = validate_df_to_model(\n        concat_with_attr([self.shapes_df, add_shapes_df], axis=0), RoadShapesTable\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.apply","title":"<code>apply(project_card, transit_net=None, **kwargs)</code>","text":"<p>Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>project_card</code> <code>Union[ProjectCard, dict]</code> <p>either a dictionary of the project card object or ProjectCard instance</p> required <code>transit_net</code> <code>Optional[TransitNetwork]</code> <p>optional transit network which will be used to if project requires as noted in <code>SECONDARY_TRANSIT_CARD_TYPES</code>.  If no transit network is provided, will skip anything related to transit network.</p> <code>None</code> <code>**kwargs</code> <p>keyword arguments to pass to project application</p> <code>{}</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def apply(\n    self,\n    project_card: Union[ProjectCard, dict],\n    transit_net: Optional[TransitNetwork] = None,\n    **kwargs,\n) -&gt; RoadwayNetwork:\n    \"\"\"Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n    Args:\n        project_card: either a dictionary of the project card object or ProjectCard instance\n        transit_net: optional transit network which will be used to if project requires as\n            noted in `SECONDARY_TRANSIT_CARD_TYPES`.  If no transit network is provided, will\n            skip anything related to transit network.\n        **kwargs: keyword arguments to pass to project application\n    \"\"\"\n    if not (isinstance(project_card, (ProjectCard, SubProject))):\n        project_card = ProjectCard(project_card)\n\n    # project_card.validate()\n    if not project_card.valid:\n        msg = f\"Project card {project_card.project} not valid.\"\n        WranglerLogger.error(msg)\n        raise ProjectCardError(msg)\n\n    if project_card._sub_projects:\n        for sp in project_card._sub_projects:\n            WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n            self._apply_change(sp, transit_net=transit_net, **kwargs)\n        return self\n    return self._apply_change(project_card, transit_net=transit_net, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.clean_unused_nodes","title":"<code>clean_unused_nodes()</code>","text":"<p>Removes any unused nodes from network that aren\u2019t referenced by links_df.</p> <p>NOTE: does not check if these nodes are used by transit, so use with caution.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def clean_unused_nodes(self):\n    \"\"\"Removes any unused nodes from network that aren't referenced by links_df.\n\n    NOTE: does not check if these nodes are used by transit, so use with caution.\n    \"\"\"\n    from .nodes.nodes import node_ids_without_links\n\n    node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n    self.nodes_df = self.nodes_df.drop(node_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.clean_unused_shapes","title":"<code>clean_unused_shapes()</code>","text":"<p>Removes any unused shapes from network that aren\u2019t referenced by links_df.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def clean_unused_shapes(self):\n    \"\"\"Removes any unused shapes from network that aren't referenced by links_df.\"\"\"\n    from .shapes.shapes import shape_ids_without_links\n\n    del_shape_ids = shape_ids_without_links(self.shapes_df, self.links_df)\n    self.shapes_df = self.shapes_df.drop(del_shape_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.coerce_crs","title":"<code>coerce_crs(v)</code>","text":"<p>Coerce crs of nodes_df and links_df to LAT_LON_CRS.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>@field_validator(\"nodes_df\", \"links_df\")\ndef coerce_crs(cls, v):\n    \"\"\"Coerce crs of nodes_df and links_df to LAT_LON_CRS.\"\"\"\n    if v.crs != LAT_LON_CRS:\n        WranglerLogger.warning(\n            f\"CRS of links_df ({v.crs}) doesn't match network crs {LAT_LON_CRS}. \\\n                Changing to network crs.\"\n        )\n        v.to_crs(LAT_LON_CRS)\n    return v\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.delete_links","title":"<code>delete_links(selection_dict, clean_nodes=False, clean_shapes=False, transit_net=None)</code>","text":"<p>Deletes links based on selection dictionary and optionally associated nodes and shapes.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>SelectLinks</code> <p>Dictionary describing link selections as follows: <code>all</code>: Optional[bool] = False. If true, will select all. <code>name</code>: Optional[list[str]] <code>ref</code>: Optional[list[str]] <code>osm_link_id</code>:Optional[list[str]] <code>model_link_id</code>: Optional[list[int]] <code>modes</code>: Optional[list[str]]. Defaults to \u201cany\u201d <code>ignore_missing</code>: if true, will not error when defaults to True. \u2026plus any other link property to select on top of these.</p> required <code>clean_nodes</code> <code>bool</code> <p>If True, will clean nodes uniquely associated with deleted links. Defaults to False.</p> <code>False</code> <code>clean_shapes</code> <code>bool</code> <p>If True, will clean nodes uniquely associated with deleted links. Defaults to False.</p> <code>False</code> <code>transit_net</code> <code>TransitNetwork</code> <p>If provided, will check TransitNetwork and warn if deletion breaks transit shapes. Defaults to None.</p> <code>None</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def delete_links(\n    self,\n    selection_dict: Union[dict, SelectLinksDict],\n    clean_nodes: bool = False,\n    clean_shapes: bool = False,\n    transit_net: Optional[TransitNetwork] = None,\n):\n    \"\"\"Deletes links based on selection dictionary and optionally associated nodes and shapes.\n\n    Args:\n        selection_dict (SelectLinks): Dictionary describing link selections as follows:\n            `all`: Optional[bool] = False. If true, will select all.\n            `name`: Optional[list[str]]\n            `ref`: Optional[list[str]]\n            `osm_link_id`:Optional[list[str]]\n            `model_link_id`: Optional[list[int]]\n            `modes`: Optional[list[str]]. Defaults to \"any\"\n            `ignore_missing`: if true, will not error when defaults to True.\n            ...plus any other link property to select on top of these.\n        clean_nodes (bool, optional): If True, will clean nodes uniquely associated with\n            deleted links. Defaults to False.\n        clean_shapes (bool, optional): If True, will clean nodes uniquely associated with\n            deleted links. Defaults to False.\n        transit_net (TransitNetwork, optional): If provided, will check TransitNetwork and\n            warn if deletion breaks transit shapes. Defaults to None.\n    \"\"\"\n    if not isinstance(selection_dict, SelectLinksDict):\n        selection_dict = SelectLinksDict(**selection_dict)\n    selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n    selection = self.get_selection({\"links\": selection_dict})\n    if isinstance(selection, RoadwayNodeSelection):\n        msg = \"Selection should be for links, but got nodes.\"\n        raise SelectionError(msg)\n    if clean_nodes:\n        node_ids_to_delete = node_ids_unique_to_link_ids(\n            selection.selected_links, selection.selected_links_df, self.nodes_df\n        )\n        WranglerLogger.debug(\n            f\"Dropping nodes associated with dropped links: \\n{node_ids_to_delete}\"\n        )\n        self.nodes_df = delete_nodes_by_ids(self.nodes_df, del_node_ids=node_ids_to_delete)\n\n    if clean_shapes:\n        shape_ids_to_delete = shape_ids_unique_to_link_ids(\n            selection.selected_links, selection.selected_links_df, self.shapes_df\n        )\n        WranglerLogger.debug(\n            f\"Dropping shapes associated with dropped links: \\n{shape_ids_to_delete}\"\n        )\n        self.shapes_df = delete_shapes_by_ids(\n            self.shapes_df, del_shape_ids=shape_ids_to_delete\n        )\n\n    self.links_df = delete_links_by_ids(\n        self.links_df,\n        selection.selected_links,\n        ignore_missing=selection.ignore_missing,\n        transit_net=transit_net,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.delete_nodes","title":"<code>delete_nodes(selection_dict, remove_links=False)</code>","text":"<p>Deletes nodes from roadway network. Wont delete nodes used by links in network.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>Union[dict, SelectNodesDict]</code> <p>dictionary of node selection criteria in the form of a SelectNodesDict.</p> required <code>remove_links</code> <code>bool</code> <p>if True, will remove any links that are associated with the nodes. If False, will only remove nodes if they are not associated with any links. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>NodeDeletionError</code> <p>If not ignore_missing and selected nodes to delete aren\u2019t in network</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def delete_nodes(\n    self,\n    selection_dict: Union[dict, SelectNodesDict],\n    remove_links: bool = False,\n) -&gt; None:\n    \"\"\"Deletes nodes from roadway network. Wont delete nodes used by links in network.\n\n    Args:\n        selection_dict: dictionary of node selection criteria in the form of a SelectNodesDict.\n        remove_links: if True, will remove any links that are associated with the nodes.\n            If False, will only remove nodes if they are not associated with any links.\n            Defaults to False.\n\n    raises:\n        NodeDeletionError: If not ignore_missing and selected nodes to delete aren't in network\n    \"\"\"\n    if not isinstance(selection_dict, SelectNodesDict):\n        selection_dict = SelectNodesDict(**selection_dict)\n    selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n    _selection = self.get_selection({\"nodes\": selection_dict})\n    assert isinstance(_selection, RoadwayNodeSelection)  # for mypy\n    selection: RoadwayNodeSelection = _selection\n    if remove_links:\n        del_node_ids = selection.selected_nodes\n        link_ids = self.links_with_nodes(selection.selected_nodes).model_link_id.to_list()\n        WranglerLogger.info(f\"Removing {len(link_ids)} links associated with nodes.\")\n        self.delete_links({\"model_link_id\": link_ids})\n    else:\n        unused_node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n        del_node_ids = list(set(selection.selected_nodes).intersection(unused_node_ids))\n\n    self.nodes_df = delete_nodes_by_ids(\n        self.nodes_df, del_node_ids, ignore_missing=selection.ignore_missing\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_modal_graph","title":"<code>get_modal_graph(mode)</code>","text":"<p>Return a networkx graph of the network for a specific mode.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <p>mode of the network, one of <code>drive</code>,<code>transit</code>,<code>walk</code>, <code>bike</code></p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_modal_graph(self, mode) -&gt; MultiDiGraph:\n    \"\"\"Return a networkx graph of the network for a specific mode.\n\n    Args:\n        mode: mode of the network, one of `drive`,`transit`,`walk`, `bike`\n    \"\"\"\n    from .graph import net_to_graph\n\n    if self._modal_graphs[mode][\"hash\"] != self.modal_graph_hash(mode):\n        self._modal_graphs[mode][\"graph\"] = net_to_graph(self, mode)\n\n    return self._modal_graphs[mode][\"graph\"]\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_property_by_timespan_and_group","title":"<code>get_property_by_timespan_and_group(link_property, category=DEFAULT_CATEGORY, timespan=DEFAULT_TIMESPAN, strict_timespan_match=False, min_overlap_minutes=60)</code>","text":"<p>Returns a new dataframe with model_link_id and link property by category and timespan.</p> <p>Convenience method for backward compatability.</p> <p>Parameters:</p> Name Type Description Default <code>link_property</code> <code>str</code> <p>link property to query</p> required <code>category</code> <code>Optional[Union[str, int]]</code> <p>category to query or a list of categories. Defaults to DEFAULT_CATEGORY.</p> <code>DEFAULT_CATEGORY</code> <code>timespan</code> <code>Optional[TimespanString]</code> <p>timespan to query in the form of [\u201cHH:MM\u201d,\u201dHH:MM\u201d]. Defaults to DEFAULT_TIMESPAN.</p> <code>DEFAULT_TIMESPAN</code> <code>strict_timespan_match</code> <code>bool</code> <p>If True, will only return links that match the timespan exactly. Defaults to False.</p> <code>False</code> <code>min_overlap_minutes</code> <code>int</code> <p>If strict_timespan_match is False, will return links that overlap with the timespan by at least this many minutes. Defaults to 60.</p> <code>60</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_property_by_timespan_and_group(\n    self,\n    link_property: str,\n    category: Optional[Union[str, int]] = DEFAULT_CATEGORY,\n    timespan: Optional[TimespanString] = DEFAULT_TIMESPAN,\n    strict_timespan_match: bool = False,\n    min_overlap_minutes: int = 60,\n) -&gt; Any:\n    \"\"\"Returns a new dataframe with model_link_id and link property by category and timespan.\n\n    Convenience method for backward compatability.\n\n    Args:\n        link_property: link property to query\n        category: category to query or a list of categories. Defaults to DEFAULT_CATEGORY.\n        timespan: timespan to query in the form of [\"HH:MM\",\"HH:MM\"].\n            Defaults to DEFAULT_TIMESPAN.\n        strict_timespan_match: If True, will only return links that match the timespan exactly.\n            Defaults to False.\n        min_overlap_minutes: If strict_timespan_match is False, will return links that overlap\n            with the timespan by at least this many minutes. Defaults to 60.\n    \"\"\"\n    from .links.scopes import prop_for_scope\n\n    return prop_for_scope(\n        self.links_df,\n        link_property,\n        timespan=timespan,\n        category=category,\n        strict_timespan_match=strict_timespan_match,\n        min_overlap_minutes=min_overlap_minutes,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_selection","title":"<code>get_selection(selection_dict, overwrite=False)</code>","text":"<p>Return selection if it already exists, otherwise performs selection.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>dict</code> <p>SelectFacility dictionary.</p> required <code>overwrite</code> <code>bool</code> <p>if True, will overwrite any previously cached searches. Defaults to False.</p> <code>False</code> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_selection(\n    self,\n    selection_dict: Union[dict, SelectFacility],\n    overwrite: bool = False,\n) -&gt; Union[RoadwayNodeSelection, RoadwayLinkSelection]:\n    \"\"\"Return selection if it already exists, otherwise performs selection.\n\n    Args:\n        selection_dict (dict): SelectFacility dictionary.\n        overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n    \"\"\"\n    key = _create_selection_key(selection_dict)\n    if (key in self._selections) and not overwrite:\n        WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n        return self._selections[key]\n\n    if isinstance(selection_dict, SelectFacility):\n        selection_data = selection_dict\n    elif isinstance(selection_dict, SelectLinksDict):\n        selection_data = SelectFacility(links=selection_dict)\n    elif isinstance(selection_dict, SelectNodesDict):\n        selection_data = SelectFacility(nodes=selection_dict)\n    elif isinstance(selection_dict, dict):\n        selection_data = SelectFacility(**selection_dict)\n    else:\n        msg = \"selection_dict arg must be a dictionary or SelectFacility model.\"\n        WranglerLogger.error(\n            msg + f\" Received: {selection_dict} of type {type(selection_dict)}\"\n        )\n        raise SelectionError(msg)\n\n    WranglerLogger.debug(f\"Getting selection from key: {key}\")\n    if \"links\" in selection_data.fields:\n        return RoadwayLinkSelection(self, selection_dict)\n    if \"nodes\" in selection_data.fields:\n        return RoadwayNodeSelection(self, selection_dict)\n    msg = \"Selection data should have either 'links' or 'nodes'.\"\n    WranglerLogger.error(msg + f\" Received: {selection_dict}\")\n    raise SelectionError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.has_link","title":"<code>has_link(ab)</code>","text":"<p>Returns true if network has links with AB values.</p> <p>Parameters:</p> Name Type Description Default <code>ab</code> <code>tuple</code> <p>Tuple of values corresponding with A and B.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def has_link(self, ab: tuple) -&gt; bool:\n    \"\"\"Returns true if network has links with AB values.\n\n    Args:\n        ab: Tuple of values corresponding with A and B.\n    \"\"\"\n    sel_a, sel_b = ab\n    has_link = (\n        self.links_df[self.links_df[[\"A\", \"B\"]]].isin_dict({\"A\": sel_a, \"B\": sel_b}).any()\n    )\n    return has_link\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.has_node","title":"<code>has_node(model_node_id)</code>","text":"<p>Queries if network has node based on model_node_id.</p> <p>Parameters:</p> Name Type Description Default <code>model_node_id</code> <code>int</code> <p>model_node_id to check for.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def has_node(self, model_node_id: int) -&gt; bool:\n    \"\"\"Queries if network has node based on model_node_id.\n\n    Args:\n        model_node_id: model_node_id to check for.\n    \"\"\"\n    has_node = self.nodes_df[self.nodes_df.model_node_id].isin([model_node_id]).any()\n\n    return has_node\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.is_connected","title":"<code>is_connected(mode)</code>","text":"<p>Determines if the network graph is \u201cstrongly\u201d connected.</p> <p>A graph is strongly connected if each vertex is reachable from every other vertex.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>mode of the network, one of <code>drive</code>,<code>transit</code>,<code>walk</code>, <code>bike</code></p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def is_connected(self, mode: str) -&gt; bool:\n    \"\"\"Determines if the network graph is \"strongly\" connected.\n\n    A graph is strongly connected if each vertex is reachable from every other vertex.\n\n    Args:\n        mode:  mode of the network, one of `drive`,`transit`,`walk`, `bike`\n    \"\"\"\n    is_connected = nx.is_strongly_connected(self.get_modal_graph(mode))\n\n    return is_connected\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.links_with_link_ids","title":"<code>links_with_link_ids(link_ids)</code>","text":"<p>Return subset of links_df based on link_ids list.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def links_with_link_ids(self, link_ids: list[int]) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Return subset of links_df based on link_ids list.\"\"\"\n    return filter_links_to_ids(self.links_df, link_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.links_with_nodes","title":"<code>links_with_nodes(node_ids)</code>","text":"<p>Return subset of links_df based on node_ids list.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def links_with_nodes(self, node_ids: list[int]) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Return subset of links_df based on node_ids list.\"\"\"\n    return filter_links_to_node_ids(self.links_df, node_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.modal_graph_hash","title":"<code>modal_graph_hash(mode)</code>","text":"<p>Hash of the links in order to detect a network change from when graph created.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def modal_graph_hash(self, mode) -&gt; str:\n    \"\"\"Hash of the links in order to detect a network change from when graph created.\"\"\"\n    _value = str.encode(self.links_df.df_hash() + \"-\" + mode)\n    _hash = hashlib.sha256(_value).hexdigest()\n\n    return _hash\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.move_nodes","title":"<code>move_nodes(node_geometry_change_table)</code>","text":"<p>Moves nodes based on updated geometry along with associated links and shape geometry.</p> <p>Parameters:</p> Name Type Description Default <code>node_geometry_change_table</code> <code>DataFrame[NodeGeometryChangeTable]</code> <p>a table with model_node_id, X, Y, and CRS.</p> required Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def move_nodes(\n    self,\n    node_geometry_change_table: DataFrame[NodeGeometryChangeTable],\n):\n    \"\"\"Moves nodes based on updated geometry along with associated links and shape geometry.\n\n    Args:\n        node_geometry_change_table: a table with model_node_id, X, Y, and CRS.\n    \"\"\"\n    node_geometry_change_table = NodeGeometryChangeTable(node_geometry_change_table)\n    node_ids = node_geometry_change_table.model_node_id.to_list()\n    WranglerLogger.debug(f\"Moving nodes: {node_ids}\")\n    self.nodes_df = edit_node_geometry(self.nodes_df, node_geometry_change_table)\n    self.links_df = edit_link_geometry_from_nodes(self.links_df, self.nodes_df, node_ids)\n    self.shapes_df = edit_shape_geometry_from_nodes(\n        self.shapes_df, self.links_df, self.nodes_df, node_ids\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.node_coords","title":"<code>node_coords(model_node_id)</code>","text":"<p>Return coordinates (x, y) of a node based on model_node_id.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def node_coords(self, model_node_id: int) -&gt; tuple:\n    \"\"\"Return coordinates (x, y) of a node based on model_node_id.\"\"\"\n    try:\n        node = self.nodes_df[self.nodes_df.model_node_id == model_node_id]\n    except ValueError as err:\n        msg = f\"Node with model_node_id {model_node_id} not found.\"\n        WranglerLogger.error(msg)\n        raise NodeNotFoundError(msg) from err\n    return node.geometry.x.values[0], node.geometry.y.values[0]\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.nodes_in_links","title":"<code>nodes_in_links()</code>","text":"<p>Returns subset of self.nodes_df that are in self.links_df.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def nodes_in_links(self) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Returns subset of self.nodes_df that are in self.links_df.\"\"\"\n    return filter_nodes_to_links(self.links_df, self.nodes_df)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.validate_config","title":"<code>validate_config(v)</code>","text":"<p>Validate config.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>@field_validator(\"config\")\ndef validate_config(cls, v):\n    \"\"\"Validate config.\"\"\"\n    return load_wrangler_config(v)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.add_incident_link_data_to_nodes","title":"<code>add_incident_link_data_to_nodes(links_df, nodes_df, link_variables=None)</code>","text":"<p>Add data from links going to/from nodes to node.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>DataFrame[RoadLinksTable]</code> <p>Will assess connectivity of this links list</p> required <code>nodes_df</code> <code>DataFrame[RoadNodesTable]</code> <p>Will assess connectivity of this nodes list</p> required <code>link_variables</code> <code>Optional[list]</code> <p>list of columns in links dataframe to add to incident nodes</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame[RoadNodesTable]</code> <p>nodes DataFrame with link data where length is N*number of links going in/out</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_incident_link_data_to_nodes(\n    links_df: DataFrame[RoadLinksTable],\n    nodes_df: DataFrame[RoadNodesTable],\n    link_variables: Optional[list] = None,\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Add data from links going to/from nodes to node.\n\n    Args:\n        links_df: Will assess connectivity of this links list\n        nodes_df: Will assess connectivity of this nodes list\n        link_variables: list of columns in links dataframe to add to incident nodes\n\n    Returns:\n        nodes DataFrame with link data where length is N*number of links going in/out\n    \"\"\"\n    WranglerLogger.debug(\"Adding following link data to nodes: \".format())\n    link_variables = link_variables or []\n\n    _link_vals_to_nodes = [x for x in link_variables if x in links_df.columns]\n    if link_variables not in _link_vals_to_nodes:\n        WranglerLogger.warning(\n            f\"Following columns not in links_df and wont be added to nodes: {list(set(link_variables) - set(_link_vals_to_nodes))} \"\n        )\n\n    _nodes_from_links_A = nodes_df.merge(\n        links_df[[links_df.A, *_link_vals_to_nodes]],\n        how=\"outer\",\n        left_on=nodes_df.model_node_id,\n        right_on=links_df.A,\n    )\n    _nodes_from_links_B = nodes_df.merge(\n        links_df[[links_df.B, *_link_vals_to_nodes]],\n        how=\"outer\",\n        left_on=nodes_df.model_node_id,\n        right_on=links_df.B,\n    )\n    _nodes_from_links_ab = concat_with_attr([_nodes_from_links_A, _nodes_from_links_B])\n\n    return _nodes_from_links_ab\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork","title":"<code>TransitNetwork</code>","text":"<p>Representation of a Transit Network.</p> <p>Typical usage example: <pre><code>import network_wrangler as wr\n\ntc = wr.load_transit(stpaul_gtfs)\n</code></pre></p> <p>Attributes:</p> Name Type Description <code>feed</code> <p>gtfs feed object with interlinked tables.</p> <code>road_net</code> <code>RoadwayNetwork</code> <p>Associated roadway network object.</p> <code>graph</code> <code>MultiDiGraph</code> <p>Graph for associated roadway network object.</p> <code>config</code> <code>WranglerConfig</code> <p>Configuration object for the transit network.</p> <code>feed_path</code> <code>str</code> <p>Where the feed was read in from.</p> <code>validated_frequencies</code> <code>bool</code> <p>The frequencies have been validated.</p> <code>validated_road_network_consistency</code> <p>The network has been validated against the road network.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>class TransitNetwork:\n    \"\"\"Representation of a Transit Network.\n\n    Typical usage example:\n    ``` py\n    import network_wrangler as wr\n\n    tc = wr.load_transit(stpaul_gtfs)\n    ```\n\n    Attributes:\n        feed: gtfs feed object with interlinked tables.\n        road_net (RoadwayNetwork): Associated roadway network object.\n        graph (nx.MultiDiGraph): Graph for associated roadway network object.\n        config (WranglerConfig): Configuration object for the transit network.\n        feed_path (str): Where the feed was read in from.\n        validated_frequencies (bool): The frequencies have been validated.\n        validated_road_network_consistency (): The network has been validated against\n            the road network.\n    \"\"\"\n\n    TIME_COLS: ClassVar = [\"arrival_time\", \"departure_time\", \"start_time\", \"end_time\"]\n\n    def __init__(self, feed: Feed, config: WranglerConfig = DefaultConfig) -&gt; None:\n        \"\"\"Constructor for TransitNetwork.\n\n        Args:\n            feed: Feed object representing the transit network gtfs tables\n            config: WranglerConfig object. Defaults to DefaultConfig.\n        \"\"\"\n        WranglerLogger.debug(\"Creating new TransitNetwork.\")\n\n        self._road_net: Optional[RoadwayNetwork] = None\n        self.feed: Feed = feed\n        self.graph: nx.MultiDiGraph = None\n        self.config: WranglerConfig = config\n        # initialize\n        self._consistent_with_road_net = False\n\n        # cached selections\n        self._selections: dict[str, TransitSelection] = {}\n\n    @property\n    def feed_path(self):\n        \"\"\"Pass through property from Feed.\"\"\"\n        return self.feed.feed_path\n\n    @property\n    def applied_projects(self) -&gt; list[str]:\n        \"\"\"List of projects applied to the network.\n\n        Note: This may or may not return a full accurate account of all the applied projects.\n        For better project accounting, please leverage the scenario object.\n        \"\"\"\n        return _get_applied_projects_from_tables(self.feed)\n\n    @property\n    def feed(self):\n        \"\"\"Feed associated with the transit network.\"\"\"\n        return self._feed\n\n    @feed.setter\n    def feed(self, feed: Feed):\n        if not isinstance(feed, Feed):\n            msg = f\"TransitNetwork's feed value must be a valid Feed instance. \\\n                             This is a {type(feed)}.\"\n            WranglerLogger.error(msg)\n            raise TransitValidationError(msg)\n        if self._road_net is None or transit_road_net_consistency(feed, self._road_net):\n            self._feed = feed\n            self._stored_feed_hash = copy.deepcopy(feed.hash)\n        else:\n            msg = \"Can't assign Feed inconsistent with set Roadway Network.\"\n            WranglerLogger.error(msg)\n            raise TransitRoadwayConsistencyError(msg)\n\n    @property\n    def road_net(self) -&gt; Union[None, RoadwayNetwork]:\n        \"\"\"Roadway network associated with the transit network.\"\"\"\n        return self._road_net\n\n    @road_net.setter\n    def road_net(self, road_net_in: RoadwayNetwork):\n        if road_net_in is None or road_net_in.__class__.__name__ != \"RoadwayNetwork\":\n            msg = f\"TransitNetwork's road_net: value must be a valid RoadwayNetwork instance. \\\n                             This is a {type(road_net_in)}.\"\n            WranglerLogger.error(msg)\n            raise TransitValidationError(msg)\n        if transit_road_net_consistency(self.feed, road_net_in):\n            self._road_net = road_net_in\n            self._stored_road_net_hash = copy.deepcopy(road_net_in.network_hash)\n            self._consistent_with_road_net = True\n        else:\n            msg = \"Can't assign inconsistent RoadwayNetwork - Roadway Network not \\\n                   set, but can be referenced separately.\"\n            WranglerLogger.error(msg)\n            raise TransitRoadwayConsistencyError(msg)\n\n    @property\n    def feed_hash(self):\n        \"\"\"Return the hash of the feed.\"\"\"\n        return self.feed.hash\n\n    @property\n    def consistent_with_road_net(self) -&gt; bool:\n        \"\"\"Indicate if road_net is consistent with transit network.\n\n        Will return True if road_net is None, but provide a warning.\n\n        Checks the network hash of when consistency was last evaluated. If transit network or\n        roadway network has changed, will re-evaluate consistency and return the updated value and\n        update self._stored_road_net_hash.\n\n        Returns:\n            Boolean indicating if road_net is consistent with transit network.\n        \"\"\"\n        if self.road_net is None:\n            WranglerLogger.warning(\"Roadway Network not set, cannot accurately check consistency.\")\n            return True\n        updated_road = self.road_net.network_hash != self._stored_road_net_hash\n        updated_feed = self.feed_hash != self._stored_feed_hash\n\n        if updated_road or updated_feed:\n            self._consistent_with_road_net = transit_road_net_consistency(self.feed, self.road_net)\n            self._stored_road_net_hash = copy.deepcopy(self.road_net.network_hash)\n            self._stored_feed_hash = copy.deepcopy(self.feed_hash)\n        return self._consistent_with_road_net\n\n    def __deepcopy__(self, memo):\n        \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n        COPY_REF_NOT_VALUE = [\"_road_net\"]\n        # Create a new, empty instance\n        copied_net = self.__class__.__new__(self.__class__)\n        # Return the new TransitNetwork instance\n        attribute_dict = vars(self)\n\n        # Copy the attributes to the new instance\n        for attr_name, attr_value in attribute_dict.items():\n            # WranglerLogger.debug(f\"Copying {attr_name}\")\n            if attr_name in COPY_REF_NOT_VALUE:\n                # If the attribute is in the COPY_REF_NOT_VALUE list, assign the reference\n                setattr(copied_net, attr_name, attr_value)\n            else:\n                # WranglerLogger.debug(f\"making deep copy: {attr_name}\")\n                # For other attributes, perform a deep copy\n                setattr(copied_net, attr_name, copy.deepcopy(attr_value, memo))\n\n        return copied_net\n\n    def deepcopy(self):\n        \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n        return copy.deepcopy(self)\n\n    @property\n    def stops_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stops as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return to_points_gdf(self.feed.stops, ref_nodes_df=ref_nodes)\n\n    @property\n    def shapes_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return aggregated shapes as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return shapes_to_trip_shapes_gdf(self.feed.shapes, ref_nodes_df=ref_nodes)\n\n    @property\n    def shape_links_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return shape-links as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return shapes_to_shape_links_gdf(self.feed.shapes, ref_nodes_df=ref_nodes)\n\n    @property\n    def stop_time_links_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stop-time-links as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return stop_times_to_stop_time_links_gdf(\n            self.feed.stop_times, self.feed.stops, ref_nodes_df=ref_nodes\n        )\n\n    @property\n    def stop_times_points_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stop-time-points as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n\n        return stop_times_to_stop_time_points_gdf(\n            self.feed.stop_times, self.feed.stops, ref_nodes_df=ref_nodes\n        )\n\n    def get_selection(\n        self,\n        selection_dict: dict,\n        overwrite: bool = False,\n    ) -&gt; TransitSelection:\n        \"\"\"Return selection if it already exists, otherwise performs selection.\n\n        Will raise an error if no trips found.\n\n        Args:\n            selection_dict (dict): _description_\n            overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n\n        Returns:\n            Selection: Selection object\n        \"\"\"\n        key = dict_to_hexkey(selection_dict)\n\n        if (key not in self._selections) or overwrite:\n            WranglerLogger.debug(f\"Performing selection from key: {key}\")\n            self._selections[key] = TransitSelection(self, selection_dict)\n        else:\n            WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n\n        if not self._selections[key]:\n            msg = f\"No links or nodes found for selection dict: \\n {selection_dict}\"\n            WranglerLogger.error(msg)\n            raise TransitSelectionEmptyError(msg)\n        return self._selections[key]\n\n    def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; TransitNetwork:\n        \"\"\"Wrapper method to apply a roadway project, returning a new TransitNetwork instance.\n\n        Args:\n            project_card: either a dictionary of the project card object or ProjectCard instance\n            **kwargs: keyword arguments to pass to project application\n        \"\"\"\n        if not (isinstance(project_card, (ProjectCard, SubProject))):\n            project_card = ProjectCard(project_card)\n\n        if not project_card.valid:\n            msg = f\"Project card {project_card.project} not valid.\"\n            WranglerLogger.error(msg)\n            raise ProjectCardError(msg)\n\n        if project_card._sub_projects:\n            for sp in project_card._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp, **kwargs)\n            return self\n        return self._apply_change(project_card, **kwargs)\n\n    def _apply_change(\n        self,\n        change: Union[ProjectCard, SubProject],\n        reference_road_net: Optional[RoadwayNetwork] = None,\n    ) -&gt; TransitNetwork:\n        \"\"\"Apply a single change: a single-project project or a sub-project.\"\"\"\n        if not isinstance(change, SubProject):\n            WranglerLogger.info(f\"Applying Project to Transit Network: {change.project}\")\n\n        if change.change_type == \"transit_property_change\":\n            return apply_transit_property_change(\n                self,\n                self.get_selection(change.transit_property_change[\"service\"]),\n                change.transit_property_change[\"property_changes\"],\n                project_name=change.project,\n            )\n\n        if change.change_type == \"transit_routing_change\":\n            return apply_transit_routing_change(\n                self,\n                self.get_selection(change.transit_routing_change[\"service\"]),\n                change.transit_routing_change[\"routing\"],\n                reference_road_net=reference_road_net,\n                project_name=change.project,\n            )\n\n        if change.change_type == \"pycode\":\n            return apply_calculated_transit(self, change.pycode)\n\n        if change.change_type == \"transit_route_addition\":\n            return apply_transit_route_addition(\n                self,\n                change.transit_route_addition,\n                reference_road_net=reference_road_net,\n            )\n        if change.change_type == \"transit_service_deletion\":\n            return apply_transit_service_deletion(\n                self,\n                self.get_selection(change.transit_service_deletion[\"service\"]),\n                clean_shapes=change.transit_service_deletion.get(\"clean_shapes\"),\n                clean_routes=change.transit_service_deletion.get(\"clean_routes\"),\n            )\n        msg = f\"Not a currently valid transit project: {change}.\"\n        WranglerLogger.error(msg)\n        raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.applied_projects","title":"<code>applied_projects: list[str]</code>  <code>property</code>","text":"<p>List of projects applied to the network.</p> <p>Note: This may or may not return a full accurate account of all the applied projects. For better project accounting, please leverage the scenario object.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.consistent_with_road_net","title":"<code>consistent_with_road_net: bool</code>  <code>property</code>","text":"<p>Indicate if road_net is consistent with transit network.</p> <p>Will return True if road_net is None, but provide a warning.</p> <p>Checks the network hash of when consistency was last evaluated. If transit network or roadway network has changed, will re-evaluate consistency and return the updated value and update self._stored_road_net_hash.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Boolean indicating if road_net is consistent with transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed","title":"<code>feed</code>  <code>property</code> <code>writable</code>","text":"<p>Feed associated with the transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed_hash","title":"<code>feed_hash</code>  <code>property</code>","text":"<p>Return the hash of the feed.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed_path","title":"<code>feed_path</code>  <code>property</code>","text":"<p>Pass through property from Feed.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.road_net","title":"<code>road_net: Union[None, RoadwayNetwork]</code>  <code>property</code> <code>writable</code>","text":"<p>Roadway network associated with the transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.shape_links_gdf","title":"<code>shape_links_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return shape-links as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.shapes_gdf","title":"<code>shapes_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return aggregated shapes as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stop_time_links_gdf","title":"<code>stop_time_links_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return stop-time-links as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stop_times_points_gdf","title":"<code>stop_times_points_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return stop-time-points as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stops_gdf","title":"<code>stops_gdf: gpd.GeoDataFrame</code>  <code>property</code>","text":"<p>Return stops as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.__deepcopy__","title":"<code>__deepcopy__(memo)</code>","text":"<p>Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n    COPY_REF_NOT_VALUE = [\"_road_net\"]\n    # Create a new, empty instance\n    copied_net = self.__class__.__new__(self.__class__)\n    # Return the new TransitNetwork instance\n    attribute_dict = vars(self)\n\n    # Copy the attributes to the new instance\n    for attr_name, attr_value in attribute_dict.items():\n        # WranglerLogger.debug(f\"Copying {attr_name}\")\n        if attr_name in COPY_REF_NOT_VALUE:\n            # If the attribute is in the COPY_REF_NOT_VALUE list, assign the reference\n            setattr(copied_net, attr_name, attr_value)\n        else:\n            # WranglerLogger.debug(f\"making deep copy: {attr_name}\")\n            # For other attributes, perform a deep copy\n            setattr(copied_net, attr_name, copy.deepcopy(attr_value, memo))\n\n    return copied_net\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.__init__","title":"<code>__init__(feed, config=DefaultConfig)</code>","text":"<p>Constructor for TransitNetwork.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Feed</code> <p>Feed object representing the transit network gtfs tables</p> required <code>config</code> <code>WranglerConfig</code> <p>WranglerConfig object. Defaults to DefaultConfig.</p> <code>DefaultConfig</code> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def __init__(self, feed: Feed, config: WranglerConfig = DefaultConfig) -&gt; None:\n    \"\"\"Constructor for TransitNetwork.\n\n    Args:\n        feed: Feed object representing the transit network gtfs tables\n        config: WranglerConfig object. Defaults to DefaultConfig.\n    \"\"\"\n    WranglerLogger.debug(\"Creating new TransitNetwork.\")\n\n    self._road_net: Optional[RoadwayNetwork] = None\n    self.feed: Feed = feed\n    self.graph: nx.MultiDiGraph = None\n    self.config: WranglerConfig = config\n    # initialize\n    self._consistent_with_road_net = False\n\n    # cached selections\n    self._selections: dict[str, TransitSelection] = {}\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.apply","title":"<code>apply(project_card, **kwargs)</code>","text":"<p>Wrapper method to apply a roadway project, returning a new TransitNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>project_card</code> <code>Union[ProjectCard, dict]</code> <p>either a dictionary of the project card object or ProjectCard instance</p> required <code>**kwargs</code> <p>keyword arguments to pass to project application</p> <code>{}</code> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; TransitNetwork:\n    \"\"\"Wrapper method to apply a roadway project, returning a new TransitNetwork instance.\n\n    Args:\n        project_card: either a dictionary of the project card object or ProjectCard instance\n        **kwargs: keyword arguments to pass to project application\n    \"\"\"\n    if not (isinstance(project_card, (ProjectCard, SubProject))):\n        project_card = ProjectCard(project_card)\n\n    if not project_card.valid:\n        msg = f\"Project card {project_card.project} not valid.\"\n        WranglerLogger.error(msg)\n        raise ProjectCardError(msg)\n\n    if project_card._sub_projects:\n        for sp in project_card._sub_projects:\n            WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n            self._apply_change(sp, **kwargs)\n        return self\n    return self._apply_change(project_card, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.deepcopy","title":"<code>deepcopy()</code>","text":"<p>Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def deepcopy(self):\n    \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n    return copy.deepcopy(self)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.get_selection","title":"<code>get_selection(selection_dict, overwrite=False)</code>","text":"<p>Return selection if it already exists, otherwise performs selection.</p> <p>Will raise an error if no trips found.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>dict</code> <p>description</p> required <code>overwrite</code> <code>bool</code> <p>if True, will overwrite any previously cached searches. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Selection</code> <code>TransitSelection</code> <p>Selection object</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def get_selection(\n    self,\n    selection_dict: dict,\n    overwrite: bool = False,\n) -&gt; TransitSelection:\n    \"\"\"Return selection if it already exists, otherwise performs selection.\n\n    Will raise an error if no trips found.\n\n    Args:\n        selection_dict (dict): _description_\n        overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n\n    Returns:\n        Selection: Selection object\n    \"\"\"\n    key = dict_to_hexkey(selection_dict)\n\n    if (key not in self._selections) or overwrite:\n        WranglerLogger.debug(f\"Performing selection from key: {key}\")\n        self._selections[key] = TransitSelection(self, selection_dict)\n    else:\n        WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n\n    if not self._selections[key]:\n        msg = f\"No links or nodes found for selection dict: \\n {selection_dict}\"\n        WranglerLogger.error(msg)\n        raise TransitSelectionEmptyError(msg)\n    return self._selections[key]\n</code></pre>"},{"location":"api/#configs","title":"Configs","text":"<p>Configuration for parameters for Network Wrangler.</p> <p>Users can change a handful of parameters which control the way Wrangler runs.  These parameters can be saved as a wrangler config file which can be read in repeatedly to make sure the same parameters are used each time.</p> Usage <p>At runtime, you can specify configurable parameters at the scenario level which will then also be assigned and accessible to the roadway and transit networks.</p> <pre><code>create_scenario(...config = myconfig)\n</code></pre> <p>Or if you are not using Scenario functionality, you can specify the config when you read in a RoadwayNetwork.</p> <pre><code>load_roadway_from_dir(**roadway, config=myconfig)\nload_transit(**transit, config=myconfig)\n</code></pre> <p><code>my_config</code> can be a:</p> <ul> <li>Path to a config file in yaml/toml/json (recommended),</li> <li>List of paths to config files (in case you want to split up various sub-configurations)</li> <li>Dictionary which is in the same structure of a config file, or</li> <li>A <code>WranglerConfig()</code>  instance.</li> </ul> <p>If not provided, Wrangler will use reasonable defaults.</p> Default Wrangler Configuration Values<p>If not explicitly provided, the following default values are used:</p> <pre><code>IDS:\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: (950000, 999999)\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: (950000, 999999)\n    ML_NODE_ID_SCALAR: 15000\nEDITS:\n    EXISTING_VALUE_CONFLIC: warn\n    OVERWRITE_SCOPED: conflicting\nMODEL_ROADWAY:\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\nCPU:\n    EST_PD_READ_SPEED:\n        csv: 0.03\n        parquet: 0.005\n        geojson: 0.03\n        json: 0.15\n        txt: 0.04\n</code></pre> Extended usage <p>Load the default configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n</code></pre> <p>Access the configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS\n&gt;&gt; -10\n</code></pre> <p>Modify the default configuration in-line:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS = 20\n</code></pre> <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_wrangler_config\n\nconfig = load_wrangler_config(\"path/to/config.yaml\")\n</code></pre> <p>Set a configuration value:</p> <pre><code>config.MODEL_ROADWAY.ML_OFFSET_METERS = 10\n</code></pre> <p>Scenario configuration for Network Wrangler.</p> <p>You can build a scenario and write out the output from a scenario configuration file using the code below.  This is very useful when you are running a specific scenario with minor variations over again because you can enter your config file into version control.  In addition to the completed roadway and transit files, the output will provide a record of how the scenario was run.</p> Usage <pre><code>    from scenario import build_scenario_from_config\n    my_scenario = build_scenario_from_config(my_scenario_config)\n</code></pre> <p>Where <code>my_scenario_config</code> can be a:</p> <ul> <li>Path to a scenario config file in yaml/toml/json (recommended),</li> <li>Dictionary which is in the same structure of a scenario config file, or</li> <li>A <code>ScenarioConfig()</code>  instance.</li> </ul> <p>Notes on relative paths in scenario configs</p> <ul> <li>Relative paths are recognized by a preceeding \u201c.\u201d.</li> <li>Relative paths within <code>output_scenario</code> for <code>roadway</code>, <code>transit</code>, and <code>project_cards</code> are interpreted to be relative to <code>output_scenario.path</code>.</li> <li>All other relative paths are interpreted to be relative to directory of the scenario config file. (Or if scenario config is provided as a dictionary, relative paths will be interpreted as relative to the current working directory.)</li> </ul> Example Scenario Config<pre><code>name: \"my_scenario\"\nbase_scenario:\n    roadway:\n        dir: \"path/to/roadway_network\"\n        file_format: \"geojson\"\n        read_in_shapes: True\n    transit:\n        dir: \"path/to/transit_network\"\n        file_format: \"txt\"\n    applied_projects:\n        - \"project1\"\n        - \"project2\"\n    conflicts:\n        \"project3\": [\"project1\", \"project2\"]\n        \"project4\": [\"project1\"]\nprojects:\n    project_card_filepath:\n        - \"path/to/projectA.yaml\"\n        - \"path/to/projectB.yaml\"\n    filter_tags:\n        - \"tag1\"\noutput_scenario:\n    overwrite: True\n    roadway:\n        out_dir: \"path/to/output/roadway\"\n        prefix: \"my_scenario\"\n        file_format: \"geojson\"\n        true_shape: False\n    transit:\n        out_dir: \"path/to/output/transit\"\n        prefix: \"my_scenario\"\n        file_format: \"txt\"\n    project_cards:\n        out_dir: \"path/to/output/project_cards\"\n\nwrangler_config: \"path/to/wrangler_config.yaml\"\n</code></pre> Extended Usage <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_scenario_config\n\nmy_scenario_config = load_scenario_config(\"path/to/config.yaml\")\n</code></pre> <p>Access the configuration:</p> <pre><code>my_scenario_config.base_transit_network.path\n&gt;&gt; path/to/transit_network\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.CpuConfig","title":"<code>CpuConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>CPU Configuration -  Will not change any outcomes.</p> <p>Attributes:</p> Name Type Description <code>EST_PD_READ_SPEED</code> <code>dict[str, float]</code> <p>Read sec / MB - WILL DEPEND ON SPECIFIC COMPUTER</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass CpuConfig(ConfigItem):\n    \"\"\"CPU Configuration -  Will not change any outcomes.\n\n    Attributes:\n        EST_PD_READ_SPEED: Read sec / MB - WILL DEPEND ON SPECIFIC COMPUTER\n    \"\"\"\n\n    EST_PD_READ_SPEED: dict[str, float] = Field(\n        default_factory=lambda: {\n            \"csv\": 0.03,\n            \"parquet\": 0.005,\n            \"geojson\": 0.03,\n            \"json\": 0.15,\n            \"txt\": 0.04,\n        }\n    )\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.EditsConfig","title":"<code>EditsConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for Edits.</p> <p>Attributes:</p> Name Type Description <code>EXISTING_VALUE_CONFLICT</code> <code>Literal['warn', 'error', 'skip']</code> <p>Only used if \u2018existing\u2019 provided in project card and <code>existing</code> doesn\u2019t match the existing network value. One of <code>error</code>, <code>warn</code>, or <code>skip</code>. <code>error</code> will raise an error, <code>warn</code> will warn the user, and <code>skip</code> will skip the change for that specific property (note it will still apply any remaining property changes). Defaults to <code>warn</code>. Can be overridden by setting <code>existing_value_conflict</code> in a <code>roadway_property_change</code> project card.</p> <code>OVERWRITE_SCOPED</code> <code>Literal['conflicting', 'all', 'error']</code> <p>How to handle conflicts with existing values. Should be one of \u201cconflicting\u201d, \u201call\u201d, or False. \u201cconflicting\u201d will only overwrite values where the scope only partially overlaps with the existing value. \u201call\u201d will overwrite all the scoped values. \u201cerror\u201d will error if there is any overlap. Default is \u201cconflicting\u201d. Can be changed at the project-level by setting <code>overwrite_scoped</code> in a <code>roadway_property_change</code> project card.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass EditsConfig(ConfigItem):\n    \"\"\"Configuration for Edits.\n\n    Attributes:\n        EXISTING_VALUE_CONFLICT: Only used if 'existing' provided in project card and\n            `existing` doesn't match the existing network value. One of `error`, `warn`, or `skip`.\n            `error` will raise an error, `warn` will warn the user, and `skip` will skip the change\n            for that specific property (note it will still apply any remaining property changes).\n            Defaults to `warn`. Can be overridden by setting `existing_value_conflict` in\n            a `roadway_property_change` project card.\n\n        OVERWRITE_SCOPED: How to handle conflicts with existing values.\n            Should be one of \"conflicting\", \"all\", or False.\n            \"conflicting\" will only overwrite values where the scope only partially overlaps with\n            the existing value. \"all\" will overwrite all the scoped values. \"error\" will error if\n            there is any overlap. Default is \"conflicting\". Can be changed at the project-level\n            by setting `overwrite_scoped` in a `roadway_property_change` project card.\n    \"\"\"\n\n    EXISTING_VALUE_CONFLICT: Literal[\"warn\", \"error\", \"skip\"] = \"warn\"\n    OVERWRITE_SCOPED: Literal[\"conflicting\", \"all\", \"error\"] = \"conflicting\"\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.IdGenerationConfig","title":"<code>IdGenerationConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> Name Type Description <code>TRANSIT_SHAPE_ID_METHOD</code> <code>Literal['scalar']</code> <p>method for creating a shape_id for a transit shape. Should be \u201cscalar\u201d.</p> <code>TRANSIT_SHAPE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a shape_id for a transit shape.</p> <code>ROAD_SHAPE_ID_METHOD</code> <code>Literal['scalar']</code> <p>method for creating a shape_id for a roadway shape. Should be \u201cscalar\u201d.</p> <code>ROAD_SHAPE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a shape_id for a roadway shape.</p> <code>ML_LINK_ID_METHOD</code> <code>Literal['range', 'scalar']</code> <p>method for creating a model_link_id for an associated link for a parallel managed lane.</p> <code>ML_LINK_ID_RANGE</code> <code>tuple[int, int]</code> <p>range of model_link_ids to use when creating an associated link for a parallel managed lane.</p> <code>ML_LINK_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a model_link_id when creating an associated link for a parallel managed lane.</p> <code>ML_NODE_ID_METHOD</code> <code>Literal['range', 'scalar']</code> <p>method for creating a model_node_id for an associated node for a parallel managed lane.</p> <code>ML_NODE_ID_RANGE</code> <code>tuple[int, int]</code> <p>range of model_node_ids to use when creating an associated node for a parallel managed lane.</p> <code>ML_NODE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane node ides create a model_node_id when creating an associated nodes for parallel managed lane.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass IdGenerationConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        TRANSIT_SHAPE_ID_METHOD: method for creating a shape_id for a transit shape.\n            Should be \"scalar\".\n        TRANSIT_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a transit shape.\n        ROAD_SHAPE_ID_METHOD: method for creating a shape_id for a roadway shape.\n            Should be \"scalar\".\n        ROAD_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a roadway shape.\n        ML_LINK_ID_METHOD: method for creating a model_link_id for an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_RANGE: range of model_link_ids to use when creating an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_SCALAR: scalar value to add to general purpose lane to create a\n            model_link_id when creating an associated link for a parallel managed lane.\n        ML_NODE_ID_METHOD: method for creating a model_node_id for an associated node\n            for a parallel managed lane.\n        ML_NODE_ID_RANGE: range of model_node_ids to use when creating an associated\n            node for a parallel managed lane.\n        ML_NODE_ID_SCALAR: scalar value to add to general purpose lane node ides create\n            a model_node_id when creating an associated nodes for parallel managed lane.\n    \"\"\"\n\n    TRANSIT_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    TRANSIT_SHAPE_ID_SCALAR: int = 1000000\n    ROAD_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    ROAD_SHAPE_ID_SCALAR: int = 1000\n    ML_LINK_ID_METHOD: Literal[\"range\", \"scalar\"] = \"scalar\"\n    ML_LINK_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_LINK_ID_SCALAR: int = 3000000\n    ML_NODE_ID_METHOD: Literal[\"range\", \"scalar\"] = \"range\"\n    ML_NODE_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_NODE_ID_SCALAR: int = 15000\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.ModelRoadwayConfig","title":"<code>ModelRoadwayConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> Name Type Description <code>ML_OFFSET_METERS</code> <code>int</code> <p>Offset in meters for managed lanes.</p> <code>ADDITIONAL_COPY_FROM_GP_TO_ML</code> <code>list[str]</code> <p>Additional fields to copy from general purpose to managed lanes.</p> <code>ADDITIONAL_COPY_TO_ACCESS_EGRESS</code> <code>list[str]</code> <p>Additional fields to copy to access and egress links.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass ModelRoadwayConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        ML_OFFSET_METERS: Offset in meters for managed lanes.\n        ADDITIONAL_COPY_FROM_GP_TO_ML: Additional fields to copy from general purpose to managed\n            lanes.\n        ADDITIONAL_COPY_TO_ACCESS_EGRESS: Additional fields to copy to access and egress links.\n    \"\"\"\n\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: list[str] = Field(default_factory=list)\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: list[str] = Field(default_factory=list)\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.WranglerConfig","title":"<code>WranglerConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for Network Wrangler.</p> <p>Attributes:</p> Name Type Description <code>IDS</code> <code>IdGenerationConfig</code> <p>Parameteters governing how new ids are generated.</p> <code>MODEL_ROADWAY</code> <code>ModelRoadwayConfig</code> <p>Parameters governing how the model roadway is created.</p> <code>CPU</code> <code>CpuConfig</code> <p>Parameters for accessing CPU information. Will not change any outcomes.</p> <code>EDITS</code> <code>EditsConfig</code> <p>Parameters governing how edits are handled.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass WranglerConfig(ConfigItem):\n    \"\"\"Configuration for Network Wrangler.\n\n    Attributes:\n        IDS: Parameteters governing how new ids are generated.\n        MODEL_ROADWAY: Parameters governing how the model roadway is created.\n        CPU: Parameters for accessing CPU information. Will not change any outcomes.\n        EDITS: Parameters governing how edits are handled.\n    \"\"\"\n\n    IDS: IdGenerationConfig = IdGenerationConfig()\n    MODEL_ROADWAY: ModelRoadwayConfig = ModelRoadwayConfig()\n    CPU: CpuConfig = CpuConfig()\n    EDITS: EditsConfig = EditsConfig()\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ProjectCardOutputConfig","title":"<code>ProjectCardOutputConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for outputing project cards in a scenario.</p> <p>Attributes:</p> Name Type Description <code>out_dir</code> <p>Path to write the project card files to if you don\u2019t want to use the default.</p> <code>write</code> <p>If True, will write the project cards. Defaults to True.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ProjectCardOutputConfig(ConfigItem):\n    \"\"\"Configuration for outputing project cards in a scenario.\n\n    Attributes:\n        out_dir: Path to write the project card files to if you don't want to use the default.\n        write: If True, will write the project cards. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        out_dir: Path = DEFAULT_PROJECT_OUT_DIR,\n        write: bool = DEFAULT_PROJECT_WRITE,\n    ):\n        \"\"\"Constructor for ProjectCardOutputConfig.\"\"\"\n        if out_dir is not None and not Path(out_dir).is_absolute():\n            self.out_dir = (base_path / Path(out_dir)).resolve()\n        else:\n            self.out_dir = Path(out_dir)\n        self.write = write\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ProjectCardOutputConfig.__init__","title":"<code>__init__(base_path=DEFAULT_BASE_DIR, out_dir=DEFAULT_PROJECT_OUT_DIR, write=DEFAULT_PROJECT_WRITE)</code>","text":"<p>Constructor for ProjectCardOutputConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_path: Path = DEFAULT_BASE_DIR,\n    out_dir: Path = DEFAULT_PROJECT_OUT_DIR,\n    write: bool = DEFAULT_PROJECT_WRITE,\n):\n    \"\"\"Constructor for ProjectCardOutputConfig.\"\"\"\n    if out_dir is not None and not Path(out_dir).is_absolute():\n        self.out_dir = (base_path / Path(out_dir)).resolve()\n    else:\n        self.out_dir = Path(out_dir)\n    self.write = write\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ProjectsConfig","title":"<code>ProjectsConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for projects in a scenario.</p> <p>Attributes:</p> Name Type Description <code>project_card_filepath</code> <p>where the project card is.  A single path, list of paths, a directory, or a glob pattern. Defaults to None.</p> <code>filter_tags</code> <p>List of tags to filter the project cards by.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ProjectsConfig(ConfigItem):\n    \"\"\"Configuration for projects in a scenario.\n\n    Attributes:\n        project_card_filepath: where the project card is.  A single path, list of paths,\n            a directory, or a glob pattern. Defaults to None.\n        filter_tags: List of tags to filter the project cards by.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        project_card_filepath: ProjectCardFilepaths = DEFAULT_PROJECT_IN_PATHS,\n        filter_tags: list[str] = DEFAULT_PROJECT_TAGS,\n    ):\n        \"\"\"Constructor for ProjectsConfig.\"\"\"\n        self.project_card_filepath = _resolve_rel_paths(project_card_filepath, base_path=base_path)\n        self.filter_tags = filter_tags\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ProjectsConfig.__init__","title":"<code>__init__(base_path=DEFAULT_BASE_DIR, project_card_filepath=DEFAULT_PROJECT_IN_PATHS, filter_tags=DEFAULT_PROJECT_TAGS)</code>","text":"<p>Constructor for ProjectsConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_path: Path = DEFAULT_BASE_DIR,\n    project_card_filepath: ProjectCardFilepaths = DEFAULT_PROJECT_IN_PATHS,\n    filter_tags: list[str] = DEFAULT_PROJECT_TAGS,\n):\n    \"\"\"Constructor for ProjectsConfig.\"\"\"\n    self.project_card_filepath = _resolve_rel_paths(project_card_filepath, base_path=base_path)\n    self.filter_tags = filter_tags\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.RoadwayNetworkInputConfig","title":"<code>RoadwayNetworkInputConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the road network in a scenario.</p> <p>Attributes:</p> Name Type Description <code>dir</code> <p>Path to directory with roadway network files.</p> <code>file_format</code> <p>File format for the roadway network files. Should be one of RoadwayFileTypes. Defaults to \u201cgeojson\u201d.</p> <code>read_in_shapes</code> <p>If True, will read in the shapes of the roadway network. Defaults to False.</p> <code>boundary_geocode</code> <p>Geocode of the boundary. Will use this to filter the roadway network.</p> <code>boundary_file</code> <p>Path to the boundary file. If provided and both boundary_gdf and boundary_geocode are not provided, will use this to filter the roadway network.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class RoadwayNetworkInputConfig(ConfigItem):\n    \"\"\"Configuration for the road network in a scenario.\n\n    Attributes:\n        dir: Path to directory with roadway network files.\n        file_format: File format for the roadway network files. Should be one of RoadwayFileTypes.\n            Defaults to \"geojson\".\n        read_in_shapes: If True, will read in the shapes of the roadway network. Defaults to False.\n        boundary_geocode: Geocode of the boundary. Will use this to filter the roadway network.\n        boundary_file: Path to the boundary file. If provided and both boundary_gdf and\n            boundary_geocode are not provided, will use this to filter the roadway network.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        dir: Path = DEFAULT_ROADWAY_IN_DIR,\n        file_format: RoadwayFileTypes = DEFAULT_ROADWAY_IN_FORMAT,\n        read_in_shapes: bool = DEFAULT_ROADWAY_SHAPE_READ,\n        boundary_geocode: Optional[str] = None,\n        boundary_file: Optional[Path] = None,\n    ):\n        \"\"\"Constructor for RoadwayNetworkInputConfig.\"\"\"\n        if dir is not None and not Path(dir).is_absolute():\n            self.dir = (base_path / Path(dir)).resolve()\n        else:\n            self.dir = Path(dir)\n        self.file_format = file_format\n        self.read_in_shapes = read_in_shapes\n        self.boundary_geocode = boundary_geocode\n        self.boundary_file = boundary_file\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.RoadwayNetworkInputConfig.__init__","title":"<code>__init__(base_path=DEFAULT_BASE_DIR, dir=DEFAULT_ROADWAY_IN_DIR, file_format=DEFAULT_ROADWAY_IN_FORMAT, read_in_shapes=DEFAULT_ROADWAY_SHAPE_READ, boundary_geocode=None, boundary_file=None)</code>","text":"<p>Constructor for RoadwayNetworkInputConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_path: Path = DEFAULT_BASE_DIR,\n    dir: Path = DEFAULT_ROADWAY_IN_DIR,\n    file_format: RoadwayFileTypes = DEFAULT_ROADWAY_IN_FORMAT,\n    read_in_shapes: bool = DEFAULT_ROADWAY_SHAPE_READ,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n):\n    \"\"\"Constructor for RoadwayNetworkInputConfig.\"\"\"\n    if dir is not None and not Path(dir).is_absolute():\n        self.dir = (base_path / Path(dir)).resolve()\n    else:\n        self.dir = Path(dir)\n    self.file_format = file_format\n    self.read_in_shapes = read_in_shapes\n    self.boundary_geocode = boundary_geocode\n    self.boundary_file = boundary_file\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.RoadwayNetworkOutputConfig","title":"<code>RoadwayNetworkOutputConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for writing out the resulting roadway network for a scenario.</p> <p>Attributes:</p> Name Type Description <code>out_dir</code> <p>Path to write the roadway network files to if you don\u2019t want to use the default.</p> <code>prefix</code> <p>Prefix to add to the file name. If not provided will use the scenario name.</p> <code>file_format</code> <p>File format to write the roadway network to. Should be one of RoadwayFileTypes. Defaults to \u201cgeojson\u201d.</p> <code>true_shape</code> <p>If True, will write the true shape of the roadway network. Defaults to False.</p> <code>write</code> <p>If True, will write the roadway network. Defaults to True.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class RoadwayNetworkOutputConfig(ConfigItem):\n    \"\"\"Configuration for writing out the resulting roadway network for a scenario.\n\n    Attributes:\n        out_dir: Path to write the roadway network files to if you don't want to use the default.\n        prefix: Prefix to add to the file name. If not provided will use the scenario name.\n        file_format: File format to write the roadway network to. Should be one of\n            RoadwayFileTypes. Defaults to \"geojson\".\n        true_shape: If True, will write the true shape of the roadway network. Defaults to False.\n        write: If True, will write the roadway network. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        out_dir: Path = DEFAULT_ROADWAY_OUT_DIR,\n        base_path: Path = DEFAULT_BASE_DIR,\n        convert_complex_link_properties_to_single_field: bool = False,\n        prefix: Optional[str] = None,\n        file_format: RoadwayFileTypes = DEFAULT_ROADWAY_OUT_FORMAT,\n        true_shape: bool = False,\n        write: bool = DEFAULT_ROADWAY_WRITE,\n    ):\n        \"\"\"Constructor for RoadwayNetworkOutputConfig.\"\"\"\n        if out_dir is not None and not Path(out_dir).is_absolute():\n            self.out_dir = (base_path / Path(out_dir)).resolve()\n        else:\n            self.out_dir = Path(out_dir)\n\n        self.convert_complex_link_properties_to_single_field = (\n            convert_complex_link_properties_to_single_field\n        )\n        self.prefix = prefix\n        self.file_format = file_format\n        self.true_shape = true_shape\n        self.write = write\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.RoadwayNetworkOutputConfig.__init__","title":"<code>__init__(out_dir=DEFAULT_ROADWAY_OUT_DIR, base_path=DEFAULT_BASE_DIR, convert_complex_link_properties_to_single_field=False, prefix=None, file_format=DEFAULT_ROADWAY_OUT_FORMAT, true_shape=False, write=DEFAULT_ROADWAY_WRITE)</code>","text":"<p>Constructor for RoadwayNetworkOutputConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    out_dir: Path = DEFAULT_ROADWAY_OUT_DIR,\n    base_path: Path = DEFAULT_BASE_DIR,\n    convert_complex_link_properties_to_single_field: bool = False,\n    prefix: Optional[str] = None,\n    file_format: RoadwayFileTypes = DEFAULT_ROADWAY_OUT_FORMAT,\n    true_shape: bool = False,\n    write: bool = DEFAULT_ROADWAY_WRITE,\n):\n    \"\"\"Constructor for RoadwayNetworkOutputConfig.\"\"\"\n    if out_dir is not None and not Path(out_dir).is_absolute():\n        self.out_dir = (base_path / Path(out_dir)).resolve()\n    else:\n        self.out_dir = Path(out_dir)\n\n    self.convert_complex_link_properties_to_single_field = (\n        convert_complex_link_properties_to_single_field\n    )\n    self.prefix = prefix\n    self.file_format = file_format\n    self.true_shape = true_shape\n    self.write = write\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioConfig","title":"<code>ScenarioConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Scenario configuration for Network Wrangler.</p> <p>Attributes:</p> Name Type Description <code>base_path</code> <p>base path of the scenario. Defaults to cwd.</p> <code>name</code> <p>Name of the scenario.</p> <code>base_scenario</code> <p>information about the base scenario</p> <code>projects</code> <p>information about the projects to apply on top of the base scenario</p> <code>output_scenario</code> <p>information about how to output the scenario</p> <code>wrangler_config</code> <p>wrangler configuration to use</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ScenarioConfig(ConfigItem):\n    \"\"\"Scenario configuration for Network Wrangler.\n\n    Attributes:\n        base_path: base path of the scenario. Defaults to cwd.\n        name: Name of the scenario.\n        base_scenario: information about the base scenario\n        projects: information about the projects to apply on top of the base scenario\n        output_scenario: information about how to output the scenario\n        wrangler_config: wrangler configuration to use\n    \"\"\"\n\n    def __init__(\n        self,\n        base_scenario: dict,\n        projects: dict,\n        output_scenario: dict,\n        base_path: Path = DEFAULT_BASE_DIR,\n        name: str = DEFAULT_SCENARIO_NAME,\n        wrangler_config=DefaultConfig,\n    ):\n        \"\"\"Constructor for ScenarioConfig.\"\"\"\n        self.base_path = Path(base_path) if base_path is not None else Path.cwd()\n        self.name = name\n        self.base_scenario = ScenarioInputConfig(**base_scenario, base_path=base_path)\n        self.projects = ProjectsConfig(**projects, base_path=base_path)\n        self.output_scenario = ScenarioOutputConfig(**output_scenario, base_path=base_path)\n        self.wrangler_config = wrangler_config\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioConfig.__init__","title":"<code>__init__(base_scenario, projects, output_scenario, base_path=DEFAULT_BASE_DIR, name=DEFAULT_SCENARIO_NAME, wrangler_config=DefaultConfig)</code>","text":"<p>Constructor for ScenarioConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_scenario: dict,\n    projects: dict,\n    output_scenario: dict,\n    base_path: Path = DEFAULT_BASE_DIR,\n    name: str = DEFAULT_SCENARIO_NAME,\n    wrangler_config=DefaultConfig,\n):\n    \"\"\"Constructor for ScenarioConfig.\"\"\"\n    self.base_path = Path(base_path) if base_path is not None else Path.cwd()\n    self.name = name\n    self.base_scenario = ScenarioInputConfig(**base_scenario, base_path=base_path)\n    self.projects = ProjectsConfig(**projects, base_path=base_path)\n    self.output_scenario = ScenarioOutputConfig(**output_scenario, base_path=base_path)\n    self.wrangler_config = wrangler_config\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioInputConfig","title":"<code>ScenarioInputConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the writing the output of a scenario.</p> <p>Attributes:</p> Name Type Description <code>roadway</code> <code>Optional[RoadwayNetworkInputConfig]</code> <p>Configuration for writing out the roadway network.</p> <code>transit</code> <code>Optional[TransitNetworkInputConfig]</code> <p>Configuration for writing out the transit network.</p> <code>applied_projects</code> <p>List of projects to apply to the base scenario.</p> <code>conflicts</code> <p>Dict of projects that conflict with the applied_projects.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ScenarioInputConfig(ConfigItem):\n    \"\"\"Configuration for the writing the output of a scenario.\n\n    Attributes:\n        roadway: Configuration for writing out the roadway network.\n        transit: Configuration for writing out the transit network.\n        applied_projects: List of projects to apply to the base scenario.\n        conflicts: Dict of projects that conflict with the applied_projects.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        roadway: Optional[dict] = None,\n        transit: Optional[dict] = None,\n        applied_projects: Optional[list[str]] = None,\n        conflicts: Optional[dict] = None,\n    ):\n        \"\"\"Constructor for ScenarioInputConfig.\"\"\"\n        if roadway is not None:\n            self.roadway: Optional[RoadwayNetworkInputConfig] = RoadwayNetworkInputConfig(\n                **roadway, base_path=base_path\n            )\n        else:\n            self.roadway = None\n\n        if transit is not None:\n            self.transit: Optional[TransitNetworkInputConfig] = TransitNetworkInputConfig(\n                **transit, base_path=base_path\n            )\n        else:\n            self.transit = None\n\n        self.applied_projects = applied_projects if applied_projects is not None else []\n        self.conflicts = conflicts if conflicts is not None else {}\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioInputConfig.__init__","title":"<code>__init__(base_path=DEFAULT_BASE_DIR, roadway=None, transit=None, applied_projects=None, conflicts=None)</code>","text":"<p>Constructor for ScenarioInputConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_path: Path = DEFAULT_BASE_DIR,\n    roadway: Optional[dict] = None,\n    transit: Optional[dict] = None,\n    applied_projects: Optional[list[str]] = None,\n    conflicts: Optional[dict] = None,\n):\n    \"\"\"Constructor for ScenarioInputConfig.\"\"\"\n    if roadway is not None:\n        self.roadway: Optional[RoadwayNetworkInputConfig] = RoadwayNetworkInputConfig(\n            **roadway, base_path=base_path\n        )\n    else:\n        self.roadway = None\n\n    if transit is not None:\n        self.transit: Optional[TransitNetworkInputConfig] = TransitNetworkInputConfig(\n            **transit, base_path=base_path\n        )\n    else:\n        self.transit = None\n\n    self.applied_projects = applied_projects if applied_projects is not None else []\n    self.conflicts = conflicts if conflicts is not None else {}\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioOutputConfig","title":"<code>ScenarioOutputConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the writing the output of a scenario.</p> <p>Attributes:</p> Name Type Description <code>roadway</code> <p>Configuration for writing out the roadway network.</p> <code>transit</code> <p>Configuration for writing out the transit network.</p> <code>project_cards</code> <code>Optional[ProjectCardOutputConfig]</code> <p>Configuration for writing out the project cards.</p> <code>overwrite</code> <p>If True, will overwrite the files if they already exist. Defaults to True</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ScenarioOutputConfig(ConfigItem):\n    \"\"\"Configuration for the writing the output of a scenario.\n\n    Attributes:\n        roadway: Configuration for writing out the roadway network.\n        transit: Configuration for writing out the transit network.\n        project_cards: Configuration for writing out the project cards.\n        overwrite: If True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Path = DEFAULT_OUTPUT_DIR,\n        base_path: Path = DEFAULT_BASE_DIR,\n        roadway: Optional[dict] = None,\n        transit: Optional[dict] = None,\n        project_cards: Optional[dict] = None,\n        overwrite: bool = True,\n    ):\n        \"\"\"Constructor for ScenarioOutputConfig.\"\"\"\n        if not Path(path).is_absolute():\n            self.path = (base_path / Path(path)).resolve()\n        else:\n            self.path = Path(path)\n\n        roadway = roadway if roadway else RoadwayNetworkOutputConfig().to_dict()\n        transit = transit if transit else TransitNetworkOutputConfig().to_dict()\n        self.roadway = RoadwayNetworkOutputConfig(**roadway, base_path=self.path)\n        self.transit = TransitNetworkOutputConfig(**transit, base_path=self.path)\n\n        if project_cards is not None:\n            self.project_cards: Optional[ProjectCardOutputConfig] = ProjectCardOutputConfig(\n                **project_cards, base_path=self.path\n            )\n        else:\n            self.project_cards = None\n\n        self.overwrite = overwrite\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioOutputConfig.__init__","title":"<code>__init__(path=DEFAULT_OUTPUT_DIR, base_path=DEFAULT_BASE_DIR, roadway=None, transit=None, project_cards=None, overwrite=True)</code>","text":"<p>Constructor for ScenarioOutputConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    path: Path = DEFAULT_OUTPUT_DIR,\n    base_path: Path = DEFAULT_BASE_DIR,\n    roadway: Optional[dict] = None,\n    transit: Optional[dict] = None,\n    project_cards: Optional[dict] = None,\n    overwrite: bool = True,\n):\n    \"\"\"Constructor for ScenarioOutputConfig.\"\"\"\n    if not Path(path).is_absolute():\n        self.path = (base_path / Path(path)).resolve()\n    else:\n        self.path = Path(path)\n\n    roadway = roadway if roadway else RoadwayNetworkOutputConfig().to_dict()\n    transit = transit if transit else TransitNetworkOutputConfig().to_dict()\n    self.roadway = RoadwayNetworkOutputConfig(**roadway, base_path=self.path)\n    self.transit = TransitNetworkOutputConfig(**transit, base_path=self.path)\n\n    if project_cards is not None:\n        self.project_cards: Optional[ProjectCardOutputConfig] = ProjectCardOutputConfig(\n            **project_cards, base_path=self.path\n        )\n    else:\n        self.project_cards = None\n\n    self.overwrite = overwrite\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.TransitNetworkInputConfig","title":"<code>TransitNetworkInputConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the transit network in a scenario.</p> <p>Attributes:</p> Name Type Description <code>dir</code> <p>Path to the transit network files. Defaults to \u201c.\u201d.</p> <code>file_format</code> <p>File format for the transit network files. Should be one of TransitFileTypes. Defaults to \u201ctxt\u201d.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class TransitNetworkInputConfig(ConfigItem):\n    \"\"\"Configuration for the transit network in a scenario.\n\n    Attributes:\n        dir: Path to the transit network files. Defaults to \".\".\n        file_format: File format for the transit network files. Should be one of TransitFileTypes.\n            Defaults to \"txt\".\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        dir: Path = DEFAULT_TRANSIT_IN_DIR,\n        file_format: TransitFileTypes = DEFAULT_TRANSIT_IN_FORMAT,\n    ):\n        \"\"\"Constructor for TransitNetworkInputConfig.\"\"\"\n        if dir is not None and not Path(dir).is_absolute():\n            self.feed = (base_path / Path(dir)).resolve()\n        else:\n            self.feed = Path(dir)\n        self.file_format = file_format\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.TransitNetworkInputConfig.__init__","title":"<code>__init__(base_path=DEFAULT_BASE_DIR, dir=DEFAULT_TRANSIT_IN_DIR, file_format=DEFAULT_TRANSIT_IN_FORMAT)</code>","text":"<p>Constructor for TransitNetworkInputConfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_path: Path = DEFAULT_BASE_DIR,\n    dir: Path = DEFAULT_TRANSIT_IN_DIR,\n    file_format: TransitFileTypes = DEFAULT_TRANSIT_IN_FORMAT,\n):\n    \"\"\"Constructor for TransitNetworkInputConfig.\"\"\"\n    if dir is not None and not Path(dir).is_absolute():\n        self.feed = (base_path / Path(dir)).resolve()\n    else:\n        self.feed = Path(dir)\n    self.file_format = file_format\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.TransitNetworkOutputConfig","title":"<code>TransitNetworkOutputConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the transit network in a scenario.</p> <p>Attributes:</p> Name Type Description <code>out_dir</code> <p>Path to write the transit network files to if you don\u2019t want to use the default.</p> <code>prefix</code> <p>Prefix to add to the file name. If not provided will use the scenario name.</p> <code>file_format</code> <p>File format to write the transit network to. Should be one of TransitFileTypes. Defaults to \u201ctxt\u201d.</p> <code>write</code> <p>If True, will write the transit network. Defaults to True.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class TransitNetworkOutputConfig(ConfigItem):\n    \"\"\"Configuration for the transit network in a scenario.\n\n    Attributes:\n        out_dir: Path to write the transit network files to if you don't want to use the default.\n        prefix: Prefix to add to the file name. If not provided will use the scenario name.\n        file_format: File format to write the transit network to. Should be one of\n            TransitFileTypes. Defaults to \"txt\".\n        write: If True, will write the transit network. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        out_dir: Path = DEFAULT_TRANSIT_OUT_DIR,\n        prefix: Optional[str] = None,\n        file_format: TransitFileTypes = DEFAULT_TRANSIT_OUT_FORMAT,\n        write: bool = DEFAULT_TRANSIT_WRITE,\n    ):\n        \"\"\"Constructor for TransitNetworkOutputCOnfig.\"\"\"\n        if out_dir is not None and not Path(out_dir).is_absolute():\n            self.out_dir = (base_path / Path(out_dir)).resolve()\n        else:\n            self.out_dir = Path(out_dir)\n        self.write = write\n        self.prefix = prefix\n        self.file_format = file_format\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.TransitNetworkOutputConfig.__init__","title":"<code>__init__(base_path=DEFAULT_BASE_DIR, out_dir=DEFAULT_TRANSIT_OUT_DIR, prefix=None, file_format=DEFAULT_TRANSIT_OUT_FORMAT, write=DEFAULT_TRANSIT_WRITE)</code>","text":"<p>Constructor for TransitNetworkOutputCOnfig.</p> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_path: Path = DEFAULT_BASE_DIR,\n    out_dir: Path = DEFAULT_TRANSIT_OUT_DIR,\n    prefix: Optional[str] = None,\n    file_format: TransitFileTypes = DEFAULT_TRANSIT_OUT_FORMAT,\n    write: bool = DEFAULT_TRANSIT_WRITE,\n):\n    \"\"\"Constructor for TransitNetworkOutputCOnfig.\"\"\"\n    if out_dir is not None and not Path(out_dir).is_absolute():\n        self.out_dir = (base_path / Path(out_dir)).resolve()\n    else:\n        self.out_dir = Path(out_dir)\n    self.write = write\n    self.prefix = prefix\n    self.file_format = file_format\n</code></pre>"},{"location":"api/#projects","title":"Projects","text":"<p>Projects are how you manipulate the networks. Each project type is defined in a module in the <code>projects</code> folder and accepts a RoadwayNetwork and or TransitNetwork as an input and returns the same objects (manipulated) as an output.  </p>"},{"location":"api/#roadway","title":"Roadway","text":"<p>The roadway module contains submodules which define and extend the links, nodes, and shapes dataframe objects which within a RoadwayNetwork object as well as other classes and methods which support and extend the RoadwayNetwork class.</p>"},{"location":"api/#roadway-network-objects","title":"Roadway Network Objects","text":"<p>Submodules which define and extend the links, nodes, and shapes dataframe objects which within a RoadwayNetwork object.  Includes classes which define:</p> <ul> <li>dataframe schemas to be used for dataframe validation using <code>pandera</code></li> <li>methods which extend the dataframes</li> </ul>"},{"location":"api/#roadway-links","title":"Roadway Links","text":"<p>:: network_wrangler.roadway.links.io     options:         heading_level: 5 :: network_wrangler.roadway.links.create     options:         heading_level: 5 :: network_wrangler.roadway.links.delete     options:         heading_level: 5 :: network_wrangler.roadway.links.edit     options:         heading_level: 5 :: network_wrangler.roadway.links.filters     options:         heading_level: 5 :: network_wrangler.roadway.links.geo     options:         heading_level: 5 :: network_wrangler.roadway.links.scopes     options:         heading_level: 5 :: network_wrangler.roadway.links.summary     options:         heading_level: 5 :: network_wrangler.roadway.links.validate     options:         heading_level: 5 :: network_wrangler.roadway.links.df_accessors     options:         heading_level: 5</p>"},{"location":"api/#roadway-nodes","title":"Roadway Nodes","text":"<p>:: network_wrangler.roadway.nodes.io     options:         heading_level: 5 :: network_wrangler.roadway.nodes.create     options:         heading_level: 5 :: network_wrangler.roadway.nodes.delete     options:         heading_level: 5 :: network_wrangler.roadway.nodes.edit     options:         heading_level: 5 :: network_wrangler.roadway.nodes.filters     options:         heading_level: 5 :: network_wrangler.roadway.nodes     options:         heading_level: 5</p>"},{"location":"api/#roadway-shapes","title":"Roadway Shapes","text":"<p>:: network_wrangler.roadway.shapes.io     options:         heading_level: 5 :: network_wrangler.roadway.shapes.create     options:         heading_level: 5 :: network_wrangler.roadway.shapes.edit     options:         heading_level: 5 :: network_wrangler.roadway.shapes.delete     options:         heading_level: 5 :: network_wrangler.roadway.shapes.filters     options:         heading_level: 5 :: network_wrangler.roadway.shapes.shapes     options:         heading_level: 5</p>"},{"location":"api/#roadway-projects","title":"Roadway Projects","text":"<p>:: network_wrangler.roadway.projects.add     options:         heading_level: 4 :: network_wrangler.roadway.projects.calculate     options:         heading_level: 4 :: network_wrangler.roadway.projects.delete     options:         heading_level: 4 :: network_wrangler.roadway.projects.edit_property     options:         heading_level: 4</p>"},{"location":"api/#roadway-supporting-modules","title":"Roadway Supporting Modules","text":"<p>:: network_wrangler.roadway.io     options:         heading_level: 4 :: network_wrangler.roadway.clip     options:         heading_level: 4 :: network_wrangler.roadway.model_roadway     options:         heading_level: 4 :: network_wrangler.roadway.utils     options:         heading_level: 4 :: network_wrangler.roadway.validate     options:         heading_level: 4 :: network_wrangler.roadway.segment     options:         heading_level: 4 :: network_wrangler.roadway.subnet     options:         heading_level: 4 :: network_wrangler.roadway.graph     options:         heading_level: 4</p>"},{"location":"api/#transit","title":"Transit","text":""},{"location":"api/#feed","title":"Feed","text":"<p>Main functionality for GTFS tables including Feed object.</p> <p>Filters and queries of a gtfs frequencies table.</p> <p>Filters and queries of a gtfs routes table and route_ids.</p> <p>Filters, queries of a gtfs shapes table and node patterns.</p> <p>Filters and queries of a gtfs stop_times table.</p> <p>Filters and queries of a gtfs stops table and stop_ids.</p> <p>Filters and queries of a gtfs trips table and trip_ids.</p> <p>Functions for translating transit tables into visualizable links relatable to roadway network.</p> <p>Functions to create segments from shapes and shape_links.</p>"},{"location":"api/#network_wrangler.transit.feed.feed.Feed","title":"<code>Feed</code>","text":"<p>               Bases: <code>DBModelMixin</code></p> <p>Wrapper class around Wrangler flavored GTFS feed.</p> <p>Most functionality derives from mixin class DBModelMixin which provides:</p> <ul> <li>validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)</li> <li>validation of fks when setting a table attribute (e.g. self.trips = trips_df)</li> <li>hashing and deep copy functionality</li> <li>overload of eq to apply only to tables in table_names.</li> <li>convenience methods for accessing tables</li> </ul> <p>Attributes:</p> Name Type Description <code>table_names</code> <code>list[str]</code> <p>list of table names in GTFS feed.</p> <code>tables</code> <code>list[DataFrame]</code> <p>: list tables as dataframes.</p> <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>: stop_times dataframe with roadway node_ids</p> <code>stops</code> <code>DataFrame[WranglerStopsTable]</code> <p>stops dataframe</p> <code>shapes(DataFrame[WranglerShapesTable])</code> <code>DataFrame[WranglerStopsTable]</code> <p>shapes dataframe</p> <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>trips dataframe</p> <code>frequencies</code> <code>DataFrame[WranglerFrequenciesTable]</code> <p>frequencies dataframe</p> <code>routes</code> <code>DataFrame[RoutesTable]</code> <p>route dataframe</p> <code>agencies</code> <code>Optional[DataFrame[AgenciesTable]]</code> <p>agencies dataframe</p> <code>net</code> <code>Optional[TransitNetwork]</code> <p>TransitNetwork object</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>class Feed(DBModelMixin):\n    \"\"\"Wrapper class around Wrangler flavored GTFS feed.\n\n    Most functionality derives from mixin class DBModelMixin which provides:\n\n    - validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)\n    - validation of fks when setting a table attribute (e.g. self.trips = trips_df)\n    - hashing and deep copy functionality\n    - overload of __eq__ to apply only to tables in table_names.\n    - convenience methods for accessing tables\n\n    Attributes:\n        table_names (list[str]): list of table names in GTFS feed.\n        tables (list[DataFrame]):: list tables as dataframes.\n        stop_times (DataFrame[WranglerStopTimesTable]):: stop_times dataframe with roadway node_ids\n        stops (DataFrame[WranglerStopsTable]):stops dataframe\n        shapes(DataFrame[WranglerShapesTable]): shapes dataframe\n        trips (DataFrame[WranglerTripsTable]): trips dataframe\n        frequencies (DataFrame[WranglerFrequenciesTable]): frequencies dataframe\n        routes (DataFrame[RoutesTable]): route dataframe\n        agencies (Optional[DataFrame[AgenciesTable]]): agencies dataframe\n        net (Optional[TransitNetwork]): TransitNetwork object\n    \"\"\"\n\n    # the ordering here matters because the stops need to be added before stop_times if\n    # stop times needs to be converted\n    _table_models: ClassVar[dict] = {\n        \"agencies\": AgenciesTable,\n        \"frequencies\": WranglerFrequenciesTable,\n        \"routes\": RoutesTable,\n        \"shapes\": WranglerShapesTable,\n        \"stops\": WranglerStopsTable,\n        \"trips\": WranglerTripsTable,\n        \"stop_times\": WranglerStopTimesTable,\n    }\n\n    # Define the converters if the table needs to be converted to a Wrangler table.\n    # Format: \"table_name\": converter_function\n    _converters: ClassVar[dict[str, Callable]] = {}\n\n    table_names: ClassVar[list[str]] = [\n        \"frequencies\",\n        \"routes\",\n        \"shapes\",\n        \"stops\",\n        \"trips\",\n        \"stop_times\",\n    ]\n\n    optional_table_names: ClassVar[list[str]] = [\"agencies\"]\n\n    def __init__(self, **kwargs):\n        \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n        Args:\n            kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n        \"\"\"\n        self._net = None\n        self.feed_path: Path = None\n        self.initialize_tables(**kwargs)\n\n        # Set extra provided attributes but just FYI in logger.\n        extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n        if extra_attr:\n            WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n        for k, v in extra_attr:\n            self.__setattr__(k, v)\n\n    def set_by_id(\n        self,\n        table_name: str,\n        set_df: pd.DataFrame,\n        id_property: str = \"index\",\n        properties: Optional[list[str]] = None,\n    ):\n        \"\"\"Set one or more property values based on an ID property for a given table.\n\n        Args:\n            table_name (str): Name of the table to modify.\n            set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n                values to set for the specified property where `&lt;id_property&gt;` is unique.\n            id_property: Property to use as ID to set by. Defaults to \"index\".\n            properties: List of properties to set which are in set_df. If not specified, will set\n                all properties.\n        \"\"\"\n        if not set_df[id_property].is_unique:\n            msg = f\"{id_property} must be unique in set_df.\"\n            _dupes = set_df[id_property][set_df[id_property].duplicated()]\n            WranglerLogger.error(msg + f\"Found duplicates: {_dupes.sum()}\")\n\n            raise ValueError(msg)\n        table_df = self.get_table(table_name)\n        updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n        self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.feed.Feed.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Create a Feed object from a dictionary of DataFrames representing a GTFS feed.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>A dictionary containing DataFrames representing the tables of a GTFS feed.</p> <code>{}</code> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n    Args:\n        kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n    \"\"\"\n    self._net = None\n    self.feed_path: Path = None\n    self.initialize_tables(**kwargs)\n\n    # Set extra provided attributes but just FYI in logger.\n    extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n    if extra_attr:\n        WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n    for k, v in extra_attr:\n        self.__setattr__(k, v)\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.feed.Feed.set_by_id","title":"<code>set_by_id(table_name, set_df, id_property='index', properties=None)</code>","text":"<p>Set one or more property values based on an ID property for a given table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table to modify.</p> required <code>set_df</code> <code>DataFrame</code> <p>DataFrame with columns <code>&lt;id_property&gt;</code> and <code>value</code> containing values to set for the specified property where <code>&lt;id_property&gt;</code> is unique.</p> required <code>id_property</code> <code>str</code> <p>Property to use as ID to set by. Defaults to \u201cindex\u201d.</p> <code>'index'</code> <code>properties</code> <code>Optional[list[str]]</code> <p>List of properties to set which are in set_df. If not specified, will set all properties.</p> <code>None</code> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def set_by_id(\n    self,\n    table_name: str,\n    set_df: pd.DataFrame,\n    id_property: str = \"index\",\n    properties: Optional[list[str]] = None,\n):\n    \"\"\"Set one or more property values based on an ID property for a given table.\n\n    Args:\n        table_name (str): Name of the table to modify.\n        set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n            values to set for the specified property where `&lt;id_property&gt;` is unique.\n        id_property: Property to use as ID to set by. Defaults to \"index\".\n        properties: List of properties to set which are in set_df. If not specified, will set\n            all properties.\n    \"\"\"\n    if not set_df[id_property].is_unique:\n        msg = f\"{id_property} must be unique in set_df.\"\n        _dupes = set_df[id_property][set_df[id_property].duplicated()]\n        WranglerLogger.error(msg + f\"Found duplicates: {_dupes.sum()}\")\n\n        raise ValueError(msg)\n    table_df = self.get_table(table_name)\n    updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n    self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.feed.merge_shapes_to_stop_times","title":"<code>merge_shapes_to_stop_times(stop_times, shapes, trips)</code>","text":"<p>Add shape_id and shape_pt_sequence to stop_times dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>stop_times dataframe to add shape_id and shape_pt_sequence to.</p> required <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>shapes dataframe to add to stop_times.</p> required <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>trips dataframe to link stop_times to shapes</p> required <p>Returns:</p> Type Description <code>DataFrame[WranglerStopTimesTable]</code> <p>stop_times dataframe with shape_id and shape_pt_sequence added.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def merge_shapes_to_stop_times(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Add shape_id and shape_pt_sequence to stop_times dataframe.\n\n    Args:\n        stop_times: stop_times dataframe to add shape_id and shape_pt_sequence to.\n        shapes: shapes dataframe to add to stop_times.\n        trips: trips dataframe to link stop_times to shapes\n\n    Returns:\n        stop_times dataframe with shape_id and shape_pt_sequence added.\n    \"\"\"\n    stop_times_w_shape_id = stop_times.merge(\n        trips[[\"trip_id\", \"shape_id\"]], on=\"trip_id\", how=\"left\"\n    )\n\n    stop_times_w_shapes = stop_times_w_shape_id.merge(\n        shapes,\n        how=\"left\",\n        left_on=[\"shape_id\", \"stop_id\"],\n        right_on=[\"shape_id\", \"shape_model_node_id\"],\n    )\n    stop_times_w_shapes = stop_times_w_shapes.drop(columns=[\"shape_model_node_id\"])\n    return stop_times_w_shapes\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.feed.stop_count_by_trip","title":"<code>stop_count_by_trip(stop_times)</code>","text":"<p>Returns dataframe with trip_id and stop_count from stop_times.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def stop_count_by_trip(\n    stop_times: DataFrame[WranglerStopTimesTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe with trip_id and stop_count from stop_times.\"\"\"\n    stops_count = stop_times.groupby(\"trip_id\").size()\n    return stops_count.reset_index(name=\"stop_count\")\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.frequencies.frequencies_for_trips","title":"<code>frequencies_for_trips(frequencies, trips)</code>","text":"<p>Filter frequenceis dataframe to records associated with trips table.</p> Source code in <code>network_wrangler/transit/feed/frequencies.py</code> <pre><code>def frequencies_for_trips(\n    frequencies: DataFrame[WranglerFrequenciesTable], trips: DataFrame[WranglerTripsTable]\n) -&gt; DataFrame[WranglerFrequenciesTable]:\n    \"\"\"Filter frequenceis dataframe to records associated with trips table.\"\"\"\n    _sel_trips = trips.trip_id.unique().tolist()\n    filtered_frequencies = frequencies[frequencies.trip_id.isin(_sel_trips)]\n    WranglerLogger.debug(\n        f\"Filtered frequencies to {len(filtered_frequencies)}/{len(frequencies)} \\\n                         records that referenced one of {len(trips)} trips.\"\n    )\n    return filtered_frequencies\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.routes.route_ids_for_trip_ids","title":"<code>route_ids_for_trip_ids(trips, trip_ids)</code>","text":"<p>Returns route ids for given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/routes.py</code> <pre><code>def route_ids_for_trip_ids(trips: DataFrame[WranglerTripsTable], trip_ids: list[str]) -&gt; list[str]:\n    \"\"\"Returns route ids for given list of trip_ids.\"\"\"\n    return trips[trips[\"trip_id\"].isin(trip_ids)].route_id.unique().tolist()\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.routes.routes_for_trip_ids","title":"<code>routes_for_trip_ids(routes, trips, trip_ids)</code>","text":"<p>Returns route records for given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/routes.py</code> <pre><code>def routes_for_trip_ids(\n    routes: DataFrame[RoutesTable], trips: DataFrame[WranglerTripsTable], trip_ids: list[str]\n) -&gt; DataFrame[RoutesTable]:\n    \"\"\"Returns route records for given list of trip_ids.\"\"\"\n    route_ids = route_ids_for_trip_ids(trips, trip_ids)\n    return routes.loc[routes.route_id.isin(route_ids)]\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.routes.routes_for_trips","title":"<code>routes_for_trips(routes, trips)</code>","text":"<p>Filter routes dataframe to records associated with trip records.</p> Source code in <code>network_wrangler/transit/feed/routes.py</code> <pre><code>def routes_for_trips(\n    routes: DataFrame[RoutesTable], trips: DataFrame[WranglerTripsTable]\n) -&gt; DataFrame[RoutesTable]:\n    \"\"\"Filter routes dataframe to records associated with trip records.\"\"\"\n    _sel_routes = trips.route_id.unique().tolist()\n    filtered_routes = routes[routes.route_id.isin(_sel_routes)]\n    WranglerLogger.debug(\n        f\"Filtered routes to {len(filtered_routes)}/{len(routes)} \\\n                         records that referenced one of {len(trips)} trips.\"\n    )\n    return filtered_routes\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.find_nearest_stops","title":"<code>find_nearest_stops(shapes, trips, stop_times, trip_id, node_id, pickup_dropoff='either')</code>","text":"<p>Returns node_ids (before and after) of nearest node_ids that are stops for a given trip_id.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>WranglerShapesTable</code> <p>WranglerShapesTable</p> required <code>trips</code> <code>WranglerTripsTable</code> <p>WranglerTripsTable</p> required <code>stop_times</code> <code>WranglerStopTimesTable</code> <p>WranglerStopTimesTable</p> required <code>trip_id</code> <code>str</code> <p>trip id to find nearest stops for</p> required <code>node_id</code> <code>int</code> <p>node_id to find nearest stops for</p> required <code>pickup_dropoff</code> <code>PickupDropoffAvailability</code> <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> <code>'either'</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[int, int]</code> <p>node_ids for stop before and stop after</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def find_nearest_stops(\n    shapes: WranglerShapesTable,\n    trips: WranglerTripsTable,\n    stop_times: WranglerStopTimesTable,\n    trip_id: str,\n    node_id: int,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; tuple[int, int]:\n    \"\"\"Returns node_ids (before and after) of nearest node_ids that are stops for a given trip_id.\n\n    Args:\n        shapes: WranglerShapesTable\n        trips: WranglerTripsTable\n        stop_times: WranglerStopTimesTable\n        trip_id: trip id to find nearest stops for\n        node_id: node_id to find nearest stops for\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n\n    Returns:\n        tuple: node_ids for stop before and stop after\n    \"\"\"\n    shapes = shapes_with_stop_id_for_trip_id(\n        shapes, trips, stop_times, trip_id, pickup_dropoff=pickup_dropoff\n    )\n    WranglerLogger.debug(f\"Looking for stops near node_id: {node_id}\")\n    if node_id not in shapes[\"shape_model_node_id\"].values:\n        msg = f\"Node ID {node_id} not in shapes for trip {trip_id}\"\n        raise ValueError(msg)\n    # Find index of node_id in shapes\n    node_idx = shapes[shapes[\"shape_model_node_id\"] == node_id].index[0]\n\n    # Find stops before and after new stop in shapes sequence\n    nodes_before = shapes.loc[: node_idx - 1]\n    stops_before = nodes_before.loc[nodes_before[\"stop_id\"].notna()]\n    stop_node_before = 0 if stops_before.empty else stops_before.iloc[-1][\"shape_model_node_id\"]\n\n    nodes_after = shapes.loc[node_idx + 1 :]\n    stops_after = nodes_after.loc[nodes_after[\"stop_id\"].notna()]\n    stop_node_after = 0 if stops_after.empty else stops_after.iloc[0][\"shape_model_node_id\"]\n\n    return stop_node_before, stop_node_after\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.node_pattern_for_shape_id","title":"<code>node_pattern_for_shape_id(shapes, shape_id)</code>","text":"<p>Returns node pattern of a shape.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def node_pattern_for_shape_id(shapes: DataFrame[WranglerShapesTable], shape_id: str) -&gt; list[int]:\n    \"\"\"Returns node pattern of a shape.\"\"\"\n    shape_df = shapes.loc[shapes[\"shape_id\"] == shape_id]\n    shape_df = shape_df.sort_values(by=[\"shape_pt_sequence\"])\n    return shape_df[\"shape_model_node_id\"].to_list()\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shape_id_for_trip_id","title":"<code>shape_id_for_trip_id(trips, trip_id)</code>","text":"<p>Returns a shape_id for a given trip_id.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shape_id_for_trip_id(trips: WranglerTripsTable, trip_id: str) -&gt; str:\n    \"\"\"Returns a shape_id for a given trip_id.\"\"\"\n    return trips.loc[trips.trip_id == trip_id, \"shape_id\"].values[0]\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shape_ids_for_trip_ids","title":"<code>shape_ids_for_trip_ids(trips, trip_ids)</code>","text":"<p>Returns a list of shape_ids for a given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shape_ids_for_trip_ids(trips: DataFrame[WranglerTripsTable], trip_ids: list[str]) -&gt; list[str]:\n    \"\"\"Returns a list of shape_ids for a given list of trip_ids.\"\"\"\n    return trips[trips[\"trip_id\"].isin(trip_ids)].shape_id.unique().tolist()\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shapes_for_road_links","title":"<code>shapes_for_road_links(shapes, links_df)</code>","text":"<p>Filter shapes dataframe to records associated with links dataframe.</p> <p>EX:</p> <p>shapes = pd.DataFrame({     \u201cshape_id\u201d: [\u201c1\u201d, \u201c1\u201d, \u201c1\u201d, \u201c1\u201d, \u201c2\u201d, \u201c2\u201d, \u201c2\u201d, \u201c2\u201d, \u201c2\u201d],     \u201cshape_pt_sequence\u201d: [1, 2, 3, 4, 1, 2, 3, 4, 5],     \u201cshape_model_node_id\u201d: [1, 2, 3, 4, 2, 3, 1, 5, 4] })</p> <p>links_df = pd.DataFrame({     \u201cA\u201d: [1, 2, 3],     \u201cB\u201d: [2, 3, 4] })</p> <p>shapes</p> <p>shape_id   shape_pt_sequence   shape_model_node_id should retain 1          1                  1                        TRUE 1          2                  2                        TRUE 1          3                  3                        TRUE 1          4                  4                        TRUE 1          5                  5                       FALSE 2          1                  1                        TRUE 2          2                  2                        TRUE 2          3                  3                        TRUE 2          4                  1                       FALSE 2          5                  5                       FALSE 2          6                  4                       FALSE 2          7                  1                       FALSE - not largest segment 2          8                  2                       FALSE - not largest segment</p> <p>links_df</p> <p>A   B 1   2 2   3 3   4</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_road_links(\n    shapes: DataFrame[WranglerShapesTable], links_df: pd.DataFrame\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Filter shapes dataframe to records associated with links dataframe.\n\n    EX:\n\n    &gt; shapes = pd.DataFrame({\n        \"shape_id\": [\"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\", \"2\", \"2\"],\n        \"shape_pt_sequence\": [1, 2, 3, 4, 1, 2, 3, 4, 5],\n        \"shape_model_node_id\": [1, 2, 3, 4, 2, 3, 1, 5, 4]\n    })\n\n    &gt; links_df = pd.DataFrame({\n        \"A\": [1, 2, 3],\n        \"B\": [2, 3, 4]\n    })\n\n    &gt; shapes\n\n    shape_id   shape_pt_sequence   shape_model_node_id *should retain*\n    1          1                  1                        TRUE\n    1          2                  2                        TRUE\n    1          3                  3                        TRUE\n    1          4                  4                        TRUE\n    1          5                  5                       FALSE\n    2          1                  1                        TRUE\n    2          2                  2                        TRUE\n    2          3                  3                        TRUE\n    2          4                  1                       FALSE\n    2          5                  5                       FALSE\n    2          6                  4                       FALSE\n    2          7                  1                       FALSE - not largest segment\n    2          8                  2                       FALSE - not largest segment\n\n    &gt; links_df\n\n    A   B\n    1   2\n    2   3\n    3   4\n    \"\"\"\n    \"\"\"\n    &gt; shape_links\n\n    shape_id  shape_pt_sequence_A  shape_model_node_id_A shape_pt_sequence_B shape_model_node_id_B\n    1          1                        1                       2                        2\n    1          2                        2                       3                        3\n    1          3                        3                       4                        4\n    1          4                        4                       5                        5\n    2          1                        1                       2                        2\n    2          2                        2                       3                        3\n    2          3                        3                       4                        1\n    2          4                        1                       5                        5\n    2          5                        5                       6                        4\n    2          6                        4                       7                        1\n    2          7                        1                       8                        2\n    \"\"\"\n    shape_links = shapes_to_shape_links(shapes)\n\n    \"\"\"\n    &gt; shape_links_w_links\n\n    shape_id  shape_pt_sequence_A shape_pt_sequence_B  A  B\n    1          1                         2             1  2\n    1          2                         3             2  3\n    1          3                         4             3  4\n    2          1                         2             1  2\n    2          2                         3             2  3\n    2          7                         8             1  2\n    \"\"\"\n\n    shape_links_w_links = shape_links.merge(\n        links_df[[\"A\", \"B\"]],\n        how=\"inner\",\n        on=[\"A\", \"B\"],\n    )\n\n    \"\"\"\n    Find largest segment of each shape_id that is in the links\n\n    &gt; longest_shape_segments\n    shape_id, segment_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq\n    1          1                        1                       4\n    2          1                        1                       3\n    \"\"\"\n    longest_shape_segments = shape_links_to_longest_shape_segments(shape_links_w_links)\n\n    \"\"\"\n    &gt; shapes\n\n    shape_id   shape_pt_sequence   shape_model_node_id\n    1          1                  1\n    1          2                  2\n    1          3                  3\n    1          4                  4\n    2          1                  1\n    2          2                  2\n    2          3                  3\n    \"\"\"\n    filtered_shapes = filter_shapes_to_segments(shapes, longest_shape_segments)\n    filtered_shapes = filtered_shapes.reset_index(drop=True)\n    return filtered_shapes\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shapes_for_shape_id","title":"<code>shapes_for_shape_id(shapes, shape_id)</code>","text":"<p>Returns shape records for a given shape_id.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_shape_id(\n    shapes: DataFrame[WranglerShapesTable], shape_id: str\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shape records for a given shape_id.\"\"\"\n    shapes = shapes.loc[shapes.shape_id == shape_id]\n    return shapes.sort_values(by=[\"shape_pt_sequence\"])\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shapes_for_trip_id","title":"<code>shapes_for_trip_id(shapes, trips, trip_id)</code>","text":"<p>Returns shape records for a single given trip_id.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_trip_id(\n    shapes: DataFrame[WranglerShapesTable], trips: DataFrame[WranglerTripsTable], trip_id: str\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shape records for a single given trip_id.\"\"\"\n    from .shapes import shape_id_for_trip_id\n\n    shape_id = shape_id_for_trip_id(trips, trip_id)\n    return shapes.loc[shapes.shape_id == shape_id]\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shapes_for_trip_ids","title":"<code>shapes_for_trip_ids(shapes, trips, trip_ids)</code>","text":"<p>Returns shape records for list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_trip_ids(\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n    trip_ids: list[str],\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shape records for list of trip_ids.\"\"\"\n    shape_ids = shape_ids_for_trip_ids(trips, trip_ids)\n    return shapes.loc[shapes.shape_id.isin(shape_ids)]\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shapes_for_trips","title":"<code>shapes_for_trips(shapes, trips)</code>","text":"<p>Filter shapes dataframe to records associated with trips table.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_trips(\n    shapes: DataFrame[WranglerShapesTable], trips: DataFrame[WranglerTripsTable]\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Filter shapes dataframe to records associated with trips table.\"\"\"\n    _sel_shapes = trips.shape_id.unique().tolist()\n    filtered_shapes = shapes[shapes.shape_id.isin(_sel_shapes)]\n    WranglerLogger.debug(\n        f\"Filtered shapes to {len(filtered_shapes)}/{len(shapes)} \\\n                         records that referenced one of {len(trips)} trips.\"\n    )\n    return filtered_shapes\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shapes_with_stop_id_for_trip_id","title":"<code>shapes_with_stop_id_for_trip_id(shapes, trips, stop_times, trip_id, pickup_dropoff='either')</code>","text":"<p>Returns shapes.txt for a given trip_id with the stop_id added based on pickup_type.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>WranglerShapesTable</p> required <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>WranglerTripsTable</p> required <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>WranglerStopTimesTable</p> required <code>trip_id</code> <code>str</code> <p>trip id to select</p> required <code>pickup_dropoff</code> <code>PickupDropoffAvailability</code> <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> <code>'either'</code> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_with_stop_id_for_trip_id(\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shapes.txt for a given trip_id with the stop_id added based on pickup_type.\n\n    Args:\n        shapes: WranglerShapesTable\n        trips: WranglerTripsTable\n        stop_times: WranglerStopTimesTable\n        trip_id: trip id to select\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n    \"\"\"\n    from .stop_times import stop_times_for_pickup_dropoff_trip_id\n\n    shapes = shapes_for_trip_id(shapes, trips, trip_id)\n    trip_stop_times = stop_times_for_pickup_dropoff_trip_id(\n        stop_times, trip_id, pickup_dropoff=pickup_dropoff\n    )\n\n    stop_times_cols = [\n        \"stop_id\",\n        \"trip_id\",\n        \"pickup_type\",\n        \"drop_off_type\",\n    ]\n\n    shape_with_trip_stops = shapes.merge(\n        trip_stop_times[stop_times_cols],\n        how=\"left\",\n        right_on=\"stop_id\",\n        left_on=\"shape_model_node_id\",\n    )\n    shape_with_trip_stops = shape_with_trip_stops.sort_values(by=[\"shape_pt_sequence\"])\n    return shape_with_trip_stops\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.shapes.shapes_with_stops_for_shape_id","title":"<code>shapes_with_stops_for_shape_id(shapes, trips, stop_times, shape_id)</code>","text":"<p>Returns a DataFrame containing shapes with associated stops for a given shape_id.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>DataFrame containing shape data.</p> required <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>DataFrame containing trip data.</p> required <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>DataFrame containing stop times data.</p> required <code>shape_id</code> <code>str</code> <p>The shape_id for which to retrieve shapes with stops.</p> required <p>Returns:</p> Type Description <code>DataFrame[WranglerShapesTable]</code> <p>DataFrame[WranglerShapesTable]: DataFrame containing shapes with associated stops.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_with_stops_for_shape_id(\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shape_id: str,\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns a DataFrame containing shapes with associated stops for a given shape_id.\n\n    Parameters:\n        shapes (DataFrame[WranglerShapesTable]): DataFrame containing shape data.\n        trips (DataFrame[WranglerTripsTable]): DataFrame containing trip data.\n        stop_times (DataFrame[WranglerStopTimesTable]): DataFrame containing stop times data.\n        shape_id (str): The shape_id for which to retrieve shapes with stops.\n\n    Returns:\n        DataFrame[WranglerShapesTable]: DataFrame containing shapes with associated stops.\n    \"\"\"\n    from .trips import trip_ids_for_shape_id\n\n    trip_ids = trip_ids_for_shape_id(trips, shape_id)\n    all_shape_stop_times = concat_with_attr(\n        [shapes_with_stop_id_for_trip_id(shapes, trips, stop_times, t) for t in trip_ids]\n    )\n    shapes_with_stops = all_shape_stop_times[all_shape_stop_times[\"stop_id\"].notna()]\n    shapes_with_stops = shapes_with_stops.sort_values(by=[\"shape_pt_sequence\"])\n    return shapes_with_stops\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_longest_segments","title":"<code>stop_times_for_longest_segments(stop_times)</code>","text":"<p>Find the longest segment of each trip_id that is in the stop_times.</p> <p>Segment ends defined based on interruptions in <code>stop_sequence</code>.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_longest_segments(\n    stop_times: DataFrame[WranglerStopTimesTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Find the longest segment of each trip_id that is in the stop_times.\n\n    Segment ends defined based on interruptions in `stop_sequence`.\n    \"\"\"\n    stop_times = stop_times.sort_values(by=[\"trip_id\", \"stop_sequence\"])\n\n    stop_times[\"prev_stop_sequence\"] = stop_times.groupby(\"trip_id\")[\"stop_sequence\"].shift(1)\n    stop_times[\"gap\"] = (stop_times[\"stop_sequence\"] - stop_times[\"prev_stop_sequence\"]).ne(\n        1\n    ) | stop_times[\"prev_stop_sequence\"].isna()\n\n    stop_times[\"segment_id\"] = stop_times[\"gap\"].cumsum()\n    # WranglerLogger.debug(f\"stop_times with segment_id:\\n{stop_times}\")\n\n    # Calculate the length of each segment\n    segment_lengths = (\n        stop_times.groupby([\"trip_id\", \"segment_id\"]).size().reset_index(name=\"segment_length\")\n    )\n\n    # Identify the longest segment for each trip\n    idx = segment_lengths.groupby(\"trip_id\")[\"segment_length\"].idxmax()\n    longest_segments = segment_lengths.loc[idx]\n\n    # Merge longest segment info back to stop_times\n    stop_times = stop_times.merge(\n        longest_segments[[\"trip_id\", \"segment_id\"]],\n        on=[\"trip_id\", \"segment_id\"],\n        how=\"inner\",\n    )\n\n    # Drop temporary columns used for calculations\n    stop_times.drop(columns=[\"prev_stop_sequence\", \"gap\", \"segment_id\"], inplace=True)\n    # WranglerLogger.debug(f\"stop_timesw/longest segments:\\n{stop_times}\")\n    return stop_times\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_min_stops","title":"<code>stop_times_for_min_stops(stop_times, min_stops)</code>","text":"<p>Filter stop_times dataframe to only the records which have &gt;= min_stops for the trip.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>stoptimestable to filter</p> required <code>min_stops</code> <code>int</code> <p>minimum stops to require to keep trip in stoptimes</p> required Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_min_stops(\n    stop_times: DataFrame[WranglerStopTimesTable], min_stops: int\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filter stop_times dataframe to only the records which have &gt;= min_stops for the trip.\n\n    Args:\n        stop_times: stoptimestable to filter\n        min_stops: minimum stops to require to keep trip in stoptimes\n    \"\"\"\n    stop_ct_by_trip_df = stop_count_by_trip(stop_times)\n\n    # Filter to obtain DataFrame of trips with stop counts &gt;= min_stops\n    min_stop_ct_trip_df = stop_ct_by_trip_df[stop_ct_by_trip_df.stop_count &gt;= min_stops]\n    if len(min_stop_ct_trip_df) == 0:\n        msg = f\"No trips meet threshold of minimum stops: {min_stops}\"\n        raise ValueError(msg)\n    WranglerLogger.debug(\n        f\"Found {len(min_stop_ct_trip_df)} trips with a minimum of {min_stops} stops.\"\n    )\n\n    # Filter the original stop_times DataFrame to only include trips with &gt;= min_stops\n    filtered_stop_times = stop_times.merge(\n        min_stop_ct_trip_df[\"trip_id\"], on=\"trip_id\", how=\"inner\"\n    )\n    WranglerLogger.debug(\n        f\"Filter stop times to {len(filtered_stop_times)}/{len(stop_times)}\\\n            w/a minimum of {min_stops} stops.\"\n    )\n\n    return filtered_stop_times\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_pickup_dropoff_trip_id","title":"<code>stop_times_for_pickup_dropoff_trip_id(stop_times, trip_id, pickup_dropoff='either')</code>","text":"<p>Filters stop_times for a given trip_id based on pickup type.</p> <p>GTFS values for pickup_type and drop_off_type\u201d     0 or empty - Regularly scheduled pickup/dropoff.     1 - No pickup/dropoff available.     2 - Must phone agency to arrange pickup/dropoff.     3 - Must coordinate with driver to arrange pickup/dropoff.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>A WranglerStopTimesTable to query.</p> required <code>trip_id</code> <code>str</code> <p>trip_id to get stop pattern for</p> required <code>pickup_dropoff</code> <code>PickupDropoffAvailability</code> <p>str indicating logic for selecting stops based on pickup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201cany\u201d: all stoptime records \u201ceither\u201d: either pickup_type or dropoff_type != 1 \u201cboth\u201d: both pickup_type and dropoff_type != 1 \u201cpickup_only\u201d: dropoff = 1; pickup != 1 \u201cdropoff_only\u201d:  pickup = 1; dropoff != 1</p> <code>'either'</code> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>@validate_call_pyd\ndef stop_times_for_pickup_dropoff_trip_id(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filters stop_times for a given trip_id based on pickup type.\n\n    GTFS values for pickup_type and drop_off_type\"\n        0 or empty - Regularly scheduled pickup/dropoff.\n        1 - No pickup/dropoff available.\n        2 - Must phone agency to arrange pickup/dropoff.\n        3 - Must coordinate with driver to arrange pickup/dropoff.\n\n    Args:\n        stop_times: A WranglerStopTimesTable to query.\n        trip_id: trip_id to get stop pattern for\n        pickup_dropoff: str indicating logic for selecting stops based on pickup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"any\": all stoptime records\n            \"either\": either pickup_type or dropoff_type != 1\n            \"both\": both pickup_type and dropoff_type != 1\n            \"pickup_only\": dropoff = 1; pickup != 1\n            \"dropoff_only\":  pickup = 1; dropoff != 1\n    \"\"\"\n    trip_stop_pattern = stop_times_for_trip_id(stop_times, trip_id)\n\n    if pickup_dropoff == \"any\":\n        return trip_stop_pattern\n\n    pickup_type_selection = {\n        \"either\": (trip_stop_pattern.pickup_type != 1) | (trip_stop_pattern.drop_off_type != 1),\n        \"both\": (trip_stop_pattern.pickup_type != 1) &amp; (trip_stop_pattern.drop_off_type != 1),\n        \"pickup_only\": (trip_stop_pattern.pickup_type != 1)\n        &amp; (trip_stop_pattern.drop_off_type == 1),\n        \"dropoff_only\": (trip_stop_pattern.drop_off_type != 1)\n        &amp; (trip_stop_pattern.pickup_type == 1),\n    }\n\n    selection = pickup_type_selection[pickup_dropoff]\n    trip_stops = trip_stop_pattern[selection]\n\n    return trip_stops\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_route_ids","title":"<code>stop_times_for_route_ids(stop_times, trips, route_ids)</code>","text":"<p>Returns a stop_time records for a list of route_ids.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_route_ids(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trips: DataFrame[WranglerTripsTable],\n    route_ids: list[str],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns a stop_time records for a list of route_ids.\"\"\"\n    trip_ids = trips.loc[trips.route_id.isin(route_ids)].trip_id.unique()\n    return stop_times_for_trip_ids(stop_times, trip_ids)\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_shapes","title":"<code>stop_times_for_shapes(stop_times, shapes, trips)</code>","text":"<p>Filter stop_times dataframe to records associated with shapes dataframe.</p> <p>Where multiple segments of stop_times are found to match shapes, retain only the longest.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>stop_times dataframe to filter</p> required <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>shapes dataframe to stop_times to.</p> required <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>trips to link stop_times to shapess</p> required <p>Returns:</p> Type Description <code>DataFrame[WranglerStopTimesTable]</code> <p>filtered stop_times dataframe</p> <ul> <li>should be retained <p>stop_times</p> </li> </ul> <p>trip_id   stop_sequence   stop_id t1          1                  1 t1          2                  2 t1          3                  3 t1           4                  5 t2          1                  1 *t2          2                  3 t2           3                  7</p> <p>shapes</p> <p>shape_id   shape_pt_sequence   shape_model_node_id s1          1                  1 s1          2                  2 s1          3                  3 s1          4                  4 s2          1                  1 s2          2                  2 s2          3                  3</p> <p>trips</p> <p>trip_id   shape_id t1          s1 t2          s2</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_shapes(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filter stop_times dataframe to records associated with shapes dataframe.\n\n    Where multiple segments of stop_times are found to match shapes, retain only the longest.\n\n    Args:\n        stop_times: stop_times dataframe to filter\n        shapes: shapes dataframe to stop_times to.\n        trips: trips to link stop_times to shapess\n\n    Returns:\n        filtered stop_times dataframe\n\n    EX:\n    * should be retained\n    &gt; stop_times\n\n    trip_id   stop_sequence   stop_id\n    *t1          1                  1\n    *t1          2                  2\n    *t1          3                  3\n    t1           4                  5\n    *t2          1                  1\n    *t2          2                  3\n    t2           3                  7\n\n    &gt; shapes\n\n    shape_id   shape_pt_sequence   shape_model_node_id\n    s1          1                  1\n    s1          2                  2\n    s1          3                  3\n    s1          4                  4\n    s2          1                  1\n    s2          2                  2\n    s2          3                  3\n\n    &gt; trips\n\n    trip_id   shape_id\n    t1          s1\n    t2          s2\n    \"\"\"\n    \"\"\"\n    &gt; stop_times_w_shapes\n\n    trip_id   stop_sequence   stop_id    shape_id   shape_pt_sequence\n    *t1          1                  1        s1          1\n    *t1          2                  2        s1          2\n    *t1          3                  3        s1          3\n    t1           4                  5        NA          NA\n    *t2          1                  1        s2          1\n    *t2          2                  3        s2          2\n    t2           3                  7        NA          NA\n\n    \"\"\"\n    stop_times_w_shapes = merge_shapes_to_stop_times(stop_times, shapes, trips)\n    # WranglerLogger.debug(f\"stop_times_w_shapes :\\n{stop_times_w_shapes}\")\n    \"\"\"\n    &gt; stop_times_w_shapes\n\n    trip_id   stop_sequence   stop_id   shape_id   shape_pt_sequence\n    *t1          1               1        s1          1\n    *t1          2               2        s1          2\n    *t1          3               3        s1          3\n    *t2          1               1        s2          1\n    *t2          2               3        s2          2\n\n    \"\"\"\n    filtered_stop_times = stop_times_w_shapes[stop_times_w_shapes[\"shape_pt_sequence\"].notna()]\n    # WranglerLogger.debug(f\"filtered_stop_times:\\n{filtered_stop_times}\")\n\n    # Filter out any stop_times the shape_pt_sequence is not ascending\n    valid_stop_times = filtered_stop_times.groupby(\"trip_id\").filter(\n        lambda x: x[\"shape_pt_sequence\"].is_monotonic_increasing\n    )\n    # WranglerLogger.debug(f\"valid_stop_times:\\n{valid_stop_times}\")\n\n    valid_stop_times = valid_stop_times.drop(columns=[\"shape_id\", \"shape_pt_sequence\"])\n\n    longest_valid_stop_times = stop_times_for_longest_segments(valid_stop_times)\n    longest_valid_stop_times = longest_valid_stop_times.reset_index(drop=True)\n\n    return longest_valid_stop_times\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_stops","title":"<code>stop_times_for_stops(stop_times, stops)</code>","text":"<p>Filter stop_times dataframe to only have stop_times associated with stops records.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_stops(\n    stop_times: DataFrame[WranglerStopTimesTable], stops: DataFrame[WranglerStopsTable]\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filter stop_times dataframe to only have stop_times associated with stops records.\"\"\"\n    _sel_stops = stops.stop_id.unique().tolist()\n    filtered_stop_times = stop_times[stop_times.stop_id.isin(_sel_stops)]\n    WranglerLogger.debug(\n        f\"Filtered stop_times to {len(filtered_stop_times)}/{len(stop_times)} \\\n                         records that referenced one of {len(stops)} stops.\"\n    )\n    return filtered_stop_times\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_trip_id","title":"<code>stop_times_for_trip_id(stop_times, trip_id)</code>","text":"<p>Returns a stop_time records for a given trip_id.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_trip_id(\n    stop_times: DataFrame[WranglerStopTimesTable], trip_id: str\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns a stop_time records for a given trip_id.\"\"\"\n    stop_times = stop_times.loc[stop_times.trip_id == trip_id]\n    return stop_times.sort_values(by=[\"stop_sequence\"])\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_trip_ids","title":"<code>stop_times_for_trip_ids(stop_times, trip_ids)</code>","text":"<p>Returns a stop_time records for a given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_trip_ids(\n    stop_times: DataFrame[WranglerStopTimesTable], trip_ids: list[str]\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns a stop_time records for a given list of trip_ids.\"\"\"\n    stop_times = stop_times.loc[stop_times.trip_id.isin(trip_ids)]\n    return stop_times.sort_values(by=[\"stop_sequence\"])\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stop_times.stop_times_for_trip_node_segment","title":"<code>stop_times_for_trip_node_segment(stop_times, trip_id, node_id_start, node_id_end, include_start=True, include_end=True)</code>","text":"<p>Returns stop_times for a given trip_id between two nodes or with those nodes included.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>WranglerStopTimesTable</p> required <code>trip_id</code> <code>str</code> <p>trip id to select</p> required <code>node_id_start</code> <code>int</code> <p>int of the starting node</p> required <code>node_id_end</code> <code>int</code> <p>int of the ending node</p> required <code>include_start</code> <code>bool</code> <p>bool indicating if the start node should be included in the segment. Defaults to True.</p> <code>True</code> <code>include_end</code> <code>bool</code> <p>bool indicating if the end node should be included in the segment. Defaults to True.</p> <code>True</code> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_trip_node_segment(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    node_id_start: int,\n    node_id_end: int,\n    include_start: bool = True,\n    include_end: bool = True,\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns stop_times for a given trip_id between two nodes or with those nodes included.\n\n    Args:\n        stop_times: WranglerStopTimesTable\n        trip_id: trip id to select\n        node_id_start: int of the starting node\n        node_id_end: int of the ending node\n        include_start: bool indicating if the start node should be included in the segment.\n            Defaults to True.\n        include_end: bool indicating if the end node should be included in the segment.\n            Defaults to True.\n    \"\"\"\n    stop_times = stop_times_for_trip_id(stop_times, trip_id)\n    start_idx = stop_times[stop_times[\"stop_id\"] == node_id_start].index[0]\n    end_idx = stop_times[stop_times[\"stop_id\"] == node_id_end].index[0]\n    if not include_start:\n        start_idx += 1\n    if include_end:\n        end_idx += 1\n    return stop_times.loc[start_idx:end_idx]\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stops.node_is_stop","title":"<code>node_is_stop(stops, stop_times, node_id, trip_id, pickup_dropoff='either')</code>","text":"<p>Returns boolean indicating if a (or list of) node(s)) is (are) stops for a given trip_id.</p> <p>Parameters:</p> Name Type Description Default <code>stops</code> <code>DataFrame[WranglerStopsTable]</code> <p>WranglerStopsTable</p> required <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>WranglerStopTimesTable</p> required <code>node_id</code> <code>Union[int, list[int]]</code> <p>node ID for roadway</p> required <code>trip_id</code> <code>str</code> <p>trip_id to get stop pattern for</p> required <code>pickup_dropoff</code> <code>PickupDropoffAvailability</code> <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> <code>'either'</code> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>def node_is_stop(\n    stops: DataFrame[WranglerStopsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    node_id: Union[int, list[int]],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; Union[bool, list[bool]]:\n    \"\"\"Returns boolean indicating if a (or list of) node(s)) is (are) stops for a given trip_id.\n\n    Args:\n        stops: WranglerStopsTable\n        stop_times: WranglerStopTimesTable\n        node_id: node ID for roadway\n        trip_id: trip_id to get stop pattern for\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n    \"\"\"\n    trip_stop_nodes = stops_for_trip_id(stops, stop_times, trip_id, pickup_dropoff=pickup_dropoff)[\n        \"stop_id\"\n    ]\n    if isinstance(node_id, list):\n        return [n in trip_stop_nodes.values for n in node_id]\n    return node_id in trip_stop_nodes.values\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stops.stop_id_pattern_for_trip","title":"<code>stop_id_pattern_for_trip(stop_times, trip_id, pickup_dropoff='either')</code>","text":"<p>Returns a stop pattern for a given trip_id given by a list of stop_ids.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>WranglerStopTimesTable</p> required <code>trip_id</code> <code>str</code> <p>trip_id to get stop pattern for</p> required <code>pickup_dropoff</code> <code>PickupDropoffAvailability</code> <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> <code>'either'</code> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>@validate_call_pyd\ndef stop_id_pattern_for_trip(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; list[str]:\n    \"\"\"Returns a stop pattern for a given trip_id given by a list of stop_ids.\n\n    Args:\n        stop_times: WranglerStopTimesTable\n        trip_id: trip_id to get stop pattern for\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n    \"\"\"\n    from .stop_times import stop_times_for_pickup_dropoff_trip_id\n\n    trip_stops = stop_times_for_pickup_dropoff_trip_id(\n        stop_times, trip_id, pickup_dropoff=pickup_dropoff\n    )\n    return trip_stops.stop_id.to_list()\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stops.stops_for_stop_times","title":"<code>stops_for_stop_times(stops, stop_times)</code>","text":"<p>Filter stops dataframe to only have stops associated with stop_times records.</p> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>def stops_for_stop_times(\n    stops: DataFrame[WranglerStopsTable], stop_times: DataFrame[WranglerStopTimesTable]\n) -&gt; DataFrame[WranglerStopsTable]:\n    \"\"\"Filter stops dataframe to only have stops associated with stop_times records.\"\"\"\n    _sel_stops_ge_min = stop_times.stop_id.unique().tolist()\n    filtered_stops = stops[stops.stop_id.isin(_sel_stops_ge_min)]\n    WranglerLogger.debug(\n        f\"Filtered stops to {len(filtered_stops)}/{len(stops)} \\\n                         records that referenced one of {len(stop_times)} stop_times.\"\n    )\n    return filtered_stops\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.stops.stops_for_trip_id","title":"<code>stops_for_trip_id(stops, stop_times, trip_id, pickup_dropoff='any')</code>","text":"<p>Returns stops.txt which are used for a given trip_id.</p> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>def stops_for_trip_id(\n    stops: DataFrame[WranglerStopsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"any\",\n) -&gt; DataFrame[WranglerStopsTable]:\n    \"\"\"Returns stops.txt which are used for a given trip_id.\"\"\"\n    stop_ids = stop_id_pattern_for_trip(stop_times, trip_id, pickup_dropoff=pickup_dropoff)\n    return stops.loc[stops.stop_id.isin(stop_ids)]\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.trips.trip_ids_for_shape_id","title":"<code>trip_ids_for_shape_id(trips, shape_id)</code>","text":"<p>Returns a list of trip_ids for a given shape_id.</p> Source code in <code>network_wrangler/transit/feed/trips.py</code> <pre><code>def trip_ids_for_shape_id(trips: DataFrame[WranglerTripsTable], shape_id: str) -&gt; list[str]:\n    \"\"\"Returns a list of trip_ids for a given shape_id.\"\"\"\n    return trips_for_shape_id(trips, shape_id)[\"trip_id\"].unique().tolist()\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.trips.trips_for_shape_id","title":"<code>trips_for_shape_id(trips, shape_id)</code>","text":"<p>Returns a trips records for a given shape_id.</p> Source code in <code>network_wrangler/transit/feed/trips.py</code> <pre><code>def trips_for_shape_id(\n    trips: DataFrame[WranglerTripsTable], shape_id: str\n) -&gt; DataFrame[WranglerTripsTable]:\n    \"\"\"Returns a trips records for a given shape_id.\"\"\"\n    return trips.loc[trips.shape_id == shape_id]\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.trips.trips_for_stop_times","title":"<code>trips_for_stop_times(trips, stop_times)</code>","text":"<p>Filter trips dataframe to records associated with stop_time records.</p> Source code in <code>network_wrangler/transit/feed/trips.py</code> <pre><code>def trips_for_stop_times(\n    trips: DataFrame[WranglerTripsTable], stop_times: DataFrame[WranglerStopTimesTable]\n) -&gt; DataFrame[WranglerTripsTable]:\n    \"\"\"Filter trips dataframe to records associated with stop_time records.\"\"\"\n    _sel_trips = stop_times.trip_id.unique().tolist()\n    filtered_trips = trips[trips.trip_id.isin(_sel_trips)]\n    WranglerLogger.debug(\n        f\"Filtered trips to {len(filtered_trips)}/{len(trips)} \\\n                         records that referenced one of {len(stop_times)} stop_times.\"\n    )\n    return filtered_trips\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.transit_links.shapes_to_shape_links","title":"<code>shapes_to_shape_links(shapes)</code>","text":"<p>Converts shapes DataFrame to shape links DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>The input shapes DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The resulting shape links DataFrame.</p> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def shapes_to_shape_links(shapes: DataFrame[WranglerShapesTable]) -&gt; pd.DataFrame:\n    \"\"\"Converts shapes DataFrame to shape links DataFrame.\n\n    Args:\n        shapes (DataFrame[WranglerShapesTable]): The input shapes DataFrame.\n\n    Returns:\n        pd.DataFrame: The resulting shape links DataFrame.\n    \"\"\"\n    return point_seq_to_links(\n        shapes,\n        id_field=\"shape_id\",\n        seq_field=\"shape_pt_sequence\",\n        node_id_field=\"shape_model_node_id\",\n    )\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.transit_links.stop_times_to_stop_times_links","title":"<code>stop_times_to_stop_times_links(stop_times, from_field='A', to_field='B')</code>","text":"<p>Converts stop times to stop times links.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>The stop times data.</p> required <code>from_field</code> <code>str</code> <p>The name of the field representing the \u2018from\u2019 stop. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_field</code> <code>str</code> <p>The name of the field representing the \u2018to\u2019 stop. Defaults to \u201cB\u201d.</p> <code>'B'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The resulting stop times links.</p> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def stop_times_to_stop_times_links(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; pd.DataFrame:\n    \"\"\"Converts stop times to stop times links.\n\n    Args:\n        stop_times (DataFrame[WranglerStopTimesTable]): The stop times data.\n        from_field (str, optional): The name of the field representing the 'from' stop.\n            Defaults to \"A\".\n        to_field (str, optional): The name of the field representing the 'to' stop.\n            Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: The resulting stop times links.\n    \"\"\"\n    return point_seq_to_links(\n        stop_times,\n        id_field=\"trip_id\",\n        seq_field=\"stop_sequence\",\n        node_id_field=\"stop_id\",\n        from_field=from_field,\n        to_field=to_field,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.transit_links.unique_shape_links","title":"<code>unique_shape_links(shapes, from_field='A', to_field='B')</code>","text":"<p>Returns a DataFrame containing unique shape links based on the provided shapes DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>The input DataFrame containing shape information.</p> required <code>from_field</code> <code>str</code> <p>The name of the column representing the \u2018from\u2019 field. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_field</code> <code>str</code> <p>The name of the column representing the \u2018to\u2019 field. Defaults to \u201cB\u201d.</p> <code>'B'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame containing unique shape links based on the provided shapes df.</p> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def unique_shape_links(\n    shapes: DataFrame[WranglerShapesTable], from_field: str = \"A\", to_field: str = \"B\"\n) -&gt; pd.DataFrame:\n    \"\"\"Returns a DataFrame containing unique shape links based on the provided shapes DataFrame.\n\n    Parameters:\n        shapes (DataFrame[WranglerShapesTable]): The input DataFrame containing shape information.\n        from_field (str, optional): The name of the column representing the 'from' field.\n            Defaults to \"A\".\n        to_field (str, optional): The name of the column representing the 'to' field.\n            Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: DataFrame containing unique shape links based on the provided shapes df.\n    \"\"\"\n    shape_links = shapes_to_shape_links(shapes)\n    # WranglerLogger.debug(f\"Shape links: \\n {shape_links[['shape_id', from_field, to_field]]}\")\n\n    _agg_dict: dict[str, Union[type, str]] = {\"shape_id\": list}\n    _opt_fields = [f\"shape_pt_{v}_{t}\" for v in [\"lat\", \"lon\"] for t in [from_field, to_field]]\n    for f in _opt_fields:\n        if f in shape_links:\n            _agg_dict[f] = \"first\"\n\n    unique_shape_links = shape_links.groupby([from_field, to_field]).agg(_agg_dict).reset_index()\n    return unique_shape_links\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.transit_links.unique_stop_time_links","title":"<code>unique_stop_time_links(stop_times, from_field='A', to_field='B')</code>","text":"<p>Returns a DataFrame containing unique stop time links based on the given stop times DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>The DataFrame containing stop times data.</p> required <code>from_field</code> <code>str</code> <p>The name of the column representing the \u2018from\u2019 field in the stop times DataFrame. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_field</code> <code>str</code> <p>The name of the column representing the \u2018to\u2019 field in the stop times DataFrame. Defaults to \u201cB\u201d.</p> <code>'B'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing unique stop time links with columns \u2018from_field\u2019, \u2018to_field\u2019, and \u2018trip_id\u2019.</p> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def unique_stop_time_links(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; pd.DataFrame:\n    \"\"\"Returns a DataFrame containing unique stop time links based on the given stop times DataFrame.\n\n    Parameters:\n        stop_times (DataFrame[WranglerStopTimesTable]): The DataFrame containing stop times data.\n        from_field (str, optional): The name of the column representing the 'from' field in the\n            stop times DataFrame. Defaults to \"A\".\n        to_field (str, optional): The name of the column representing the 'to' field in the stop\n            times DataFrame. Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: A DataFrame containing unique stop time links with columns 'from_field',\n            'to_field', and 'trip_id'.\n    \"\"\"\n    links = stop_times_to_stop_times_links(stop_times, from_field=from_field, to_field=to_field)\n    unique_links = links.groupby([from_field, to_field])[\"trip_id\"].apply(list).reset_index()\n    return unique_links\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.transit_segments.filter_shapes_to_segments","title":"<code>filter_shapes_to_segments(shapes, segments)</code>","text":"<p>Filter shapes dataframe to records associated with segments dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>shapes dataframe to filter</p> required <code>segments</code> <code>DataFrame</code> <p>segments dataframe to filter by with shape_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq . Should have one record per shape_id.</p> required <p>Returns:</p> Type Description <code>DataFrame[WranglerShapesTable]</code> <p>filtered shapes dataframe</p> Source code in <code>network_wrangler/transit/feed/transit_segments.py</code> <pre><code>def filter_shapes_to_segments(\n    shapes: DataFrame[WranglerShapesTable], segments: pd.DataFrame\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Filter shapes dataframe to records associated with segments dataframe.\n\n    Args:\n        shapes: shapes dataframe to filter\n        segments: segments dataframe to filter by with shape_id, segment_start_shape_pt_seq,\n            segment_end_shape_pt_seq . Should have one record per shape_id.\n\n    Returns:\n        filtered shapes dataframe\n    \"\"\"\n    shapes_w_segs = shapes.merge(segments, on=\"shape_id\", how=\"left\")\n\n    # Retain only those points within the segment sequences\n    filtered_shapes = shapes_w_segs[\n        (shapes_w_segs[\"shape_pt_sequence\"] &gt;= shapes_w_segs[\"segment_start_shape_pt_seq\"])\n        &amp; (shapes_w_segs[\"shape_pt_sequence\"] &lt;= shapes_w_segs[\"segment_end_shape_pt_seq\"])\n    ]\n\n    drop_cols = [\n        \"segment_id\",\n        \"segment_start_shape_pt_seq\",\n        \"segment_end_shape_pt_seq\",\n        \"segment_length\",\n    ]\n    filtered_shapes = filtered_shapes.drop(columns=drop_cols)\n\n    return filtered_shapes\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.transit_segments.shape_links_to_longest_shape_segments","title":"<code>shape_links_to_longest_shape_segments(shape_links)</code>","text":"<p>Find the longest segment of each shape_id that is in the links.</p> <p>Parameters:</p> Name Type Description Default <code>shape_links</code> <p>DataFrame with shape_id, shape_pt_sequence_A, shape_pt_sequence_B</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with shape_id, segment_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq</p> Source code in <code>network_wrangler/transit/feed/transit_segments.py</code> <pre><code>def shape_links_to_longest_shape_segments(shape_links) -&gt; pd.DataFrame:\n    \"\"\"Find the longest segment of each shape_id that is in the links.\n\n    Args:\n        shape_links: DataFrame with shape_id, shape_pt_sequence_A, shape_pt_sequence_B\n\n    Returns:\n        DataFrame with shape_id, segment_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq\n    \"\"\"\n    segments = shape_links_to_segments(shape_links)\n    idx = segments.groupby(\"shape_id\")[\"segment_length\"].idxmax()\n    longest_segments = segments.loc[idx]\n    return longest_segments\n</code></pre>"},{"location":"api/#network_wrangler.transit.feed.transit_segments.shape_links_to_segments","title":"<code>shape_links_to_segments(shape_links)</code>","text":"<p>Convert shape_links to segments by shape_id with segments of continuous shape_pt_sequence.</p> <p>DataFrame with shape_id, segment_id, segment_start_shape_pt_seq,</p> Type Description <code>DataFrame</code> <p>segment_end_shape_pt_seq</p> Source code in <code>network_wrangler/transit/feed/transit_segments.py</code> <pre><code>def shape_links_to_segments(shape_links) -&gt; pd.DataFrame:\n    \"\"\"Convert shape_links to segments by shape_id with segments of continuous shape_pt_sequence.\n\n    Returns: DataFrame with shape_id, segment_id, segment_start_shape_pt_seq,\n        segment_end_shape_pt_seq\n    \"\"\"\n    shape_links[\"gap\"] = shape_links.groupby(\"shape_id\")[\"shape_pt_sequence_A\"].diff().gt(1)\n    shape_links[\"segment_id\"] = shape_links.groupby(\"shape_id\")[\"gap\"].cumsum()\n\n    # Define segment starts and ends\n    segment_definitions = (\n        shape_links.groupby([\"shape_id\", \"segment_id\"])\n        .agg(\n            segment_start_shape_pt_seq=(\"shape_pt_sequence_A\", \"min\"),\n            segment_end_shape_pt_seq=(\"shape_pt_sequence_B\", \"max\"),\n        )\n        .reset_index()\n    )\n\n    # Optionally calculate segment lengths for further uses\n    segment_definitions[\"segment_length\"] = (\n        segment_definitions[\"segment_end_shape_pt_seq\"]\n        - segment_definitions[\"segment_start_shape_pt_seq\"]\n        + 1\n    )\n\n    return segment_definitions\n</code></pre>"},{"location":"api/#transit-projects","title":"Transit Projects","text":"<p>Functions for adding a transit route to a TransitNetwork.</p> <p>Module for applying calculated transit projects to a transit network object.</p> <p>These projects are stored in project card <code>pycode</code> property as python code strings which are executed to change the transit network object.</p> <p>Functions for adding a transit route to a TransitNetwork.</p> <p>Functions for editing transit properties in a TransitNetwork.</p> <p>Functions for editing the transit route shapes and stop patterns.</p>"},{"location":"api/#network_wrangler.transit.projects.add_route.apply_transit_route_addition","title":"<code>apply_transit_route_addition(net, transit_route_addition, reference_road_net=None)</code>","text":"<p>Add transit route to TransitNetwork.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>TransitNetwork</code> <p>Network to modify.</p> required <code>transit_route_addition</code> <code>dict</code> <p>route dictionary to add to the feed.</p> required <code>reference_road_net</code> <code>Optional[RoadwayNetwork]</code> <p>(RoadwayNetwork, optional): Reference roadway network to use for adding shapes and stops. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TransitNetwork</code> <code>TransitNetwork</code> <p>Modified network.</p> Source code in <code>network_wrangler/transit/projects/add_route.py</code> <pre><code>def apply_transit_route_addition(\n    net: TransitNetwork,\n    transit_route_addition: dict,\n    reference_road_net: Optional[RoadwayNetwork] = None,\n) -&gt; TransitNetwork:\n    \"\"\"Add transit route to TransitNetwork.\n\n    Args:\n        net (TransitNetwork): Network to modify.\n        transit_route_addition: route dictionary to add to the feed.\n        reference_road_net: (RoadwayNetwork, optional): Reference roadway network to use for adding shapes and stops. Defaults to None.\n\n    Returns:\n        TransitNetwork: Modified network.\n    \"\"\"\n    WranglerLogger.debug(\"Applying add transit route project.\")\n\n    add_routes = transit_route_addition[\"routes\"]\n\n    road_net = net.road_net if reference_road_net is None else reference_road_net\n    if road_net is None:\n        WranglerLogger.error(\n            \"! Must have a reference road network set in order to update transit \\\n                         routin.  Either provide as an input to this function or set it for the \\\n                         transit network: &gt;&gt; transit_net.road_net = ...\"\n        )\n        msg = \"Must have a reference road network set in order to update transit routing.\"\n        raise TransitRouteAddError(msg)\n\n    net.feed = _add_route_to_feed(net.feed, add_routes, road_net)\n\n    return net\n</code></pre>"},{"location":"api/#network_wrangler.transit.projects.calculate.apply_calculated_transit","title":"<code>apply_calculated_transit(net, pycode)</code>","text":"<p>Changes transit network object by executing pycode.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>TransitNetwork</code> <p>transit network to manipulate</p> required <code>pycode</code> <code>str</code> <p>python code which changes values in the transit network object</p> required Source code in <code>network_wrangler/transit/projects/calculate.py</code> <pre><code>def apply_calculated_transit(\n    net: TransitNetwork,\n    pycode: str,\n) -&gt; TransitNetwork:\n    \"\"\"Changes transit network object by executing pycode.\n\n    Args:\n        net: transit network to manipulate\n        pycode: python code which changes values in the transit network object\n    \"\"\"\n    WranglerLogger.debug(\"Applying calculated transit project.\")\n    exec(pycode)\n\n    return net\n</code></pre>"},{"location":"api/#network_wrangler.transit.projects.delete_service.apply_transit_service_deletion","title":"<code>apply_transit_service_deletion(net, selection, clean_shapes=False, clean_routes=False)</code>","text":"<p>Delete transit service to TransitNetwork.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>TransitNetwork</code> <p>Network to modify.</p> required <code>selection</code> <code>TransitSelection</code> <p>TransitSelection object, created from a selection dictionary.</p> required <code>clean_shapes</code> <code>bool</code> <p>If True, remove shapes not used by any trips. Defaults to False.</p> <code>False</code> <code>clean_routes</code> <code>bool</code> <p>If True, remove routes not used by any trips. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>TransitNetwork</code> <code>TransitNetwork</code> <p>Modified network.</p> Source code in <code>network_wrangler/transit/projects/delete_service.py</code> <pre><code>def apply_transit_service_deletion(\n    net: TransitNetwork,\n    selection: TransitSelection,\n    clean_shapes: Optional[bool] = False,\n    clean_routes: Optional[bool] = False,\n) -&gt; TransitNetwork:\n    \"\"\"Delete transit service to TransitNetwork.\n\n    Args:\n        net (TransitNetwork): Network to modify.\n        selection: TransitSelection object, created from a selection dictionary.\n        clean_shapes (bool, optional): If True, remove shapes not used by any trips.\n            Defaults to False.\n        clean_routes (bool, optional): If True, remove routes not used by any trips.\n            Defaults to False.\n\n    Returns:\n        TransitNetwork: Modified network.\n    \"\"\"\n    WranglerLogger.debug(\"Applying delete transit service project.\")\n\n    trip_ids = selection.selected_trips\n    net.feed = _delete_trips_from_feed(\n        net.feed, trip_ids, clean_shapes=clean_shapes, clean_routes=clean_routes\n    )\n\n    return net\n</code></pre>"},{"location":"api/#network_wrangler.transit.projects.edit_property.apply_transit_property_change","title":"<code>apply_transit_property_change(net, selection, property_changes, project_name=None)</code>","text":"<p>Apply changes to transit properties.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>TransitNetwork</code> <p>Network to modify.</p> required <code>selection</code> <code>TransitSelection</code> <p>Selection of trips to modify.</p> required <code>property_changes</code> <code>dict</code> <p>Dictionary of properties to change.</p> required <code>project_name</code> <code>str</code> <p>Name of the project. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TransitNetwork</code> <code>TransitNetwork</code> <p>Modified network.</p> Source code in <code>network_wrangler/transit/projects/edit_property.py</code> <pre><code>def apply_transit_property_change(\n    net: TransitNetwork,\n    selection: TransitSelection,\n    property_changes: dict,\n    project_name: Optional[str] = None,\n) -&gt; TransitNetwork:\n    \"\"\"Apply changes to transit properties.\n\n    Args:\n        net (TransitNetwork): Network to modify.\n        selection (TransitSelection): Selection of trips to modify.\n        property_changes (dict): Dictionary of properties to change.\n        project_name (str, optional): Name of the project. Defaults to None.\n\n    Returns:\n        TransitNetwork: Modified network.\n    \"\"\"\n    WranglerLogger.debug(\"Applying transit property change project.\")\n    for property, property_change in property_changes.items():\n        net = _apply_transit_property_change_to_table(\n            net,\n            selection,\n            property,\n            property_change,\n            project_name=project_name,\n        )\n    return net\n</code></pre>"},{"location":"api/#network_wrangler.transit.projects.edit_routing.apply_transit_routing_change","title":"<code>apply_transit_routing_change(net, selection, routing_change, reference_road_net=None, project_name=None)</code>","text":"<p>Apply a routing change to the transit network, including stop updates.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>TransitNetwork</code> <p>TransitNetwork object to apply routing change to.</p> required <code>selection</code> <code>Selection</code> <p>TransitSelection object, created from a selection dictionary.</p> required <code>routing_change</code> <code>dict</code> <p>Routing Change dictionary, e.g. <pre><code>{\n    \"existing\": [46665, 150855],\n    \"set\": [-46665, 150855, 46665, 150855],\n}\n</code></pre></p> required <code>shape_id_scalar</code> <code>int</code> <p>Initial scalar value to add to duplicated shape_ids to create a new shape_id. Defaults to SHAPE_ID_SCALAR.</p> required <code>reference_road_net</code> <code>RoadwayNetwork</code> <p>Reference roadway network to use for updating shapes and stops. Defaults to None.</p> <code>None</code> <code>project_name</code> <code>str</code> <p>Name of the project. Defaults to None.</p> <code>None</code> Source code in <code>network_wrangler/transit/projects/edit_routing.py</code> <pre><code>def apply_transit_routing_change(\n    net: TransitNetwork,\n    selection: TransitSelection,\n    routing_change: dict,\n    reference_road_net: Optional[RoadwayNetwork] = None,\n    project_name: Optional[str] = None,\n) -&gt; TransitNetwork:\n    \"\"\"Apply a routing change to the transit network, including stop updates.\n\n    Args:\n        net (TransitNetwork): TransitNetwork object to apply routing change to.\n        selection (Selection): TransitSelection object, created from a selection dictionary.\n        routing_change (dict): Routing Change dictionary, e.g.\n            ```python\n            {\n                \"existing\": [46665, 150855],\n                \"set\": [-46665, 150855, 46665, 150855],\n            }\n            ```\n        shape_id_scalar (int, optional): Initial scalar value to add to duplicated shape_ids to\n            create a new shape_id. Defaults to SHAPE_ID_SCALAR.\n        reference_road_net (RoadwayNetwork, optional): Reference roadway network to use for\n            updating shapes and stops. Defaults to None.\n        project_name (str, optional): Name of the project. Defaults to None.\n    \"\"\"\n    WranglerLogger.debug(\"Applying transit routing change project.\")\n    WranglerLogger.debug(f\"...selection: {selection.selection_dict}\")\n    WranglerLogger.debug(f\"...routing: {routing_change}\")\n\n    # ---- Secure all inputs needed --------------\n    updated_feed = copy.deepcopy(net.feed)\n    trip_ids = selection.selected_trips\n    if project_name:\n        updated_feed.trips.loc[updated_feed.trips.trip_id.isin(trip_ids), \"projects\"] += (\n            f\"{project_name},\"\n        )\n\n    road_net = net.road_net if reference_road_net is None else reference_road_net\n    if road_net is None:\n        WranglerLogger.error(\n            \"! Must have a reference road network set in order to update transit \\\n                         routin.  Either provide as an input to this function or set it for the \\\n                         transit network: &gt;&gt; transit_net.road_net = ...\"\n        )\n        msg = \"Must have a reference road network set in order to update transit routing.\"\n        raise TransitRoutingChangeError(msg)\n\n    # ---- update each shape that is used by selected trips to use new routing -------\n    shape_ids = shape_ids_for_trip_ids(updated_feed.trips, trip_ids)\n    # WranglerLogger.debug(f\"shape_ids: {shape_ids}\")\n    for shape_id in shape_ids:\n        updated_feed.shapes, updated_feed.trips = _update_shapes_and_trips(\n            updated_feed,\n            shape_id,\n            trip_ids,\n            routing_change[\"set\"],\n            net.config.IDS.TRANSIT_SHAPE_ID_SCALAR,\n            road_net,\n            routing_existing=routing_change.get(\"existing\", []),\n            project_name=project_name,\n        )\n    # WranglerLogger.debug(f\"updated_feed.shapes: \\n{updated_feed.shapes}\")\n    # WranglerLogger.debug(f\"updated_feed.trips: \\n{updated_feed.trips}\")\n    # ---- Check if any stops need adding to stops.txt and add if they do ----------\n    updated_feed.stops = _update_stops(\n        updated_feed, routing_change[\"set\"], road_net, project_name=project_name\n    )\n    # WranglerLogger.debug(f\"updated_feed.stops: \\n{updated_feed.stops}\")\n    # ---- Update stop_times --------------------------------------------------------\n    for trip_id in trip_ids:\n        updated_feed.stop_times = _update_stop_times_for_trip(\n            updated_feed,\n            trip_id,\n            routing_change[\"set\"],\n            routing_change.get(\"existing\", []),\n        )\n\n    # ---- Check result -------------------------------------------------------------\n    _show_col = [\n        \"trip_id\",\n        \"stop_id\",\n        \"stop_sequence\",\n        \"departure_time\",\n        \"arrival_time\",\n    ]\n    _ex_stoptimes = updated_feed.stop_times.loc[\n        updated_feed.stop_times.trip_id == trip_ids[0], _show_col\n    ]\n    # WranglerLogger.debug(f\"stop_times for first updated trip: \\n {_ex_stoptimes}\")\n\n    # ---- Update transit network with updated feed.\n    net.feed = updated_feed\n    # WranglerLogger.debug(f\"net.feed.stops: \\n {net.feed.stops}\")\n    return net\n</code></pre>"},{"location":"api/#transit-helper-modules","title":"Transit Helper Modules","text":"<p>Functions to clip a TransitNetwork object to a boundary.</p> <p>Clipped transit is an independent transit network that is a subset of the original transit network.</p> <p>Example usage:</p> <pre><code>from network_wrangler.transit load_transit, write_transit\nfrom network_wrangler.transit.clip import clip_transit\n\nstpaul_transit = load_transit(example_dir / \"stpaul\")\nboundary_file = test_dir / \"data\" / \"ecolab.geojson\"\nclipped_network = clip_transit(stpaul_transit, boundary_file=boundary_file)\nwrite_transit(clipped_network, out_dir, prefix=\"ecolab\", format=\"geojson\", true_shape=True)\n</code></pre> <p>Utilities for working with transit geodataframes.</p> <p>Functions for reading and writing transit feeds and networks.</p> <p>ModelTransit class and functions for managing consistency between roadway and transit networks.</p> <p>NOTE: this is not thoroughly tested and may not be fully functional.</p> <p>Classes and functions for selecting transit trips from a transit network.</p> <p>Usage:</p> <p>Create a TransitSelection object by providing a TransitNetwork object and a selection dictionary:</p> <pre><code>```python\nselection_dict = {\n    \"links\": {...},\n    \"nodes\": {...},\n    \"route_properties\": {...},\n    \"trip_properties\": {...},\n    \"timespans\": {...},\n}\ntransit_selection = TransitSelection(transit_network, selection_dict)\n```\n</code></pre> <p>Access the selected trip ids or dataframe as follows:</p> <pre><code>```python\nselected_trips = transit_selection.selected_trips\nselected_trips_df = transit_selection.selected_trips_df\n```\n</code></pre> <p>Note: The selection dictionary should conform to the SelectTransitTrips model defined in the models.projects.transit_selection module.</p> <p>Functions to check for transit network validity and consistency with roadway network.</p>"},{"location":"api/#network_wrangler.transit.clip.clip_feed_to_boundary","title":"<code>clip_feed_to_boundary(feed, ref_nodes_df, boundary_gdf=None, boundary_geocode=None, boundary_file=None, min_stops=DEFAULT_MIN_STOPS)</code>","text":"<p>Clips a transit Feed object to a boundary and returns the resulting GeoDataFrames.</p> <p>Retains only the stops within the boundary and trips that traverse them subject to a minimum number of stops per trip as defined by <code>min_stops</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Feed</code> <p>Feed object to be clipped.</p> required <code>ref_nodes_df</code> <code>GeoDataFrame</code> <p>geodataframe with node geometry to reference</p> required <code>boundary_geocode</code> <code>Union[str, dict]</code> <p>A geocode string or dictionary representing the boundary. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Union[str, Path]</code> <p>A path to the boundary file. Only used if boundary_geocode is None. Defaults to None.</p> <code>None</code> <code>boundary_gdf</code> <code>GeoDataFrame</code> <p>A GeoDataFrame representing the boundary. Only used if boundary_geocode and boundary_file are None. Defaults to None.</p> <code>None</code> <code>min_stops</code> <code>int</code> <p>minimum number of stops needed to retain a transit trip within clipped area. Defaults to DEFAULT_MIN_STOPS which is set to 2.</p> <code>DEFAULT_MIN_STOPS</code> Source code in <code>network_wrangler/transit/clip.py</code> <pre><code>def clip_feed_to_boundary(\n    feed: Feed,\n    ref_nodes_df: gpd.GeoDataFrame,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[Union[str, dict]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n    min_stops: int = DEFAULT_MIN_STOPS,\n) -&gt; Feed:\n    \"\"\"Clips a transit Feed object to a boundary and returns the resulting GeoDataFrames.\n\n    Retains only the stops within the boundary and trips that traverse them subject to a minimum\n    number of stops per trip as defined by `min_stops`.\n\n    Args:\n        feed: Feed object to be clipped.\n        ref_nodes_df: geodataframe with node geometry to reference\n        boundary_geocode (Union[str, dict], optional): A geocode string or dictionary\n            representing the boundary. Defaults to None.\n        boundary_file (Union[str, Path], optional): A path to the boundary file. Only used if\n            boundary_geocode is None. Defaults to None.\n        boundary_gdf (gpd.GeoDataFrame, optional): A GeoDataFrame representing the boundary.\n            Only used if boundary_geocode and boundary_file are None. Defaults to None.\n        min_stops: minimum number of stops needed to retain a transit trip within clipped area.\n            Defaults to DEFAULT_MIN_STOPS which is set to 2.\n\n    Returns: Feed object trimmed to the boundary.\n    \"\"\"\n    WranglerLogger.info(\"Clipping transit network to boundary.\")\n\n    boundary_gdf = get_bounding_polygon(\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n\n    shape_links_gdf = shapes_to_shape_links_gdf(feed.shapes, ref_nodes_df=ref_nodes_df)\n\n    # make sure boundary_gdf.crs == network.crs\n    if boundary_gdf.crs != shape_links_gdf.crs:\n        boundary_gdf = boundary_gdf.to_crs(shape_links_gdf.crs)\n\n    # get the boundary as a single polygon\n    boundary = boundary_gdf.geometry.union_all()\n    # get the shape_links that intersect the boundary\n    clipped_shape_links = shape_links_gdf[shape_links_gdf.geometry.intersects(boundary)]\n\n    # nodes within clipped_shape_links\n    node_ids = list(set(clipped_shape_links.A.to_list() + clipped_shape_links.B.to_list()))\n    WranglerLogger.debug(f\"Clipping network to {len(node_ids)} nodes.\")\n    if not node_ids:\n        msg = \"No nodes found within the boundary.\"\n        raise ValueError(msg)\n    return _clip_feed_to_nodes(feed, node_ids, min_stops=min_stops)\n</code></pre>"},{"location":"api/#network_wrangler.transit.clip.clip_feed_to_roadway","title":"<code>clip_feed_to_roadway(feed, roadway_net, min_stops=DEFAULT_MIN_STOPS)</code>","text":"<p>Returns a copy of transit feed clipped to the roadway network.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Feed</code> <p>Transit Feed to clip.</p> required <code>roadway_net</code> <code>RoadwayNetwork</code> <p>Roadway network to clip to.</p> required <code>min_stops</code> <code>int</code> <p>minimum number of stops needed to retain a transit trip within clipped area. Defaults to DEFAULT_MIN_STOPS which is set to 2.</p> <code>DEFAULT_MIN_STOPS</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no stops found within the roadway network.</p> <p>Returns:</p> Name Type Description <code>Feed</code> <code>Feed</code> <p>Clipped deep copy of feed limited to the roadway network.</p> Source code in <code>network_wrangler/transit/clip.py</code> <pre><code>def clip_feed_to_roadway(\n    feed: Feed,\n    roadway_net: RoadwayNetwork,\n    min_stops: int = DEFAULT_MIN_STOPS,\n) -&gt; Feed:\n    \"\"\"Returns a copy of transit feed clipped to the roadway network.\n\n    Args:\n        feed (Feed): Transit Feed to clip.\n        roadway_net: Roadway network to clip to.\n        min_stops: minimum number of stops needed to retain a transit trip within clipped area.\n            Defaults to DEFAULT_MIN_STOPS which is set to 2.\n\n    Raises:\n        ValueError: If no stops found within the roadway network.\n\n    Returns:\n        Feed: Clipped deep copy of feed limited to the roadway network.\n    \"\"\"\n    WranglerLogger.info(\"Clipping transit network to roadway network.\")\n\n    clipped_feed = _remove_links_from_feed(feed, roadway_net.links_df, min_stops=min_stops)\n\n    return clipped_feed\n</code></pre>"},{"location":"api/#network_wrangler.transit.clip.clip_transit","title":"<code>clip_transit(network, node_ids=None, boundary_geocode=None, boundary_file=None, boundary_gdf=None, ref_nodes_df=None, roadway_net=None, min_stops=DEFAULT_MIN_STOPS)</code>","text":"<p>Returns a new TransitNetwork clipped to a boundary as determined by arguments.</p> <p>Will clip based on which arguments are provided as prioritized below:</p> <ol> <li>If <code>node_ids</code> provided, will clip based on <code>node_ids</code></li> <li>If <code>boundary_geocode</code> provided, will clip based on on search in OSM for that jurisdiction     boundary using reference geometry from <code>ref_nodes_df</code>, <code>roadway_net</code>, or <code>roadway_path</code></li> <li>If <code>boundary_file</code> provided, will clip based on that polygon  using reference geometry     from <code>ref_nodes_df</code>, <code>roadway_net</code>, or <code>roadway_path</code></li> <li>If <code>boundary_gdf</code> provided, will clip based on that geodataframe  using reference geometry     from <code>ref_nodes_df</code>, <code>roadway_net</code>, or <code>roadway_path</code></li> <li>If <code>roadway_net</code> provided, will clip based on that roadway network</li> </ol> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>TransitNetwork</code> <p>TransitNetwork to clip.</p> required <code>node_ids</code> <code>list[str]</code> <p>A list of node_ids to clip to. Defaults to None.</p> <code>None</code> <code>boundary_geocode</code> <code>Union[str, dict]</code> <p>A geocode string or dictionary representing the boundary. Only used if node_ids are None. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Union[str, Path]</code> <p>A path to the boundary file. Only used if node_ids and boundary_geocode are None. Defaults to None.</p> <code>None</code> <code>boundary_gdf</code> <code>GeoDataFrame</code> <p>A GeoDataFrame representing the boundary. Only used if node_ids, boundary_geocode and boundary_file are None. Defaults to None.</p> <code>None</code> <code>ref_nodes_df</code> <code>Optional[Union[None, GeoDataFrame]]</code> <p>GeoDataFrame of geographic references for node_ids.  Only used if node_ids is None and one of boundary_* is not None.</p> <code>None</code> <code>roadway_net</code> <code>Optional[Union[None, RoadwayNetwork]]</code> <p>Roadway Network  instance to clip transit network to.  Only used if node_ids is None and allof boundary_* are None</p> <code>None</code> <code>min_stops</code> <code>int</code> <p>minimum number of stops needed to retain a transit trip within clipped area. Defaults to DEFAULT_MIN_STOPS which is set to 2.</p> <code>DEFAULT_MIN_STOPS</code> Source code in <code>network_wrangler/transit/clip.py</code> <pre><code>def clip_transit(\n    network: Union[TransitNetwork, str, Path],\n    node_ids: Optional[Union[None, list[str]]] = None,\n    boundary_geocode: Optional[Union[str, dict, None]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n    boundary_gdf: Optional[Union[None, gpd.GeoDataFrame]] = None,\n    ref_nodes_df: Optional[Union[None, gpd.GeoDataFrame]] = None,\n    roadway_net: Optional[Union[None, RoadwayNetwork]] = None,\n    min_stops: int = DEFAULT_MIN_STOPS,\n) -&gt; TransitNetwork:\n    \"\"\"Returns a new TransitNetwork clipped to a boundary as determined by arguments.\n\n    Will clip based on which arguments are provided as prioritized below:\n\n    1. If `node_ids` provided, will clip based on `node_ids`\n    2. If `boundary_geocode` provided, will clip based on on search in OSM for that jurisdiction\n        boundary using reference geometry from `ref_nodes_df`, `roadway_net`, or `roadway_path`\n    3. If `boundary_file` provided, will clip based on that polygon  using reference geometry\n        from `ref_nodes_df`, `roadway_net`, or `roadway_path`\n    4. If `boundary_gdf` provided, will clip based on that geodataframe  using reference geometry\n        from `ref_nodes_df`, `roadway_net`, or `roadway_path`\n    5. If `roadway_net` provided, will clip based on that roadway network\n\n    Args:\n        network (TransitNetwork): TransitNetwork to clip.\n        node_ids (list[str], optional): A list of node_ids to clip to. Defaults to None.\n        boundary_geocode (Union[str, dict], optional): A geocode string or dictionary\n            representing the boundary. Only used if node_ids are None. Defaults to None.\n        boundary_file (Union[str, Path], optional): A path to the boundary file. Only used if\n            node_ids and boundary_geocode are None. Defaults to None.\n        boundary_gdf (gpd.GeoDataFrame, optional): A GeoDataFrame representing the boundary.\n            Only used if node_ids, boundary_geocode and boundary_file are None. Defaults to None.\n        ref_nodes_df: GeoDataFrame of geographic references for node_ids.  Only used if\n            node_ids is None and one of boundary_* is not None.\n        roadway_net: Roadway Network  instance to clip transit network to.  Only used if\n            node_ids is None and allof boundary_* are None\n        min_stops: minimum number of stops needed to retain a transit trip within clipped area.\n            Defaults to DEFAULT_MIN_STOPS which is set to 2.\n    \"\"\"\n    if not isinstance(network, TransitNetwork):\n        network = load_transit(network)\n    set_roadway_network = False\n    feed = network.feed\n\n    if node_ids is not None:\n        clipped_feed = _clip_feed_to_nodes(feed, node_ids=node_ids, min_stops=min_stops)\n    elif any(i is not None for i in [boundary_file, boundary_geocode, boundary_gdf]):\n        if ref_nodes_df is None:\n            ref_nodes_df = get_nodes(transit_net=network, roadway_net=roadway_net)\n\n        clipped_feed = clip_feed_to_boundary(\n            feed,\n            ref_nodes_df,\n            boundary_file=boundary_file,\n            boundary_geocode=boundary_geocode,\n            boundary_gdf=boundary_gdf,\n            min_stops=min_stops,\n        )\n    elif roadway_net is not None:\n        clipped_feed = clip_feed_to_roadway(feed, roadway_net=roadway_net)\n        set_roadway_network = True\n    else:\n        msg = \"Missing required arguments from clip_transit\"\n        raise ValueError(msg)\n\n    # create a new TransitNetwork object with the clipped feed dataframes\n    clipped_net = TransitNetwork(clipped_feed)\n\n    if set_roadway_network:\n        WranglerLogger.info(\"Setting roadway network for clipped transit network.\")\n        clipped_net.road_net = roadway_net\n    return clipped_net\n</code></pre>"},{"location":"api/#network_wrangler.transit.geo.shapes_to_shape_links_gdf","title":"<code>shapes_to_shape_links_gdf(shapes, ref_nodes_df=None, from_field='A', to_field='B', crs=LAT_LON_CRS)</code>","text":"<p>Translates shapes to shape links geodataframe using geometry from ref_nodes_df if provided.</p> <p>TODO: Add join to links and then shapes to get true geometry.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>Feed shapes table</p> required <code>ref_nodes_df</code> <code>Optional[DataFrame[RoadNodesTable]]</code> <p>If specified, will use geometry from these nodes.  Otherwise, will use geometry in shapes file. Defaults to None.</p> <code>None</code> <code>from_field</code> <code>str</code> <p>Field used for the link\u2019s from node <code>model_node_id</code>. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_field</code> <code>str</code> <p>Field used for the link\u2019s to node <code>model_node_id</code>. Defaults to \u201cB\u201d.</p> <code>'B'</code> <code>crs</code> <code>int</code> <p>Coordinate reference system. SHouldn\u2019t be changed unless you know what you are doing. Defaults to LAT_LON_CRS which is WGS84 lat/long.</p> <code>LAT_LON_CRS</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: description</p> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def shapes_to_shape_links_gdf(\n    shapes: DataFrame[WranglerShapesTable],\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n    crs: int = LAT_LON_CRS,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Translates shapes to shape links geodataframe using geometry from ref_nodes_df if provided.\n\n    TODO: Add join to links and then shapes to get true geometry.\n\n    Args:\n        shapes: Feed shapes table\n        ref_nodes_df: If specified, will use geometry from these nodes.  Otherwise, will use\n            geometry in shapes file. Defaults to None.\n        from_field: Field used for the link's from node `model_node_id`. Defaults to \"A\".\n        to_field: Field used for the link's to node `model_node_id`. Defaults to \"B\".\n        crs (int, optional): Coordinate reference system. SHouldn't be changed unless you know\n            what you are doing. Defaults to LAT_LON_CRS which is WGS84 lat/long.\n\n    Returns:\n        gpd.GeoDataFrame: _description_\n    \"\"\"\n    if ref_nodes_df is not None:\n        shapes = update_shapes_geometry(shapes, ref_nodes_df)\n    tr_links = unique_shape_links(shapes, from_field=from_field, to_field=to_field)\n    # WranglerLogger.debug(f\"tr_links :\\n{tr_links }\")\n\n    geometry = linestring_from_lats_lons(\n        tr_links,\n        [f\"shape_pt_lat_{from_field}\", f\"shape_pt_lat_{to_field}\"],\n        [f\"shape_pt_lon_{from_field}\", f\"shape_pt_lon_{to_field}\"],\n    )\n    # WranglerLogger.debug(f\"geometry\\n{geometry}\")\n    shapes_gdf = gpd.GeoDataFrame(tr_links, geometry=geometry, crs=crs).set_crs(LAT_LON_CRS)\n    return shapes_gdf\n</code></pre>"},{"location":"api/#network_wrangler.transit.geo.shapes_to_trip_shapes_gdf","title":"<code>shapes_to_trip_shapes_gdf(shapes, ref_nodes_df=None, crs=LAT_LON_CRS)</code>","text":"<p>Geodataframe with one polyline shape per shape_id.</p> <p>TODO: add information about the route and trips.</p> <p>Parameters:</p> Name Type Description Default <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>WranglerShapesTable</p> required <code>trips</code> <p>WranglerTripsTable</p> required <code>ref_nodes_df</code> <code>Optional[DataFrame[RoadNodesTable]]</code> <p>If specified, will use geometry from these nodes.  Otherwise, will use geometry in shapes file. Defaults to None.</p> <code>None</code> <code>crs</code> <code>int</code> <p>int, optional, default 4326</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def shapes_to_trip_shapes_gdf(\n    shapes: DataFrame[WranglerShapesTable],\n    # trips: WranglerTripsTable,\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    crs: int = LAT_LON_CRS,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Geodataframe with one polyline shape per shape_id.\n\n    TODO: add information about the route and trips.\n\n    Args:\n        shapes: WranglerShapesTable\n        trips: WranglerTripsTable\n        ref_nodes_df: If specified, will use geometry from these nodes.  Otherwise, will use\n            geometry in shapes file. Defaults to None.\n        crs: int, optional, default 4326\n    \"\"\"\n    if ref_nodes_df is not None:\n        shapes = update_shapes_geometry(shapes, ref_nodes_df)\n\n    shape_geom = (\n        shapes[[\"shape_id\", \"shape_pt_lat\", \"shape_pt_lon\"]]\n        .groupby(\"shape_id\")\n        .agg(list)\n        .apply(lambda x: LineString(zip(x[1], x[0])), axis=1)\n    )\n\n    route_shapes_gdf = gpd.GeoDataFrame(\n        data=shape_geom.index, geometry=shape_geom.values, crs=crs\n    ).set_crs(LAT_LON_CRS)\n\n    return route_shapes_gdf\n</code></pre>"},{"location":"api/#network_wrangler.transit.geo.stop_times_to_stop_time_links_gdf","title":"<code>stop_times_to_stop_time_links_gdf(stop_times, stops, ref_nodes_df=None, from_field='A', to_field='B')</code>","text":"<p>Stop times geodataframe as links using geometry from stops.txt or optionally another df.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>WranglerStopTimesTable</code> <p>Feed stop times table.</p> required <code>stops</code> <code>WranglerStopsTable</code> <p>Feed stops table.</p> required <code>ref_nodes_df</code> <code>DataFrame</code> <p>If specified, will use geometry from these nodes. Otherwise, will use geometry in shapes file. Defaults to None.</p> <code>None</code> <code>from_field</code> <code>str</code> <p>Field used for the link\u2019s from node <code>model_node_id</code>. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_field</code> <code>str</code> <p>Field used for the link\u2019s to node <code>model_node_id</code>. Defaults to \u201cB\u201d.</p> <code>'B'</code> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def stop_times_to_stop_time_links_gdf(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    stops: DataFrame[WranglerStopsTable],\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Stop times geodataframe as links using geometry from stops.txt or optionally another df.\n\n    Args:\n        stop_times (WranglerStopTimesTable): Feed stop times table.\n        stops (WranglerStopsTable): Feed stops table.\n        ref_nodes_df (pd.DataFrame, optional): If specified, will use geometry from these nodes.\n            Otherwise, will use geometry in shapes file. Defaults to None.\n        from_field: Field used for the link's from node `model_node_id`. Defaults to \"A\".\n        to_field: Field used for the link's to node `model_node_id`. Defaults to \"B\".\n    \"\"\"\n    from ..utils.geo import linestring_from_lats_lons\n\n    if ref_nodes_df is not None:\n        stops = update_stops_geometry(stops, ref_nodes_df)\n\n    lat_fields = []\n    lon_fields = []\n    tr_links = unique_stop_time_links(stop_times, from_field=from_field, to_field=to_field)\n    for f in (from_field, to_field):\n        tr_links = tr_links.merge(\n            stops[[\"stop_id\", \"stop_lat\", \"stop_lon\"]],\n            right_on=\"stop_id\",\n            left_on=f,\n            how=\"left\",\n        )\n        lon_f = f\"{f}_X\"\n        lat_f = f\"{f}_Y\"\n        tr_links = tr_links.rename(columns={\"stop_lon\": lon_f, \"stop_lat\": lat_f})\n        lon_fields.append(lon_f)\n        lat_fields.append(lat_f)\n\n    geometry = linestring_from_lats_lons(tr_links, lat_fields, lon_fields)\n    return gpd.GeoDataFrame(tr_links, geometry=geometry).set_crs(LAT_LON_CRS)\n</code></pre>"},{"location":"api/#network_wrangler.transit.geo.stop_times_to_stop_time_points_gdf","title":"<code>stop_times_to_stop_time_points_gdf(stop_times, stops, ref_nodes_df=None)</code>","text":"<p>Stoptimes geodataframe as points using geometry from stops.txt or optionally another df.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>WranglerStopTimesTable</code> <p>Feed stop times table.</p> required <code>stops</code> <code>WranglerStopsTable</code> <p>Feed stops table.</p> required <code>ref_nodes_df</code> <code>DataFrame</code> <p>If specified, will use geometry from these nodes. Otherwise, will use geometry in shapes file. Defaults to None.</p> <code>None</code> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def stop_times_to_stop_time_points_gdf(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    stops: DataFrame[WranglerStopsTable],\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Stoptimes geodataframe as points using geometry from stops.txt or optionally another df.\n\n    Args:\n        stop_times (WranglerStopTimesTable): Feed stop times table.\n        stops (WranglerStopsTable): Feed stops table.\n        ref_nodes_df (pd.DataFrame, optional): If specified, will use geometry from these nodes.\n            Otherwise, will use geometry in shapes file. Defaults to None.\n    \"\"\"\n    if ref_nodes_df is not None:\n        stops = update_stops_geometry(stops, ref_nodes_df)\n\n    stop_times_geo = stop_times.merge(\n        stops[[\"stop_id\", \"stop_lat\", \"stop_lon\"]],\n        right_on=\"stop_id\",\n        left_on=\"stop_id\",\n        how=\"left\",\n    )\n    return gpd.GeoDataFrame(\n        stop_times_geo,\n        geometry=gpd.points_from_xy(stop_times_geo[\"stop_lon\"], stop_times_geo[\"stop_lat\"]),\n        crs=LAT_LON_CRS,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.transit.geo.update_shapes_geometry","title":"<code>update_shapes_geometry(shapes, ref_nodes_df)</code>","text":"<p>Returns shapes table with geometry updated from ref_nodes_df.</p> <p>NOTE: does not update \u201cgeometry\u201d field if it exists.</p> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def update_shapes_geometry(\n    shapes: DataFrame[WranglerShapesTable], ref_nodes_df: DataFrame[RoadNodesTable]\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shapes table with geometry updated from ref_nodes_df.\n\n    NOTE: does not update \"geometry\" field if it exists.\n    \"\"\"\n    return update_point_geometry(\n        shapes,\n        ref_nodes_df,\n        id_field=\"shape_model_node_id\",\n        lon_field=\"shape_pt_lon\",\n        lat_field=\"shape_pt_lat\",\n    )\n</code></pre>"},{"location":"api/#network_wrangler.transit.geo.update_stops_geometry","title":"<code>update_stops_geometry(stops, ref_nodes_df)</code>","text":"<p>Returns stops table with geometry updated from ref_nodes_df.</p> <p>NOTE: does not update \u201cgeometry\u201d field if it exists.</p> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def update_stops_geometry(\n    stops: DataFrame[WranglerStopsTable], ref_nodes_df: DataFrame[RoadNodesTable]\n) -&gt; DataFrame[WranglerStopsTable]:\n    \"\"\"Returns stops table with geometry updated from ref_nodes_df.\n\n    NOTE: does not update \"geometry\" field if it exists.\n    \"\"\"\n    return update_point_geometry(\n        stops, ref_nodes_df, id_field=\"stop_id\", lon_field=\"stop_lon\", lat_field=\"stop_lat\"\n    )\n</code></pre>"},{"location":"api/#network_wrangler.transit.io.convert_transit_serialization","title":"<code>convert_transit_serialization(input_path, output_format, out_dir='.', input_file_format='csv', out_prefix='', overwrite=True)</code>","text":"<p>Converts a transit network from one serialization to another.</p> <p>Parameters:</p> Name Type Description Default <code>input_path</code> <code>Union[str, Path]</code> <p>path to the input network</p> required <code>output_format</code> <code>TransitFileTypes</code> <p>the format of the output files. Should be txt, csv, or parquet.</p> required <code>out_dir</code> <code>Union[Path, str]</code> <p>directory to write the network to. Defaults to current directory.</p> <code>'.'</code> <code>input_file_format</code> <code>TransitFileTypes</code> <p>the file_format of the files to read. Should be txt, csv, or parquet. Defaults to \u201ctxt\u201d</p> <code>'csv'</code> <code>out_prefix</code> <code>str</code> <p>prefix to add to the file name. Defaults to \u201c\u201d</p> <code>''</code> <code>overwrite</code> <code>bool</code> <p>if True, will overwrite the files if they already exist. Defaults to True</p> <code>True</code> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def convert_transit_serialization(\n    input_path: Union[str, Path],\n    output_format: TransitFileTypes,\n    out_dir: Union[Path, str] = \".\",\n    input_file_format: TransitFileTypes = \"csv\",\n    out_prefix: str = \"\",\n    overwrite: bool = True,\n):\n    \"\"\"Converts a transit network from one serialization to another.\n\n    Args:\n        input_path: path to the input network\n        output_format: the format of the output files. Should be txt, csv, or parquet.\n        out_dir: directory to write the network to. Defaults to current directory.\n        input_file_format: the file_format of the files to read. Should be txt, csv, or parquet.\n            Defaults to \"txt\"\n        out_prefix: prefix to add to the file name. Defaults to \"\"\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n    WranglerLogger.info(\n        f\"Loading transit net from {input_path} with input type {input_file_format}\"\n    )\n    net = load_transit(input_path, file_format=input_file_format)\n    WranglerLogger.info(f\"Writing transit network to {out_dir} in {output_format} format.\")\n    write_transit(\n        net,\n        prefix=out_prefix,\n        out_dir=out_dir,\n        file_format=output_format,\n        overwrite=overwrite,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.transit.io.load_feed_from_dfs","title":"<code>load_feed_from_dfs(feed_dfs)</code>","text":"<p>Create a TransitNetwork object from a dictionary of DataFrames representing a GTFS feed.</p> <p>Parameters:</p> Name Type Description Default <code>feed_dfs</code> <code>dict</code> <p>A dictionary containing DataFrames representing the tables of a GTFS feed.</p> required <p>Returns:</p> Name Type Description <code>Feed</code> <code>Feed</code> <p>A Feed object representing the transit network.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the feed_dfs dictionary does not contain all the required tables.</p> Example <p>feed_dfs = { \u2026     \u201cagency\u201d: agency_df, \u2026     \u201croutes\u201d: routes_df, \u2026     \u201cstops\u201d: stops_df, \u2026     \u201ctrips\u201d: trips_df, \u2026     \u201cstop_times\u201d: stop_times_df, \u2026 } feed = load_feed_from_dfs(feed_dfs)</p> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def load_feed_from_dfs(feed_dfs: dict) -&gt; Feed:\n    \"\"\"Create a TransitNetwork object from a dictionary of DataFrames representing a GTFS feed.\n\n    Args:\n        feed_dfs (dict): A dictionary containing DataFrames representing the tables of a GTFS feed.\n\n    Returns:\n        Feed: A Feed object representing the transit network.\n\n    Raises:\n        ValueError: If the feed_dfs dictionary does not contain all the required tables.\n\n    Example:\n        &gt;&gt;&gt; feed_dfs = {\n        ...     \"agency\": agency_df,\n        ...     \"routes\": routes_df,\n        ...     \"stops\": stops_df,\n        ...     \"trips\": trips_df,\n        ...     \"stop_times\": stop_times_df,\n        ... }\n        &gt;&gt;&gt; feed = load_feed_from_dfs(feed_dfs)\n    \"\"\"\n    if not all(table in feed_dfs for table in Feed.table_names):\n        msg = f\"feed_dfs must contain the following tables: {Feed.table_names}\"\n        raise ValueError(msg)\n\n    feed = Feed(**feed_dfs)\n\n    return feed\n</code></pre>"},{"location":"api/#network_wrangler.transit.io.load_feed_from_path","title":"<code>load_feed_from_path(feed_path, file_format='txt')</code>","text":"<p>Create a Feed object from the path to a GTFS transit feed.</p> <p>Parameters:</p> Name Type Description Default <code>feed_path</code> <code>Union[Path, str]</code> <p>The path to the GTFS transit feed.</p> required <code>file_format</code> <code>TransitFileTypes</code> <p>the format of the files to read. Defaults to \u201ctxt\u201d</p> <code>'txt'</code> <p>Returns:</p> Name Type Description <code>Feed</code> <code>Feed</code> <p>The TransitNetwork object created from the GTFS transit feed.</p> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def load_feed_from_path(\n    feed_path: Union[Path, str], file_format: TransitFileTypes = \"txt\"\n) -&gt; Feed:\n    \"\"\"Create a Feed object from the path to a GTFS transit feed.\n\n    Args:\n        feed_path (Union[Path, str]): The path to the GTFS transit feed.\n        file_format: the format of the files to read. Defaults to \"txt\"\n\n    Returns:\n        Feed: The TransitNetwork object created from the GTFS transit feed.\n    \"\"\"\n    feed_path = _feed_path_ref(Path(feed_path))  # unzips if needs to be unzipped\n\n    if not feed_path.is_dir():\n        msg = f\"Feed path not a directory: {feed_path}\"\n        raise NotADirectoryError(msg)\n\n    WranglerLogger.info(f\"Reading GTFS feed tables from {feed_path}\")\n\n    feed_possible_files = {\n        table: list(feed_path.glob(f\"*{table}.{file_format}\")) for table in Feed.table_names\n    }\n\n    # make sure we have all the tables we need\n    _missing_files = [t for t, v in feed_possible_files.items() if not v]\n\n    if _missing_files:\n        WranglerLogger.debug(f\"!!! Missing transit files: {_missing_files}\")\n        msg = f\"Required GTFS Feed table(s) not in {feed_path}: \\n  {_missing_files}\"\n        raise RequiredTableError(msg)\n\n    # but don't want to have more than one file per search\n    _ambiguous_files = [t for t, v in feed_possible_files.items() if len(v) &gt; 1]\n    if _ambiguous_files:\n        WranglerLogger.warning(\n            f\"! More than one file matches following tables. \\\n                               Using the first on the list: {_ambiguous_files}\"\n        )\n\n    feed_files = {t: f[0] for t, f in feed_possible_files.items()}\n    feed_dfs = {table: _read_table_from_file(table, file) for table, file in feed_files.items()}\n\n    return load_feed_from_dfs(feed_dfs)\n</code></pre>"},{"location":"api/#network_wrangler.transit.io.load_transit","title":"<code>load_transit(feed, file_format='txt', config=DefaultConfig)</code>","text":"<p>Create a TransitNetwork object.</p> <p>This function takes in a <code>feed</code> parameter, which can be one of the following types: - <code>Feed</code>: A Feed object representing a transit feed. - <code>dict[str, pd.DataFrame]</code>: A dictionary of DataFrames representing transit data. - <code>str</code> or <code>Path</code>: A string or a Path object representing the path to a transit feed file.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Union[Feed, GtfsModel, dict[str, DataFrame], str, Path]</code> <p>Feed boject, dict of transit data frames, or path to transit feed data</p> required <code>file_format</code> <code>TransitFileTypes</code> <p>the format of the files to read. Defaults to \u201ctxt\u201d</p> <code>'txt'</code> <code>config</code> <code>WranglerConfig</code> <p>WranglerConfig object. Defaults to DefaultConfig.</p> <code>DefaultConfig</code> <p>A TransitNetwork object representing the loaded transit network.</p> <p>Raises: ValueError: If the <code>feed</code> parameter is not one of the supported types.</p> <p>Example usage: <pre><code>transit_network_from_zip = load_transit(\"path/to/gtfs.zip\")\n\ntransit_network_from_unzipped_dir = load_transit(\"path/to/files\")\n\ntransit_network_from_parquet = load_transit(\"path/to/files\", file_format=\"parquet\")\n\ndfs_of_transit_data = {\"routes\": routes_df, \"stops\": stops_df, \"trips\": trips_df...}\ntransit_network_from_dfs = load_transit(dfs_of_transit_data)\n</code></pre></p> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def load_transit(\n    feed: Union[Feed, GtfsModel, dict[str, pd.DataFrame], str, Path],\n    file_format: TransitFileTypes = \"txt\",\n    config: WranglerConfig = DefaultConfig,\n) -&gt; \"TransitNetwork\":\n    \"\"\"Create a TransitNetwork object.\n\n    This function takes in a `feed` parameter, which can be one of the following types:\n    - `Feed`: A Feed object representing a transit feed.\n    - `dict[str, pd.DataFrame]`: A dictionary of DataFrames representing transit data.\n    - `str` or `Path`: A string or a Path object representing the path to a transit feed file.\n\n    Args:\n        feed: Feed boject, dict of transit data frames, or path to transit feed data\n        file_format: the format of the files to read. Defaults to \"txt\"\n        config: WranglerConfig object. Defaults to DefaultConfig.\n\n    Returns:\n    A TransitNetwork object representing the loaded transit network.\n\n    Raises:\n    ValueError: If the `feed` parameter is not one of the supported types.\n\n    Example usage:\n    ```\n    transit_network_from_zip = load_transit(\"path/to/gtfs.zip\")\n\n    transit_network_from_unzipped_dir = load_transit(\"path/to/files\")\n\n    transit_network_from_parquet = load_transit(\"path/to/files\", file_format=\"parquet\")\n\n    dfs_of_transit_data = {\"routes\": routes_df, \"stops\": stops_df, \"trips\": trips_df...}\n    transit_network_from_dfs = load_transit(dfs_of_transit_data)\n    ```\n\n    \"\"\"\n    if isinstance(feed, (Path, str)):\n        feed = Path(feed)\n        feed_obj = load_feed_from_path(feed, file_format=file_format)\n        feed_obj.feed_path = feed\n    elif isinstance(feed, dict):\n        feed_obj = load_feed_from_dfs(feed)\n    elif isinstance(feed, GtfsModel):\n        feed_obj = Feed(**feed.__dict__)\n    else:\n        if not isinstance(feed, Feed):\n            msg = f\"TransitNetwork must be seeded with a Feed, dict of dfs or Path. Found {type(feed)}\"\n            raise ValueError(msg)\n        feed_obj = feed\n\n    return TransitNetwork(feed_obj, config=config)\n</code></pre>"},{"location":"api/#network_wrangler.transit.io.write_feed_geo","title":"<code>write_feed_geo(feed, ref_nodes_df, out_dir, file_format='geojson', out_prefix=None, overwrite=True)</code>","text":"<p>Write a Feed object to a directory in a geospatial format.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Feed</code> <p>Feed object to write</p> required <code>ref_nodes_df</code> <code>GeoDataFrame</code> <p>Reference nodes dataframe to use for geometry</p> required <code>out_dir</code> <code>Union[str, Path]</code> <p>directory to write the network to</p> required <code>file_format</code> <code>Literal['geojson', 'shp', 'parquet']</code> <p>the format of the output files. Defaults to \u201cgeojson\u201d</p> <code>'geojson'</code> <code>out_prefix</code> <p>prefix to add to the file name</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>if True, will overwrite the files if they already exist. Defaults to True</p> <code>True</code> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def write_feed_geo(\n    feed: Feed,\n    ref_nodes_df: gpd.GeoDataFrame,\n    out_dir: Union[str, Path],\n    file_format: Literal[\"geojson\", \"shp\", \"parquet\"] = \"geojson\",\n    out_prefix=None,\n    overwrite: bool = True,\n) -&gt; None:\n    \"\"\"Write a Feed object to a directory in a geospatial format.\n\n    Args:\n        feed: Feed object to write\n        ref_nodes_df: Reference nodes dataframe to use for geometry\n        out_dir: directory to write the network to\n        file_format: the format of the output files. Defaults to \"geojson\"\n        out_prefix: prefix to add to the file name\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n    from .geo import shapes_to_shape_links_gdf\n\n    out_dir = Path(out_dir)\n    if not out_dir.is_dir():\n        if out_dir.parent.is_dir():\n            out_dir.mkdir()\n        else:\n            msg = f\"Output directory {out_dir} ands its parent path does not exist\"\n            raise FileNotFoundError(msg)\n\n    prefix = f\"{out_prefix}_\" if out_prefix else \"\"\n    shapes_outpath = out_dir / f\"{prefix}trn_shapes.{file_format}\"\n    shapes_gdf = shapes_to_shape_links_gdf(feed.shapes, ref_nodes_df=ref_nodes_df)\n    write_table(shapes_gdf, shapes_outpath, overwrite=overwrite)\n\n    stops_outpath = out_dir / f\"{prefix}trn_stops.{file_format}\"\n    stops_gdf = to_points_gdf(feed.stops, ref_nodes_df=ref_nodes_df)\n    write_table(stops_gdf, stops_outpath, overwrite=overwrite)\n</code></pre>"},{"location":"api/#network_wrangler.transit.io.write_transit","title":"<code>write_transit(transit_net, out_dir='.', prefix=None, file_format='txt', overwrite=True)</code>","text":"<p>Writes a network in the transit network standard.</p> <p>Parameters:</p> Name Type Description Default <code>transit_net</code> <p>a TransitNetwork instance</p> required <code>out_dir</code> <code>Union[Path, str]</code> <p>directory to write the network to</p> <code>'.'</code> <code>file_format</code> <code>Literal['txt', 'csv', 'parquet']</code> <p>the format of the output files. Defaults to \u201ctxt\u201d which is csv with txt file format.</p> <code>'txt'</code> <code>prefix</code> <code>Optional[Union[Path, str]]</code> <p>prefix to add to the file name</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>if True, will overwrite the files if they already exist. Defaults to True</p> <code>True</code> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def write_transit(\n    transit_net,\n    out_dir: Union[Path, str] = \".\",\n    prefix: Optional[Union[Path, str]] = None,\n    file_format: Literal[\"txt\", \"csv\", \"parquet\"] = \"txt\",\n    overwrite: bool = True,\n) -&gt; None:\n    \"\"\"Writes a network in the transit network standard.\n\n    Args:\n        transit_net: a TransitNetwork instance\n        out_dir: directory to write the network to\n        file_format: the format of the output files. Defaults to \"txt\" which is csv with txt\n            file format.\n        prefix: prefix to add to the file name\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n    out_dir = Path(out_dir)\n    prefix = f\"{prefix}_\" if prefix else \"\"\n    for table in transit_net.feed.table_names:\n        df = transit_net.feed.get_table(table)\n        outpath = out_dir / f\"{prefix}{table}.{file_format}\"\n        write_table(df, outpath, overwrite=overwrite)\n    WranglerLogger.info(f\"Wrote {len(transit_net.feed.tables)} files to {out_dir}\")\n</code></pre>"},{"location":"api/#network_wrangler.transit.model_transit.ModelTransit","title":"<code>ModelTransit</code>","text":"<p>ModelTransit class for managing consistency between roadway and transit networks.</p> Source code in <code>network_wrangler/transit/model_transit.py</code> <pre><code>class ModelTransit:\n    \"\"\"ModelTransit class for managing consistency between roadway and transit networks.\"\"\"\n\n    def __init__(\n        self,\n        transit_net: TransitNetwork,\n        roadway_net: RoadwayNetwork,\n        shift_transit_to_managed_lanes: bool = True,\n    ):\n        \"\"\"ModelTransit class for managing consistency between roadway and transit networks.\"\"\"\n        self.transit_net = transit_net\n        self.roadway_net = roadway_net\n        self._roadway_net_hash = None\n        self._transit_feed_hash = None\n        self._transit_shifted_to_ML = shift_transit_to_managed_lanes\n\n    @property\n    def model_roadway_net(self):\n        \"\"\"ModelRoadwayNetwork associated with this ModelTransit.\"\"\"\n        return self.roadway_net.model_net\n\n    @property\n    def consistent_nets(self) -&gt; bool:\n        \"\"\"Indicate if roadway and transit networks have changed since self.m_feed updated.\"\"\"\n        return bool(\n            self.roadway_net.network_hash == self._roadway_net_hash\n            and self.transit_net.feed_hash == self._transit_feed_hash\n        )\n\n    @property\n    def m_feed(self):\n        \"\"\"TransitNetwork.feed with updates for consistency with associated ModelRoadwayNetwork.\"\"\"\n        if self.consistent_nets:\n            return self._m_feed\n        # NOTE: look at this\n        # If netoworks have changed, updated model transit and update reference hash\n        self._roadway_net_hash = copy.deepcopy(self.roadway_net.network_hash)\n        self._transit_feed_hash = copy.deepcopy(self.transit_net.feed_hash)\n\n        if not self._transit_shifted_to_ML:\n            self._m_feed = copy.deepcopy(self.transit_net.feed)\n            return self._m_feed\n        return None\n</code></pre>"},{"location":"api/#network_wrangler.transit.model_transit.ModelTransit.consistent_nets","title":"<code>consistent_nets: bool</code>  <code>property</code>","text":"<p>Indicate if roadway and transit networks have changed since self.m_feed updated.</p>"},{"location":"api/#network_wrangler.transit.model_transit.ModelTransit.m_feed","title":"<code>m_feed</code>  <code>property</code>","text":"<p>TransitNetwork.feed with updates for consistency with associated ModelRoadwayNetwork.</p>"},{"location":"api/#network_wrangler.transit.model_transit.ModelTransit.model_roadway_net","title":"<code>model_roadway_net</code>  <code>property</code>","text":"<p>ModelRoadwayNetwork associated with this ModelTransit.</p>"},{"location":"api/#network_wrangler.transit.model_transit.ModelTransit.__init__","title":"<code>__init__(transit_net, roadway_net, shift_transit_to_managed_lanes=True)</code>","text":"<p>ModelTransit class for managing consistency between roadway and transit networks.</p> Source code in <code>network_wrangler/transit/model_transit.py</code> <pre><code>def __init__(\n    self,\n    transit_net: TransitNetwork,\n    roadway_net: RoadwayNetwork,\n    shift_transit_to_managed_lanes: bool = True,\n):\n    \"\"\"ModelTransit class for managing consistency between roadway and transit networks.\"\"\"\n    self.transit_net = transit_net\n    self.roadway_net = roadway_net\n    self._roadway_net_hash = None\n    self._transit_feed_hash = None\n    self._transit_shifted_to_ML = shift_transit_to_managed_lanes\n</code></pre>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection","title":"<code>TransitSelection</code>","text":"<p>Object to perform and store information about a selection from a project card \u201cfacility\u201d.</p> <p>Attributes:</p> Name Type Description <code>selection_dict</code> <code>selected_trips</code> <code>list</code> <code>selected_trips_df</code> <code>DataFrame[WranglerTripsTable]</code> <p>pd.DataFrame: DataFrame of selected trips</p> <code>sel_key</code> <code>net</code> Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>class TransitSelection:\n    \"\"\"Object to perform and store information about a selection from a project card \"facility\".\n\n    Attributes:\n        selection_dict: dict: Dictionary of selection criteria\n        selected_trips: list: List of selected trips\n        selected_trips_df: pd.DataFrame: DataFrame of selected trips\n        sel_key: str: Hash of selection_dict\n        net: TransitNetwork: Network to select from\n    \"\"\"\n\n    def __init__(\n        self,\n        net: TransitNetwork,\n        selection_dict: Union[dict, SelectTransitTrips],\n    ):\n        \"\"\"Constructor for TransitSelection object.\n\n        Args:\n            net (TransitNetwork): Transit network object to select from.\n            selection_dict: Selection dictionary conforming to SelectTransitTrips\n        \"\"\"\n        self.net = net\n        self.selection_dict = selection_dict\n\n        # Initialize\n        self._selected_trips_df = None\n        self.sel_key = dict_to_hexkey(selection_dict)\n        self._stored_feed_hash = copy.deepcopy(self.net.feed.hash)\n\n        WranglerLogger.debug(f\"...created TransitSelection object: {selection_dict}\")\n\n    def __nonzero__(self):\n        \"\"\"Return True if there are selected trips.\"\"\"\n        return len(self.selected_trips_df) &gt; 0\n\n    @property\n    def selection_dict(self):\n        \"\"\"Getter for selection_dict.\"\"\"\n        return self._selection_dict\n\n    @selection_dict.setter\n    def selection_dict(self, value: Union[dict, SelectTransitTrips]):\n        self._selection_dict = self.validate_selection_dict(value)\n\n    def validate_selection_dict(self, selection_dict: Union[dict, SelectTransitTrips]) -&gt; dict:\n        \"\"\"Check that selection dictionary has valid and used properties consistent with network.\n\n        Checks that selection_dict is a valid TransitSelectionDict:\n            - query vars exist in respective Feed tables\n        Args:\n            selection_dict (dict): selection dictionary\n\n        Raises:\n            TransitSelectionNetworkConsistencyError: If not consistent with transit network\n            ValidationError: if format not consistent with SelectTransitTrips\n        \"\"\"\n        if not isinstance(selection_dict, SelectTransitTrips):\n            selection_dict = SelectTransitTrips(**selection_dict)\n        selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n        WranglerLogger.debug(f\"SELECT DICT - before Validation: \\n{selection_dict}\")\n        _trip_selection_fields = list((selection_dict.get(\"trip_properties\", {}) or {}).keys())\n        _missing_trip_fields = set(_trip_selection_fields) - set(self.net.feed.trips.columns)\n\n        if _missing_trip_fields:\n            msg = f\"Fields in trip selection dictionary but not trips.txt: {_missing_trip_fields}\"\n            raise TransitSelectionNetworkConsistencyError(msg)\n\n        _route_selection_fields = list((selection_dict.get(\"route_properties\", {}) or {}).keys())\n        _missing_route_fields = set(_route_selection_fields) - set(self.net.feed.routes.columns)\n\n        if _missing_route_fields:\n            msg = (\n                f\"Fields in route selection dictionary but not routes.txt: {_missing_route_fields}\"\n            )\n            raise TransitSelectionNetworkConsistencyError(msg)\n        return selection_dict\n\n    @property\n    def selected_trips(self) -&gt; list:\n        \"\"\"List of selected trip_ids.\"\"\"\n        if self.selected_trips_df is None:\n            return []\n        return self.selected_trips_df.trip_id.tolist()\n\n    @property\n    def selected_trips_df(self) -&gt; DataFrame[WranglerTripsTable]:\n        \"\"\"Lazily evaluates selection for trips or returns stored value in self._selected_trips_df.\n\n        Will re-evaluate if the current network hash is different than the stored one from the\n        last selection.\n\n        Returns:\n            DataFrame[WranglerTripsTable] of selected trips\n        \"\"\"\n        if (self._selected_trips_df is not None) and self._stored_feed_hash == self.net.feed_hash:\n            return self._selected_trips_df\n\n        self._selected_trips_df = self._select_trips()\n        self._stored_feed_hash = copy.deepcopy(self.net.feed_hash)\n        return self._selected_trips_df\n\n    @property\n    def selected_frequencies_df(self) -&gt; DataFrame[WranglerFrequenciesTable]:\n        \"\"\"DataFrame of selected frequencies.\"\"\"\n        sel_freq_df = self.net.feed.frequencies.loc[\n            self.net.feed.frequencies.trip_id.isin(self.selected_trips_df.trip_id)\n        ]\n        # if timespans are selected, filter to those that overlap\n        if self.selection_dict.get(\"timespans\"):\n            sel_freq_df = filter_df_to_overlapping_timespans(\n                sel_freq_df, self.selection_dict.get(\"timespans\")\n            )\n        return sel_freq_df\n\n    @property\n    def selected_shapes_df(self) -&gt; DataFrame[WranglerShapesTable]:\n        \"\"\"DataFrame of selected shapes.\n\n        Can visualize the selected shapes quickly using the following code:\n\n        ```python\n        all_routes = net.feed.shapes.plot(color=\"gray\")\n        selection.selected_shapes_df.plot(ax=all_routes, color=\"red\")\n        ```\n\n        \"\"\"\n        return self.net.feed.shapes.loc[\n            self.net.feed.shapes.shape_id.isin(self.selected_trips_df.shape_id)\n        ]\n\n    def _select_trips(self) -&gt; DataFrame[WranglerTripsTable]:\n        \"\"\"Selects transit trips based on selection dictionary.\n\n        Returns:\n            DataFrame[WranglerTripsTable]: trips_df DataFrame of selected trips\n        \"\"\"\n        return _filter_trips_by_selection_dict(\n            self.net.feed,\n            self.selection_dict,\n        )\n</code></pre>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.selected_frequencies_df","title":"<code>selected_frequencies_df: DataFrame[WranglerFrequenciesTable]</code>  <code>property</code>","text":"<p>DataFrame of selected frequencies.</p>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.selected_shapes_df","title":"<code>selected_shapes_df: DataFrame[WranglerShapesTable]</code>  <code>property</code>","text":"<p>DataFrame of selected shapes.</p> <p>Can visualize the selected shapes quickly using the following code:</p> <pre><code>all_routes = net.feed.shapes.plot(color=\"gray\")\nselection.selected_shapes_df.plot(ax=all_routes, color=\"red\")\n</code></pre>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.selected_trips","title":"<code>selected_trips: list</code>  <code>property</code>","text":"<p>List of selected trip_ids.</p>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.selected_trips_df","title":"<code>selected_trips_df: DataFrame[WranglerTripsTable]</code>  <code>property</code>","text":"<p>Lazily evaluates selection for trips or returns stored value in self._selected_trips_df.</p> <p>Will re-evaluate if the current network hash is different than the stored one from the last selection.</p> <p>Returns:</p> Type Description <code>DataFrame[WranglerTripsTable]</code> <p>DataFrame[WranglerTripsTable] of selected trips</p>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.selection_dict","title":"<code>selection_dict</code>  <code>property</code> <code>writable</code>","text":"<p>Getter for selection_dict.</p>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.__init__","title":"<code>__init__(net, selection_dict)</code>","text":"<p>Constructor for TransitSelection object.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>TransitNetwork</code> <p>Transit network object to select from.</p> required <code>selection_dict</code> <code>Union[dict, SelectTransitTrips]</code> <p>Selection dictionary conforming to SelectTransitTrips</p> required Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>def __init__(\n    self,\n    net: TransitNetwork,\n    selection_dict: Union[dict, SelectTransitTrips],\n):\n    \"\"\"Constructor for TransitSelection object.\n\n    Args:\n        net (TransitNetwork): Transit network object to select from.\n        selection_dict: Selection dictionary conforming to SelectTransitTrips\n    \"\"\"\n    self.net = net\n    self.selection_dict = selection_dict\n\n    # Initialize\n    self._selected_trips_df = None\n    self.sel_key = dict_to_hexkey(selection_dict)\n    self._stored_feed_hash = copy.deepcopy(self.net.feed.hash)\n\n    WranglerLogger.debug(f\"...created TransitSelection object: {selection_dict}\")\n</code></pre>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.__nonzero__","title":"<code>__nonzero__()</code>","text":"<p>Return True if there are selected trips.</p> Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>def __nonzero__(self):\n    \"\"\"Return True if there are selected trips.\"\"\"\n    return len(self.selected_trips_df) &gt; 0\n</code></pre>"},{"location":"api/#network_wrangler.transit.selection.TransitSelection.validate_selection_dict","title":"<code>validate_selection_dict(selection_dict)</code>","text":"<p>Check that selection dictionary has valid and used properties consistent with network.</p> Checks that selection_dict is a valid TransitSelectionDict <ul> <li>query vars exist in respective Feed tables</li> </ul> <p>Raises:</p> Type Description <code>TransitSelectionNetworkConsistencyError</code> <p>If not consistent with transit network</p> <code>ValidationError</code> <p>if format not consistent with SelectTransitTrips</p> Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>def validate_selection_dict(self, selection_dict: Union[dict, SelectTransitTrips]) -&gt; dict:\n    \"\"\"Check that selection dictionary has valid and used properties consistent with network.\n\n    Checks that selection_dict is a valid TransitSelectionDict:\n        - query vars exist in respective Feed tables\n    Args:\n        selection_dict (dict): selection dictionary\n\n    Raises:\n        TransitSelectionNetworkConsistencyError: If not consistent with transit network\n        ValidationError: if format not consistent with SelectTransitTrips\n    \"\"\"\n    if not isinstance(selection_dict, SelectTransitTrips):\n        selection_dict = SelectTransitTrips(**selection_dict)\n    selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n    WranglerLogger.debug(f\"SELECT DICT - before Validation: \\n{selection_dict}\")\n    _trip_selection_fields = list((selection_dict.get(\"trip_properties\", {}) or {}).keys())\n    _missing_trip_fields = set(_trip_selection_fields) - set(self.net.feed.trips.columns)\n\n    if _missing_trip_fields:\n        msg = f\"Fields in trip selection dictionary but not trips.txt: {_missing_trip_fields}\"\n        raise TransitSelectionNetworkConsistencyError(msg)\n\n    _route_selection_fields = list((selection_dict.get(\"route_properties\", {}) or {}).keys())\n    _missing_route_fields = set(_route_selection_fields) - set(self.net.feed.routes.columns)\n\n    if _missing_route_fields:\n        msg = (\n            f\"Fields in route selection dictionary but not routes.txt: {_missing_route_fields}\"\n        )\n        raise TransitSelectionNetworkConsistencyError(msg)\n    return selection_dict\n</code></pre>"},{"location":"api/#network_wrangler.transit.validate.shape_links_without_road_links","title":"<code>shape_links_without_road_links(tr_shapes, rd_links_df)</code>","text":"<p>Validate that links in transit shapes exist in referenced roadway links.</p> <p>Parameters:</p> Name Type Description Default <code>tr_shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>transit shapes from shapes.txt to validate foreign key to.</p> required <code>rd_links_df</code> <code>DataFrame[RoadLinksTable]</code> <p>Links dataframe from roadway network to validate</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>df with shape_id and A, B</p> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def shape_links_without_road_links(\n    tr_shapes: DataFrame[WranglerShapesTable],\n    rd_links_df: DataFrame[RoadLinksTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Validate that links in transit shapes exist in referenced roadway links.\n\n    Args:\n        tr_shapes: transit shapes from shapes.txt to validate foreign key to.\n        rd_links_df: Links dataframe from roadway network to validate\n\n    Returns:\n        df with shape_id and A, B\n    \"\"\"\n    tr_shape_links = unique_shape_links(tr_shapes)\n    # WranglerLogger.debug(f\"Unique shape links: \\n {tr_shape_links}\")\n    rd_links_transit_ok = rd_links_df[\n        (rd_links_df[\"drive_access\"]) | (rd_links_df[\"bus_only\"]) | (rd_links_df[\"rail_only\"])\n    ]\n\n    merged_df = tr_shape_links.merge(\n        rd_links_transit_ok[[\"A\", \"B\"]],\n        how=\"left\",\n        on=[\"A\", \"B\"],\n        indicator=True,\n    )\n\n    missing_links_df = merged_df.loc[merged_df._merge == \"left_only\", [\"shape_id\", \"A\", \"B\"]]\n    if len(missing_links_df):\n        WranglerLogger.error(\n            f\"! Transit shape links missing in roadway network: \\n {missing_links_df}\"\n        )\n    return missing_links_df[[\"shape_id\", \"A\", \"B\"]]\n</code></pre>"},{"location":"api/#network_wrangler.transit.validate.stop_times_without_road_links","title":"<code>stop_times_without_road_links(tr_stop_times, rd_links_df)</code>","text":"<p>Validate that links in transit shapes exist in referenced roadway links.</p> <p>Parameters:</p> Name Type Description Default <code>tr_stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>transit stop_times from stop_times.txt to validate foreign key to.</p> required <code>rd_links_df</code> <code>DataFrame[RoadLinksTable]</code> <p>Links dataframe from roadway network to validate</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>df with shape_id and A, B</p> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def stop_times_without_road_links(\n    tr_stop_times: DataFrame[WranglerStopTimesTable],\n    rd_links_df: DataFrame[RoadLinksTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Validate that links in transit shapes exist in referenced roadway links.\n\n    Args:\n        tr_stop_times: transit stop_times from stop_times.txt to validate foreign key to.\n        rd_links_df: Links dataframe from roadway network to validate\n\n    Returns:\n        df with shape_id and A, B\n    \"\"\"\n    tr_links = unique_stop_time_links(tr_stop_times)\n\n    rd_links_transit_ok = rd_links_df[\n        (rd_links_df[\"drive_access\"]) | (rd_links_df[\"bus_only\"]) | (rd_links_df[\"rail_only\"])\n    ]\n\n    merged_df = tr_links.merge(\n        rd_links_transit_ok[[\"A\", \"B\"]],\n        how=\"left\",\n        on=[\"A\", \"B\"],\n        indicator=True,\n    )\n\n    missing_links_df = merged_df.loc[merged_df._merge == \"left_only\", [\"trip_id\", \"A\", \"B\"]]\n    if len(missing_links_df):\n        WranglerLogger.error(\n            f\"! Transit stop_time links missing in roadway network: \\n {missing_links_df}\"\n        )\n    return missing_links_df[[\"trip_id\", \"A\", \"B\"]]\n</code></pre>"},{"location":"api/#network_wrangler.transit.validate.transit_nodes_without_road_nodes","title":"<code>transit_nodes_without_road_nodes(feed, nodes_df, rd_field='model_node_id')</code>","text":"<p>Validate all of a transit feeds node foreign keys exist in referenced roadway nodes.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Feed</code> <p>Transit Feed to query.</p> required <code>nodes_df</code> <code>DataFrame</code> <p>Nodes dataframe from roadway network to validate foreign key to. Defaults to self.roadway_net.nodes_df</p> required <code>rd_field</code> <code>str</code> <p>field in roadway nodes to check against. Defaults to \u201cmodel_node_id\u201d</p> <code>'model_node_id'</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>boolean indicating if relationships are all valid</p> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def transit_nodes_without_road_nodes(\n    feed: Feed,\n    nodes_df: DataFrame[RoadNodesTable],\n    rd_field: str = \"model_node_id\",\n) -&gt; list[int]:\n    \"\"\"Validate all of a transit feeds node foreign keys exist in referenced roadway nodes.\n\n    Args:\n        feed: Transit Feed to query.\n        nodes_df (pd.DataFrame, optional): Nodes dataframe from roadway network to validate\n            foreign key to. Defaults to self.roadway_net.nodes_df\n        rd_field: field in roadway nodes to check against. Defaults to \"model_node_id\"\n\n    Returns:\n        boolean indicating if relationships are all valid\n    \"\"\"\n    feed_nodes_series = [\n        feed.stops[\"stop_id\"],\n        feed.shapes[\"shape_model_node_id\"],\n        feed.stop_times[\"stop_id\"],\n    ]\n    tr_nodes = set(concat_with_attr(feed_nodes_series).unique())\n    rd_nodes = set(nodes_df[rd_field].unique().tolist())\n    # nodes in tr_nodes but not rd_nodes\n    missing_tr_nodes = list(tr_nodes - rd_nodes)\n\n    if missing_tr_nodes:\n        WranglerLogger.error(\n            f\"! Transit nodes in missing in roadway network: \\n {missing_tr_nodes}\"\n        )\n    return missing_tr_nodes\n</code></pre>"},{"location":"api/#network_wrangler.transit.validate.transit_road_net_consistency","title":"<code>transit_road_net_consistency(feed, road_net)</code>","text":"<p>Checks foreign key and network link relationships between transit feed and a road_net.</p> <p>Parameters:</p> Name Type Description Default <code>feed</code> <code>Feed</code> <p>Transit Feed.</p> required <code>road_net</code> <code>RoadwayNetwork</code> <p>Roadway network to check relationship with.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>boolean indicating if road_net is consistent with transit network.</p> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def transit_road_net_consistency(feed: Feed, road_net: RoadwayNetwork) -&gt; bool:\n    \"\"\"Checks foreign key and network link relationships between transit feed and a road_net.\n\n    Args:\n        feed: Transit Feed.\n        road_net (RoadwayNetwork): Roadway network to check relationship with.\n\n    Returns:\n        bool: boolean indicating if road_net is consistent with transit network.\n    \"\"\"\n    _missing_links = shape_links_without_road_links(feed.shapes, road_net.links_df)\n    _missing_nodes = transit_nodes_without_road_nodes(feed, road_net.nodes_df)\n    _consistency = _missing_links.empty and not _missing_nodes\n    return _consistency\n</code></pre>"},{"location":"api/#network_wrangler.transit.validate.validate_transit_in_dir","title":"<code>validate_transit_in_dir(dir, file_format='txt', road_dir=None, road_file_format='geojson')</code>","text":"<p>Validates a roadway network in a directory to the wrangler data model specifications.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>Path</code> <p>The transit network file directory.</p> required <code>file_format</code> <code>str</code> <p>The format of roadway network file name. Defaults to \u201ctxt\u201d.</p> <code>'txt'</code> <code>road_dir</code> <code>Path</code> <p>The roadway network file directory. Defaults to None.</p> <code>None</code> <code>road_file_format</code> <code>str</code> <p>The format of roadway network file name. Defaults to \u201cgeojson\u201d.</p> <code>'geojson'</code> <code>output_dir</code> <code>str</code> <p>The output directory for the validation report. Defaults to \u201c.\u201d.</p> required Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def validate_transit_in_dir(\n    dir: Path,\n    file_format: TransitFileTypes = \"txt\",\n    road_dir: Optional[Path] = None,\n    road_file_format: RoadwayFileTypes = \"geojson\",\n) -&gt; bool:\n    \"\"\"Validates a roadway network in a directory to the wrangler data model specifications.\n\n    Args:\n        dir (Path): The transit network file directory.\n        file_format (str): The format of roadway network file name. Defaults to \"txt\".\n        road_dir (Path): The roadway network file directory. Defaults to None.\n        road_file_format (str): The format of roadway network file name. Defaults to \"geojson\".\n        output_dir (str): The output directory for the validation report. Defaults to \".\".\n    \"\"\"\n    from .io import load_transit\n\n    try:\n        t = load_transit(dir, file_format=file_format)\n    except SchemaErrors as e:\n        WranglerLogger.error(f\"!!! [Transit Network invalid] - Failed Loading to Feed object\\n{e}\")\n        return False\n    if road_dir is not None:\n        from ..roadway import load_roadway_from_dir\n        from .network import TransitRoadwayConsistencyError\n\n        try:\n            r = load_roadway_from_dir(road_dir, file_format=road_file_format)\n        except FileNotFoundError:\n            WranglerLogger.error(f\"! Roadway network not found in {road_dir}\")\n            return False\n        except Exception as e:\n            WranglerLogger.error(f\"! Error loading roadway network. \\\n                                 Skipping validation of road to transit network.\\n{e}\")\n        try:\n            t.road_net = r\n        except TransitRoadwayConsistencyError as e:\n            WranglerLogger.error(f\"!!! [Tranit Network inconsistent] Error in road to transit \\\n                                 network consistency.\\n{e}\")\n            return False\n\n    return True\n</code></pre>"},{"location":"api/#utils-and-functions","title":"Utils and Functions","text":"<p>General utility functions used throughout package.</p> <p>Helper functions for reading and writing files to reduce boilerplate.</p> <p>Utility functions for loading dictionaries from files.</p> <p>Helper functions for data models.</p> <p>Functions to help with network manipulations in dataframes.</p> <p>Functions related to parsing and comparing time objects and series.</p> <p>Internal function terminology for timespan scopes:</p> <ul> <li><code>matching</code>: a scope that could be applied for a given timespan combination.     This includes the default timespan as well as scopes wholely contained within.</li> <li><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan.     This includes the default timespan, all <code>matching</code> timespans and all timespans where     at least one minute overlap.</li> <li><code>conflicting</code>: a timespan that is overlapping but not matching. By definition default      scope values are not conflicting.</li> <li><code>independent</code> a timespan that is not overlapping.</li> </ul> <p>Utility functions for pandas data manipulation.</p> <p>Helper geographic manipulation functions.</p> <p>Dataframe accessors that allow functions to be called directly on the dataframe.</p> <p>Logging utilities for Network Wrangler.</p> <p>Configuration utilities.</p> <p>Module for time and timespan objects.</p> <p>Module for visualizing roadway and transit networks using Mapbox tiles.</p> <p>This module provides a function <code>net_to_mapbox</code> that creates and serves Mapbox tiles on a local web server based on roadway and transit networks.</p> Example usage <p>net_to_mapbox(roadway, transit)</p> <p>All network wrangler errors.</p>"},{"location":"api/#network_wrangler.utils.utils.DictionaryMergeError","title":"<code>DictionaryMergeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when there is a conflict in merging two dictionaries.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>class DictionaryMergeError(Exception):\n    \"\"\"Error raised when there is a conflict in merging two dictionaries.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.check_one_or_one_superset_present","title":"<code>check_one_or_one_superset_present(mixed_list, all_fields_present)</code>","text":"<p>Checks that exactly one of the fields in mixed_list is in fields_present or one superset.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def check_one_or_one_superset_present(\n    mixed_list: list[Union[str, list[str]]], all_fields_present: list[str]\n) -&gt; bool:\n    \"\"\"Checks that exactly one of the fields in mixed_list is in fields_present or one superset.\"\"\"\n    normalized_list = normalize_to_lists(mixed_list)\n\n    list_items_present = [i for i in normalized_list if set(i).issubset(all_fields_present)]\n\n    if len(list_items_present) == 1:\n        return True\n\n    return list_elements_subset_of_single_element(list_items_present)\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.combine_unique_unhashable_list","title":"<code>combine_unique_unhashable_list(list1, list2)</code>","text":"<p>Combines lists preserving order of first and removing duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>list1</code> <code>list</code> <p>The first list.</p> required <code>list2</code> <code>list</code> <p>The second list.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A new list containing the elements from list1 followed by the</p> <p>unique elements from list2.</p> Example <p>list1 = [1, 2, 3] list2 = [2, 3, 4, 5] combine_unique_unhashable_list(list1, list2) [1, 2, 3, 4, 5]</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def combine_unique_unhashable_list(list1: list, list2: list):\n    \"\"\"Combines lists preserving order of first and removing duplicates.\n\n    Args:\n        list1 (list): The first list.\n        list2 (list): The second list.\n\n    Returns:\n        list: A new list containing the elements from list1 followed by the\n        unique elements from list2.\n\n    Example:\n        &gt;&gt;&gt; list1 = [1, 2, 3]\n        &gt;&gt;&gt; list2 = [2, 3, 4, 5]\n        &gt;&gt;&gt; combine_unique_unhashable_list(list1, list2)\n        [1, 2, 3, 4, 5]\n    \"\"\"\n    return [item for item in list1 if item not in list2] + list2\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.delete_keys_from_dict","title":"<code>delete_keys_from_dict(dictionary, keys)</code>","text":"<p>Removes list of keys from potentially nested dictionary.</p> <p>SOURCE: https://stackoverflow.com/questions/3405715/ User: @mseifert</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>dict</code> <p>dictionary to remove keys from</p> required <code>keys</code> <code>list</code> <p>list of keys to remove</p> required Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def delete_keys_from_dict(dictionary: dict, keys: list) -&gt; dict:\n    \"\"\"Removes list of keys from potentially nested dictionary.\n\n    SOURCE: https://stackoverflow.com/questions/3405715/\n    User: @mseifert\n\n    Args:\n        dictionary: dictionary to remove keys from\n        keys: list of keys to remove\n\n    \"\"\"\n    keys_set = list(set(keys))  # Just an optimization for the \"if key in keys\" lookup.\n\n    modified_dict = {}\n    for key, value in dictionary.items():\n        if key not in keys_set:\n            if isinstance(value, dict):\n                modified_dict[key] = delete_keys_from_dict(value, keys_set)\n            else:\n                modified_dict[key] = (\n                    value  # or copy.deepcopy(value) if a copy is desired for non-dicts.\n                )\n    return modified_dict\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.dict_to_hexkey","title":"<code>dict_to_hexkey(d)</code>","text":"<p>Converts a dictionary to a hexdigest of the sha1 hash of the dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>dictionary to convert to string</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>hexdigest of the sha1 hash of dictionary</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def dict_to_hexkey(d: dict) -&gt; str:\n    \"\"\"Converts a dictionary to a hexdigest of the sha1 hash of the dictionary.\n\n    Args:\n        d (dict): dictionary to convert to string\n\n    Returns:\n        str: hexdigest of the sha1 hash of dictionary\n    \"\"\"\n    return hashlib.sha1(str(d).encode()).hexdigest()\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.findkeys","title":"<code>findkeys(node, kv)</code>","text":"<p>Returns values of all keys in various objects.</p> <p>Adapted from arainchi on Stack Overflow: https://stackoverflow.com/questions/9807634/find-all-occurrences-of-a-key-in-nested-dictionaries-and-lists</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def findkeys(node, kv):\n    \"\"\"Returns values of all keys in various objects.\n\n    Adapted from arainchi on Stack Overflow:\n    https://stackoverflow.com/questions/9807634/find-all-occurrences-of-a-key-in-nested-dictionaries-and-lists\n    \"\"\"\n    if isinstance(node, list):\n        for i in node:\n            for x in findkeys(i, kv):\n                yield x\n    elif isinstance(node, dict):\n        if kv in node:\n            yield node[kv]\n        for j in node.values():\n            for x in findkeys(j, kv):\n                yield x\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.get_overlapping_range","title":"<code>get_overlapping_range(ranges)</code>","text":"<p>Returns the overlapping range for a list of ranges or tuples defining ranges.</p> <p>Parameters:</p> Name Type Description Default <code>ranges</code> <code>list[Union[tuple[int], range]]</code> <p>A list of ranges or tuples defining ranges.</p> required <p>Returns:</p> Type Description <code>Union[None, range]</code> <p>Union[None, range]: The overlapping range if found, otherwise None.</p> Example <p>ranges = [(1, 5), (3, 7), (6, 10)] get_overlapping_range(ranges) range(3, 5)</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def get_overlapping_range(ranges: list[Union[tuple[int, int], range]]) -&gt; Union[None, range]:\n    \"\"\"Returns the overlapping range for a list of ranges or tuples defining ranges.\n\n    Args:\n        ranges (list[Union[tuple[int], range]]): A list of ranges or tuples defining ranges.\n\n    Returns:\n        Union[None, range]: The overlapping range if found, otherwise None.\n\n    Example:\n        &gt;&gt;&gt; ranges = [(1, 5), (3, 7), (6, 10)]\n        &gt;&gt;&gt; get_overlapping_range(ranges)\n        range(3, 5)\n\n    \"\"\"\n    # check that any tuples have two values\n    if any(isinstance(r, tuple) and len(r) != 2 for r in ranges):  # noqa: PLR2004\n        msg = \"Tuple ranges must have two values.\"\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n\n    _ranges = [r if isinstance(r, range) else range(r[0], r[1]) for r in ranges]\n\n    _overlap_start = max(r.start for r in _ranges)\n    _overlap_end = min(r.stop for r in _ranges)\n\n    if _overlap_start &lt; _overlap_end:\n        return range(_overlap_start, _overlap_end)\n    return None\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.list_elements_subset_of_single_element","title":"<code>list_elements_subset_of_single_element(mixed_list)</code>","text":"<p>Find the first list in the mixed_list.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>@validate_call\ndef list_elements_subset_of_single_element(mixed_list: list[Union[str, list[str]]]) -&gt; bool:\n    \"\"\"Find the first list in the mixed_list.\"\"\"\n    potential_supersets = []\n    for item in mixed_list:\n        if isinstance(item, list) and len(item) &gt; 0:\n            potential_supersets.append(set(item))\n\n    # If no list is found, return False\n    if not potential_supersets:\n        return False\n\n    normalized_list = normalize_to_lists(mixed_list)\n\n    valid_supersets = []\n    for ss in potential_supersets:\n        if all(ss.issuperset(i) for i in normalized_list):\n            valid_supersets.append(ss)\n\n    return len(valid_supersets) == 1\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.make_slug","title":"<code>make_slug(text, delimiter='_')</code>","text":"<p>Makes a slug from text.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def make_slug(text: str, delimiter: str = \"_\") -&gt; str:\n    \"\"\"Makes a slug from text.\"\"\"\n    text = re.sub(\"[,.;@#?!&amp;$']+\", \"\", text.lower())\n    return re.sub(\"[\\ ]+\", delimiter, text)\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.merge_dicts","title":"<code>merge_dicts(right, left, path=None)</code>","text":"<p>Merges the contents of nested dict left into nested dict right.</p> <p>Raises errors in case of namespace conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>right</code> <p>dict, modified in place</p> required <code>left</code> <p>dict to be merged into right</p> required <code>path</code> <p>default None, sequence of keys to be reported in case of error in merging nested dictionaries</p> <code>None</code> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def merge_dicts(right, left, path=None):\n    \"\"\"Merges the contents of nested dict left into nested dict right.\n\n    Raises errors in case of namespace conflicts.\n\n    Args:\n        right: dict, modified in place\n        left: dict to be merged into right\n        path: default None, sequence of keys to be reported in case of\n            error in merging nested dictionaries\n    \"\"\"\n    if path is None:\n        path = []\n    for key in left:\n        if key in right:\n            if isinstance(right[key], dict) and isinstance(left[key], dict):\n                merge_dicts(right[key], left[key], [*path, str(key)])\n            else:\n                path = \".\".join([*path, str(key)])\n                msg = f\"duplicate keys in source dict files: {path}\"\n                WranglerLogger.error(msg)\n                raise DictionaryMergeError(msg)\n        else:\n            right[key] = left[key]\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.normalize_to_lists","title":"<code>normalize_to_lists(mixed_list)</code>","text":"<p>Turn a mixed list of scalars and lists into a list of lists.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def normalize_to_lists(mixed_list: list[Union[str, list]]) -&gt; list[list]:\n    \"\"\"Turn a mixed list of scalars and lists into a list of lists.\"\"\"\n    normalized_list = []\n    for item in mixed_list:\n        if isinstance(item, str):\n            normalized_list.append([item])\n        else:\n            normalized_list.append(item)\n    return normalized_list\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.split_string_prefix_suffix_from_num","title":"<code>split_string_prefix_suffix_from_num(input_string)</code>","text":"<p>Split a string prefix and suffix from last number.</p> <p>Parameters:</p> Name Type Description Default <code>input_string</code> <code>str</code> <p>The input string to be processed.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the prefix (including preceding numbers),    the last numeric part as an integer, and the suffix.</p> Notes <p>This function uses regular expressions to split a string into three parts: the prefix, the last numeric part, and the suffix. The prefix includes any preceding numbers, the last numeric part is converted to an integer, and the suffix includes any non-digit characters after the last numeric part.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"abc123def456\")\n('abc', 123, 'def456')\n</code></pre> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"hello\")\n('hello', 0, '')\n</code></pre> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"123\")\n('', 123, '')\n</code></pre> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def split_string_prefix_suffix_from_num(input_string: str):\n    \"\"\"Split a string prefix and suffix from *last* number.\n\n    Args:\n        input_string (str): The input string to be processed.\n\n    Returns:\n        tuple: A tuple containing the prefix (including preceding numbers),\n               the last numeric part as an integer, and the suffix.\n\n    Notes:\n        This function uses regular expressions to split a string into three parts:\n        the prefix, the last numeric part, and the suffix. The prefix includes any\n        preceding numbers, the last numeric part is converted to an integer, and\n        the suffix includes any non-digit characters after the last numeric part.\n\n    Examples:\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"abc123def456\")\n        ('abc', 123, 'def456')\n\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"hello\")\n        ('hello', 0, '')\n\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"123\")\n        ('', 123, '')\n\n    \"\"\"\n    input_string = str(input_string)\n    pattern = re.compile(r\"(.*?)(\\d+)(\\D*)$\")\n    match = pattern.match(input_string)\n\n    if match:\n        # Extract the groups: prefix (including preceding numbers), last numeric part, suffix\n        prefix, numeric_part, suffix = match.groups()\n        # Convert the numeric part to an integer\n        num_variable = int(numeric_part)\n        return prefix, num_variable, suffix\n    return input_string, 0, \"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.utils.topological_sort","title":"<code>topological_sort(adjacency_list, visited_list)</code>","text":"<p>Topological sorting for Acyclic Directed Graph.</p> <p>Parameters: - adjacency_list (dict): A dictionary representing the adjacency list of the graph. - visited_list (list): A list representing the visited status of each vertex in the graph.</p> <p>Returns: - output_stack (list): A list containing the vertices in topological order.</p> <p>This function performs a topological sort on an acyclic directed graph. It takes an adjacency list and a visited list as input. The adjacency list represents the connections between vertices in the graph, and the visited list keeps track of the visited status of each vertex.</p> <p>The function uses a recursive helper function to perform the topological sort. It starts by iterating over each vertex in the visited list. For each unvisited vertex, it calls the helper function, which recursively visits all the neighbors of the vertex and adds them to the output stack in reverse order. Finally, it returns the output stack, which contains the vertices in topological order.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def topological_sort(adjacency_list, visited_list):\n    \"\"\"Topological sorting for Acyclic Directed Graph.\n\n    Parameters:\n    - adjacency_list (dict): A dictionary representing the adjacency list of the graph.\n    - visited_list (list): A list representing the visited status of each vertex in the graph.\n\n    Returns:\n    - output_stack (list): A list containing the vertices in topological order.\n\n    This function performs a topological sort on an acyclic directed graph. It takes an adjacency\n    list and a visited list as input. The adjacency list represents the connections between\n    vertices in the graph, and the visited list keeps track of the visited status of each vertex.\n\n    The function uses a recursive helper function to perform the topological sort. It starts by\n    iterating over each vertex in the visited list. For each unvisited vertex, it calls the helper\n    function, which recursively visits all the neighbors of the vertex and adds them to the output\n    stack in reverse order. Finally, it returns the output stack, which contains the vertices in\n    topological order.\n    \"\"\"\n    output_stack = []\n\n    def _topology_sort_util(vertex):\n        if not visited_list[vertex]:\n            visited_list[vertex] = True\n            for neighbor in adjacency_list[vertex]:\n                _topology_sort_util(neighbor)\n            output_stack.insert(0, vertex)\n\n    for vertex in visited_list:\n        _topology_sort_util(vertex)\n\n    return output_stack\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_table.FileReadError","title":"<code>FileReadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error reading a file.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>class FileReadError(Exception):\n    \"\"\"Raised when there is an error reading a file.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_table.FileWriteError","title":"<code>FileWriteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error writing a file.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>class FileWriteError(Exception):\n    \"\"\"Raised when there is an error writing a file.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_table.convert_file_serialization","title":"<code>convert_file_serialization(input_file, output_file, overwrite=True, boundary_gdf=None, boundary_geocode=None, boundary_file=None, node_filter_s=None, chunk_size=None)</code>","text":"<p>Convert a file serialization format to another and optionally filter to a boundary.</p> <p>If the input file is a JSON file that is larger than a reasonable portion of available memory, and the output file is a Parquet file the JSON file will be read in chunks.</p> <p>If the input file is a Geographic data type (shp, geojon, geoparquet) and a boundary is provided, the data will be filtered to the boundary.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>Path</code> <p>Path to the input JSON or GEOJSON file.</p> required <code>output_file</code> <code>Path</code> <p>Path to the output Parquet file.</p> required <code>overwrite</code> <code>bool</code> <p>If True, overwrite the output file if it exists.</p> <code>True</code> <code>boundary_gdf</code> <code>Optional[GeoDataFrame]</code> <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_geocode</code> <code>Optional[str]</code> <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Optional[Path]</code> <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>node_filter_s</code> <code>Optional[Series]</code> <p>If provided, will filter links in .json file to only those that connect to nodes. Defaults to None.</p> <code>None</code> <code>chunk_size</code> <code>Optional[int]</code> <p>Number of JSON objects to process in each chunk. Only works for JSON to Parquet. If None, will determine if chunking needed and what size.</p> <code>None</code> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def convert_file_serialization(\n    input_file: Path,\n    output_file: Path,\n    overwrite: bool = True,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    node_filter_s: Optional[pd.Series] = None,\n    chunk_size: Optional[int] = None,\n):\n    \"\"\"Convert a file serialization format to another and optionally filter to a boundary.\n\n    If the input file is a JSON file that is larger than a reasonable portion of available\n    memory, *and* the output file is a Parquet file the JSON file will be read in chunks.\n\n    If the input file is a Geographic data type (shp, geojon, geoparquet) and a boundary is\n    provided, the data will be filtered to the boundary.\n\n    Args:\n        input_file: Path to the input JSON or GEOJSON file.\n        output_file: Path to the output Parquet file.\n        overwrite: If True, overwrite the output file if it exists.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        node_filter_s: If provided, will filter links in .json file to only those that connect to\n            nodes. Defaults to None.\n        chunk_size: Number of JSON objects to process in each chunk. Only works for\n            JSON to Parquet. If None, will determine if chunking needed and what size.\n    \"\"\"\n    WranglerLogger.debug(f\"Converting {input_file} to {output_file}.\")\n\n    if output_file.exists() and not overwrite:\n        msg = f\"File {output_file} already exists and overwrite is False.\"\n        raise FileExistsError(msg)\n\n    if Path(input_file).suffix == \".json\" and Path(output_file).suffix == \".parquet\":\n        if chunk_size is None:\n            chunk_size = _suggest_json_chunk_size(input_file)\n        if chunk_size is None:\n            df = read_table(input_file)\n            if node_filter_s is not None and \"A\" in df.columns and \"B\" in df.columns:\n                df = df[df[\"A\"].isin(node_filter_s) | df[\"B\"].isin(node_filter_s)]\n            write_table(df, output_file, overwrite=overwrite)\n        else:\n            _json_to_parquet_in_chunks(input_file, output_file, chunk_size)\n\n    df = read_table(\n        input_file,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n    if node_filter_s is not None and \"A\" in df.columns and \"B\" in df.columns:\n        df = df[df[\"A\"].isin(node_filter_s) | df[\"B\"].isin(node_filter_s)]\n    write_table(df, output_file, overwrite=overwrite)\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_table.prep_dir","title":"<code>prep_dir(outdir, overwrite=True)</code>","text":"<p>Prepare a directory for writing files.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def prep_dir(outdir: Path, overwrite: bool = True):\n    \"\"\"Prepare a directory for writing files.\"\"\"\n    if not overwrite and outdir.exists() and len(list(outdir.iterdir())) &gt; 0:\n        msg = f\"Directory {outdir} is not empty and overwrite is False.\"\n        raise FileExistsError(msg)\n    outdir.mkdir(parents=True, exist_ok=True)\n\n    # clean out existing files\n    for f in outdir.iterdir():\n        if f.is_file():\n            f.unlink()\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_table.read_table","title":"<code>read_table(filename, sub_filename=None, boundary_gdf=None, boundary_geocode=None, boundary_file=None, read_speed=DefaultConfig.CPU.EST_PD_READ_SPEED)</code>","text":"<p>Read file and return a dataframe or geodataframe.</p> <p>If filename is a zip file, will unzip to a temporary directory.</p> <p>If filename is a geojson or shapefile, will filter the data to the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only provide one of these boundary filters.</p> <p>If filename is a geoparquet file, will filter the data to the bounding box of the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only provide one of these boundary filters.</p> <p>NOTE:  if you are accessing multiple files from this zip file you will want to unzip it first and THEN access the table files so you don\u2019t create multiple duplicate unzipped tmp dirs.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path</code> <p>filename to load.</p> required <code>sub_filename</code> <code>Optional[str]</code> <p>if the file is a zip, the sub_filename to load.</p> <code>None</code> <code>boundary_gdf</code> <code>Optional[GeoDataFrame]</code> <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_geocode</code> <code>Optional[str]</code> <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Optional[Path]</code> <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> <code>None</code> <code>read_speed</code> <code>dict</code> <p>dictionary of read speeds for different file types. Defaults to DefaultConfig.CPU.EST_PD_READ_SPEED.</p> <code>EST_PD_READ_SPEED</code> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def read_table(\n    filename: Path,\n    sub_filename: Optional[str] = None,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    read_speed: dict = DefaultConfig.CPU.EST_PD_READ_SPEED,\n) -&gt; Union[pd.DataFrame, gpd.GeoDataFrame]:\n    \"\"\"Read file and return a dataframe or geodataframe.\n\n    If filename is a zip file, will unzip to a temporary directory.\n\n    If filename is a geojson or shapefile, will filter the data\n    to the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only\n    provide one of these boundary filters.\n\n    If filename is a geoparquet file, will filter the data to the *bounding box* of the\n    boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only\n    provide one of these boundary filters.\n\n    NOTE:  if you are accessing multiple files from this zip file you will want to unzip it first\n    and THEN access the table files so you don't create multiple duplicate unzipped tmp dirs.\n\n    Args:\n        filename (Path): filename to load.\n        sub_filename: if the file is a zip, the sub_filename to load.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        read_speed: dictionary of read speeds for different file types. Defaults to\n            DefaultConfig.CPU.EST_PD_READ_SPEED.\n    \"\"\"\n    filename = Path(filename)\n    if not filename.exists():\n        msg = f\"Input file {filename} does not exist.\"\n        raise FileNotFoundError(msg)\n    if filename.stat().st_size == 0:\n        msg = f\"File {filename} is empty.\"\n        raise FileExistsError(msg)\n    if filename.suffix == \".zip\":\n        if not sub_filename:\n            msg = \"sub_filename must be provided for zip files.\"\n            raise ValueError(msg)\n        filename = unzip_file(filename) / sub_filename\n    WranglerLogger.debug(\n        f\"Estimated read time: {_estimate_read_time_of_file(filename, read_speed)}.\"\n    )\n\n    # will result in None if no boundary is provided\n    mask_gdf = get_bounding_polygon(\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n\n    if any(x in filename.suffix for x in [\"geojson\", \"shp\", \"csv\"]):\n        try:\n            # masking only supported by fiona engine, which is slower.\n            if mask_gdf is None:\n                return gpd.read_file(filename, engine=\"pyogrio\")\n            return gpd.read_file(filename, mask=mask_gdf, engine=\"fiona\")\n        except Exception as err:\n            if \"csv\" in filename.suffix:\n                return pd.read_csv(filename)\n            raise FileReadError from err\n    elif \"parquet\" in filename.suffix:\n        return _read_parquet_table(filename, mask_gdf)\n    elif \"json\" in filename.suffix:\n        with filename.open() as f:\n            return pd.read_json(f, orient=\"records\")\n    msg = f\"Filetype {filename.suffix} not implemented.\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_table.unzip_file","title":"<code>unzip_file(path)</code>","text":"<p>Unzips a file to a temporary directory and returns the directory path.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def unzip_file(path: Path) -&gt; Path:\n    \"\"\"Unzips a file to a temporary directory and returns the directory path.\"\"\"\n    tmpdir = tempfile.mkdtemp()\n    shutil.unpack_archive(path, tmpdir)\n\n    def finalize() -&gt; None:\n        shutil.rmtree(tmpdir)\n\n    # Lazy cleanup\n    weakref.finalize(tmpdir, finalize)\n\n    return Path(tmpdir)\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_table.write_table","title":"<code>write_table(df, filename, overwrite=False, **kwargs)</code>","text":"<p>Write a dataframe or geodataframe to a file.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataframe to write.</p> required <code>filename</code> <code>Path</code> <p>filename to write to.</p> required <code>overwrite</code> <code>bool</code> <p>whether to overwrite the file if it exists. Defaults to False.</p> <code>False</code> <code>kwargs</code> <p>additional arguments to pass to the writer.</p> <code>{}</code> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def write_table(\n    df: Union[pd.DataFrame, gpd.GeoDataFrame],\n    filename: Path,\n    overwrite: bool = False,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Write a dataframe or geodataframe to a file.\n\n    Args:\n        df (pd.DataFrame): dataframe to write.\n        filename (Path): filename to write to.\n        overwrite (bool): whether to overwrite the file if it exists. Defaults to False.\n        kwargs: additional arguments to pass to the writer.\n\n    \"\"\"\n    filename = Path(filename)\n    if filename.exists() and not overwrite:\n        msg = f\"File {filename} already exists and overwrite is False.\"\n        raise FileExistsError(msg)\n\n    if filename.parent.is_dir() and not filename.parent.exists():\n        filename.parent.mkdir(parents=True)\n\n    WranglerLogger.debug(f\"Writing to {filename}.\")\n\n    if \"shp\" in filename.suffix:\n        df.to_file(filename, index=False, **kwargs)\n    elif \"parquet\" in filename.suffix:\n        df.to_parquet(filename, index=False, **kwargs)\n    elif \"csv\" in filename.suffix or \"txt\" in filename.suffix:\n        df.to_csv(filename, index=False, date_format=\"%H:%M:%S\", **kwargs)\n    elif \"geojson\" in filename.suffix:\n        # required due to issues with list-like columns\n        if isinstance(df, gpd.GeoDataFrame):\n            data = df.to_json(drop_id=True)\n        else:\n            data = df.to_json(orient=\"records\", index=False)\n        with filename.open(\"w\", encoding=\"utf-8\") as file:\n            file.write(data)\n    elif \"json\" in filename.suffix:\n        with filename.open(\"w\") as f:\n            f.write(df.to_json(orient=\"records\"))\n    else:\n        msg = f\"Filetype {filename.suffix} not implemented.\"\n        raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_dict.load_dict","title":"<code>load_dict(path)</code>","text":"<p>Load a dictionary from a file.</p> Source code in <code>network_wrangler/utils/io_dict.py</code> <pre><code>def load_dict(path: Path) -&gt; dict:\n    \"\"\"Load a dictionary from a file.\"\"\"\n    path = Path(path)\n    if not path.is_file():\n        msg = f\"Specified dict file {path} not found.\"\n        raise FileNotFoundError(msg)\n\n    if path.suffix.lower() == \".toml\":\n        return _load_toml(path)\n    if path.suffix.lower() == \".json\":\n        return _load_json(path)\n    if path.suffix.lower() == \".yaml\" or path.suffix.lower() == \".yml\":\n        return _load_yaml(path)\n    msg = f\"Filetype {path.suffix} not implemented.\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.utils.io_dict.load_merge_dict","title":"<code>load_merge_dict(path)</code>","text":"<p>Load and merge multiple dictionaries from files.</p> Source code in <code>network_wrangler/utils/io_dict.py</code> <pre><code>def load_merge_dict(path: Union[Path, list[Path]]) -&gt; dict:\n    \"\"\"Load and merge multiple dictionaries from files.\"\"\"\n    if not isinstance(path, list):\n        path = [path]\n    data = load_dict(path[0])\n    for path_item in path[1:]:\n        merge_dicts(data, load_dict(path_item))\n    return data\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.DatamodelDataframeIncompatableError","title":"<code>DatamodelDataframeIncompatableError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a data model and a dataframe are not compatable.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>class DatamodelDataframeIncompatableError(Exception):\n    \"\"\"Raised when a data model and a dataframe are not compatable.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.TableValidationError","title":"<code>TableValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a table validation fails.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>class TableValidationError(Exception):\n    \"\"\"Raised when a table validation fails.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.coerce_extra_fields_to_type_in_df","title":"<code>coerce_extra_fields_to_type_in_df(data, model, df)</code>","text":"<p>Coerce extra fields in data that aren\u2019t specified in Pydantic model to the type in the df.</p> <p>Note: will not coerce lists of submodels, etc.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>The data to coerce.</p> required <code>model</code> <code>BaseModel</code> <p>The Pydantic model to validate the data against.</p> required <code>df</code> <code>DataFrame</code> <p>The DataFrame to coerce the data to.</p> required Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def coerce_extra_fields_to_type_in_df(\n    data: BaseModel, model: BaseModel, df: pd.DataFrame\n) -&gt; BaseModel:\n    \"\"\"Coerce extra fields in data that aren't specified in Pydantic model to the type in the df.\n\n    Note: will not coerce lists of submodels, etc.\n\n    Args:\n        data (dict): The data to coerce.\n        model (BaseModel): The Pydantic model to validate the data against.\n        df (pd.DataFrame): The DataFrame to coerce the data to.\n    \"\"\"\n    out_data = copy.deepcopy(data)\n\n    # Coerce submodels\n    for field in submodel_fields_in_model(model, data):\n        out_data.__dict__[field] = coerce_extra_fields_to_type_in_df(\n            data.__dict__[field], model.__annotations__[field], df\n        )\n\n    for field in extra_attributes_undefined_in_model(data, model):\n        try:\n            v = coerce_val_to_df_types(field, data.model_extra[field], df)\n        except ValueError as err:\n            raise DatamodelDataframeIncompatableError() from err\n        out_data.model_extra[field] = v\n    return out_data\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.default_from_datamodel","title":"<code>default_from_datamodel(data_model, field)</code>","text":"<p>Returns default value from pandera data model for a given field name.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def default_from_datamodel(data_model: pa.DataFrameModel, field: str):\n    \"\"\"Returns default value from pandera data model for a given field name.\"\"\"\n    if field in data_model.__fields__ and hasattr(data_model.__fields__[field][1], \"default\"):\n        return data_model.__fields__[field][1].default\n    return None\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.empty_df_from_datamodel","title":"<code>empty_df_from_datamodel(model, crs=LAT_LON_CRS)</code>","text":"<p>Create an empty DataFrame or GeoDataFrame with the specified columns.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>A pandera data model to create empty [Geo]DataFrame from.</p> required <code>crs</code> <code>int</code> <p>if schema has geometry, will use this as the geometry\u2019s crs. Defaults to LAT_LONG_CRS</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def empty_df_from_datamodel(\n    model: DataFrameModel, crs: int = LAT_LON_CRS\n) -&gt; Union[gpd.GeoDataFrame, pd.DataFrame]:\n    \"\"\"Create an empty DataFrame or GeoDataFrame with the specified columns.\n\n    Args:\n        model (BaseModel): A pandera data model to create empty [Geo]DataFrame from.\n        crs: if schema has geometry, will use this as the geometry's crs. Defaults to LAT_LONG_CRS\n    Returns:\n        An empty [Geo]DataFrame that validates to the specified model.\n    \"\"\"\n    schema = model.to_schema()\n    data: dict[str, list] = {col: [] for col in schema.columns}\n\n    if \"geometry\" in data:\n        return model(gpd.GeoDataFrame(data, crs=crs))\n\n    return model(pd.DataFrame(data))\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.extra_attributes_undefined_in_model","title":"<code>extra_attributes_undefined_in_model(instance, model)</code>","text":"<p>Find the extra attributes in a pydantic model that are not defined in the model.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def extra_attributes_undefined_in_model(instance: BaseModel, model: BaseModel) -&gt; list:\n    \"\"\"Find the extra attributes in a pydantic model that are not defined in the model.\"\"\"\n    defined_fields = model.model_fields\n    all_attributes = list(instance.model_dump(exclude_none=True, by_alias=True).keys())\n    extra_attributes = [a for a in all_attributes if a not in defined_fields]\n    return extra_attributes\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.fill_df_with_defaults_from_model","title":"<code>fill_df_with_defaults_from_model(df, model)</code>","text":"<p>Fill a DataFrame with default values from a Pandera DataFrameModel.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>DataFrame to fill with default values.</p> required <code>model</code> <p>Pandera DataFrameModel to get default values from.</p> required Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def fill_df_with_defaults_from_model(df, model):\n    \"\"\"Fill a DataFrame with default values from a Pandera DataFrameModel.\n\n    Args:\n        df: DataFrame to fill with default values.\n        model: Pandera DataFrameModel to get default values from.\n    \"\"\"\n    for c in df.columns:\n        default_value = default_from_datamodel(model, c)\n        if default_value is None:\n            df[c] = df[c].where(pd.notna(df[c]), None)\n        else:\n            df[c] = df[c].fillna(default_value)\n    return df\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.identify_model","title":"<code>identify_model(data, models)</code>","text":"<p>Identify the model that the input data conforms to.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, dict]</code> <p>The input data to identify.</p> required <code>models</code> <code>list[DataFrameModel, BaseModel]</code> <p>A list of models to validate the input data against.</p> required Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def identify_model(\n    data: Union[pd.DataFrame, dict], models: list\n) -&gt; Union[DataFrameModel, BaseModel]:\n    \"\"\"Identify the model that the input data conforms to.\n\n    Args:\n        data (Union[pd.DataFrame, dict]): The input data to identify.\n        models (list[DataFrameModel,BaseModel]): A list of models to validate the input\n          data against.\n    \"\"\"\n    for m in models:\n        try:\n            if isinstance(data, pd.DataFrame):\n                validate_df_to_model(data, m)\n            else:\n                m(**data)\n            return m\n        except ValidationError:\n            continue\n        except SchemaError:\n            continue\n\n    WranglerLogger.error(\n        f\"The input data isn't consistant with any provided data model.\\\n                         \\nInput data: {data}\\\n                         \\nData Models: {models}\"\n    )\n    msg = \"The input data isn't consistant with any provided data model.\"\n    raise TableValidationError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.order_fields_from_data_model","title":"<code>order_fields_from_data_model(df, model)</code>","text":"<p>Order the fields in a DataFrame to match the order in a Pandera DataFrameModel.</p> <p>Will add any fields that are not in the model to the end of the DataFrame. Will not add any fields that are in the model but not in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to order.</p> required <code>model</code> <code>DataFrameModel</code> <p>Pandera DataFrameModel to order the DataFrame to.</p> required Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def order_fields_from_data_model(df: pd.DataFrame, model: DataFrameModel) -&gt; pd.DataFrame:\n    \"\"\"Order the fields in a DataFrame to match the order in a Pandera DataFrameModel.\n\n    Will add any fields that are not in the model to the end of the DataFrame.\n    Will not add any fields that are in the model but not in the DataFrame.\n\n    Args:\n        df: DataFrame to order.\n        model: Pandera DataFrameModel to order the DataFrame to.\n    \"\"\"\n    model_fields = list(model.__fields__.keys())\n    df_model_fields = [f for f in model_fields if f in df.columns]\n    df_additional_fields = [f for f in df.columns if f not in model_fields]\n    return df[df_model_fields + df_additional_fields]\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.submodel_fields_in_model","title":"<code>submodel_fields_in_model(model, instance=None)</code>","text":"<p>Find the fields in a pydantic model that are submodels.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def submodel_fields_in_model(model: type, instance: Optional[BaseModel] = None) -&gt; list:\n    \"\"\"Find the fields in a pydantic model that are submodels.\"\"\"\n    types = get_type_hints(model)\n    model_type = (ModelMetaclass, BaseModel)\n    submodels = [f for f in model.model_fields if isinstance(types.get(f), model_type)]\n    if instance is not None:\n        defined = list(instance.model_dump(exclude_none=True, by_alias=True).keys())\n        return [f for f in submodels if f in defined]\n    return submodels\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.validate_call_pyd","title":"<code>validate_call_pyd(func)</code>","text":"<p>Decorator to validate the function i/o using Pydantic models without Pandera.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def validate_call_pyd(func):\n    \"\"\"Decorator to validate the function i/o using Pydantic models without Pandera.\"\"\"\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        type_hints = get_type_hints(func)\n        # Modify the type hints to replace pandera DataFrame models with pandas DataFrames\n        modified_type_hints = {\n            key: value\n            for key, value in type_hints.items()\n            if not _is_type_from_type_hint(value, PanderaDataFrame)\n        }\n\n        new_func = func\n        new_func.__annotations__ = modified_type_hints\n        validated_func = validate_call(new_func, config={\"arbitrary_types_allowed\": True})\n\n        return validated_func(*args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/#network_wrangler.utils.models.validate_df_to_model","title":"<code>validate_df_to_model(df, model, output_file=Path('validation_failure_cases.csv'))</code>","text":"<p>Wrapper to validate a DataFrame against a Pandera DataFrameModel with better logging.</p> <p>Also copies the attrs from the input DataFrame to the validated DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to validate.</p> required <code>model</code> <code>type</code> <p>Pandera DataFrameModel to validate against.</p> required <code>output_file</code> <code>Path</code> <p>Optional file to write validation errors to. Defaults to validation_failure_cases.csv.</p> <code>Path('validation_failure_cases.csv')</code> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef validate_df_to_model(\n    df: DataFrame, model: type, output_file: Path = Path(\"validation_failure_cases.csv\")\n) -&gt; DataFrame:\n    \"\"\"Wrapper to validate a DataFrame against a Pandera DataFrameModel with better logging.\n\n    Also copies the attrs from the input DataFrame to the validated DataFrame.\n\n    Args:\n        df: DataFrame to validate.\n        model: Pandera DataFrameModel to validate against.\n        output_file: Optional file to write validation errors to. Defaults to\n            validation_failure_cases.csv.\n    \"\"\"\n    attrs = copy.deepcopy(df.attrs)\n    err_msg = f\"Validation to {model.__name__} failed.\"\n    try:\n        model_df = model.validate(df, lazy=True)\n        model_df = fill_df_with_defaults_from_model(model_df, model)\n        model_df.attrs = attrs\n        return model_df\n    except (TypeError, ValueError) as e:\n        WranglerLogger.error(f\"Validation to {model.__name__} failed.\\n{e}\")\n        raise TableValidationError(err_msg) from e\n    except SchemaErrors as e:\n        # Log the summary of errors\n        WranglerLogger.error(\n            f\"Validation to {model.__name__} failed with {len(e.failure_cases)} \\\n            errors: \\n{e.failure_cases}\"\n        )\n\n        # If there are many errors, save them to a file\n        if len(e.failure_cases) &gt; SMALL_RECS:\n            error_file = output_file\n            e.failure_cases.to_csv(error_file)\n            WranglerLogger.info(f\"Detailed error cases written to {error_file}\")\n        else:\n            # Otherwise log the errors directly\n            WranglerLogger.error(\"Detailed failure cases:\\n%s\", e.failure_cases)\n        raise TableValidationError(err_msg) from e\n    except SchemaError as e:\n        WranglerLogger.error(f\"Validation to {model.__name__} failed with error: {e}\")\n        WranglerLogger.error(f\"Failure Cases:\\n{e.failure_cases}\")\n        raise TableValidationError(err_msg) from e\n</code></pre>"},{"location":"api/#network_wrangler.utils.net.point_seq_to_links","title":"<code>point_seq_to_links(point_seq_df, id_field, seq_field, node_id_field, from_field='A', to_field='B')</code>","text":"<p>Translates a df with tidy data representing a sequence of points into links.</p> <p>Parameters:</p> Name Type Description Default <code>point_seq_df</code> <code>DataFrame</code> <p>Dataframe with source breadcrumbs</p> required <code>id_field</code> <code>str</code> <p>Trace ID</p> required <code>seq_field</code> <code>str</code> <p>Order of breadcrumbs within ID_field</p> required <code>node_id_field</code> <code>str</code> <p>field denoting the node ID</p> required <code>from_field</code> <code>str</code> <p>Field to export from_field to. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_field</code> <code>str</code> <p>Field to export to_field to. Defaults to \u201cB\u201d.</p> <code>'B'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Link records with id_field, from_field, to_field</p> Source code in <code>network_wrangler/utils/net.py</code> <pre><code>def point_seq_to_links(\n    point_seq_df: DataFrame,\n    id_field: str,\n    seq_field: str,\n    node_id_field: str,\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; DataFrame:\n    \"\"\"Translates a df with tidy data representing a sequence of points into links.\n\n    Args:\n        point_seq_df (pd.DataFrame): Dataframe with source breadcrumbs\n        id_field (str): Trace ID\n        seq_field (str): Order of breadcrumbs within ID_field\n        node_id_field (str): field denoting the node ID\n        from_field (str, optional): Field to export from_field to. Defaults to \"A\".\n        to_field (str, optional): Field to export to_field to. Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: Link records with id_field, from_field, to_field\n    \"\"\"\n    point_seq_df = point_seq_df.sort_values(by=[id_field, seq_field])\n\n    links = point_seq_df.add_suffix(f\"_{from_field}\").join(\n        point_seq_df.shift(-1).add_suffix(f\"_{to_field}\")\n    )\n\n    links = links[links[f\"{id_field}_{to_field}\"] == links[f\"{id_field}_{from_field}\"]]\n\n    links = links.drop(columns=[f\"{id_field}_{to_field}\"])\n    links = links.rename(\n        columns={\n            f\"{id_field}_{from_field}\": id_field,\n            f\"{node_id_field}_{from_field}\": from_field,\n            f\"{node_id_field}_{to_field}\": to_field,\n        }\n    )\n\n    links = links.dropna(subset=[from_field, to_field])\n    # Since join with a shift() has some NAs, we need to recast the columns to int\n    _int_cols = [to_field, f\"{seq_field}_{to_field}\"]\n    links[_int_cols] = links[_int_cols].astype(int)\n    return links\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.TimespanDfQueryError","title":"<code>TimespanDfQueryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error for timespan query errors.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>class TimespanDfQueryError(Exception):\n    \"\"\"Error for timespan query errors.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.calc_overlap_duration_with_query","title":"<code>calc_overlap_duration_with_query(start_time_s, end_time_s, start_time_q, end_time_q)</code>","text":"<p>Calculate the overlap series of start and end times and a query start and end times.</p> <p>Parameters:</p> Name Type Description Default <code>start_time_s</code> <code>Series[datetime]</code> <p>Series of start times to calculate overlap with.</p> required <code>end_time_s</code> <code>Series[datetime]</code> <p>Series of end times to calculate overlap with.</p> required <code>start_time_q</code> <code>datetime</code> <p>Query start time to calculate overlap with.</p> required <code>end_time_q</code> <code>datetime</code> <p>Query end time to calculate overlap with.</p> required Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def calc_overlap_duration_with_query(\n    start_time_s: pd.Series[datetime],\n    end_time_s: pd.Series[datetime],\n    start_time_q: datetime,\n    end_time_q: datetime,\n) -&gt; pd.Series[timedelta]:\n    \"\"\"Calculate the overlap series of start and end times and a query start and end times.\n\n    Args:\n        start_time_s: Series of start times to calculate overlap with.\n        end_time_s: Series of end times to calculate overlap with.\n        start_time_q: Query start time to calculate overlap with.\n        end_time_q: Query end time to calculate overlap with.\n    \"\"\"\n    overlap_start = start_time_s.combine(start_time_q, max)\n    overlap_end = end_time_s.combine(end_time_q, min)\n    overlap_duration_s = (overlap_end - overlap_start).dt.total_seconds() / 60\n\n    return overlap_duration_s\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.convert_timespan_to_start_end_dt","title":"<code>convert_timespan_to_start_end_dt(timespan_s)</code>","text":"<p>Convert a timespan string [\u201812:00\u2019,\u201814:00] to start_time &amp; end_time datetime cols in df.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def convert_timespan_to_start_end_dt(timespan_s: pd.Serie[str]) -&gt; pd.DataFrame:\n    \"\"\"Convert a timespan string ['12:00','14:00] to start_time &amp; end_time datetime cols in df.\"\"\"\n    start_time = timespan_s.apply(lambda x: str_to_time(x[0]))\n    end_time = timespan_s.apply(lambda x: str_to_time(x[1]))\n    return pd.DataFrame({\"start_time\": start_time, \"end_time\": end_time})\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_contains","title":"<code>dt_contains(timespan1, timespan2)</code>","text":"<p>Check timespan1 inclusively contains timespan2.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p>Parameters:</p> Name Type Description Default <code>timespan1</code> <code>list[time]</code> <p>The first timespan represented as a list containing the start time and end time.</p> required <code>timespan2</code> <code>list[time]</code> <p>The second timespan represented as a list containing the start time and end time.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the first timespan contains the second timespan, False otherwise.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef dt_contains(timespan1: list[datetime], timespan2: list[datetime]) -&gt; bool:\n    \"\"\"Check timespan1 inclusively contains timespan2.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    Args:\n        timespan1 (list[time]): The first timespan represented as a list containing the start\n            time and end time.\n        timespan2 (list[time]): The second timespan represented as a list containing the start\n            time and end time.\n\n    Returns:\n        bool: True if the first timespan contains the second timespan, False otherwise.\n    \"\"\"\n    start_time_dt, end_time_dt = timespan1\n\n    if end_time_dt &lt; start_time_dt:\n        end_time_dt = end_time_dt + timedelta(days=1)\n\n    start_time_dt2, end_time_dt2 = timespan2\n\n    if end_time_dt2 &lt; start_time_dt2:\n        end_time_dt2 = end_time_dt2 + timedelta(days=1)\n\n    return (start_time_dt &lt;= start_time_dt2) and (end_time_dt &gt;= end_time_dt2)\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_list_overlaps","title":"<code>dt_list_overlaps(timespans)</code>","text":"<p>Check if any of the timespans overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def dt_list_overlaps(timespans: list[list[datetime]]) -&gt; bool:\n    \"\"\"Check if any of the timespans overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    return bool(filter_dt_list_to_overlaps(timespans))\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_overlap_duration","title":"<code>dt_overlap_duration(timedelta1, timedelta2)</code>","text":"<p>Check if two timespans overlap and return the amount of overlap.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef dt_overlap_duration(timedelta1: timedelta, timedelta2: timedelta) -&gt; timedelta:\n    \"\"\"Check if two timespans overlap and return the amount of overlap.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n    \"\"\"\n    if timedelta1.end_time &lt; timedelta1.start_time:\n        timedelta1 = timedelta1 + timedelta(days=1)\n    if timedelta2.end_time &lt; timedelta2.start_time:\n        timedelta2 = timedelta2 + timedelta(days=1)\n    overlap_start = max(timedelta1.start_time, timedelta2.start_time)\n    overlap_end = min(timedelta1.end_time, timedelta2.end_time)\n    overlap_duration = max(overlap_end - overlap_start, timedelta(0))\n    return overlap_duration\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_overlaps","title":"<code>dt_overlaps(timespan1, timespan2)</code>","text":"<p>Check if two timespans overlap.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef dt_overlaps(timespan1: list[datetime], timespan2: list[datetime]) -&gt; bool:\n    \"\"\"Check if two timespans overlap.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    time1_start, time1_end = timespan1\n    time2_start, time2_end = timespan2\n\n    if time1_end &lt; time1_start:\n        time1_end += timedelta(days=1)\n    if time2_end &lt; time2_start:\n        time2_end += timedelta(days=1)\n\n    return (time1_start &lt; time2_end) and (time2_start &lt; time1_end)\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.dt_to_seconds_from_midnight","title":"<code>dt_to_seconds_from_midnight(dt)</code>","text":"<p>Convert a datetime object to the number of seconds since midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef dt_to_seconds_from_midnight(dt: datetime) -&gt; int:\n    \"\"\"Convert a datetime object to the number of seconds since midnight.\"\"\"\n    return round((dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds())\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.duration_dt","title":"<code>duration_dt(start_time_dt, end_time_dt)</code>","text":"<p>Returns a datetime.timedelta object representing the duration of the timespan.</p> <p>If end_time is less than start_time, the duration will assume that it crosses over midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def duration_dt(start_time_dt: datetime, end_time_dt: datetime) -&gt; timedelta:\n    \"\"\"Returns a datetime.timedelta object representing the duration of the timespan.\n\n    If end_time is less than start_time, the duration will assume that it crosses over\n    midnight.\n    \"\"\"\n    if end_time_dt &lt; start_time_dt:\n        return timedelta(\n            hours=24 - start_time_dt.hour + end_time_dt.hour,\n            minutes=end_time_dt.minute - start_time_dt.minute,\n            seconds=end_time_dt.second - start_time_dt.second,\n        )\n    return end_time_dt - start_time_dt\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.filter_df_to_max_overlapping_timespans","title":"<code>filter_df_to_max_overlapping_timespans(orig_df, query_timespan, strict_match=False, min_overlap_minutes=1, keep_max_of_cols=None)</code>","text":"<p>Filters dataframe for entries that have maximum overlap with the given query timespan.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p>Parameters:</p> Name Type Description Default <code>orig_df</code> <code>DataFrame</code> <p>dataframe to query timespans for with <code>start_time</code> and <code>end_time</code> fields.</p> required <code>query_timespan</code> <code>list[TimeString]</code> <p>TimespanString of format [\u2018HH:MM\u2019,\u2019HH:MM\u2019] to query orig_df for overlapping records.</p> required <code>strict_match</code> <code>bool</code> <p>boolean indicating if the returned df should only contain records that fully contain the query timespan. If set to True, min_overlap_minutes does not apply. Defaults to False.</p> <code>False</code> <code>min_overlap_minutes</code> <code>int</code> <p>minimum number of minutes the timespans need to overlap to keep. Defaults to 1.</p> <code>1</code> <code>keep_max_of_cols</code> <code>Optional[list[str]]</code> <p>list of fields to return the maximum value of overlap for.  If None, will return all overlapping time periods. Defaults to <code>['model_link_id']</code></p> <code>None</code> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef filter_df_to_max_overlapping_timespans(\n    orig_df: pd.DataFrame,\n    query_timespan: list[TimeString],\n    strict_match: bool = False,\n    min_overlap_minutes: int = 1,\n    keep_max_of_cols: Optional[list[str]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Filters dataframe for entries that have maximum overlap with the given query timespan.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    Args:\n        orig_df: dataframe to query timespans for with `start_time` and `end_time` fields.\n        query_timespan: TimespanString of format ['HH:MM','HH:MM'] to query orig_df for overlapping\n            records.\n        strict_match: boolean indicating if the returned df should only contain\n            records that fully contain the query timespan. If set to True, min_overlap_minutes\n            does not apply. Defaults to False.\n        min_overlap_minutes: minimum number of minutes the timespans need to overlap to keep.\n            Defaults to 1.\n        keep_max_of_cols: list of fields to return the maximum value of overlap for.  If None,\n            will return all overlapping time periods. Defaults to `['model_link_id']`\n    \"\"\"\n    if keep_max_of_cols is None:\n        keep_max_of_cols = [\"model_link_id\"]\n    if \"start_time\" not in orig_df.columns or \"end_time\" not in orig_df.columns:\n        msg = \"DataFrame must have 'start_time' and 'end_time' columns\"\n        WranglerLogger.error(msg)\n        raise TimespanDfQueryError(msg)\n    q_start, q_end = str_to_time_list(query_timespan)\n\n    real_end = orig_df[\"end_time\"]\n    real_end.loc[orig_df[\"end_time\"] &lt; orig_df[\"start_time\"]] += pd.Timedelta(days=1)\n\n    orig_df[\"overlap_duration\"] = calc_overlap_duration_with_query(\n        orig_df[\"start_time\"],\n        real_end,\n        q_start,\n        q_end,\n    )\n    if strict_match:\n        overlap_df = orig_df.loc[(orig_df.start_time &lt;= q_start) &amp; (real_end &gt;= q_end)]\n    else:\n        overlap_df = orig_df.loc[orig_df.overlap_duration &gt; min_overlap_minutes]\n    WranglerLogger.debug(f\"overlap_df: \\n{overlap_df}\")\n    if keep_max_of_cols:\n        # keep only the maximum overlap\n        idx = overlap_df.groupby(keep_max_of_cols)[\"overlap_duration\"].idxmax()\n        overlap_df = overlap_df.loc[idx]\n    return overlap_df\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.filter_df_to_overlapping_timespans","title":"<code>filter_df_to_overlapping_timespans(orig_df, query_timespans)</code>","text":"<p>Filters dataframe for entries that have any overlap with ANY of the given query timespans.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p>Parameters:</p> Name Type Description Default <code>orig_df</code> <code>DataFrame</code> <p>dataframe to query timespans for with <code>start_time</code> and <code>end_time</code> fields.</p> required <code>query_timespans</code> <code>list[TimespanString]</code> <p>List of a list of TimespanStr of format [\u2018HH:MM\u2019,\u2019HH:MM\u2019] to query orig_df for overlapping records.</p> required Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef filter_df_to_overlapping_timespans(\n    orig_df: pd.DataFrame,\n    query_timespans: list[TimespanString],\n) -&gt; pd.DataFrame:\n    \"\"\"Filters dataframe for entries that have any overlap with ANY of the given query timespans.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    Args:\n        orig_df: dataframe to query timespans for with `start_time` and `end_time` fields.\n        query_timespans: List of a list of TimespanStr of format ['HH:MM','HH:MM'] to query orig_df\n            for overlapping records.\n    \"\"\"\n    if \"start_time\" not in orig_df.columns or \"end_time\" not in orig_df.columns:\n        msg = \"DataFrame must have 'start_time' and 'end_time' columns\"\n        WranglerLogger.error(msg)\n        raise TimespanDfQueryError(msg)\n\n    mask = pd.Series([False] * len(orig_df), index=orig_df.index)\n    for query_timespan in query_timespans:\n        q_start_time, q_end_time = str_to_time_list(query_timespan)\n        end_time_s = orig_df[\"end_time\"]\n        end_time_s.loc[orig_df[\"end_time\"] &lt; orig_df[\"start_time\"]] += pd.Timedelta(days=1)\n        this_ts_mask = (orig_df[\"start_time\"] &lt; q_end_time) &amp; (q_start_time &lt; end_time_s)\n        mask |= this_ts_mask\n    return orig_df.loc[mask]\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.filter_dt_list_to_overlaps","title":"<code>filter_dt_list_to_overlaps(timespans)</code>","text":"<p>Filter a list of timespans to only include those that overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef filter_dt_list_to_overlaps(timespans: list[list[datetime]]) -&gt; list[list[datetime]]:\n    \"\"\"Filter a list of timespans to only include those that overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    overlaps = []\n    for i in range(len(timespans)):\n        for j in range(i + 1, len(timespans)):\n            if dt_overlaps(timespans[i], timespans[j]):\n                overlaps += [timespans[i], timespans[j]]\n\n    # remove dupes\n    return list(map(list, set(map(tuple, overlaps))))\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.format_seconds_to_legible_str","title":"<code>format_seconds_to_legible_str(seconds)</code>","text":"<p>Formats seconds into a human-friendly string for log files.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def format_seconds_to_legible_str(seconds: int) -&gt; str:\n    \"\"\"Formats seconds into a human-friendly string for log files.\"\"\"\n    if seconds &lt; 60:  # noqa: PLR2004\n        return f\"{int(seconds)} seconds\"\n    if seconds &lt; 3600:  # noqa: PLR2004\n        return f\"{int(seconds // 60)} minutes\"\n    hours = int(seconds // 3600)\n    minutes = int((seconds % 3600) // 60)\n    return f\"{hours} hours and {minutes} minutes\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.is_increasing","title":"<code>is_increasing(datetimes)</code>","text":"<p>Check if a list of datetime objects is increasing in time.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def is_increasing(datetimes: list[datetime]) -&gt; bool:\n    \"\"\"Check if a list of datetime objects is increasing in time.\"\"\"\n    return all(datetimes[i] &lt;= datetimes[i + 1] for i in range(len(datetimes) - 1))\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.seconds_from_midnight_to_str","title":"<code>seconds_from_midnight_to_str(seconds)</code>","text":"<p>Convert the number of seconds since midnight to a TimeString (HH:MM).</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef seconds_from_midnight_to_str(seconds: int) -&gt; TimeString:\n    \"\"\"Convert the number of seconds since midnight to a TimeString (HH:MM).\"\"\"\n    return str(timedelta(seconds=seconds))\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_seconds_from_midnight","title":"<code>str_to_seconds_from_midnight(time_str)</code>","text":"<p>Convert a TimeString (HH:MM&lt;:SS&gt;) to the number of seconds since midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef str_to_seconds_from_midnight(time_str: TimeString) -&gt; int:\n    \"\"\"Convert a TimeString (HH:MM&lt;:SS&gt;) to the number of seconds since midnight.\"\"\"\n    dt = str_to_time(time_str)\n    return dt_to_seconds_from_midnight(dt)\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_time","title":"<code>str_to_time(time_str, base_date=None)</code>","text":"<p>Convert TimeString (HH:MM&lt;:SS&gt;) to datetime object.</p> <p>If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.</p> <p>Parameters:</p> Name Type Description Default <code>time_str</code> <code>TimeString</code> <p>TimeString in HH:MM:SS or HH:MM format.</p> required <code>base_date</code> <code>Optional[date]</code> <p>optional date to base the datetime on. Defaults to None. If not provided, will use today.</p> <code>None</code> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef str_to_time(time_str: TimeString, base_date: Optional[date] = None) -&gt; datetime:\n    \"\"\"Convert TimeString (HH:MM&lt;:SS&gt;) to datetime object.\n\n    If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.\n\n    Args:\n        time_str: TimeString in HH:MM:SS or HH:MM format.\n        base_date: optional date to base the datetime on. Defaults to None.\n            If not provided, will use today.\n    \"\"\"\n    # Set the base date to today if not provided\n    if base_date is None:\n        base_date = date.today()\n\n    # Split the time string to extract hours, minutes, and seconds\n    parts = time_str.split(\":\")\n    hours = int(parts[0])\n    minutes = int(parts[1])\n    seconds = int(parts[2]) if len(parts) == 3 else 0  # noqa: PLR2004\n\n    if hours &gt;= 24:  # noqa: PLR2004\n        add_days = hours // 24\n        base_date += timedelta(days=add_days)\n        hours -= 24 * add_days\n\n    # Create a time object with the adjusted hours, minutes, and seconds\n    adjusted_time = datetime.strptime(f\"{hours:02}:{minutes:02}:{seconds:02}\", \"%H:%M:%S\").time()\n\n    # Combine the base date with the adjusted time and add the extra days if needed\n    combined_datetime = datetime.combine(base_date, adjusted_time)\n\n    return combined_datetime\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_time_list","title":"<code>str_to_time_list(timespan)</code>","text":"<p>Convert list of TimeStrings (HH:MM&lt;:SS&gt;) to list of datetime.time objects.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef str_to_time_list(timespan: list[TimeString]) -&gt; list[datetime]:\n    \"\"\"Convert list of TimeStrings (HH:MM&lt;:SS&gt;) to list of datetime.time objects.\"\"\"\n    timespan_dt: list[datetime] = list(map(str_to_time, timespan))\n    if not is_increasing(timespan_dt):\n        timespan_dt = [timespan_dt[0], timespan_dt[1] + timedelta(days=1)]\n        WranglerLogger.warning(f\"Timespan is not in increasing order: {timespan}.\\\n            End time will be treated as next day.\")\n    return timespan_dt\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.str_to_time_series","title":"<code>str_to_time_series(time_str_s, base_date=None)</code>","text":"<p>Convert mixed panda series datetime and TimeString (HH:MM&lt;:SS&gt;) to datetime object.</p> <p>If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.</p> <p>Parameters:</p> Name Type Description Default <code>time_str_s</code> <code>Series</code> <p>Pandas Series of TimeStrings in HH:MM:SS or HH:MM format.</p> required <code>base_date</code> <code>Optional[Union[Series, date]]</code> <p>optional date to base the datetime on. Defaults to None. If not provided, will use today. Can be either a single instance or a series of same length as time_str_s</p> <code>None</code> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def str_to_time_series(\n    time_str_s: pd.Series, base_date: Optional[Union[pd.Series, date]] = None\n) -&gt; pd.Series:\n    \"\"\"Convert mixed panda series datetime and TimeString (HH:MM&lt;:SS&gt;) to datetime object.\n\n    If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.\n\n    Args:\n        time_str_s: Pandas Series of TimeStrings in HH:MM:SS or HH:MM format.\n        base_date: optional date to base the datetime on. Defaults to None.\n            If not provided, will use today. Can be either a single instance or a series of\n            same length as time_str_s\n    \"\"\"\n    # check strings are in the correct format, leave existing date times alone\n    is_string = time_str_s.apply(lambda x: isinstance(x, str))\n    time_strings = time_str_s[is_string]\n    result = time_str_s.copy()\n    if is_string.any():\n        result[is_string] = _all_str_to_time_series(time_strings, base_date)\n    result = result.astype(\"datetime64[ns]\")\n    return result\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.timespan_str_list_to_dt","title":"<code>timespan_str_list_to_dt(timespans)</code>","text":"<p>Convert list of TimespanStrings to list of datetime.time objects.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef timespan_str_list_to_dt(timespans: list[TimespanString]) -&gt; list[list[datetime]]:\n    \"\"\"Convert list of TimespanStrings to list of datetime.time objects.\"\"\"\n    return [str_to_time_list(ts) for ts in timespans]\n</code></pre>"},{"location":"api/#network_wrangler.utils.time.timespans_overlap","title":"<code>timespans_overlap(timespan1, timespan2)</code>","text":"<p>Check if two timespan strings overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def timespans_overlap(timespan1: list[TimespanString], timespan2: list[TimespanString]) -&gt; bool:\n    \"\"\"Check if two timespan strings overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    timespan1 = str_to_time_list(timespan1)\n    timespan2 = str_to_time_list(timespan2)\n    return dt_overlaps(timespan1, timespan2)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.DataSegmentationError","title":"<code>DataSegmentationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error segmenting data.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class DataSegmentationError(Exception):\n    \"\"\"Raised when there is an error segmenting data.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.InvalidJoinFieldError","title":"<code>InvalidJoinFieldError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when the join field is not unique.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class InvalidJoinFieldError(Exception):\n    \"\"\"Raised when the join field is not unique.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.MissingPropertiesError","title":"<code>MissingPropertiesError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when properties are missing from the dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class MissingPropertiesError(Exception):\n    \"\"\"Raised when properties are missing from the dataframe.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_dict_to_df_types","title":"<code>coerce_dict_to_df_types(d, df, skip_keys=None, return_skipped=False)</code>","text":"<p>Coerce dictionary values to match the type of a dataframe columns matching dict keys.</p> <p>Will also coerce a list of values.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>dictionary to coerce with singleton or list values</p> required <code>df</code> <code>DataFrame</code> <p>dataframe to get types from</p> required <code>skip_keys</code> <code>Optional[list]</code> <p>list of dict keys to skip. Defaults to []/</p> <code>None</code> <code>return_skipped</code> <code>bool</code> <p>keep the uncoerced, skipped keys/vals in the resulting dict. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, CoerceTypes]</code> <p>dict with coerced types</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_dict_to_df_types(\n    d: dict[str, CoerceTypes],\n    df: pd.DataFrame,\n    skip_keys: Optional[list] = None,\n    return_skipped: bool = False,\n) -&gt; dict[str, CoerceTypes]:\n    \"\"\"Coerce dictionary values to match the type of a dataframe columns matching dict keys.\n\n    Will also coerce a list of values.\n\n    Args:\n        d (dict): dictionary to coerce with singleton or list values\n        df (pd.DataFrame): dataframe to get types from\n        skip_keys: list of dict keys to skip. Defaults to []/\n        return_skipped: keep the uncoerced, skipped keys/vals in the resulting dict.\n            Defaults to False.\n\n    Returns:\n        dict: dict with coerced types\n    \"\"\"\n    if skip_keys is None:\n        skip_keys = []\n    coerced_dict: dict[str, CoerceTypes] = {}\n    for k, vals in d.items():\n        if k in skip_keys:\n            if return_skipped:\n                coerced_dict[k] = vals\n            continue\n        if k not in df.columns:\n            msg = f\"Key {k} not in dataframe columns.\"\n            raise ValueError(msg)\n        if pd.api.types.infer_dtype(df[k]) == \"integer\":\n            if isinstance(vals, list):\n                coerced_v: CoerceTypes = [int(float(v)) for v in vals]\n            else:\n                coerced_v = int(float(vals))\n        elif pd.api.types.infer_dtype(df[k]) == \"floating\":\n            coerced_v = [float(v) for v in vals] if isinstance(vals, list) else float(vals)\n        elif pd.api.types.infer_dtype(df[k]) == \"boolean\":\n            coerced_v = [bool(v) for v in vals] if isinstance(vals, list) else bool(vals)\n        elif isinstance(vals, list):\n            coerced_v = [str(v) for v in vals]\n        else:\n            coerced_v = str(vals)\n        coerced_dict[k] = coerced_v\n    return coerced_dict\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_gdf","title":"<code>coerce_gdf(df, geometry=None, in_crs=LAT_LON_CRS)</code>","text":"<p>Coerce a DataFrame to a GeoDataFrame, optionally with a new geometry.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_gdf(\n    df: pd.DataFrame, geometry: GeoSeries = None, in_crs: int = LAT_LON_CRS\n) -&gt; GeoDataFrame:\n    \"\"\"Coerce a DataFrame to a GeoDataFrame, optionally with a new geometry.\"\"\"\n    if isinstance(df, GeoDataFrame):\n        if df.crs is None:\n            df.crs = in_crs\n        return df\n    p = None\n\n    if \"geometry\" not in df and geometry is None:\n        msg = \"Must give geometry argument if don't have Geometry in dataframe\"\n        raise ValueError(msg)\n\n    geometry = geometry if geometry is not None else df[\"geometry\"]\n    if not isinstance(geometry, GeoSeries):\n        try:\n            geometry = GeoSeries(geometry)\n        except Exception:\n            geometry = geometry.apply(wkt.loads)\n    df = GeoDataFrame(df, geometry=geometry, crs=in_crs)\n\n    return df\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_val_to_df_types","title":"<code>coerce_val_to_df_types(field, val, df)</code>","text":"<p>Coerce field value to match the type of a matching dataframe columns.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>field to lookup</p> required <code>val</code> <code>CoerceTypes</code> <p>value or list of values to coerce</p> required <code>df</code> <code>DataFrame</code> <p>dataframe to get types from</p> required Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_val_to_df_types(  # noqa: PLR0911\n    field: str,\n    val: CoerceTypes,\n    df: pd.DataFrame,\n) -&gt; CoerceTypes:\n    \"\"\"Coerce field value to match the type of a matching dataframe columns.\n\n    Args:\n        field: field to lookup\n        val: value or list of values to coerce\n        df (pd.DataFrame): dataframe to get types from\n\n    Returns: coerced value or list of values\n    \"\"\"\n    if field not in df.columns:\n        msg = f\"Field {field} not in dataframe columns.\"\n        raise ValueError(msg)\n    if pd.api.types.infer_dtype(df[field]) == \"integer\":\n        if isinstance(val, list):\n            return [int(float(v)) for v in val]\n        return int(float(val))\n    if pd.api.types.infer_dtype(df[field]) == \"floating\":\n        if isinstance(val, list):\n            return [float(v) for v in val]\n        return float(val)\n    if pd.api.types.infer_dtype(df[field]) == \"boolean\":\n        if isinstance(val, list):\n            return [bool(v) for v in val]\n        return bool(val)\n    if isinstance(val, list):\n        return [str(v) for v in val]\n    return str(val)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.coerce_val_to_series_type","title":"<code>coerce_val_to_series_type(val, s)</code>","text":"<p>Coerces a value to match type of pandas series.</p> <p>Will try not to fail so if you give it a value that can\u2019t convert to a number, it will return a string.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <p>Any type of singleton value</p> required <code>s</code> <code>Series</code> <p>series to match the type to</p> required Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_val_to_series_type(val, s: pd.Series) -&gt; Union[float, str, bool]:\n    \"\"\"Coerces a value to match type of pandas series.\n\n    Will try not to fail so if you give it a value that can't convert to a number, it will\n    return a string.\n\n    Args:\n        val: Any type of singleton value\n        s (pd.Series): series to match the type to\n    \"\"\"\n    # WranglerLogger.debug(f\"Input val: {val} of type {type(val)} to match with series type \\\n    #    {pd.api.types.infer_dtype(s)}.\")\n    if pd.api.types.infer_dtype(s) in [\"integer\", \"floating\"]:\n        try:\n            v: Union[float, str, bool] = float(val)\n        except:\n            v = str(val)\n    elif pd.api.types.infer_dtype(s) == \"boolean\":\n        v = bool(val)\n    else:\n        v = str(val)\n    # WranglerLogger.debug(f\"Return value: {v}\")\n    return v\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.compare_df_values","title":"<code>compare_df_values(df1, df2, join_col=None, ignore=None, atol=1e-05)</code>","text":"<p>Compare overlapping part of dataframes and returns where there are differences.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def compare_df_values(\n    df1, df2, join_col: Optional[str] = None, ignore: Optional[list[str]] = None, atol=1e-5\n):\n    \"\"\"Compare overlapping part of dataframes and returns where there are differences.\"\"\"\n    if ignore is None:\n        ignore = []\n    comp_c = [\n        c\n        for c in df1.columns\n        if c in df2.columns and c not in ignore and not isinstance(df1[c], GeoSeries)\n    ]\n    if join_col is None:\n        comp_df = df1[comp_c].merge(\n            df2[comp_c],\n            how=\"inner\",\n            right_index=True,\n            left_index=True,\n            suffixes=[\"_a\", \"_b\"],\n        )\n    else:\n        comp_df = df1[comp_c].merge(df2[comp_c], how=\"inner\", on=join_col, suffixes=[\"_a\", \"_b\"])\n\n    # Filter columns by data type\n    numeric_cols = [col for col in comp_c if np.issubdtype(df1[col].dtype, np.number)]\n    ll_cols = list(set(list_like_columns(df1) + list_like_columns(df2)))\n    other_cols = [col for col in comp_c if col not in numeric_cols and col not in ll_cols]\n\n    # For numeric columns, use np.isclose\n    if numeric_cols:\n        numeric_a = comp_df[[f\"{col}_a\" for col in numeric_cols]]\n        numeric_b = comp_df[[f\"{col}_b\" for col in numeric_cols]]\n        is_close = np.isclose(numeric_a, numeric_b, atol=atol, equal_nan=True)\n        comp_df[numeric_cols] = ~is_close\n\n    if ll_cols:\n        for ll_c in ll_cols:\n            comp_df[ll_c] = diff_list_like_series(comp_df[ll_c + \"_a\"], comp_df[ll_c + \"_b\"])\n\n    # For non-numeric columns, use direct comparison\n    if other_cols:\n        for col in other_cols:\n            comp_df[col] = (comp_df[f\"{col}_a\"] != comp_df[f\"{col}_b\"]) &amp; ~(\n                comp_df[f\"{col}_a\"].isna() &amp; comp_df[f\"{col}_b\"].isna()\n            )\n\n    # Filter columns and rows where no differences\n    cols_w_diffs = [col for col in comp_c if comp_df[col].any()]\n    out_cols = [col for subcol in cols_w_diffs for col in (f\"{subcol}_a\", f\"{subcol}_b\", subcol)]\n    comp_df = comp_df[out_cols]\n    comp_df = comp_df.loc[comp_df[cols_w_diffs].any(axis=1)]\n\n    return comp_df\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.compare_lists","title":"<code>compare_lists(list1, list2)</code>","text":"<p>Compare two lists.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def compare_lists(list1, list2) -&gt; bool:\n    \"\"\"Compare two lists.\"\"\"\n    list1 = convert_numpy_to_list(list1)\n    list2 = convert_numpy_to_list(list1)\n    return list1 != list2\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.concat_with_attr","title":"<code>concat_with_attr(dfs, **kwargs)</code>","text":"<p>Concatenate a list of dataframes and retain the attributes of the first dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def concat_with_attr(dfs: list[pd.DataFrame], **kwargs) -&gt; pd.DataFrame:\n    \"\"\"Concatenate a list of dataframes and retain the attributes of the first dataframe.\"\"\"\n    import copy\n\n    if not dfs:\n        msg = \"No dataframes to concatenate.\"\n        raise ValueError(msg)\n    attrs = copy.deepcopy(dfs[0].attrs)\n    df = pd.concat(dfs, **kwargs)\n    df.attrs = attrs\n    return df\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.convert_numpy_to_list","title":"<code>convert_numpy_to_list(item)</code>","text":"<p>Function to recursively convert numpy arrays to lists.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def convert_numpy_to_list(item):\n    \"\"\"Function to recursively convert numpy arrays to lists.\"\"\"\n    if isinstance(item, np.ndarray):\n        return item.tolist()\n    if isinstance(item, list):\n        return [convert_numpy_to_list(sub_item) for sub_item in item]\n    if isinstance(item, dict):\n        return {key: convert_numpy_to_list(value) for key, value in item.items()}\n    return item\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.dict_fields_in_df","title":"<code>dict_fields_in_df(d, df)</code>","text":"<p>Check if all fields in dict are in dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def dict_fields_in_df(d: dict, df: pd.DataFrame) -&gt; bool:\n    \"\"\"Check if all fields in dict are in dataframe.\"\"\"\n    missing_fields = [f for f in d if f not in df.columns]\n    if missing_fields:\n        msg = f\"Fields in dictionary missing from dataframe: {missing_fields}.\"\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.dict_to_query","title":"<code>dict_to_query(selection_dict)</code>","text":"<p>Generates the query of from selection_dict.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>Mapping[str, Any]</code> <p>selection dictionary</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <code>str</code> <p>Query value</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def dict_to_query(\n    selection_dict: Mapping[str, Any],\n) -&gt; str:\n    \"\"\"Generates the query of from selection_dict.\n\n    Args:\n        selection_dict: selection dictionary\n\n    Returns:\n        _type_: Query value\n    \"\"\"\n    WranglerLogger.debug(\"Building selection query\")\n\n    def _kv_to_query_part(k, v, _q_part=\"\"):\n        if isinstance(v, list):\n            _q_part += \"(\" + \" or \".join([_kv_to_query_part(k, i) for i in v]) + \")\"\n            return _q_part\n        if isinstance(v, str):\n            return k + '.str.contains(\"' + v + '\")'\n        return k + \"==\" + str(v)\n\n    query = \"(\" + \" and \".join([_kv_to_query_part(k, v) for k, v in selection_dict.items()]) + \")\"\n    WranglerLogger.debug(f\"Selection query: \\n{query}\")\n    return query\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.diff_dfs","title":"<code>diff_dfs(df1, df2, ignore=None)</code>","text":"<p>Returns True if two dataframes are different and log differences.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def diff_dfs(df1, df2, ignore: Optional[list[str]] = None) -&gt; bool:\n    \"\"\"Returns True if two dataframes are different and log differences.\"\"\"\n    if ignore is None:\n        ignore = []\n    diff = False\n    if set(df1.columns) != set(df2.columns):\n        WranglerLogger.warning(\n            f\" Columns are different 1vs2 \\n    {set(df1.columns) ^ set(df2.columns)}\"\n        )\n        common_cols = [col for col in df1.columns if col in df2.columns]\n        df1 = df1[common_cols]\n        df2 = df2[common_cols]\n        diff = True\n\n    cols_to_compare = [col for col in df1.columns if col not in ignore]\n    df1 = df1[cols_to_compare]\n    df2 = df2[cols_to_compare]\n\n    if len(df1) != len(df2):\n        WranglerLogger.warning(\n            f\" Length is different /\" f\"DF1: {len(df1)} vs /\" f\"DF2: {len(df2)}\\n /\"\n        )\n        diff = True\n\n    diff_df = compare_df_values(df1, df2)\n\n    if not diff_df.empty:\n        WranglerLogger.error(f\"!!! Differences dfs: \\n{diff_df}\")\n        return True\n\n    if not diff:\n        WranglerLogger.info(\"...no differences in df found.\")\n    return diff\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.diff_list_like_series","title":"<code>diff_list_like_series(s1, s2)</code>","text":"<p>Compare two series that contain list-like items as strings.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def diff_list_like_series(s1, s2) -&gt; bool:\n    \"\"\"Compare two series that contain list-like items as strings.\"\"\"\n    diff_df = concat_with_attr([s1, s2], axis=1, keys=[\"s1\", \"s2\"])\n    # diff_df[\"diff\"] = diff_df.apply(lambda x: str(x[\"s1\"]) != str(x[\"s2\"]), axis=1)\n    diff_df[\"diff\"] = diff_df.apply(lambda x: compare_lists(x[\"s1\"], x[\"s2\"]), axis=1)\n    if diff_df[\"diff\"].any():\n        WranglerLogger.info(\"List-Like differences:\")\n        WranglerLogger.info(diff_df)\n        return True\n    return False\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.fk_in_pk","title":"<code>fk_in_pk(pk, fk, ignore_nan=True)</code>","text":"<p>Check if all foreign keys are in the primary keys, optionally ignoring NaN.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def fk_in_pk(\n    pk: Union[pd.Series, list], fk: Union[pd.Series, list], ignore_nan: bool = True\n) -&gt; tuple[bool, list]:\n    \"\"\"Check if all foreign keys are in the primary keys, optionally ignoring NaN.\"\"\"\n    if isinstance(fk, list):\n        fk = pd.Series(fk)\n\n    if ignore_nan:\n        fk = fk.dropna()\n\n    missing_flag = ~fk.isin(pk)\n\n    if missing_flag.any():\n        WranglerLogger.warning(\n            f\"Following keys referenced in {fk.name} but missing in\\\n            primary key table: \\n{fk[missing_flag]} \"\n        )\n        return False, fk[missing_flag].tolist()\n\n    return True, []\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.isin_dict","title":"<code>isin_dict(df, d, ignore_missing=True, strict_str=False)</code>","text":"<p>Filter the dataframe using a dictionary - faster than using isin.</p> <p>Uses merge to filter the dataframe by the dictionary keys and values.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataframe to filter</p> required <code>d</code> <code>dict</code> <p>dictionary with keys as column names and values as values to filter by</p> required <code>ignore_missing</code> <code>bool</code> <p>if True, will ignore missing values in the selection dict.</p> <code>True</code> <code>strict_str</code> <code>bool</code> <p>if True, will not allow partial string matches and will force case-matching. Defaults to False. If False, will be overridden if key is in STRICT_MATCH_FIELDS or if ignore_missing is False.</p> <code>False</code> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def isin_dict(\n    df: pd.DataFrame, d: dict, ignore_missing: bool = True, strict_str: bool = False\n) -&gt; pd.DataFrame:\n    \"\"\"Filter the dataframe using a dictionary - faster than using isin.\n\n    Uses merge to filter the dataframe by the dictionary keys and values.\n\n    Args:\n        df: dataframe to filter\n        d: dictionary with keys as column names and values as values to filter by\n        ignore_missing: if True, will ignore missing values in the selection dict.\n        strict_str: if True, will not allow partial string matches and will force case-matching.\n            Defaults to False. If False, will be overridden if key is in STRICT_MATCH_FIELDS or if\n            ignore_missing is False.\n    \"\"\"\n    sel_links_mask = np.zeros(len(df), dtype=bool)\n    missing = {}\n    for col, vals in d.items():\n        if vals is None:\n            continue\n        if col not in df.columns:\n            msg = f\"Key {col} not in dataframe columns.\"\n            raise DataframeSelectionError(msg)\n        _strict_str = strict_str or col in STRICT_MATCH_FIELDS or not ignore_missing\n        vals_list = [vals] if not isinstance(vals, list) else vals\n\n        index_name = df.index.name if df.index.name is not None else \"index\"\n        _df = df[[col]].reset_index(names=index_name)\n\n        if isinstance(vals_list[0], str) and not _strict_str:\n            vals_list = [val.lower() for val in vals_list]\n            _df[col] = _df[col].str.lower()\n\n            # Use str.contains for partial matching\n            mask = np.zeros(len(_df), dtype=bool)\n            for val in vals_list:\n                mask |= _df[col].str.contains(val, case=False, na=False)\n            selected = _df[mask].set_index(index_name)\n        else:\n            vals_df = pd.DataFrame({col: vals_list}, index=range(len(vals_list)))\n            merged_df = _df.merge(vals_df, on=col, how=\"outer\", indicator=True)\n            selected = merged_df[merged_df[\"_merge\"] == \"both\"].set_index(index_name)\n            _missing_vals = merged_df[merged_df[\"_merge\"] == \"right_only\"][col].tolist()\n            if _missing_vals:\n                missing[col] = _missing_vals\n                WranglerLogger.warning(f\"Missing values in selection dict for {col}: {missing}\")\n\n        sel_links_mask |= df.index.isin(selected.index)\n\n    if not ignore_missing and any(missing):\n        msg = \"Missing values in selection dict.\"\n        raise DataframeSelectionError(msg)\n\n    return df.loc[sel_links_mask]\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.list_like_columns","title":"<code>list_like_columns(df, item_type=None)</code>","text":"<p>Find columns in a dataframe that contain list-like items that can\u2019t be json-serialized.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>dataframe to check</p> required <code>item_type</code> <code>Optional[type]</code> <p>if not None, will only return columns where all items are of this type by checking only the first item in the column.  Defaults to None.</p> <code>None</code> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def list_like_columns(df, item_type: Optional[type] = None) -&gt; list[str]:\n    \"\"\"Find columns in a dataframe that contain list-like items that can't be json-serialized.\n\n    Args:\n        df: dataframe to check\n        item_type: if not None, will only return columns where all items are of this type by\n            checking **only** the first item in the column.  Defaults to None.\n    \"\"\"\n    list_like_columns = []\n\n    for column in df.columns:\n        if df[column].apply(lambda x: isinstance(x, (list, ndarray))).any():\n            if item_type is not None and not isinstance(df[column].iloc[0], item_type):\n                continue\n            list_like_columns.append(column)\n    return list_like_columns\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.segment_data_by_selection","title":"<code>segment_data_by_selection(item_list, data, field=None, end_val=0)</code>","text":"<p>Segment a dataframe or series into before, middle, and end segments based on item_list.</p> <p>selected segment = everything from the first to last item in item_list inclusive of the first     and last items. Before segment = everything before After segment = everything after</p> <p>Parameters:</p> Name Type Description Default <code>item_list</code> <code>list</code> <p>List of items to segment data by. If longer than two, will only use the first and last items.</p> required <code>data</code> <code>Union[Series, DataFrame]</code> <p>Data to segment into before, middle, and after.</p> required <code>field</code> <code>str</code> <p>If a dataframe, specifies which field to reference. Defaults to None.</p> <code>None</code> <code>end_val</code> <code>int</code> <p>Notation for util the end or from the begining. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>DataSegmentationError</code> <p>If item list isn\u2019t found in data in correct order.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[Union[Series, list, DataFrame], Union[Series, list, DataFrame], Union[Series, list, DataFrame]]</code> <p>data broken out by beofore, selected segment, and after.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def segment_data_by_selection(\n    item_list: list,\n    data: Union[list, pd.DataFrame, pd.Series],\n    field: Optional[str] = None,\n    end_val=0,\n) -&gt; tuple[\n    Union[pd.Series, list, pd.DataFrame],\n    Union[pd.Series, list, pd.DataFrame],\n    Union[pd.Series, list, pd.DataFrame],\n]:\n    \"\"\"Segment a dataframe or series into before, middle, and end segments based on item_list.\n\n    selected segment = everything from the first to last item in item_list inclusive of the first\n        and last items.\n    Before segment = everything before\n    After segment = everything after\n\n    Args:\n        item_list (list): List of items to segment data by. If longer than two, will only\n            use the first and last items.\n        data (Union[pd.Series, pd.DataFrame]): Data to segment into before, middle, and after.\n        field (str, optional): If a dataframe, specifies which field to reference.\n            Defaults to None.\n        end_val (int, optional): Notation for util the end or from the begining. Defaults to 0.\n\n    Raises:\n        DataSegmentationError: If item list isn't found in data in correct order.\n\n    Returns:\n        tuple: data broken out by beofore, selected segment, and after.\n    \"\"\"\n    ref_data = data\n    if isinstance(data, pd.DataFrame):\n        ref_data = data[field].tolist()\n    elif isinstance(data, pd.Series):\n        ref_data = data.tolist()\n\n    # ------- Replace \"to the end\" indicators with first or last value --------\n    start_item, end_item = item_list[0], item_list[-1]\n    if start_item == end_val:\n        start_item = ref_data[0]\n    if end_item == end_val:\n        end_item = ref_data[-1]\n\n    # --------Find the start and end indices -----------------------------------\n    start_idxs = list({i for i, item in enumerate(ref_data) if item == start_item})\n    if not start_idxs:\n        msg = f\"Segment start item: {start_item} not in data.\"\n        raise DataSegmentationError(msg)\n    if len(start_idxs) &gt; 1:\n        WranglerLogger.warning(\n            f\"Found multiple starting locations for data segment: {start_item}.\\\n                                Choosing first ... largest segment being selected.\"\n        )\n    start_idx = min(start_idxs)\n\n    # find the end node starting from the start index.\n    end_idxs = [i + start_idx for i, item in enumerate(ref_data[start_idx:]) if item == end_item]\n    # WranglerLogger.debug(f\"End indexes: {end_idxs}\")\n    if not end_idxs:\n        msg = f\"Segment end item: {end_item} not in data after starting idx.\"\n        raise DataSegmentationError(msg)\n    if len(end_idxs) &gt; 1:\n        WranglerLogger.warning(\n            f\"Found multiple ending locations for data segment: {end_item}.\\\n                                Choosing last ... largest segment being selected.\"\n        )\n    end_idx = max(end_idxs) + 1\n    # WranglerLogger.debug(\n    # f\"Segmenting data fr {start_item} idx:{start_idx} to {end_item} idx:{end_idx}.\\n{ref_data}\")\n    # -------- Extract the segments --------------------------------------------\n    if isinstance(data, pd.DataFrame):\n        before_segment = data.iloc[:start_idx]\n        selected_segment = data.iloc[start_idx:end_idx]\n        after_segment = data.iloc[end_idx:]\n    else:\n        before_segment = data[:start_idx]\n        selected_segment = data[start_idx:end_idx]\n        after_segment = data[end_idx:]\n\n    if isinstance(data, (pd.DataFrame, pd.Series)):\n        before_segment = before_segment.reset_index(drop=True)\n        selected_segment = selected_segment.reset_index(drop=True)\n        after_segment = after_segment.reset_index(drop=True)\n\n    # WranglerLogger.debug(f\"Segmented data into before, selected, and after.\\n \\\n    #    Before:\\n{before_segment}\\nSelected:\\n{selected_segment}\\nAfter:\\n{after_segment}\")\n\n    return before_segment, selected_segment, after_segment\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.segment_data_by_selection_min_overlap","title":"<code>segment_data_by_selection_min_overlap(selection_list, data, field, replacements_list, end_val=0)</code>","text":"<p>Segments data based on item_list reducing overlap with replacement list.</p> <p>selected segment: everything from the first to last item in item_list inclusive of the first     and last items but not if first and last items overlap with replacement list. Before segment = everything before After segment = everything after</p> <p>Example: selection_list = [2,5] data = pd.DataFrame({\u201ci\u201d:[1,2,3,4,5,6]}) field = \u201ci\u201d replacements_list = [2,22,33]</p> <p>Returns:</p> Type Description <code>list</code> <p>[22,33]</p> <code>tuple[Union[Series, DataFrame], Union[Series, DataFrame], Union[Series, DataFrame]]</code> <p>[1], [2,3,4,5], [6]</p> <p>Parameters:</p> Name Type Description Default <code>selection_list</code> <code>list</code> <p>List of items to segment data by. If longer than two, will only use the first and last items.</p> required <code>data</code> <code>Union[Series, DataFrame]</code> <p>Data to segment into before, middle, and after.</p> required <code>field</code> <code>str</code> <p>Specifies which field to reference.</p> required <code>replacements_list</code> <code>list</code> <p>List of items to eventually replace the selected segment with.</p> required <code>end_val</code> <code>int</code> <p>Notation for util the end or from the begining. Defaults to 0.</p> <code>0</code> <p>tuple containing:</p> Type Description <code>list</code> <ul> <li>updated replacement_list</li> </ul> <code>tuple[Union[Series, DataFrame], Union[Series, DataFrame], Union[Series, DataFrame]]</code> <ul> <li>tuple of before, selected segment, and after data</li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def segment_data_by_selection_min_overlap(\n    selection_list: list,\n    data: pd.DataFrame,\n    field: str,\n    replacements_list: list,\n    end_val=0,\n) -&gt; tuple[\n    list,\n    tuple[\n        Union[pd.Series, pd.DataFrame],\n        Union[pd.Series, pd.DataFrame],\n        Union[pd.Series, pd.DataFrame],\n    ],\n]:\n    \"\"\"Segments data based on item_list reducing overlap with replacement list.\n\n    *selected segment*: everything from the first to last item in item_list inclusive of the first\n        and last items but not if first and last items overlap with replacement list.\n    Before segment = everything before\n    After segment = everything after\n\n    Example:\n    selection_list = [2,5]\n    data = pd.DataFrame({\"i\":[1,2,3,4,5,6]})\n    field = \"i\"\n    replacements_list = [2,22,33]\n\n    returns:\n        [22,33]\n        [1], [2,3,4,5], [6]\n\n    Args:\n        selection_list (list): List of items to segment data by. If longer than two, will only\n            use the first and last items.\n        data (Union[pd.Series, pd.DataFrame]): Data to segment into before, middle, and after.\n        field (str): Specifies which field to reference.\n        replacements_list (list): List of items to eventually replace the selected segment with.\n        end_val (int, optional): Notation for util the end or from the begining. Defaults to 0.\n\n    Returns: tuple containing:\n        - updated replacement_list\n        - tuple of before, selected segment, and after data\n    \"\"\"\n    before_segment, segment_df, after_segment = segment_data_by_selection(\n        selection_list, data, field=field, end_val=end_val\n    )\n    if not isinstance(segment_df, pd.DataFrame):\n        msg = \"segment_df should be a DataFrame - something is wrong.\"\n        raise ValueError(msg)\n\n    if replacements_list and replacements_list[0] == segment_df[field].iat[0]:\n        # move first item from selected segment to the before_segment df\n        replacements_list = replacements_list[1:]\n        before_segment = concat_with_attr(\n            [before_segment, segment_df.iloc[:1]], ignore_index=True, sort=False\n        )\n        segment_df = segment_df.iloc[1:]\n        # WranglerLogger.debug(f\"item start overlaps with replacement. Repl: {replacements_list}\")\n    if replacements_list and replacements_list[-1] == data[field].iat[-1]:\n        # move last item from selected segment to the after_segment df\n        replacements_list = replacements_list[:-1]\n        after_segment = concat_with_attr(\n            [data.iloc[-1:], after_segment], ignore_index=True, sort=False\n        )\n        segment_df = segment_df.iloc[:-1]\n        # WranglerLogger.debug(f\"item end overlaps with replacement. Repl: {replacements_list}\")\n\n    return replacements_list, (before_segment, segment_df, after_segment)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.update_df_by_col_value","title":"<code>update_df_by_col_value(destination_df, source_df, join_col, properties=None, fail_if_missing=True)</code>","text":"<p>Updates destination_df with ALL values in source_df for specified props with same join_col.</p> <p>Source_df can contain a subset of IDs of destination_df. If fail_if_missing is true, destination_df must have all the IDS in source DF - ensuring all source_df values are contained in resulting df.</p> <pre><code>&gt;&gt; destination_df\ntrip_id  property1  property2\n1         10      100\n2         20      200\n3         30      300\n4         40      400\n\n&gt;&gt; source_df\ntrip_id  property1  property2\n2         25      250\n3         35      350\n\n&gt;&gt; updated_df\ntrip_id  property1  property2\n0        1       10      100\n1        2       25      250\n2        3       35      350\n3        4       40      400\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>destination_df</code> <code>DataFrame</code> <p>Dataframe to modify.</p> required <code>source_df</code> <code>DataFrame</code> <p>Dataframe with updated columns</p> required <code>join_col</code> <code>str</code> <p>column to join on</p> required <code>properties</code> <code>list[str]</code> <p>List of properties to use. If None, will default to all in source_df.</p> <code>None</code> <code>fail_if_missing</code> <code>bool</code> <p>If True, will raise an error if there are missing IDs in destination_df that exist in source_df.</p> <code>True</code> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def update_df_by_col_value(\n    destination_df: pd.DataFrame,\n    source_df: pd.DataFrame,\n    join_col: str,\n    properties: Optional[list[str]] = None,\n    fail_if_missing: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Updates destination_df with ALL values in source_df for specified props with same join_col.\n\n    Source_df can contain a subset of IDs of destination_df.\n    If fail_if_missing is true, destination_df must have all\n    the IDS in source DF - ensuring all source_df values are contained in resulting df.\n\n    ```\n    &gt;&gt; destination_df\n    trip_id  property1  property2\n    1         10      100\n    2         20      200\n    3         30      300\n    4         40      400\n\n    &gt;&gt; source_df\n    trip_id  property1  property2\n    2         25      250\n    3         35      350\n\n    &gt;&gt; updated_df\n    trip_id  property1  property2\n    0        1       10      100\n    1        2       25      250\n    2        3       35      350\n    3        4       40      400\n    ```\n\n    Args:\n        destination_df (pd.DataFrame): Dataframe to modify.\n        source_df (pd.DataFrame): Dataframe with updated columns\n        join_col (str): column to join on\n        properties (list[str]): List of properties to use. If None, will default to all\n            in source_df.\n        fail_if_missing (bool): If True, will raise an error if there are missing IDs in\n            destination_df that exist in source_df.\n    \"\"\"\n    # 1. Identify which properties should be updated; and if they exist in both DFs.\n    if properties is None:\n        properties = [\n            c for c in source_df.columns if c in destination_df.columns and c != join_col\n        ]\n    else:\n        _dest_miss = _df_missing_cols(destination_df, [*properties, join_col])\n        if _dest_miss:\n            msg = f\"Properties missing from destination_df: {_dest_miss}\"\n            raise MissingPropertiesError(msg)\n        _source_miss = _df_missing_cols(source_df, [*properties, join_col])\n        if _source_miss:\n            msg = f\"Properties missing from source_df: {_source_miss}\"\n            raise MissingPropertiesError(msg)\n\n    # 2. Identify if there are IDs missing from destination_df that exist in source_df\n    if fail_if_missing:\n        missing_ids = set(source_df[join_col]) - set(destination_df[join_col])\n        if missing_ids:\n            msg = f\"IDs missing from source_df: \\n{missing_ids}\"\n            raise InvalidJoinFieldError(msg)\n\n    WranglerLogger.debug(f\"Updating properties for {len(source_df)} records: {properties}.\")\n\n    if not source_df[join_col].is_unique:\n        msg = f\"Can't join from source_df when join_col: {join_col} is not unique.\"\n        raise InvalidJoinFieldError(msg)\n\n    if not destination_df[join_col].is_unique:\n        return _update_props_from_one_to_many(destination_df, source_df, join_col, properties)\n\n    return _update_props_for_common_idx(destination_df, source_df, join_col, properties)\n</code></pre>"},{"location":"api/#network_wrangler.utils.data.validate_existing_value_in_df","title":"<code>validate_existing_value_in_df(df, idx, field, expected_value)</code>","text":"<p>Validate if df[field]==expected_value for all indices in idx.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def validate_existing_value_in_df(df: pd.DataFrame, idx: list[int], field: str, expected_value):\n    \"\"\"Validate if df[field]==expected_value for all indices in idx.\"\"\"\n    if field not in df.columns:\n        WranglerLogger.warning(f\"!! {field} Not an existing field.\")\n        return False\n    if not df.loc[idx, field].eq(expected_value).all():\n        WranglerLogger.warning(\n            f\"Existing value defined for {field} in project card \\\n            does not match the value in the selection links. \\n\\\n            Specified Existing: {expected_value}\\n\\\n            Actual Existing: \\n {df.loc[idx, field]}.\"\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.InvalidCRSError","title":"<code>InvalidCRSError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a point is not valid for a given coordinate reference system.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>class InvalidCRSError(Exception):\n    \"\"\"Raised when a point is not valid for a given coordinate reference system.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.check_point_valid_for_crs","title":"<code>check_point_valid_for_crs(point, crs)</code>","text":"<p>Check if a point is valid for a given coordinate reference system.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>Point</code> <p>Shapely Point</p> required <code>crs</code> <code>int</code> <p>coordinate reference system in ESPG code</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def check_point_valid_for_crs(point: Point, crs: int):\n    \"\"\"Check if a point is valid for a given coordinate reference system.\n\n    Args:\n        point: Shapely Point\n        crs: coordinate reference system in ESPG code\n\n    raises: InvalidCRSError if point is not valid for the given crs\n    \"\"\"\n    crs = CRS.from_user_input(crs)\n    minx, miny, maxx, maxy = crs.area_of_use.bounds\n    ok_bounds = True\n    if not minx &lt;= point.x &lt;= maxx:\n        WranglerLogger.error(f\"Invalid X coordinate for CRS {crs}: {point.x}\")\n        ok_bounds = False\n    if not miny &lt;= point.y &lt;= maxy:\n        WranglerLogger.error(f\"Invalid Y coordinate for CRS {crs}: {point.y}\")\n        ok_bounds = False\n\n    if not ok_bounds:\n        msg = f\"Invalid coordinate for CRS {crs}: {point.x}, {point.y}\"\n        raise InvalidCRSError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.get_bearing","title":"<code>get_bearing(lat1, lon1, lat2, lon2)</code>","text":"<p>Calculate the bearing (forward azimuth) b/w the two points.</p> <p>returns: bearing in radians</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_bearing(lat1, lon1, lat2, lon2):\n    \"\"\"Calculate the bearing (forward azimuth) b/w the two points.\n\n    returns: bearing in radians\n    \"\"\"\n    # bearing in degrees\n    brng = Geodesic.WGS84.Inverse(lat1, lon1, lat2, lon2)[\"azi1\"]\n\n    # convert bearing to radians\n    brng = math.radians(brng)\n\n    return brng\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.get_bounding_polygon","title":"<code>get_bounding_polygon(boundary_geocode=None, boundary_file=None, boundary_gdf=None, crs=LAT_LON_CRS)</code>","text":"<p>Get the bounding polygon for a given boundary.</p> <p>Will return None if no arguments given. Will raise a ValueError if more than one given.</p> <p>This function retrieves the bounding polygon for a given boundary. The boundary can be provided as a GeoDataFrame, a geocode string or dictionary, or a boundary file. The resulting polygon geometry is returned as a GeoSeries.</p> <p>Parameters:</p> Name Type Description Default <code>boundary_geocode</code> <code>Union[str, dict]</code> <p>A geocode string or dictionary representing the boundary. Defaults to None.</p> <code>None</code> <code>boundary_file</code> <code>Union[str, Path]</code> <p>A path to the boundary file. Only used if boundary_geocode is None. Defaults to None.</p> <code>None</code> <code>boundary_gdf</code> <code>GeoDataFrame</code> <p>A GeoDataFrame representing the boundary. Only used if boundary_geocode and boundary_file are None. Defaults to None.</p> <code>None</code> <code>crs</code> <code>int</code> <p>The coordinate reference system (CRS) code. Defaults to 4326 (WGS84).</p> <code>LAT_LON_CRS</code> <p>Returns:</p> Type Description <code>GeoSeries</code> <p>gpd.GeoSeries: The polygon geometry representing the bounding polygon.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_bounding_polygon(\n    boundary_geocode: Optional[Union[str, dict]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    crs: int = LAT_LON_CRS,  # WGS84\n) -&gt; gpd.GeoSeries:\n    \"\"\"Get the bounding polygon for a given boundary.\n\n    Will return None if no arguments given. Will raise a ValueError if more than one given.\n\n    This function retrieves the bounding polygon for a given boundary. The boundary can be provided\n    as a GeoDataFrame, a geocode string or dictionary, or a boundary file. The resulting polygon\n    geometry is returned as a GeoSeries.\n\n    Args:\n        boundary_geocode (Union[str, dict], optional): A geocode string or dictionary\n            representing the boundary. Defaults to None.\n        boundary_file (Union[str, Path], optional): A path to the boundary file. Only used if\n            boundary_geocode is None. Defaults to None.\n        boundary_gdf (gpd.GeoDataFrame, optional): A GeoDataFrame representing the boundary.\n            Only used if boundary_geocode and boundary_file are None. Defaults to None.\n        crs (int, optional): The coordinate reference system (CRS) code. Defaults to 4326 (WGS84).\n\n    Returns:\n        gpd.GeoSeries: The polygon geometry representing the bounding polygon.\n    \"\"\"\n    import osmnx as ox\n\n    nargs = sum(x is not None for x in [boundary_gdf, boundary_geocode, boundary_file])\n    if nargs == 0:\n        return None\n    if nargs != 1:\n        msg = \"Exactly one of boundary_gdf, boundary_geocode, or boundary_file must be provided.\"\n        raise ValueError(msg)\n\n    OK_BOUNDARY_SUFF = [\".shp\", \".geojson\", \".parquet\"]\n\n    if boundary_geocode is not None:\n        boundary_gdf = ox.geocode_to_gdf(boundary_geocode)\n    elif boundary_file is not None:\n        boundary_file = Path(boundary_file)\n        if boundary_file.suffix not in OK_BOUNDARY_SUFF:\n            msg = \"Boundary file must have one of the following suffixes: {OK_BOUNDARY_SUFF}\"\n            raise ValueError(msg)\n        if not boundary_file.exists():\n            msg = f\"Boundary file {boundary_file} does not exist\"\n            raise FileNotFoundError(msg)\n        if boundary_file.suffix == \".parquet\":\n            boundary_gdf = gpd.read_parquet(boundary_file)\n        else:\n            boundary_gdf = gpd.read_file(boundary_file)\n            if boundary_file.suffix == \".geojson\":  # geojson standard is WGS84\n                boundary_gdf.crs = crs\n\n    if boundary_gdf is None:\n        msg = \"One of boundary_gdf, boundary_geocode or boundary_file must be provided.\"\n        raise ValueError(msg)\n\n    if boundary_gdf.crs is not None:\n        boundary_gdf = boundary_gdf.to_crs(crs)\n    # make sure boundary_gdf is a polygon\n    if len(boundary_gdf.geom_type[boundary_gdf.geom_type != \"Polygon\"]) &gt; 0:\n        msg = \"boundary_gdf must all be Polygons\"\n        raise ValueError(msg)\n    # get the boundary as a single polygon\n    boundary_gs = gpd.GeoSeries([boundary_gdf.geometry.union_all()], crs=crs)\n\n    return boundary_gs\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.get_point_geometry_from_linestring","title":"<code>get_point_geometry_from_linestring(polyline_geometry, pos=0)</code>","text":"<p>Get a point geometry from a linestring geometry.</p> <p>Parameters:</p> Name Type Description Default <code>polyline_geometry</code> <p>shapely LineString instance</p> required <code>pos</code> <code>int</code> <p>position in the linestring to get the point from. Defaults to 0.</p> <code>0</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_point_geometry_from_linestring(polyline_geometry, pos: int = 0):\n    \"\"\"Get a point geometry from a linestring geometry.\n\n    Args:\n        polyline_geometry: shapely LineString instance\n        pos: position in the linestring to get the point from. Defaults to 0.\n    \"\"\"\n    # WranglerLogger.debug(\n    #    f\"get_point_geometry_from_linestring.polyline_geometry.coords[0]: \\\n    #    {polyline_geometry.coords[0]}.\"\n    # )\n\n    # Note: when upgrading to shapely 2.0, will need to use following command\n    # _point_coords = get_coordinates(polyline_geometry).tolist()[pos]\n    return point_from_xy(*polyline_geometry.coords[pos])\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.length_of_linestring_miles","title":"<code>length_of_linestring_miles(gdf)</code>","text":"<p>Returns a Series with the linestring length in miles.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>Union[GeoSeries, GeoDataFrame]</code> <p>GeoDataFrame with linestring geometry.  If given a GeoSeries will attempt to convert to a GeoDataFrame.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def length_of_linestring_miles(gdf: Union[gpd.GeoSeries, gpd.GeoDataFrame]) -&gt; pd.Series:\n    \"\"\"Returns a Series with the linestring length in miles.\n\n    Args:\n        gdf: GeoDataFrame with linestring geometry.  If given a GeoSeries will attempt to convert\n            to a GeoDataFrame.\n    \"\"\"\n    # WranglerLogger.debug(f\"length_of_linestring_miles.gdf input:\\n{gdf}.\")\n    if isinstance(gdf, gpd.GeoSeries):\n        gdf = gpd.GeoDataFrame(geometry=gdf)\n\n    p_crs = gdf.estimate_utm_crs()\n    gdf = gdf.to_crs(p_crs)\n    METERS_IN_MILES = 1609.34\n    length_miles = gdf.geometry.length / METERS_IN_MILES\n    length_s = pd.Series(length_miles, index=gdf.index)\n\n    return length_s\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.linestring_from_lats_lons","title":"<code>linestring_from_lats_lons(df, lat_fields, lon_fields)</code>","text":"<p>Create a LineString geometry from a DataFrame with lon/lat fields.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>DataFrame with columns for lon/lat fields.</p> required <code>lat_fields</code> <p>list of column names for the lat fields.</p> required <code>lon_fields</code> <p>list of column names for the lon fields.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def linestring_from_lats_lons(df, lat_fields, lon_fields) -&gt; gpd.GeoSeries:\n    \"\"\"Create a LineString geometry from a DataFrame with lon/lat fields.\n\n    Args:\n        df: DataFrame with columns for lon/lat fields.\n        lat_fields: list of column names for the lat fields.\n        lon_fields: list of column names for the lon fields.\n    \"\"\"\n    if len(lon_fields) != len(lat_fields):\n        msg = \"lon_fields and lat_fields lists must have the same length\"\n        raise ValueError(msg)\n\n    line_geometries = gpd.GeoSeries(\n        [\n            LineString([(row[lon], row[lat]) for lon, lat in zip(lon_fields, lat_fields)])\n            for _, row in df.iterrows()\n        ]\n    )\n\n    return gpd.GeoSeries(line_geometries)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.linestring_from_nodes","title":"<code>linestring_from_nodes(links_df, nodes_df, from_node='A', to_node='B', node_pk='model_node_id')</code>","text":"<p>Creates a LineString geometry GeoSeries from a DataFrame of links and a DataFrame of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>links_df</code> <code>DataFrame</code> <p>DataFrame with columns for from_node and to_node.</p> required <code>nodes_df</code> <code>GeoDataFrame</code> <p>GeoDataFrame with geometry column.</p> required <code>from_node</code> <code>str</code> <p>column name in links_df for the from node. Defaults to \u201cA\u201d.</p> <code>'A'</code> <code>to_node</code> <code>str</code> <p>column name in links_df for the to node. Defaults to \u201cB\u201d.</p> <code>'B'</code> <code>node_pk</code> <code>str</code> <p>primary key column name in nodes_df. Defaults to \u201cmodel_node_id\u201d.</p> <code>'model_node_id'</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def linestring_from_nodes(\n    links_df: pd.DataFrame,\n    nodes_df: gpd.GeoDataFrame,\n    from_node: str = \"A\",\n    to_node: str = \"B\",\n    node_pk: str = \"model_node_id\",\n) -&gt; gpd.GeoSeries:\n    \"\"\"Creates a LineString geometry GeoSeries from a DataFrame of links and a DataFrame of nodes.\n\n    Args:\n        links_df: DataFrame with columns for from_node and to_node.\n        nodes_df: GeoDataFrame with geometry column.\n        from_node: column name in links_df for the from node. Defaults to \"A\".\n        to_node: column name in links_df for the to node. Defaults to \"B\".\n        node_pk: primary key column name in nodes_df. Defaults to \"model_node_id\".\n    \"\"\"\n    assert \"geometry\" in nodes_df.columns, \"nodes_df must have a 'geometry' column\"\n\n    idx_name = \"index\" if links_df.index.name is None else links_df.index.name\n    # WranglerLogger.debug(f\"Index name: {idx_name}\")\n    required_link_cols = [from_node, to_node]\n\n    if not all(col in links_df.columns for col in required_link_cols):\n        WranglerLogger.error(\n            f\"links_df.columns missing required columns.\\n\\\n                            links_df.columns: {links_df.columns}\\n\\\n                            required_link_cols: {required_link_cols}\"\n        )\n        msg = \"links_df must have columns {required_link_cols} to create linestring from nodes\"\n        raise ValueError(msg)\n\n    links_geo_df = copy.deepcopy(links_df[required_link_cols])\n    # need to continuously reset the index to make sure the index is the same as the link index\n    links_geo_df = (\n        links_geo_df.reset_index()\n        .merge(\n            nodes_df[[node_pk, \"geometry\"]],\n            left_on=from_node,\n            right_on=node_pk,\n            how=\"left\",\n        )\n        .set_index(idx_name)\n    )\n\n    links_geo_df = links_geo_df.rename(columns={\"geometry\": \"geometry_A\"})\n\n    links_geo_df = (\n        links_geo_df.reset_index()\n        .merge(\n            nodes_df[[node_pk, \"geometry\"]],\n            left_on=to_node,\n            right_on=node_pk,\n            how=\"left\",\n        )\n        .set_index(idx_name)\n    )\n\n    links_geo_df = links_geo_df.rename(columns={\"geometry\": \"geometry_B\"})\n\n    # makes sure all nodes exist\n    _missing_geo_links_df = links_geo_df[\n        links_geo_df[\"geometry_A\"].isnull() | links_geo_df[\"geometry_B\"].isnull()\n    ]\n    if not _missing_geo_links_df.empty:\n        missing_nodes = _missing_geo_links_df[[from_node, to_node]].values\n        WranglerLogger.error(\n            f\"Cannot create link geometry from nodes because the nodes are\\\n                             missing from the network. Missing nodes: {missing_nodes}\"\n        )\n        msg = \"Cannot create link geometry from nodes because the nodes are missing from the network.\"\n        raise MissingNodesError(msg)\n\n    # create geometry from points\n    links_geo_df[\"geometry\"] = links_geo_df.apply(\n        lambda row: LineString([row[\"geometry_A\"], row[\"geometry_B\"]]), axis=1\n    )\n\n    # convert to GeoDataFrame\n    links_gdf = gpd.GeoDataFrame(links_geo_df[\"geometry\"], geometry=links_geo_df[\"geometry\"])\n    return links_gdf[\"geometry\"]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.location_ref_from_point","title":"<code>location_ref_from_point(geometry, sequence=1, bearing=None, distance_to_next_ref=None)</code>","text":"<p>Generates a shared street point location reference.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Point</code> <p>Point shapely geometry</p> required <code>sequence</code> <code>int</code> <p>Sequence if part of polyline. Defaults to None.</p> <code>1</code> <code>bearing</code> <code>float</code> <p>Direction of line if part of polyline. Defaults to None.</p> <code>None</code> <code>distance_to_next_ref</code> <code>float</code> <p>Distnce to next point if part of polyline. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LocationReference</code> <code>LocationReference</code> <p>As defined by sharedStreets.io schema</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def location_ref_from_point(\n    geometry: Point,\n    sequence: int = 1,\n    bearing: Optional[float] = None,\n    distance_to_next_ref: Optional[float] = None,\n) -&gt; LocationReference:\n    \"\"\"Generates a shared street point location reference.\n\n    Args:\n        geometry (Point): Point shapely geometry\n        sequence (int, optional): Sequence if part of polyline. Defaults to None.\n        bearing (float, optional): Direction of line if part of polyline. Defaults to None.\n        distance_to_next_ref (float, optional): Distnce to next point if part of polyline.\n            Defaults to None.\n\n    Returns:\n        LocationReference: As defined by sharedStreets.io schema\n    \"\"\"\n    lr = {\n        \"point\": LatLongCoordinates(geometry.coords[0]),\n    }\n\n    for arg in [\"sequence\", \"bearing\", \"distance_to_next_ref\"]:\n        if locals()[arg] is not None:\n            lr[arg] = locals()[arg]\n\n    return LocationReference(**lr)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.location_refs_from_linestring","title":"<code>location_refs_from_linestring(geometry)</code>","text":"<p>Generates a shared street location reference from linestring.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>LineString</code> <p>Shapely LineString instance</p> required <p>Returns:</p> Name Type Description <code>LocationReferences</code> <code>list[LocationReference]</code> <p>As defined by sharedStreets.io schema</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def location_refs_from_linestring(geometry: LineString) -&gt; list[LocationReference]:\n    \"\"\"Generates a shared street location reference from linestring.\n\n    Args:\n        geometry (LineString): Shapely LineString instance\n\n    Returns:\n        LocationReferences: As defined by sharedStreets.io schema\n    \"\"\"\n    return [\n        location_ref_from_point(\n            point,\n            sequence=i + 1,\n            distance_to_next_ref=point.distance(geometry.coords[i + 1]),\n            bearing=get_bearing(*point.coords[0], *geometry.coords[i + 1]),\n        )\n        for i, point in enumerate(geometry.coords[:-1])\n    ]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.offset_geometry_meters","title":"<code>offset_geometry_meters(geo_s, offset_distance_meters)</code>","text":"<p>Offset a GeoSeries of LineStrings by a given distance in meters.</p> <p>Parameters:</p> Name Type Description Default <code>geo_s</code> <code>GeoSeries</code> <p>GeoSeries of LineStrings to offset.</p> required <code>offset_distance_meters</code> <code>float</code> <p>distance in meters to offset the LineStrings.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def offset_geometry_meters(geo_s: gpd.GeoSeries, offset_distance_meters: float) -&gt; gpd.GeoSeries:\n    \"\"\"Offset a GeoSeries of LineStrings by a given distance in meters.\n\n    Args:\n        geo_s: GeoSeries of LineStrings to offset.\n        offset_distance_meters: distance in meters to offset the LineStrings.\n    \"\"\"\n    if geo_s.empty:\n        return geo_s\n    og_crs = geo_s.crs\n    meters_crs = _id_utm_crs(geo_s)\n    geo_s = geo_s.to_crs(meters_crs)\n    offset_geo = geo_s.apply(lambda x: x.offset_curve(offset_distance_meters))\n    offset_geo = gpd.GeoSeries(offset_geo)\n    return offset_geo.to_crs(og_crs)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.offset_point_with_distance_and_bearing","title":"<code>offset_point_with_distance_and_bearing(lon, lat, distance, bearing)</code>","text":"<p>Get the new lon-lat (in degrees) given current point (lon-lat), distance and bearing.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>float</code> <p>longitude of original point</p> required <code>lat</code> <code>float</code> <p>latitude of original point</p> required <code>distance</code> <code>float</code> <p>distance in meters to offset point by</p> required <code>bearing</code> <code>float</code> <p>direction to offset point to in radians</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def offset_point_with_distance_and_bearing(\n    lon: float, lat: float, distance: float, bearing: float\n) -&gt; list[float]:\n    \"\"\"Get the new lon-lat (in degrees) given current point (lon-lat), distance and bearing.\n\n    Args:\n        lon: longitude of original point\n        lat: latitude of original point\n        distance: distance in meters to offset point by\n        bearing: direction to offset point to in radians\n\n    returns: list of new offset lon-lat\n    \"\"\"\n    # Earth's radius in meters\n    radius = 6378137\n\n    # convert the lat long from degree to radians\n    lat_radians = math.radians(lat)\n    lon_radians = math.radians(lon)\n\n    # calculate the new lat long in radians\n    out_lat_radians = math.asin(\n        math.sin(lat_radians) * math.cos(distance / radius)\n        + math.cos(lat_radians) * math.sin(distance / radius) * math.cos(bearing)\n    )\n\n    out_lon_radians = lon_radians + math.atan2(\n        math.sin(bearing) * math.sin(distance / radius) * math.cos(lat_radians),\n        math.cos(distance / radius) - math.sin(lat_radians) * math.sin(lat_radians),\n    )\n    # convert the new lat long back to degree\n    out_lat = math.degrees(out_lat_radians)\n    out_lon = math.degrees(out_lon_radians)\n\n    return [out_lon, out_lat]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.point_from_xy","title":"<code>point_from_xy(x, y, xy_crs=LAT_LON_CRS, point_crs=LAT_LON_CRS)</code>","text":"<p>Creates point geometry from x and y coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>x coordinate, in xy_crs</p> required <code>y</code> <p>y coordinate, in xy_crs</p> required <code>xy_crs</code> <code>int</code> <p>coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)</p> <code>LAT_LON_CRS</code> <code>point_crs</code> <code>int</code> <p>coordinate reference system in ESPG code for point output. Defaults to 4326 (WGS84)</p> <code>LAT_LON_CRS</code> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def point_from_xy(x, y, xy_crs: int = LAT_LON_CRS, point_crs: int = LAT_LON_CRS):\n    \"\"\"Creates point geometry from x and y coordinates.\n\n    Args:\n        x: x coordinate, in xy_crs\n        y: y coordinate, in xy_crs\n        xy_crs: coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)\n        point_crs: coordinate reference system in ESPG code for point output.\n            Defaults to 4326 (WGS84)\n\n    Returns: Shapely Point in point_crs\n    \"\"\"\n    point = Point(x, y)\n\n    if xy_crs == point_crs:\n        check_point_valid_for_crs(point, point_crs)\n        return point\n\n    if (xy_crs, point_crs) not in transformers:\n        # store transformers in dictionary because they are an \"expensive\" operation\n        transformers[(xy_crs, point_crs)] = Transformer.from_proj(\n            Proj(init=\"epsg:\" + str(xy_crs)),\n            Proj(init=\"epsg:\" + str(point_crs)),\n            always_xy=True,  # required b/c Proj v6+ uses lon/lat instead of x/y\n        )\n\n    return transform(transformers[(xy_crs, point_crs)].transform, point)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.to_points_gdf","title":"<code>to_points_gdf(table, ref_nodes_df=None, ref_road_net=None)</code>","text":"<p>Convert a table to a GeoDataFrame.</p> <p>If the table is already a GeoDataFrame, return it as is. Otherwise, attempt to convert the table to a GeoDataFrame using the following methods: 1. If the table has a \u2018geometry\u2019 column, return a GeoDataFrame using that column. 2. If the table has \u2018lat\u2019 and \u2018lon\u2019 columns, return a GeoDataFrame using those columns. 3. If the table has a \u2018*model_node_id\u2019 or \u2018stop_id\u2019 column, return a GeoDataFrame using that column and the      nodes_df provided. If none of the above, raise a ValueError.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DataFrame</code> <p>DataFrame to convert to GeoDataFrame.</p> required <code>ref_nodes_df</code> <code>Optional[GeoDataFrame]</code> <p>GeoDataFrame of nodes to use to convert model_node_id to geometry.</p> <code>None</code> <code>ref_road_net</code> <code>Optional[RoadwayNetwork]</code> <p>RoadwayNetwork object to use to convert model_node_id to geometry.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GeoDataFrame</code> <code>GeoDataFrame</code> <p>GeoDataFrame representation of the table.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def to_points_gdf(\n    table: pd.DataFrame,\n    ref_nodes_df: Optional[gpd.GeoDataFrame] = None,\n    ref_road_net: Optional[RoadwayNetwork] = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Convert a table to a GeoDataFrame.\n\n    If the table is already a GeoDataFrame, return it as is. Otherwise, attempt to convert the\n    table to a GeoDataFrame using the following methods:\n    1. If the table has a 'geometry' column, return a GeoDataFrame using that column.\n    2. If the table has 'lat' and 'lon' columns, return a GeoDataFrame using those columns.\n    3. If the table has a '*model_node_id' or 'stop_id' column, return a GeoDataFrame using that column and the\n         nodes_df provided.\n    If none of the above, raise a ValueError.\n\n    Args:\n        table: DataFrame to convert to GeoDataFrame.\n        ref_nodes_df: GeoDataFrame of nodes to use to convert model_node_id to geometry.\n        ref_road_net: RoadwayNetwork object to use to convert model_node_id to geometry.\n\n    Returns:\n        GeoDataFrame: GeoDataFrame representation of the table.\n    \"\"\"\n    if table is gpd.GeoDataFrame:\n        return table\n\n    WranglerLogger.debug(\"Converting GTFS table to GeoDataFrame\")\n    if \"geometry\" in table.columns:\n        return gpd.GeoDataFrame(table, geometry=\"geometry\")\n\n    lat_cols = list(filter(lambda col: \"lat\" in col, table.columns))\n    lon_cols = list(filter(lambda col: \"lon\" in col, table.columns))\n    model_node_id_cols = [\n        c for c in [\"model_node_id\", \"stop_id\", \"shape_model_node_id\"] if c in table.columns\n    ]\n\n    if not (lat_cols and lon_cols) or not model_node_id_cols:\n        WranglerLogger.error(\n            \"Needed either lat/long or *model_node_id columns to convert \\\n            to GeoDataFrame. Columns found: {table.columns}\"\n        )\n        if not (lat_cols and lon_cols):\n            WranglerLogger.error(\"No lat/long cols found.\")\n        if not model_node_id_cols:\n            WranglerLogger.error(\"No *model_node_id cols found.\")\n        msg = \"Could not find lat/long, geometry columns or *model_node_id column in \\\n                         table necessary to convert to GeoDataFrame\"\n        raise ValueError(msg)\n\n    if lat_cols and lon_cols:\n        # using first found lat and lon columns\n        return gpd.GeoDataFrame(\n            table,\n            geometry=gpd.points_from_xy(table[lon_cols[0]], table[lat_cols[0]]),\n            crs=\"EPSG:4326\",\n        )\n\n    if model_node_id_cols:\n        node_id_col = model_node_id_cols[0]\n\n        if ref_nodes_df is None:\n            if ref_road_net is None:\n                msg = \"Must provide either nodes_df or road_net to convert \\\n                                 model_node_id to geometry\"\n                raise ValueError(msg)\n            ref_nodes_df = ref_road_net.nodes_df\n\n        WranglerLogger.debug(\"Converting table to GeoDataFrame using model_node_id\")\n\n        _table = table.merge(\n            ref_nodes_df[[\"model_node_id\", \"geometry\"]],\n            left_on=node_id_col,\n            right_on=\"model_node_id\",\n        )\n        return gpd.GeoDataFrame(_table, geometry=\"geometry\")\n    msg = \"Could not find lat/long, geometry columns or *model_node_id column in table \\\n                        necessary to convert to GeoDataFrame\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.update_nodes_in_linestring_geometry","title":"<code>update_nodes_in_linestring_geometry(original_df, updated_nodes_df, position)</code>","text":"<p>Updates the nodes in a linestring geometry and returns updated geometry.</p> <p>Parameters:</p> Name Type Description Default <code>original_df</code> <code>GeoDataFrame</code> <p>GeoDataFrame with the <code>model_node_id</code> and linestring geometry</p> required <code>updated_nodes_df</code> <code>GeoDataFrame</code> <p>GeoDataFrame with updated node geometries.</p> required <code>position</code> <code>int</code> <p>position in the linestring to update with the node.</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_nodes_in_linestring_geometry(\n    original_df: gpd.GeoDataFrame,\n    updated_nodes_df: gpd.GeoDataFrame,\n    position: int,\n) -&gt; gpd.GeoSeries:\n    \"\"\"Updates the nodes in a linestring geometry and returns updated geometry.\n\n    Args:\n        original_df: GeoDataFrame with the `model_node_id` and linestring geometry\n        updated_nodes_df: GeoDataFrame with updated node geometries.\n        position: position in the linestring to update with the node.\n    \"\"\"\n    LINK_FK_NODE = [\"A\", \"B\"]\n    original_index = original_df.index\n\n    updated_df = original_df.reset_index().merge(\n        updated_nodes_df[[\"model_node_id\", \"geometry\"]],\n        left_on=LINK_FK_NODE[position],\n        right_on=\"model_node_id\",\n        suffixes=(\"\", \"_node\"),\n    )\n\n    updated_df[\"geometry\"] = updated_df.apply(\n        lambda row: update_points_in_linestring(\n            row[\"geometry\"], row[\"geometry_node\"].coords[0], position\n        ),\n        axis=1,\n    )\n\n    updated_df = updated_df.reset_index().set_index(original_index.names)\n\n    WranglerLogger.debug(f\"updated_df - AFTER: \\n {updated_df.geometry}\")\n    return updated_df[\"geometry\"]\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.update_point_geometry","title":"<code>update_point_geometry(df, ref_point_df, lon_field='X', lat_field='Y', id_field='model_node_id', ref_lon_field='X', ref_lat_field='Y', ref_id_field='model_node_id')</code>","text":"<p>Returns copy of df with lat and long fields updated with geometry from ref_point_df.</p> <p>NOTE: does not update \u201cgeometry\u201d field if it exists.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_point_geometry(\n    df: pd.DataFrame,\n    ref_point_df: pd.DataFrame,\n    lon_field: str = \"X\",\n    lat_field: str = \"Y\",\n    id_field: str = \"model_node_id\",\n    ref_lon_field: str = \"X\",\n    ref_lat_field: str = \"Y\",\n    ref_id_field: str = \"model_node_id\",\n) -&gt; pd.DataFrame:\n    \"\"\"Returns copy of df with lat and long fields updated with geometry from ref_point_df.\n\n    NOTE: does not update \"geometry\" field if it exists.\n    \"\"\"\n    df = copy.deepcopy(df)\n\n    ref_df = ref_point_df.rename(\n        columns={\n            ref_lon_field: lon_field,\n            ref_lat_field: lat_field,\n            ref_id_field: id_field,\n        }\n    )\n\n    updated_df = update_df_by_col_value(\n        df,\n        ref_df[[id_field, lon_field, lat_field]],\n        id_field,\n        properties=[lat_field, lon_field],\n        fail_if_missing=False,\n    )\n    return updated_df\n</code></pre>"},{"location":"api/#network_wrangler.utils.geo.update_points_in_linestring","title":"<code>update_points_in_linestring(linestring, updated_coords, position)</code>","text":"<p>Replaces a point in a linestring with a new point.</p> <p>Parameters:</p> Name Type Description Default <code>linestring</code> <code>LineString</code> <p>original_linestring</p> required <code>updated_coords</code> <code>List[float]</code> <p>updated poimt coordinates</p> required <code>position</code> <code>int</code> <p>position in the linestring to update</p> required Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_points_in_linestring(\n    linestring: LineString, updated_coords: list[float], position: int\n):\n    \"\"\"Replaces a point in a linestring with a new point.\n\n    Args:\n        linestring (LineString): original_linestring\n        updated_coords (List[float]): updated poimt coordinates\n        position (int): position in the linestring to update\n    \"\"\"\n    coords = [c for c in linestring.coords]\n    coords[position] = updated_coords\n    return LineString(coords)\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.DictQueryAccessor","title":"<code>DictQueryAccessor</code>","text":"<p>Query link, node and shape dataframes using project selection dictionary.</p> <p>Will overlook any keys which are not columns in the dataframe.</p> <p>Usage:</p> <pre><code>selection_dict = {\n    \"lanes\": [1, 2, 3],\n    \"name\": [\"6th\", \"Sixth\", \"sixth\"],\n    \"drive_access\": 1,\n}\nselected_links_df = links_df.dict_query(selection_dict)\n</code></pre> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"dict_query\")\nclass DictQueryAccessor:\n    \"\"\"Query link, node and shape dataframes using project selection dictionary.\n\n    Will overlook any keys which are not columns in the dataframe.\n\n    Usage:\n\n    ```\n    selection_dict = {\n        \"lanes\": [1, 2, 3],\n        \"name\": [\"6th\", \"Sixth\", \"sixth\"],\n        \"drive_access\": 1,\n    }\n    selected_links_df = links_df.dict_query(selection_dict)\n    ```\n\n    \"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dictionary query accessor.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self, selection_dict: dict, return_all_if_none: bool = False):\n        \"\"\"Queries the dataframe using the selection dictionary.\n\n        Args:\n            selection_dict (dict): _description_\n            return_all_if_none (bool, optional): If True, will return entire df if dict has\n                 no values. Defaults to False.\n        \"\"\"\n        _not_selection_keys = [\"modes\", \"all\", \"ignore_missing\"]\n        _selection_dict = {\n            k: v\n            for k, v in selection_dict.items()\n            if k not in _not_selection_keys and v is not None\n        }\n        missing_columns = [k for k in _selection_dict if k not in self._obj.columns]\n        if missing_columns:\n            msg = f\"Selection fields not found in dataframe: {missing_columns}\"\n            raise SelectionError(msg)\n\n        if not _selection_dict:\n            if return_all_if_none:\n                return self._obj\n            msg = f\"Relevant part of selection dictionary is empty: {selection_dict}\"\n            raise SelectionError(msg)\n\n        _sel_query = dict_to_query(_selection_dict)\n        # WranglerLogger.debug(f\"_sel_query: \\n   {_sel_query}\")\n        _df = self._obj.query(_sel_query, engine=\"python\")\n\n        if len(_df) == 0:\n            WranglerLogger.warning(\n                f\"No records found in df \\\n                  using selection: {selection_dict}\"\n            )\n        return _df\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.DictQueryAccessor.__call__","title":"<code>__call__(selection_dict, return_all_if_none=False)</code>","text":"<p>Queries the dataframe using the selection dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>selection_dict</code> <code>dict</code> <p>description</p> required <code>return_all_if_none</code> <code>bool</code> <p>If True, will return entire df if dict has  no values. Defaults to False.</p> <code>False</code> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self, selection_dict: dict, return_all_if_none: bool = False):\n    \"\"\"Queries the dataframe using the selection dictionary.\n\n    Args:\n        selection_dict (dict): _description_\n        return_all_if_none (bool, optional): If True, will return entire df if dict has\n             no values. Defaults to False.\n    \"\"\"\n    _not_selection_keys = [\"modes\", \"all\", \"ignore_missing\"]\n    _selection_dict = {\n        k: v\n        for k, v in selection_dict.items()\n        if k not in _not_selection_keys and v is not None\n    }\n    missing_columns = [k for k in _selection_dict if k not in self._obj.columns]\n    if missing_columns:\n        msg = f\"Selection fields not found in dataframe: {missing_columns}\"\n        raise SelectionError(msg)\n\n    if not _selection_dict:\n        if return_all_if_none:\n            return self._obj\n        msg = f\"Relevant part of selection dictionary is empty: {selection_dict}\"\n        raise SelectionError(msg)\n\n    _sel_query = dict_to_query(_selection_dict)\n    # WranglerLogger.debug(f\"_sel_query: \\n   {_sel_query}\")\n    _df = self._obj.query(_sel_query, engine=\"python\")\n\n    if len(_df) == 0:\n        WranglerLogger.warning(\n            f\"No records found in df \\\n              using selection: {selection_dict}\"\n        )\n    return _df\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.DictQueryAccessor.__init__","title":"<code>__init__(pandas_obj)</code>","text":"<p>Initialization function for the dictionary query accessor.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dictionary query accessor.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.Isin_dict","title":"<code>Isin_dict</code>","text":"<p>Faster implimentation of isin for querying dataframes with dictionary.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"isin_dict\")\nclass Isin_dict:\n    \"\"\"Faster implimentation of isin for querying dataframes with dictionary.\"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dataframe hash.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self, d: dict, **kwargs) -&gt; pd.DataFrame:\n        \"\"\"Function to perform the faster dictionary isin().\"\"\"\n        return isin_dict(self._obj, d, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.Isin_dict.__call__","title":"<code>__call__(d, **kwargs)</code>","text":"<p>Function to perform the faster dictionary isin().</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self, d: dict, **kwargs) -&gt; pd.DataFrame:\n    \"\"\"Function to perform the faster dictionary isin().\"\"\"\n    return isin_dict(self._obj, d, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.Isin_dict.__init__","title":"<code>__init__(pandas_obj)</code>","text":"<p>Initialization function for the dataframe hash.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dataframe hash.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.dfHash","title":"<code>dfHash</code>","text":"<p>Creates a dataframe hash that is compatable with geopandas and various metadata.</p> <p>Definitely not the fastest, but she seems to work where others have failed.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"df_hash\")\nclass dfHash:\n    \"\"\"Creates a dataframe hash that is compatable with geopandas and various metadata.\n\n    Definitely not the fastest, but she seems to work where others have failed.\n    \"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dataframe hash.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self):\n        \"\"\"Function to hash the dataframe.\"\"\"\n        _value = str(self._obj.values).encode()\n        hash = hashlib.sha1(_value).hexdigest()\n        return hash\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.dfHash.__call__","title":"<code>__call__()</code>","text":"<p>Function to hash the dataframe.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self):\n    \"\"\"Function to hash the dataframe.\"\"\"\n    _value = str(self._obj.values).encode()\n    hash = hashlib.sha1(_value).hexdigest()\n    return hash\n</code></pre>"},{"location":"api/#network_wrangler.utils.df_accessors.dfHash.__init__","title":"<code>__init__(pandas_obj)</code>","text":"<p>Initialization function for the dataframe hash.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dataframe hash.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api/#network_wrangler.logger.setup_logging","title":"<code>setup_logging(info_log_filename=None, debug_log_filename=None, std_out_level='info')</code>","text":"<p>Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.</p> <p>Called by the test_logging fixture in conftest.py and can be called by the user to setup logging for their session. If called multiple times, the logger will be reset.</p> <p>Parameters:</p> Name Type Description Default <code>info_log_filename</code> <code>Optional[Path]</code> <p>the location of the log file that will get created to add the INFO log. The INFO Log is terse, just gives the bare minimum of details. Defaults to file in cwd() <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> <code>None</code> <code>debug_log_filename</code> <code>Optional[Path]</code> <p>the location of the log file that will get created to add the DEBUG log The DEBUG log is very noisy, for debugging. Defaults to file in cwd() <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> <code>None</code> <code>std_out_level</code> <code>str</code> <p>the level of logging to the console. One of \u201cinfo\u201d, \u201cwarning\u201d, \u201cdebug\u201d. Defaults to \u201cinfo\u201d but will be set to ERROR if nothing provided matches.</p> <code>'info'</code> Source code in <code>network_wrangler/logger.py</code> <pre><code>def setup_logging(\n    info_log_filename: Optional[Path] = None,\n    debug_log_filename: Optional[Path] = None,\n    std_out_level: str = \"info\",\n):\n    \"\"\"Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.\n\n    Called by the test_logging fixture in conftest.py and can be called by the user to setup\n    logging for their session. If called multiple times, the logger will be reset.\n\n    Args:\n        info_log_filename: the location of the log file that will get created to add the INFO log.\n            The INFO Log is terse, just gives the bare minimum of details.\n            Defaults to file in cwd() `wrangler_[datetime].log`. To turn off logging to a file,\n            use log_filename = None.\n        debug_log_filename: the location of the log file that will get created to add the DEBUG log\n            The DEBUG log is very noisy, for debugging. Defaults to file in cwd()\n            `wrangler_[datetime].log`. To turn off logging to a file, use log_filename = None.\n        std_out_level: the level of logging to the console. One of \"info\", \"warning\", \"debug\".\n            Defaults to \"info\" but will be set to ERROR if nothing provided matches.\n    \"\"\"\n    # add function variable so that we know if logging has been called\n    setup_logging.called = True\n\n    DEFAULT_LOG_PATH = Path(f\"wrangler_{datetime.now().strftime('%Y_%m_%d__%H_%M_%S')}.debug.log\")\n    debug_log_filename = debug_log_filename if debug_log_filename else DEFAULT_LOG_PATH\n\n    # Clear handles if any exist already\n    WranglerLogger.handlers = []\n\n    WranglerLogger.setLevel(logging.DEBUG)\n\n    FORMAT = logging.Formatter(\n        \"%(asctime)-15s %(levelname)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S,\"\n    )\n    default_info_f = f\"network_wrangler_{datetime.now().strftime('%Y_%m_%d__%H_%M_%S')}.info.log\"\n    info_log_filename = info_log_filename or Path.cwd() / default_info_f\n\n    info_file_handler = logging.FileHandler(Path(info_log_filename))\n    info_file_handler.setLevel(logging.INFO)\n    info_file_handler.setFormatter(FORMAT)\n    WranglerLogger.addHandler(info_file_handler)\n\n    # create debug file only when debug_log_filename is provided\n    if debug_log_filename:\n        debug_log_handler = logging.FileHandler(Path(debug_log_filename))\n        debug_log_handler.setLevel(logging.DEBUG)\n        debug_log_handler.setFormatter(FORMAT)\n        WranglerLogger.addHandler(debug_log_handler)\n\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.DEBUG)\n    console_handler.setFormatter(FORMAT)\n    WranglerLogger.addHandler(console_handler)\n    if std_out_level in (\"debug\", \"info\"):\n        console_handler.setLevel(logging.DEBUG)\n    elif std_out_level == \"warning\":\n        console_handler.setLevel(logging.WARNING)\n    else:\n        console_handler.setLevel(logging.ERROR)\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem","title":"<code>ConfigItem</code>","text":"<p>Base class to add partial dict-like interface to  configuration.</p> <p>Allow use of .items() [\u201cX\u201d] and .get(\u201cX\u201d) .to_dict() from configuration.</p> <p>Not to be constructed directly. To be used a mixin for dataclasses representing config schema. Do not use \u201cget\u201d \u201cto_dict\u201d, or \u201citems\u201d for key names.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>class ConfigItem:\n    \"\"\"Base class to add partial dict-like interface to  configuration.\n\n    Allow use of .items() [\"X\"] and .get(\"X\") .to_dict() from configuration.\n\n    Not to be constructed directly. To be used a mixin for dataclasses\n    representing config schema.\n    Do not use \"get\" \"to_dict\", or \"items\" for key names.\n    \"\"\"\n\n    base_path: Optional[Path] = None\n\n    def __getitem__(self, key):\n        \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n        return getattr(self, key)\n\n    def items(self):\n        \"\"\"A set-like object providing a view on D's items.\"\"\"\n        return self.__dict__.items()\n\n    def to_dict(self):\n        \"\"\"Convert the configuration to a dictionary.\"\"\"\n        result = {}\n        for key, value in self.__dict__.items():\n            if isinstance(value, ConfigItem):\n                result[key] = value.to_dict()\n            else:\n                result[key] = value\n        return result\n\n    def get(self, key, default=None):\n        \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n        return self.__dict__.get(key, default)\n\n    def update(self, data: Union[Path, list[Path], dict]):\n        \"\"\"Update the configuration with a dictionary of new values.\"\"\"\n        if not isinstance(data, dict):\n            WranglerLogger.info(f\"Updating configuration with {data}.\")\n            data = load_merge_dict(data)\n\n        self.__dict__.update(data)\n        return self\n\n    def resolve_paths(self, base_path):\n        \"\"\"Resolve relative paths in the configuration.\"\"\"\n        base_path = Path(base_path)\n        for key, value in self.__dict__.items():\n            if isinstance(value, ConfigItem):\n                value.resolve_paths(base_path)\n            elif isinstance(value, str) and value.startswith(\".\"):\n                resolved_path = (base_path / value).resolve()\n                setattr(self, key, str(resolved_path))\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the value for key if key is in the dictionary, else default.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def __getitem__(self, key):\n    \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n    return getattr(self, key)\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.get","title":"<code>get(key, default=None)</code>","text":"<p>Return the value for key if key is in the dictionary, else default.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def get(self, key, default=None):\n    \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n    return self.__dict__.get(key, default)\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.items","title":"<code>items()</code>","text":"<p>A set-like object providing a view on D\u2019s items.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def items(self):\n    \"\"\"A set-like object providing a view on D's items.\"\"\"\n    return self.__dict__.items()\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.resolve_paths","title":"<code>resolve_paths(base_path)</code>","text":"<p>Resolve relative paths in the configuration.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def resolve_paths(self, base_path):\n    \"\"\"Resolve relative paths in the configuration.\"\"\"\n    base_path = Path(base_path)\n    for key, value in self.__dict__.items():\n        if isinstance(value, ConfigItem):\n            value.resolve_paths(base_path)\n        elif isinstance(value, str) and value.startswith(\".\"):\n            resolved_path = (base_path / value).resolve()\n            setattr(self, key, str(resolved_path))\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the configuration to a dictionary.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def to_dict(self):\n    \"\"\"Convert the configuration to a dictionary.\"\"\"\n    result = {}\n    for key, value in self.__dict__.items():\n        if isinstance(value, ConfigItem):\n            result[key] = value.to_dict()\n        else:\n            result[key] = value\n    return result\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.update","title":"<code>update(data)</code>","text":"<p>Update the configuration with a dictionary of new values.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def update(self, data: Union[Path, list[Path], dict]):\n    \"\"\"Update the configuration with a dictionary of new values.\"\"\"\n    if not isinstance(data, dict):\n        WranglerLogger.info(f\"Updating configuration with {data}.\")\n        data = load_merge_dict(data)\n\n    self.__dict__.update(data)\n    return self\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.find_configs_in_dir","title":"<code>find_configs_in_dir(dir, config_type)</code>","text":"<p>Find configuration files in the directory that match <code>*config&lt;ext&gt;</code>.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def find_configs_in_dir(dir: Union[Path, list[Path]], config_type) -&gt; list[Path]:\n    \"\"\"Find configuration files in the directory that match `*config&lt;ext&gt;`.\"\"\"\n    config_files: list[Path] = []\n    if isinstance(dir, list):\n        for d in dir:\n            config_files.extend(find_configs_in_dir(d, config_type))\n    elif dir.is_dir():\n        dir = Path(dir)\n        for ext in SUPPORTED_CONFIG_EXTENSIONS:\n            config_like_files = list(dir.glob(f\"*config{ext}\"))\n            config_files.extend(find_configs_in_dir(config_like_files, config_type))\n    elif dir.is_file():\n        try:\n            config_type(load_dict(dir))\n        except ValidationError:\n            return config_files\n        config_files.append(dir)\n\n    if config_files:\n        return [Path(config_file) for config_file in config_files]\n    return []\n</code></pre>"},{"location":"api/#network_wrangler.time.Time","title":"<code>Time</code>","text":"<p>Represents a time object.</p> <p>This class provides methods to initialize and manipulate time objects.</p> <p>Attributes:</p> Name Type Description <code>datetime</code> <code>datetime</code> <p>The underlying datetime object representing the time.</p> <code>time_str</code> <code>str</code> <p>The time string representation in HH:MM:SS format.</p> <code>time_sec</code> <code>int</code> <p>The time in seconds since midnight.</p> <code>_raw_time_in</code> <code>TimeType</code> <p>The raw input value used to initialize the Time object.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>class Time:\n    \"\"\"Represents a time object.\n\n    This class provides methods to initialize and manipulate time objects.\n\n    Attributes:\n        datetime (datetime): The underlying datetime object representing the time.\n        time_str (str): The time string representation in HH:MM:SS format.\n        time_sec (int): The time in seconds since midnight.\n\n        _raw_time_in (TimeType): The raw input value used to initialize the Time object.\n\n    \"\"\"\n\n    def __init__(self, value: TimeType):\n        \"\"\"Initializes a Time object.\n\n        Args:\n            value (TimeType): A time object, string in HH:MM[:SS] format, or seconds since\n                midnight.\n\n        Raises:\n            TimeFormatError: If the value is not a valid time format.\n\n        \"\"\"\n        if isinstance(value, datetime):\n            self.datetime: datetime = value\n        elif isinstance(value, time):\n            self.datetime = datetime.combine(datetime.today(), value)\n        elif isinstance(value, str):\n            self.datetime = str_to_time(value)\n        elif isinstance(value, int):\n            self.datetime = datetime.datetime.fromtimestamp(value).time()\n        else:\n            msg = \"time must be a string, int, or time object\"\n            raise TimeFormatError(msg)\n\n        self._raw_time_in = value\n\n    def __getitem__(self, item: Any) -&gt; str:\n        \"\"\"Get the time string representation.\n\n        Args:\n            item (Any): Not used.\n\n        Returns:\n            str: The time string representation in HH:MM:SS format.\n        \"\"\"\n        return self.time_str\n\n    @property\n    def time_str(self):\n        \"\"\"Get the time string representation.\n\n        Returns:\n            str: The time string representation in HH:MM:SS format.\n        \"\"\"\n        return self.datetime.strftime(\"%H:%M:%S\")\n\n    @property\n    def time_sec(self):\n        \"\"\"Get the time in seconds since midnight.\n\n        Returns:\n            int: The time in seconds since midnight.\n        \"\"\"\n        return self.datetime.hour * 3600 + self.datetime.minute * 60 + self.datetime.second\n\n    def __str__(self) -&gt; str:\n        \"\"\"Get the string representation of the Time object.\n\n        Returns:\n            str: The time string representation in HH:MM:SS format.\n        \"\"\"\n        return self.time_str\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Get the hash value of the Time object.\n\n        Returns:\n            int: The hash value of the Time object.\n        \"\"\"\n        return hash(str(self))\n</code></pre>"},{"location":"api/#network_wrangler.time.Time.time_sec","title":"<code>time_sec</code>  <code>property</code>","text":"<p>Get the time in seconds since midnight.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The time in seconds since midnight.</p>"},{"location":"api/#network_wrangler.time.Time.time_str","title":"<code>time_str</code>  <code>property</code>","text":"<p>Get the time string representation.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The time string representation in HH:MM:SS format.</p>"},{"location":"api/#network_wrangler.time.Time.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Get the time string representation.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Any</code> <p>Not used.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The time string representation in HH:MM:SS format.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __getitem__(self, item: Any) -&gt; str:\n    \"\"\"Get the time string representation.\n\n    Args:\n        item (Any): Not used.\n\n    Returns:\n        str: The time string representation in HH:MM:SS format.\n    \"\"\"\n    return self.time_str\n</code></pre>"},{"location":"api/#network_wrangler.time.Time.__hash__","title":"<code>__hash__()</code>","text":"<p>Get the hash value of the Time object.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The hash value of the Time object.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Get the hash value of the Time object.\n\n    Returns:\n        int: The hash value of the Time object.\n    \"\"\"\n    return hash(str(self))\n</code></pre>"},{"location":"api/#network_wrangler.time.Time.__init__","title":"<code>__init__(value)</code>","text":"<p>Initializes a Time object.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>TimeType</code> <p>A time object, string in HH:MM[:SS] format, or seconds since midnight.</p> required <p>Raises:</p> Type Description <code>TimeFormatError</code> <p>If the value is not a valid time format.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __init__(self, value: TimeType):\n    \"\"\"Initializes a Time object.\n\n    Args:\n        value (TimeType): A time object, string in HH:MM[:SS] format, or seconds since\n            midnight.\n\n    Raises:\n        TimeFormatError: If the value is not a valid time format.\n\n    \"\"\"\n    if isinstance(value, datetime):\n        self.datetime: datetime = value\n    elif isinstance(value, time):\n        self.datetime = datetime.combine(datetime.today(), value)\n    elif isinstance(value, str):\n        self.datetime = str_to_time(value)\n    elif isinstance(value, int):\n        self.datetime = datetime.datetime.fromtimestamp(value).time()\n    else:\n        msg = \"time must be a string, int, or time object\"\n        raise TimeFormatError(msg)\n\n    self._raw_time_in = value\n</code></pre>"},{"location":"api/#network_wrangler.time.Time.__str__","title":"<code>__str__()</code>","text":"<p>Get the string representation of the Time object.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The time string representation in HH:MM:SS format.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Get the string representation of the Time object.\n\n    Returns:\n        str: The time string representation in HH:MM:SS format.\n    \"\"\"\n    return self.time_str\n</code></pre>"},{"location":"api/#network_wrangler.time.Timespan","title":"<code>Timespan</code>","text":"<p>Timespan object.</p> <p>This class provides methods to initialize and manipulate time objects.</p> <p>If the end_time is less than the start_time, the duration will assume that it crosses     over midnight.</p> <p>Attributes:</p> Name Type Description <code>start_time</code> <code>time</code> <p>The start time of the timespan.</p> <code>end_time</code> <code>time</code> <p>The end time of the timespan.</p> <code>timespan_str_list</code> <code>str</code> <p>A list of start time and end time in HH:MM:SS format.</p> <code>start_time_sec</code> <code>int</code> <p>The start time in seconds since midnight.</p> <code>end_time_sec</code> <code>int</code> <p>The end time in seconds since midnight.</p> <code>duration</code> <code>timedelta</code> <p>The duration of the timespan.</p> <code>duration_sec</code> <code>int</code> <p>The duration of the timespan in seconds.</p> <code>_raw_timespan_in</code> <code>Any</code> <p>The raw input value used to initialize the Timespan object.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>class Timespan:\n    \"\"\"Timespan object.\n\n    This class provides methods to initialize and manipulate time objects.\n\n    If the end_time is less than the start_time, the duration will assume that it crosses\n        over midnight.\n\n    Attributes:\n        start_time (datetime.time): The start time of the timespan.\n        end_time (datetime.time): The end time of the timespan.\n        timespan_str_list (str): A list of start time and end time in HH:MM:SS format.\n        start_time_sec (int): The start time in seconds since midnight.\n        end_time_sec (int): The end time in seconds since midnight.\n        duration (datetime.timedelta): The duration of the timespan.\n        duration_sec (int): The duration of the timespan in seconds.\n\n        _raw_timespan_in (Any): The raw input value used to initialize the Timespan object.\n\n    \"\"\"\n\n    def __init__(self, value: list[TimeType]):\n        \"\"\"Constructor for the Timespan object.\n\n        If the value is a list of two time strings, datetime objects, Time, or seconds from\n        midnight, the start_time and end_time attributes will be set accordingly.\n\n        Args:\n            value (time): a list of two time strings, datetime objects, Time, or seconds from\n              midnight.\n        \"\"\"\n        if len(value) != 2:  # noqa: PLR2004\n            msg = \"timespan must be a list of 2 time strings, datetime objs, Time, or sec from midnight.\"\n            raise TimespanFormatError(msg)\n\n        self.start_time, self.end_time = (Time(t) for t in value)\n        self._raw_timespan_in = value\n\n    @property\n    def timespan_str_list(self):\n        \"\"\"Get the timespan string representation.\"\"\"\n        return [self.start_time.time_str, self.end_time.time_str]\n\n    @property\n    def start_time_sec(self):\n        \"\"\"Start time in seconds since midnight.\"\"\"\n        return self.start_time.time_sec\n\n    @property\n    def end_time_sec(self):\n        \"\"\"End time in seconds since midnight.\"\"\"\n        return self.end_time.time_sec\n\n    @property\n    def duration(self):\n        \"\"\"Duration of timespan as a timedelta object.\"\"\"\n        return duration_dt(self.start_time, self.end_time)\n\n    @property\n    def duration_sec(self):\n        \"\"\"Duration of timespan in seconds.\n\n        If end_time is less than start_time, the duration will assume that it crosses over\n        midnight.\n        \"\"\"\n        if self.end_time_sec &lt; self.start_time_sec:\n            return (24 * 3600) - self.start_time_sec + self.end_time_sec\n        return self.end_time_sec - self.start_time_sec\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the Timespan object.\"\"\"\n        return str(self.timespan_str)\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Hash value of the Timespan object.\"\"\"\n        return hash(str(self))\n\n    def overlaps(self, other: Timespan) -&gt; bool:\n        \"\"\"Check if two timespans overlap.\n\n        If the start time is greater than the end time, the timespan is assumed to cross over\n        midnight.\n\n        Args:\n            other (Timespan): The other timespan to compare.\n\n        Returns:\n            bool: True if the two timespans overlap, False otherwise.\n        \"\"\"\n        real_end_time = self.end_time.datetime\n        if self.end_time.datetime &gt; self.start_time.datetime:\n            real_end_time = self.end_time.datetime + datetime.timedelta(days=1)\n\n        real_other_end_time = other.end_time.datetime\n        if other.end_time.datetime &gt; other.start_time.datetime:\n            real_other_end_time = other.end_time.datetime + datetime.timedelta(days=1)\n        return (\n            self.start_time.datetime &lt;= real_other_end_time\n            and real_end_time &gt;= other.start_time.datetime\n        )\n</code></pre>"},{"location":"api/#network_wrangler.time.Timespan.duration","title":"<code>duration</code>  <code>property</code>","text":"<p>Duration of timespan as a timedelta object.</p>"},{"location":"api/#network_wrangler.time.Timespan.duration_sec","title":"<code>duration_sec</code>  <code>property</code>","text":"<p>Duration of timespan in seconds.</p> <p>If end_time is less than start_time, the duration will assume that it crosses over midnight.</p>"},{"location":"api/#network_wrangler.time.Timespan.end_time_sec","title":"<code>end_time_sec</code>  <code>property</code>","text":"<p>End time in seconds since midnight.</p>"},{"location":"api/#network_wrangler.time.Timespan.start_time_sec","title":"<code>start_time_sec</code>  <code>property</code>","text":"<p>Start time in seconds since midnight.</p>"},{"location":"api/#network_wrangler.time.Timespan.timespan_str_list","title":"<code>timespan_str_list</code>  <code>property</code>","text":"<p>Get the timespan string representation.</p>"},{"location":"api/#network_wrangler.time.Timespan.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash value of the Timespan object.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Hash value of the Timespan object.\"\"\"\n    return hash(str(self))\n</code></pre>"},{"location":"api/#network_wrangler.time.Timespan.__init__","title":"<code>__init__(value)</code>","text":"<p>Constructor for the Timespan object.</p> <p>If the value is a list of two time strings, datetime objects, Time, or seconds from midnight, the start_time and end_time attributes will be set accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>time</code> <p>a list of two time strings, datetime objects, Time, or seconds from midnight.</p> required Source code in <code>network_wrangler/time.py</code> <pre><code>def __init__(self, value: list[TimeType]):\n    \"\"\"Constructor for the Timespan object.\n\n    If the value is a list of two time strings, datetime objects, Time, or seconds from\n    midnight, the start_time and end_time attributes will be set accordingly.\n\n    Args:\n        value (time): a list of two time strings, datetime objects, Time, or seconds from\n          midnight.\n    \"\"\"\n    if len(value) != 2:  # noqa: PLR2004\n        msg = \"timespan must be a list of 2 time strings, datetime objs, Time, or sec from midnight.\"\n        raise TimespanFormatError(msg)\n\n    self.start_time, self.end_time = (Time(t) for t in value)\n    self._raw_timespan_in = value\n</code></pre>"},{"location":"api/#network_wrangler.time.Timespan.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the Timespan object.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the Timespan object.\"\"\"\n    return str(self.timespan_str)\n</code></pre>"},{"location":"api/#network_wrangler.time.Timespan.overlaps","title":"<code>overlaps(other)</code>","text":"<p>Check if two timespans overlap.</p> <p>If the start time is greater than the end time, the timespan is assumed to cross over midnight.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Timespan</code> <p>The other timespan to compare.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the two timespans overlap, False otherwise.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def overlaps(self, other: Timespan) -&gt; bool:\n    \"\"\"Check if two timespans overlap.\n\n    If the start time is greater than the end time, the timespan is assumed to cross over\n    midnight.\n\n    Args:\n        other (Timespan): The other timespan to compare.\n\n    Returns:\n        bool: True if the two timespans overlap, False otherwise.\n    \"\"\"\n    real_end_time = self.end_time.datetime\n    if self.end_time.datetime &gt; self.start_time.datetime:\n        real_end_time = self.end_time.datetime + datetime.timedelta(days=1)\n\n    real_other_end_time = other.end_time.datetime\n    if other.end_time.datetime &gt; other.start_time.datetime:\n        real_other_end_time = other.end_time.datetime + datetime.timedelta(days=1)\n    return (\n        self.start_time.datetime &lt;= real_other_end_time\n        and real_end_time &gt;= other.start_time.datetime\n    )\n</code></pre>"},{"location":"api/#network_wrangler.viz.MissingMapboxTokenError","title":"<code>MissingMapboxTokenError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when MAPBOX_ACCESS_TOKEN is not found in environment variables.</p> Source code in <code>network_wrangler/viz.py</code> <pre><code>class MissingMapboxTokenError(Exception):\n    \"\"\"Raised when MAPBOX_ACCESS_TOKEN is not found in environment variables.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.viz.net_to_mapbox","title":"<code>net_to_mapbox(roadway=None, transit=None, roadway_geojson_out=Path('roadway_shapes.geojson'), transit_geojson_out=Path('transit_shapes.geojson'), mbtiles_out=Path('network.mbtiles'), overwrite=True, port='9000')</code>","text":"<p>Creates and serves mapbox tiles on local web server based on roadway and transit networks.</p> <p>Parameters:</p> Name Type Description Default <code>roadway</code> <code>Optional[Union[RoadwayNetwork, GeoDataFrame, str, Path]]</code> <p>a RoadwayNetwork instance, geodataframe with roadway linetrings, or path to a geojson file. Defaults to empty GeoDataFrame.</p> <code>None</code> <code>transit</code> <code>Optional[Union[TransitNetwork, GeoDataFrame]]</code> <p>a TransitNetwork instance or a geodataframe with roadway linetrings, or path to a geojson file. Defaults to empty GeoDataFrame.</p> <code>None</code> <code>roadway_geojson_out</code> <code>Path</code> <p>file path for roadway geojson which gets created if roadway is not a path to a geojson file. Defaults to roadway_shapes.geojson.</p> <code>Path('roadway_shapes.geojson')</code> <code>transit_geojson_out</code> <code>Path</code> <p>file path for transit geojson which gets created if transit is not a path to a geojson file. Defaults to transit_shapes.geojson.</p> <code>Path('transit_shapes.geojson')</code> <code>mbtiles_out</code> <code>Path</code> <p>path to output mapbox tiles. Defaults to network.mbtiles</p> <code>Path('network.mbtiles')</code> <code>overwrite</code> <code>bool</code> <p>boolean indicating if can overwrite mbtiles_out and roadway_geojson_out and transit_geojson_out. Defaults to True.</p> <code>True</code> <code>port</code> <code>str</code> <p>port to serve resulting tiles on. Defaults to 9000.</p> <code>'9000'</code> Source code in <code>network_wrangler/viz.py</code> <pre><code>def net_to_mapbox(\n    roadway: Optional[Union[RoadwayNetwork, gpd.GeoDataFrame, str, Path]] = None,\n    transit: Optional[Union[TransitNetwork, gpd.GeoDataFrame]] = None,\n    roadway_geojson_out: Path = Path(\"roadway_shapes.geojson\"),\n    transit_geojson_out: Path = Path(\"transit_shapes.geojson\"),\n    mbtiles_out: Path = Path(\"network.mbtiles\"),\n    overwrite: bool = True,\n    port: str = \"9000\",\n):\n    \"\"\"Creates and serves mapbox tiles on local web server based on roadway and transit networks.\n\n    Args:\n        roadway: a RoadwayNetwork instance, geodataframe with roadway linetrings, or path to a\n            geojson file. Defaults to empty GeoDataFrame.\n        transit: a TransitNetwork instance or a geodataframe with roadway linetrings, or path to a\n            geojson file. Defaults to empty GeoDataFrame.\n        roadway_geojson_out: file path for roadway geojson which gets created if roadway is not\n            a path to a geojson file. Defaults to roadway_shapes.geojson.\n        transit_geojson_out: file path for transit geojson which gets created if transit is not\n            a path to a geojson file. Defaults to transit_shapes.geojson.\n        mbtiles_out: path to output mapbox tiles. Defaults to network.mbtiles\n        overwrite: boolean indicating if can overwrite mbtiles_out and roadway_geojson_out and\n            transit_geojson_out. Defaults to True.\n        port: port to serve resulting tiles on. Defaults to 9000.\n    \"\"\"\n    import subprocess\n\n    if roadway is None:\n        roadway = gpd.GeoDataFrame()\n    if transit is None:\n        transit = gpd.GeoDataFrame()\n    # test for mapbox token\n    try:\n        os.getenv(\"MAPBOX_ACCESS_TOKEN\")\n    except Exception as err:\n        WranglerLogger.error(\n            \"NEED TO SET MAPBOX ACCESS TOKEN IN ENVIRONMENT VARIABLES/n \\\n                In command line: &gt;&gt;export MAPBOX_ACCESS_TOKEN='pk.0000.1111' # \\\n                replace value with your mapbox public access token\"\n        )\n        raise MissingMapboxTokenError() from err\n\n    if isinstance(transit, TransitNetwork):\n        transit = transit.shape_links_gdf\n        transit.to_file(transit_geojson_out, driver=\"GeoJSON\")\n    elif Path(transit).exists():\n        transit_geojson_out = transit\n    else:\n        msg = f\"Don't understand transit input: {transit}\"\n        raise ValueError(msg)\n\n    if isinstance(roadway, RoadwayNetwork):\n        roadway = roadway.link_shapes_df\n        roadway.to_file(roadway_geojson_out, driver=\"GeoJSON\")\n    elif Path(roadway).exists():\n        roadway_geojson_out = Path(roadway)\n    else:\n        msg = \"Don't understand roadway input: {roadway}\"\n        raise ValueError(msg)\n\n    tippe_options_list: list[str] = [\"-zg\", \"-o\", str(mbtiles_out)]\n    if overwrite:\n        tippe_options_list.append(\"--force\")\n    # tippe_options_list.append(\"--drop-densest-as-needed\")\n    tippe_options_list.append(str(roadway_geojson_out))\n    tippe_options_list.append(str(transit_geojson_out))\n\n    try:\n        WranglerLogger.info(\n            f\"Running tippecanoe with following options: {' '.join(tippe_options_list)}\"\n        )\n        subprocess.run([\"tippecanoe\", *tippe_options_list], check=False)\n    except Exception as err:\n        WranglerLogger.error(\n            \"If tippecanoe isn't installed, try `brew install tippecanoe` or \\\n                visit https://github.com/mapbox/tippecanoe\"\n        )\n        raise ImportError() from err\n\n    try:\n        WranglerLogger.info(\n            \"Running mbview with following options: {}\".format(\" \".join(tippe_options_list))\n        )\n        subprocess.run([\"mbview\", \"--port\", port, f\", /{mbtiles_out}\"], check=False)\n    except Exception as err:\n        WranglerLogger.error(\n            \"If mbview isn't installed, try `npm install -g @mapbox/mbview` or \\\n                visit https://github.com/mapbox/mbview\"\n        )\n        raise ImportError(msg) from err\n</code></pre>"},{"location":"api/#network_wrangler.errors.DataframeSelectionError","title":"<code>DataframeSelectionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with a selection from a dataframe.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class DataframeSelectionError(Exception):\n    \"\"\"Raised when there is an issue with a selection from a dataframe.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.FeedReadError","title":"<code>FeedReadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error reading a transit feed.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class FeedReadError(Exception):\n    \"\"\"Raised when there is an error reading a transit feed.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.FeedValidationError","title":"<code>FeedValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with the validation of the GTFS data.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class FeedValidationError(Exception):\n    \"\"\"Raised when there is an issue with the validation of the GTFS data.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.InvalidScopedLinkValue","title":"<code>InvalidScopedLinkValue</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with a scoped link value.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class InvalidScopedLinkValue(Exception):\n    \"\"\"Raised when there is an issue with a scoped link value.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.LinkAddError","title":"<code>LinkAddError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with adding links.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkAddError(Exception):\n    \"\"\"Raised when there is an issue with adding links.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.LinkChangeError","title":"<code>LinkChangeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error in changing a link property.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkChangeError(Exception):\n    \"\"\"Raised when there is an error in changing a link property.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.LinkCreationError","title":"<code>LinkCreationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with creating links.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkCreationError(Exception):\n    \"\"\"Raised when there is an issue with creating links.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.LinkDeletionError","title":"<code>LinkDeletionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with deleting links.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkDeletionError(Exception):\n    \"\"\"Raised when there is an issue with deleting links.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.LinkNotFoundError","title":"<code>LinkNotFoundError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a link is not found in the links table.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkNotFoundError(Exception):\n    \"\"\"Raised when a link is not found in the links table.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ManagedLaneAccessEgressError","title":"<code>ManagedLaneAccessEgressError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with access/egress points to managed lanes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ManagedLaneAccessEgressError(Exception):\n    \"\"\"Raised when there is an issue with access/egress points to managed lanes.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.MissingNodesError","title":"<code>MissingNodesError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when referenced nodes are missing from the network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class MissingNodesError(Exception):\n    \"\"\"Raised when referenced nodes are missing from the network.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NewRoadwayError","title":"<code>NewRoadwayError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a new roadway.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NewRoadwayError(Exception):\n    \"\"\"Raised when there is an issue with applying a new roadway.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NodeAddError","title":"<code>NodeAddError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with adding nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeAddError(Exception):\n    \"\"\"Raised when there is an issue with adding nodes.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NodeChangeError","title":"<code>NodeChangeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a node change.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeChangeError(Exception):\n    \"\"\"Raised when there is an issue with applying a node change.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NodeDeletionError","title":"<code>NodeDeletionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with deleting nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeDeletionError(Exception):\n    \"\"\"Raised when there is an issue with deleting nodes.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NodeNotFoundError","title":"<code>NodeNotFoundError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a node is not found in the nodes table.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeNotFoundError(Exception):\n    \"\"\"Raised when a node is not found in the nodes table.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NodesInLinksMissingError","title":"<code>NodesInLinksMissingError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with validating links and nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodesInLinksMissingError(Exception):\n    \"\"\"Raised when there is an issue with validating links and nodes.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NotLinksError","title":"<code>NotLinksError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a dataframe is not a RoadLinksTable.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NotLinksError(Exception):\n    \"\"\"Raised when a dataframe is not a RoadLinksTable.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.NotNodesError","title":"<code>NotNodesError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a dataframe is not a RoadNodesTable.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NotNodesError(Exception):\n    \"\"\"Raised when a dataframe is not a RoadNodesTable.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ProjectCardError","title":"<code>ProjectCardError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a project card is not valid.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ProjectCardError(Exception):\n    \"\"\"Raised when a project card is not valid.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.RoadwayDeletionError","title":"<code>RoadwayDeletionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a roadway deletion.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class RoadwayDeletionError(Exception):\n    \"\"\"Raised when there is an issue with applying a roadway deletion.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.RoadwayPropertyChangeError","title":"<code>RoadwayPropertyChangeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a roadway property change.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class RoadwayPropertyChangeError(Exception):\n    \"\"\"Raised when there is an issue with applying a roadway property change.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ScenarioConflictError","title":"<code>ScenarioConflictError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a conflict is detected.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScenarioConflictError(Exception):\n    \"\"\"Raised when a conflict is detected.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ScenarioCorequisiteError","title":"<code>ScenarioCorequisiteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a co-requisite is not satisfied.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScenarioCorequisiteError(Exception):\n    \"\"\"Raised when a co-requisite is not satisfied.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ScenarioPrerequisiteError","title":"<code>ScenarioPrerequisiteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a pre-requisite is not satisfied.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScenarioPrerequisiteError(Exception):\n    \"\"\"Raised when a pre-requisite is not satisfied.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ScopeConflictError","title":"<code>ScopeConflictError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is a scope conflict in a list of ScopedPropertySetItems.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScopeConflictError(Exception):\n    \"\"\"Raised when there is a scope conflict in a list of ScopedPropertySetItems.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ScopeLinkValueError","title":"<code>ScopeLinkValueError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with ScopedLinkValueList.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScopeLinkValueError(Exception):\n    \"\"\"Raised when there is an issue with ScopedLinkValueList.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.SegmentFormatError","title":"<code>SegmentFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error in segment format.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SegmentFormatError(Exception):\n    \"\"\"Error in segment format.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.SegmentSelectionError","title":"<code>SegmentSelectionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error in segment selection.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SegmentSelectionError(Exception):\n    \"\"\"Error in segment selection.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.SelectionError","title":"<code>SelectionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with a selection.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SelectionError(Exception):\n    \"\"\"Raised when there is an issue with a selection.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ShapeAddError","title":"<code>ShapeAddError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with adding shapes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ShapeAddError(Exception):\n    \"\"\"Raised when there is an issue with adding shapes.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.ShapeDeletionError","title":"<code>ShapeDeletionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with deleting shapes from a network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ShapeDeletionError(Exception):\n    \"\"\"Raised when there is an issue with deleting shapes from a network.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.SubnetCreationError","title":"<code>SubnetCreationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a subnet can\u2019t be created.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SubnetCreationError(Exception):\n    \"\"\"Raised when a subnet can't be created.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.SubnetExpansionError","title":"<code>SubnetExpansionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a subnet can\u2019t be expanded to include a node or set of nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SubnetExpansionError(Exception):\n    \"\"\"Raised when a subnet can't be expanded to include a node or set of nodes.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TimeFormatError","title":"<code>TimeFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Time format error exception.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TimeFormatError(Exception):\n    \"\"\"Time format error exception.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TimespanFormatError","title":"<code>TimespanFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Timespan format error exception.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TimespanFormatError(Exception):\n    \"\"\"Timespan format error exception.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitPropertyChangeError","title":"<code>TransitPropertyChangeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when applying transit property changes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitPropertyChangeError(Exception):\n    \"\"\"Error raised when applying transit property changes.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitRoadwayConsistencyError","title":"<code>TransitRoadwayConsistencyError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when transit network is inconsistent with roadway network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitRoadwayConsistencyError(Exception):\n    \"\"\"Error raised when transit network is inconsistent with roadway network.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitRouteAddError","title":"<code>TransitRouteAddError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when applying add transit route.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitRouteAddError(Exception):\n    \"\"\"Error raised when applying add transit route.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitRoutingChangeError","title":"<code>TransitRoutingChangeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error in the transit routing change.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitRoutingChangeError(Exception):\n    \"\"\"Raised when there is an error in the transit routing change.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitSelectionEmptyError","title":"<code>TransitSelectionEmptyError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error for when no transit trips are selected.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitSelectionEmptyError(Exception):\n    \"\"\"Error for when no transit trips are selected.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitSelectionError","title":"<code>TransitSelectionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base error for transit selection errors.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitSelectionError(Exception):\n    \"\"\"Base error for transit selection errors.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitSelectionNetworkConsistencyError","title":"<code>TransitSelectionNetworkConsistencyError</code>","text":"<p>               Bases: <code>TransitSelectionError</code></p> <p>Error for when transit selection dictionary is not consistent with transit network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitSelectionNetworkConsistencyError(TransitSelectionError):\n    \"\"\"Error for when transit selection dictionary is not consistent with transit network.\"\"\"\n</code></pre>"},{"location":"api/#network_wrangler.errors.TransitValidationError","title":"<code>TransitValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when transit network doesn\u2019t have expected values.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitValidationError(Exception):\n    \"\"\"Error raised when transit network doesn't have expected values.\"\"\"\n</code></pre>"},{"location":"data_models/","title":"Data Models","text":""},{"location":"data_models/#roadway","title":"Roadway","text":""},{"location":"data_models/#tables","title":"Tables","text":"<p>Datamodels for Roadway Network Tables.</p> <p>This module contains the datamodels used to validate the format and types of Roadway Network tables.</p> <p>Includes:</p> <ul> <li>RoadLinksTable</li> <li>RoadNodesTable</li> <li>RoadShapesTable</li> <li>ExplodedScopedLinkPropertyTable</li> </ul>"},{"location":"data_models/#network_wrangler.models.roadway.tables.ExplodedScopedLinkPropertyTable","title":"<code>ExplodedScopedLinkPropertyTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate an exploded links_df by scope.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class ExplodedScopedLinkPropertyTable(DataFrameModel):\n    \"\"\"Datamodel used to validate an exploded links_df by scope.\"\"\"\n\n    model_link_id: Series[int]\n    category: Series[Any]\n    timespan: Series[list[str]]\n    start_time: Series[dt.datetime]\n    end_time: Series[dt.datetime]\n    scoped: Series[Any] = pa.Field(default=None, nullable=True)\n\n    class Config:\n        \"\"\"Config for ExplodedScopedLinkPropertySchema.\"\"\"\n\n        name = \"ExplodedScopedLinkPropertySchema\"\n        coerce = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.ExplodedScopedLinkPropertyTable.Config","title":"<code>Config</code>","text":"<p>Config for ExplodedScopedLinkPropertySchema.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for ExplodedScopedLinkPropertySchema.\"\"\"\n\n    name = \"ExplodedScopedLinkPropertySchema\"\n    coerce = True\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable","title":"<code>RoadLinksTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> <p>Attributes:</p> Name Type Description <code>model_link_id</code> <code>int</code> <p>Unique identifier for the link.</p> <code>A</code> <code>int</code> <p><code>model_node_id</code> of the link\u2019s start node. Foreign key to <code>road_nodes</code>.</p> <code>B</code> <code>int</code> <p><code>model_node_id</code> of the link\u2019s end node. Foreign key to <code>road_nodes</code>.</p> <code>geometry</code> <code>GeoSeries</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Simple A\u2192B geometry of the link.</p> <code>name</code> <code>str</code> <p>Name of the link.</p> <code>rail_only</code> <code>bool</code> <p>If the link is only for rail. Default is False.</p> <code>bus_only</code> <code>bool</code> <p>If the link is only for buses. Default is False.</p> <code>drive_access</code> <code>bool</code> <p>If the link allows driving. Default is True.</p> <code>bike_access</code> <code>bool</code> <p>If the link allows biking. Default is True.</p> <code>walk_access</code> <code>bool</code> <p>If the link allows walking. Default is True.</p> <code>truck_access</code> <code>bool</code> <p>If the link allows trucks. Default is True.</p> <code>distance</code> <code>float</code> <p>Length of the link.</p> <code>roadway</code> <code>str</code> <p>Type of roadway per OSM definitions. Default is \u201croad\u201d.</p> <code>projects</code> <code>str</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Comma-separated list of project names applied to the link. Default is \u201c\u201d.</p> <code>managed</code> <code>int</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Indicator for the type of managed lane facility. Values can be:</p> <ul> <li>0 indicating no managed lane on this link.</li> <li>1 indicates that there is a managed lane on the link (std network) or that the link is a     managed lane (model network).</li> <li>-1 indicates that there is a parallel managed lane derived from this link (model network).</li> </ul> <code>shape_id</code> <code>str</code> <p>Identifier referencing the primary key of the shapes table. Default is None.</p> <code>lanes</code> <code>int</code> <p>Default number of lanes on the link. Default is 1.</p> <code>sc_lanes</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the number of lanes. Default is None. Example: <code>[{'timespan':['12:00':'15:00'], 'value': 3},{'timespan':['15:00':'19:00'], 'value': 2}]</code>.</p> <code>price</code> <code>float</code> <p>Default price to use the link. Default is 0.</p> <code>sc_price</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the price. Default is None. Example: <code>[{'timespan':['15:00':'19:00'],'category': 'sov', 'value': 2.5}]</code>.</p> <code>ref</code> <code>Optional[str]</code> <p>Reference numbers for link referring to a route or exit number per the OSM definition. Default is None.</p> <code>access</code> <code>Optional[Any]</code> <p>User-defined method to note access restrictions for the link. Default is None.</p> <code>ML_projects</code> <code>Optional[str]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Comma-separated list of project names applied to the managed lane. Default is \u201c\u201d.</p> <code>ML_lanes</code> <code>Optional[int]</code> <p>Default number of lanes on the managed lane. Default is None.</p> <code>ML_price</code> <code>Optional[float]</code> <p>Default price to use the managed lane. Default is 0.</p> <code>ML_access</code> <code>Optional[Any]</code> <p>User-defined method to note access restrictions for the managed lane. Default is None.</p> <code>ML_access_point</code> <code>Optional[bool]</code> <p>If the link is an access point for the managed lane. Default is False.</p> <code>ML_egress_point</code> <code>Optional[bool]</code> <p>If the link is an egress point for the managed lane. Default is False.</p> <code>sc_ML_lanes</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the number of lanes on the managed lane. Default is None.</p> <code>sc_ML_price</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the price of the managed lane. Default is None.</p> <code>sc_ML_access</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the access restrictions of the managed lane. Default is None.</p> <code>ML_geometry</code> <code>Optional[GeoSeries]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Simple A\u2192B geometry of the managed lane. Default is None.</p> <code>ML_shape_id</code> <code>Optional[str]</code> <p>Identifier referencing the primary key of the shapes table for the managed lane. Default is None.</p> <code>osm_link_id</code> <code>Optional[str]</code> <p>Identifier referencing the OSM link ID. Default is \u201c\u201d.</p> <code>GP_A</code> <code>Optional[int]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Identifier referencing the primary key of the associated general purpose link start node for a managed lane link in a model network. Default is None.</p> <code>GP_B</code> <code>Optional[int]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Identifier referencing the primary key of the associated general purpose link end node for a managed lane link in a model network. Default is None.</p> <p>User Defined Properties</p> <p>Additional properites may be defined and are assumed to have the same definition of OpenStreetMap if they have overlapping property names.</p>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable--properties-for-parallel-managed-lanes","title":"Properties for parallel managed lanes","text":"<p>Properties for parallel managed lanes are prefixed with <code>ML_</code>. (Almost) any property, including an ad-hoc one, can be made to apply to a parallel managed lane by applying the prefix <code>ML_</code>, e.g. <code>ML_lanes</code></p> <p>Warning</p> <p>The following properties should not be assigned an <code>ML_</code> prefix by the user because they are assigned one within networkwrangler:</p> <ul> <li><code>name</code></li> <li><code>A</code></li> <li><code>B</code></li> <li><code>model_link_id</code></li> </ul>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable--time-or-category-dependent-properties","title":"Time- or category-dependent properties","text":"<p>The following properties can be time-dependent, category-dependent, or both by adding <code>sc_</code>. The \u201cplain\u201d property without the prefix becomes the default when no scoped property applies.</p> Property # of Lanes Price Default value <code>lanes</code> <code>price</code> Time- and/or category-dependent value <code>sc_lanes</code> <code>sc_price</code> Default value for managed lane <code>ML_lanes</code> <code>ML_price</code> Time- and/or category-dependent value for managed lane <code>sc_ML_lanes</code> <code>sc_ML_price</code> previous format for scoped properties<p>Some previous tooling was developed around a previous method for serializing scoped properties.  In order to retain compatability with this format:</p> <ul> <li><code>load_roadway_from_dir()</code>, <code>read_links()</code>, and associated functions will \u201csniff\u201d the network for the old format and apply the converter function <code>translate_links_df_v0_to_v1()</code></li> <li><code>write_links()</code> has an boolean attribute to <code>convert_complex_properties_to_single_field</code> which can also be invoked from <code>write_roadway()</code> as <code>convert_complex_link_properties_to_single_field</code>.</li> </ul>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable--defining-time-dependent-properties","title":"Defining time-dependent properties","text":"<p>Time-dependent properties are defined as a list of dictionaries with timespans and values.</p> <ul> <li>Timespans must be defined as a list of HH:MM or HH:MM:SS using a 24-hour clock: <code>('06:00':'09:00')</code>.</li> <li>Timespans must not intersect.</li> </ul> <p>Time-dependent property</p> <p>$3 peak-period pricing</p> <pre><code># default price\n'price' = 0\n'sc_price':\n[\n    {\n        'time':['06:00':'09:00'],\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'value': 3,\n    }\n]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable--defining-time-and-category-dependent-properties","title":"Defining time- and category-dependent properties","text":"<p>Properties co-dependent on time- and category are defined as a list of dictionaries with value, category and time defined.</p> <p>time- and category-dependent property</p> <p>A pricing strategy which only applies in peak period for trucks and sovs:</p> <pre><code># default price\n\"price\": 0\n# price scoped by time of day\n\"sc_price\":\n[\n    {\n        'timespan':['06:00':'09:00'],\n        'category': ('sov','truck'),\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'category': ('sov','truck'),\n        'value': 3,\n    }\n]\n</code></pre> <p>Tip</p> <p>There is no limit on other, user-defined properties being listed as time-dependent or time- and category-dependent.</p> <p>User-defined variable by time of day</p> <p>Define a variable <code>access</code> to represent which categories can access the network and vary it by time of day.</p> <pre><code>#access\n{\n    # default value for access\n    'access': ('any'),\n    # scoped value for access\n    'sc_access': [\n        {\n            'timespan':['06:00':'09:00'],\n            'value': ('no-trucks')\n        },\n        {\n            'timespan':['16:00':'19:00'],\n            'value': ('hov2','hov3','trucks')\n        }\n    ]\n}\n</code></pre> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadLinksTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\n\n    Attributes:\n        model_link_id (int): Unique identifier for the link.\n        A (int): `model_node_id` of the link's start node. Foreign key to `road_nodes`.\n        B (int): `model_node_id` of the link's end node. Foreign key to `road_nodes`.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Simple A--&gt;B geometry of the link.\n        name (str): Name of the link.\n        rail_only (bool): If the link is only for rail. Default is False.\n        bus_only (bool): If the link is only for buses. Default is False.\n        drive_access (bool): If the link allows driving. Default is True.\n        bike_access (bool): If the link allows biking. Default is True.\n        walk_access (bool): If the link allows walking. Default is True.\n        truck_access (bool): If the link allows trucks. Default is True.\n        distance (float): Length of the link.\n        roadway (str): Type of roadway per [OSM definitions](https://wiki.openstreetmap.org/wiki/Key:highway#Roads).\n            Default is \"road\".\n        projects (str): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Comma-separated list of project names applied to the link. Default is \"\".\n        managed (int): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Indicator for the type of managed lane facility. Values can be:\n\n            - 0 indicating no managed lane on this link.\n            - 1 indicates that there is a managed lane on the link (std network) or that the link is a\n                managed lane (model network).\n            - -1 indicates that there is a parallel managed lane derived from this link (model network).\n        shape_id (str): Identifier referencing the primary key of the shapes table. Default is None.\n        lanes (int): Default number of lanes on the link. Default is 1.\n        sc_lanes (Optional[list[dict]]: List of scoped link values for the number of lanes. Default is None.\n            Example: `[{'timespan':['12:00':'15:00'], 'value': 3},{'timespan':['15:00':'19:00'], 'value': 2}]`.\n\n        price (float): Default price to use the link. Default is 0.\n        sc_price (Optional[list[dict]]): List of scoped link values for the price. Default is None.\n            Example: `[{'timespan':['15:00':'19:00'],'category': 'sov', 'value': 2.5}]`.\n        ref (Optional[str]): Reference numbers for link referring to a route or exit number per the\n            [OSM definition](https://wiki.openstreetmap.org/wiki/Key:ref). Default is None.\n        access (Optional[Any]): User-defined method to note access restrictions for the link. Default is None.\n        ML_projects (Optional[str]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Comma-separated list of project names applied to the managed lane. Default is \"\".\n        ML_lanes (Optional[int]): Default number of lanes on the managed lane. Default is None.\n        ML_price (Optional[float]): Default price to use the managed lane. Default is 0.\n        ML_access (Optional[Any]): User-defined method to note access restrictions for the managed lane. Default is None.\n        ML_access_point (Optional[bool]): If the link is an access point for the managed lane. Default is False.\n        ML_egress_point (Optional[bool]): If the link is an egress point for the managed lane. Default is False.\n        sc_ML_lanes (Optional[list[dict]]): List of scoped link values for the number of lanes on the managed lane.\n            Default is None.\n        sc_ML_price (Optional[list[dict]]): List of scoped link values for the price of the managed lane. Default is None.\n        sc_ML_access (Optional[list[dict]]): List of scoped link values for the access restrictions of the managed lane.\n            Default is None.\n        ML_geometry (Optional[GeoSeries]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Simple A--&gt;B geometry of the managed lane. Default is None.\n        ML_shape_id (Optional[str]): Identifier referencing the primary key of the shapes table for the managed lane.\n            Default is None.\n        osm_link_id (Optional[str]): Identifier referencing the OSM link ID. Default is \"\".\n        GP_A (Optional[int]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Identifier referencing the primary key of the associated general purpose link start node for\n            a managed lane link in a model network. Default is None.\n        GP_B (Optional[int]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Identifier referencing the primary key of the associated general purpose link end node for\n            a managed lane link in a model network. Default is None.\n\n    !!! tip \"User Defined Properties\"\n\n        Additional properites may be defined and are assumed to have the same definition of OpenStreetMap if they\n        have overlapping property names.\n\n    ### Properties for parallel managed lanes\n\n    Properties for parallel managed lanes are prefixed with `ML_`. (Almost) any property,\n    including an ad-hoc one, can be made to apply to a parallel managed lane by applying\n    the prefix `ML_`, e.g. `ML_lanes`\n\n    !!! warning\n\n        The following properties should **not** be assigned an `ML_` prefix by the user\n        because they are assigned one within networkwrangler:\n\n        - `name`\n        - `A`\n        - `B`\n        - `model_link_id`\n\n    ### Time- or category-dependent properties\n\n    The following properties can be time-dependent, category-dependent, or both by adding `sc_`.\n    The \"plain\" property without the prefix becomes the default when no scoped property applies.\n\n    | Property | # of Lanes | Price |\n    | -----------| ----------------- | ---------------- |\n    | Default value | `lanes` | `price` |\n    | Time- and/or category-dependent value | `sc_lanes` | `sc_price` |\n    | Default value for managed lane | `ML_lanes` | `ML_price` |\n    | Time- and/or category-dependent value for managed lane | `sc_ML_lanes` | `sc_ML_price` |\n\n\n    ??? note \"previous format for scoped properties\"\n\n        Some previous tooling was developed around a previous method for serializing scoped properties.  In order to retain compatability with this format:\n\n        - `load_roadway_from_dir()`, `read_links()`, and associated functions will \"sniff\" the network for the old format and apply the converter function `translate_links_df_v0_to_v1()`\n        - `write_links()` has an boolean attribute to `convert_complex_properties_to_single_field` which can also be invoked from `write_roadway()` as `convert_complex_link_properties_to_single_field`.\n\n    #### Defining time-dependent properties\n\n    Time-dependent properties are defined as a list of dictionaries with timespans and values.\n\n    - Timespans must be defined as a list of HH:MM or HH:MM:SS using a 24-hour clock: `('06:00':'09:00')`.\n    - Timespans must not intersect.\n\n    !!! example  \"Time-dependent property\"\n\n        $3 peak-period pricing\n\n        ```python\n        # default price\n        'price' = 0\n        'sc_price':\n        [\n            {\n                'time':['06:00':'09:00'],\n                'value': 3\n            },\n            {\n                'timespan':['16:00':'19:00'],\n                'value': 3,\n            }\n        ]\n        ```\n\n    #### Defining time- and category-dependent properties\n\n    Properties co-dependent on time- and category are defined as a list of dictionaries with value, category and time defined.\n\n    !!! example \"time- and category-dependent property\"\n\n        A pricing strategy which only applies in peak period for trucks and sovs:\n\n        ```python\n        # default price\n        \"price\": 0\n        # price scoped by time of day\n        \"sc_price\":\n        [\n            {\n                'timespan':['06:00':'09:00'],\n                'category': ('sov','truck'),\n                'value': 3\n            },\n            {\n                'timespan':['16:00':'19:00'],\n                'category': ('sov','truck'),\n                'value': 3,\n            }\n        ]\n        ```\n\n    !!! tip\n\n        There is no limit on other, user-defined properties being listed as time-dependent or time- and category-dependent.\n\n    !!! example \"User-defined variable by time of day\"\n\n        Define a variable `access` to represent which categories can access the network and vary it by time of day.\n\n        ```python\n        #access\n        {\n            # default value for access\n            'access': ('any'),\n            # scoped value for access\n            'sc_access': [\n                {\n                    'timespan':['06:00':'09:00'],\n                    'value': ('no-trucks')\n                },\n                {\n                    'timespan':['16:00':'19:00'],\n                    'value': ('hov2','hov3','trucks')\n                }\n            ]\n        }\n        ```\n    \"\"\"\n\n    model_link_id: Series[int] = pa.Field(coerce=True, unique=True)\n    model_link_id_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True)\n    A: Series[int] = pa.Field(nullable=False, coerce=True)\n    B: Series[int] = pa.Field(nullable=False, coerce=True)\n    geometry: GeoSeries = pa.Field(nullable=False)\n    name: Series[str] = pa.Field(nullable=False, default=\"unknown\")\n    rail_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    bus_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    drive_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    bike_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    walk_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    distance: Series[float] = pa.Field(coerce=True, nullable=False)\n\n    roadway: Series[str] = pa.Field(nullable=False, default=\"road\")\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    managed: Series[int] = pa.Field(coerce=True, nullable=False, default=0)\n\n    shape_id: Series[str] = pa.Field(coerce=True, nullable=True)\n    lanes: Series[int] = pa.Field(coerce=True, nullable=False)\n    price: Series[float] = pa.Field(coerce=True, nullable=False, default=0)\n\n    # Optional Fields\n    ref: Optional[Series[str]] = pa.Field(coerce=True, nullable=True, default=None)\n    access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    sc_lanes: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n    sc_price: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    ML_projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    ML_lanes: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    ML_price: Optional[Series[float]] = pa.Field(coerce=True, nullable=True, default=0)\n    ML_access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=True)\n    ML_access_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    ML_egress_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    sc_ML_lanes: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_price: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_access: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n\n    ML_geometry: Optional[GeoSeries] = pa.Field(nullable=True, coerce=True, default=None)\n    ML_shape_id: Optional[Series[str]] = pa.Field(nullable=True, coerce=True, default=None)\n\n    truck_access: Optional[Series[bool]] = pa.Field(coerce=True, nullable=True, default=True)\n    osm_link_id: Series[str] = pa.Field(coerce=True, nullable=True, default=\"\")\n    # todo this should be List[dict] but ranch output something else so had to have it be Any.\n    locationReferences: Optional[Series[Any]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n\n    GP_A: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    GP_B: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    class Config:\n        \"\"\"Config for RoadLinksTable.\"\"\"\n\n        add_missing_columns = True\n        coerce = True\n        unique: ClassVar[list[str]] = [\"A\", \"B\"]\n\n    @pa.check(\"sc_*\", regex=True, element_wise=True)\n    def check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n        \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n        Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n        against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n        \"\"\"\n        if scoped_value is None or (not isinstance(scoped_value, list) and pd.isna(scoped_value)):\n            return True\n        return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadLinksTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadLinksTable.\"\"\"\n\n    add_missing_columns = True\n    coerce = True\n    unique: ClassVar[list[str]] = [\"A\", \"B\"]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadLinksTable.check_scoped_fields","title":"<code>check_scoped_fields(scoped_value)</code>","text":"<p>Checks that all fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 are valid ScopedLinkValueList.</p> <p>Custom check to validate fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 against a ScopedLinkValueItem model, handling both mandatory and optional fields.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>@pa.check(\"sc_*\", regex=True, element_wise=True)\ndef check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n    \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n    Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n    against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n    \"\"\"\n    if scoped_value is None or (not isinstance(scoped_value, list) and pd.isna(scoped_value)):\n        return True\n    return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadNodesTable","title":"<code>RoadNodesTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> <p>Must have a record for each node used by the <code>links</code> table and by the transit <code>shapes</code>, <code>stop_times</code>, and <code>stops</code> tables.</p> <p>Attributes:</p> Name Type Description <code>model_node_id</code> <code>int</code> <p>Unique identifier for the node.</p> <code>osm_node_id</code> <code>Optional[str]</code> <p>Reference to open street map node id. Used for querying. Not guaranteed to be unique.</p> <code>X</code> <code>float</code> <p>Longitude of the node in WGS84. Must be in the range of -180 to 180.</p> <code>Y</code> <code>float</code> <p>Latitude of the node in WGS84. Must be in the range of -90 to 90.</p> <code>geometry</code> <code>GeoSeries</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadNodesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\n\n    Must have a record for each node used by the `links` table and by the transit `shapes`, `stop_times`, and `stops` tables.\n\n    Attributes:\n        model_node_id (int): Unique identifier for the node.\n        osm_node_id (Optional[str]): Reference to open street map node id. Used for querying. Not guaranteed to be unique.\n        X (float): Longitude of the node in WGS84. Must be in the range of -180 to 180.\n        Y (float): Latitude of the node in WGS84. Must be in the range of -90 to 90.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n    \"\"\"\n\n    model_node_id: Series[int] = pa.Field(coerce=True, unique=True, nullable=False)\n    model_node_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True, nullable=False)\n    X: Series[float] = pa.Field(coerce=True, nullable=False)\n    Y: Series[float] = pa.Field(coerce=True, nullable=False)\n    geometry: GeoSeries\n\n    # optional fields\n    osm_node_id: Series[str] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    inboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n    outboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadNodesTable.\"\"\"\n\n        add_missing_columns = True\n        coerce = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"model_node_id\"]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadNodesTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadNodesTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadNodesTable.\"\"\"\n\n    add_missing_columns = True\n    coerce = True\n    _pk: ClassVar[TablePrimaryKeys] = [\"model_node_id\"]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadShapesTable","title":"<code>RoadShapesTable</code>","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if shapes_df is of correct format and types.</p> <p>Should have a record for each <code>shape_id</code> referenced in <code>links</code> table.</p> <p>Attributes:</p> Name Type Description <code>shape_id</code> <code>str</code> <p>Unique identifier for the shape.</p> <code>geometry</code> <code>GeoSeries</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Geometry of the shape.</p> <code>ref_shape_id</code> <code>Optional[str]</code> <p>Reference to another <code>shape_id</code> that it may have been created from. Default is None.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadShapesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if shapes_df is of correct format and types.\n\n    Should have a record for each `shape_id` referenced in `links` table.\n\n    Attributes:\n        shape_id (str): Unique identifier for the shape.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Geometry of the shape.\n        ref_shape_id (Optional[str]): Reference to another `shape_id` that it may\n            have been created from. Default is None.\n    \"\"\"\n\n    shape_id: Series[str] = pa.Field(unique=True)\n    shape_id_idx: Optional[Series[int]] = pa.Field(unique=True)\n\n    geometry: GeoSeries = pa.Field()\n    ref_shape_id: Optional[Series] = pa.Field(nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadShapesTable.\"\"\"\n\n        coerce = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"shape_id\"]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.tables.RoadShapesTable.Config","title":"<code>Config</code>","text":"<p>Config for RoadShapesTable.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class Config:\n    \"\"\"Config for RoadShapesTable.\"\"\"\n\n    coerce = True\n    _pk: ClassVar[TablePrimaryKeys] = [\"shape_id\"]\n</code></pre>"},{"location":"data_models/#types","title":"Types","text":"<p>Complex roadway types defined using Pydantic models to facilitation validation.</p>"},{"location":"data_models/#network_wrangler.models.roadway.types.LocationReferences","title":"<code>LocationReferences = conlist(LocationReference, min_length=2)</code>  <code>module-attribute</code>","text":"<p>List of at least two LocationReferences which define a path.</p>"},{"location":"data_models/#network_wrangler.models.roadway.types.LocationReference","title":"<code>LocationReference</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>SharedStreets-defined object for location reference.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class LocationReference(BaseModel):\n    \"\"\"SharedStreets-defined object for location reference.\"\"\"\n\n    sequence: PositiveInt\n    point: LatLongCoordinates\n    bearing: float = Field(None, ge=-360, le=360)\n    distanceToNextRef: NonNegativeFloat\n    intersectionId: str\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueItem","title":"<code>ScopedLinkValueItem</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Define the value of a link property for a particular timespan or category.</p> <p>Attributes:</p> Name Type Description <code>`category`</code> <code>str</code> <p>Category or link user that this scoped value applies to, ex: <code>HOV2</code>, <code>truck</code>, etc.  Categories are user-defined with the exception of <code>any</code> which is reserved as the default category. Default is <code>DEFAULT_CATEGORY</code>, which is <code>all</code>.</p> <code>`timespan`</code> <code>list[TimeString]</code> <p>timespan of the link property as defined as a list of two HH:MM(:SS) strings. Default is <code>DEFAULT_TIMESPAN</code>, which is <code>[\"00:00\", \"24:00\"]</code>.</p> <code>`value`</code> <code>Union[float, int, str]</code> <p>Value of the link property for the given category and timespan.</p> <p>Conflicting or matching scopes are not allowed in a list of ScopedLinkValueItems:</p> <ul> <li><code>matching</code>: a scope that could be applied for a given category/timespan combination. This includes the default scopes as well as scopes that are contained within the given category AND timespan combination.</li> <li><code>overlapping</code>: a scope that fully or partially overlaps a given category OR timespan combination.  This includes the default scopes, all <code>matching</code> scopes and all scopes where at least one minute of timespan or one category overlap.</li> <li><code>conflicting</code>: a scope that is overlapping but not matching for a given category/timespan.</li> </ul> <p>NOTE: Default scope values of <code>category: any</code> and <code>timespan:[\"00:00\", \"24:00\"]</code> are not considered conflicting, but are applied to residual scopes.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class ScopedLinkValueItem(RecordModel):\n    \"\"\"Define the value of a link property for a particular timespan or category.\n\n    Attributes:\n        `category` (str): Category or link user that this scoped value applies to, ex: `HOV2`,\n            `truck`, etc.  Categories are user-defined with the exception of `any` which is\n            reserved as the default category. Default is `DEFAULT_CATEGORY`, which is `all`.\n        `timespan` (list[TimeString]): timespan of the link property as defined as a list of\n            two HH:MM(:SS) strings. Default is `DEFAULT_TIMESPAN`, which is `[\"00:00\", \"24:00\"]`.\n        `value` (Union[float, int, str]): Value of the link property for the given category and\n            timespan.\n\n    Conflicting or matching scopes are not allowed in a list of ScopedLinkValueItems:\n\n    - `matching`: a scope that could be applied for a given category/timespan combination. This includes the default scopes as well as scopes that are contained within the given category AND timespan combination.\n    - `overlapping`: a scope that fully or partially overlaps a given category OR timespan combination.  This includes the default scopes, all `matching` scopes and all scopes where at least one minute of timespan or one category overlap.\n    - `conflicting`: a scope that is overlapping but not matching for a given category/timespan.\n\n    NOTE: Default scope values of `category: any` and `timespan:[\"00:00\", \"24:00\"]` are **not** considered conflicting, but are applied to residual scopes.\n    \"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"category\", \"timespan\"]]\n    model_config = ConfigDict(extra=\"forbid\")\n    category: Optional[Union[str, int]] = Field(default=DEFAULT_CATEGORY)\n    timespan: Optional[list[TimeString]] = Field(default=DEFAULT_TIMESPAN)\n    value: Union[int, float, str]\n\n    @property\n    def timespan_dt(self) -&gt; list[list[datetime]]:\n        \"\"\"Convert timespan to list of datetime objects.\"\"\"\n        return str_to_time_list(self.timespan)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueItem.timespan_dt","title":"<code>timespan_dt: list[list[datetime]]</code>  <code>property</code>","text":"<p>Convert timespan to list of datetime objects.</p>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueList","title":"<code>ScopedLinkValueList</code>","text":"<p>               Bases: <code>RootListMixin</code>, <code>RootModel</code></p> <p>List of non-conflicting ScopedLinkValueItems.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class ScopedLinkValueList(RootListMixin, RootModel):\n    \"\"\"List of non-conflicting ScopedLinkValueItems.\"\"\"\n\n    root: list[ScopedLinkValueItem]\n\n    def overlapping_timespans(self, timespan: Timespan):\n        \"\"\"Identify overlapping timespans in the list.\"\"\"\n        timespan_dt = str_to_time_list(timespan)\n        return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n\n    @model_validator(mode=\"after\")\n    def check_conflicting_scopes(self):\n        \"\"\"Check for conflicting scopes in the list.\"\"\"\n        conflicts = []\n        for i in self:\n            if i.timespan == DEFAULT_TIMESPAN:\n                continue\n            overlapping_ts_i = self.overlapping_timespans(i.timespan)\n            for j in overlapping_ts_i:\n                if j == i:\n                    continue\n                if j.category == i.category:\n                    conflicts.append((i, j))\n        if conflicts:\n            msg = \"Conflicting scopes in ScopedLinkValueList:\\n\"\n            WranglerLogger.error(msg + f\" Conflicts: \\n{conflicts}\")\n            raise ScopeLinkValueError(msg)\n\n        return self\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueList.check_conflicting_scopes","title":"<code>check_conflicting_scopes()</code>","text":"<p>Check for conflicting scopes in the list.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_conflicting_scopes(self):\n    \"\"\"Check for conflicting scopes in the list.\"\"\"\n    conflicts = []\n    for i in self:\n        if i.timespan == DEFAULT_TIMESPAN:\n            continue\n        overlapping_ts_i = self.overlapping_timespans(i.timespan)\n        for j in overlapping_ts_i:\n            if j == i:\n                continue\n            if j.category == i.category:\n                conflicts.append((i, j))\n    if conflicts:\n        msg = \"Conflicting scopes in ScopedLinkValueList:\\n\"\n        WranglerLogger.error(msg + f\" Conflicts: \\n{conflicts}\")\n        raise ScopeLinkValueError(msg)\n\n    return self\n</code></pre>"},{"location":"data_models/#network_wrangler.models.roadway.types.ScopedLinkValueList.overlapping_timespans","title":"<code>overlapping_timespans(timespan)</code>","text":"<p>Identify overlapping timespans in the list.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>def overlapping_timespans(self, timespan: Timespan):\n    \"\"\"Identify overlapping timespans in the list.\"\"\"\n    timespan_dt = str_to_time_list(timespan)\n    return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n</code></pre>"},{"location":"data_models/#transit","title":"Transit","text":"<p>Main functionality for GTFS tables including Feed object.</p>"},{"location":"data_models/#network_wrangler.transit.feed.feed.Feed","title":"<code>Feed</code>","text":"<p>               Bases: <code>DBModelMixin</code></p> <p>Wrapper class around Wrangler flavored GTFS feed.</p> <p>Most functionality derives from mixin class DBModelMixin which provides:</p> <ul> <li>validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)</li> <li>validation of fks when setting a table attribute (e.g. self.trips = trips_df)</li> <li>hashing and deep copy functionality</li> <li>overload of eq to apply only to tables in table_names.</li> <li>convenience methods for accessing tables</li> </ul> <p>Attributes:</p> Name Type Description <code>table_names</code> <code>list[str]</code> <p>list of table names in GTFS feed.</p> <code>tables</code> <code>list[DataFrame]</code> <p>: list tables as dataframes.</p> <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>: stop_times dataframe with roadway node_ids</p> <code>stops</code> <code>DataFrame[WranglerStopsTable]</code> <p>stops dataframe</p> <code>shapes(DataFrame[WranglerShapesTable])</code> <code>DataFrame[WranglerStopsTable]</code> <p>shapes dataframe</p> <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>trips dataframe</p> <code>frequencies</code> <code>DataFrame[WranglerFrequenciesTable]</code> <p>frequencies dataframe</p> <code>routes</code> <code>DataFrame[RoutesTable]</code> <p>route dataframe</p> <code>agencies</code> <code>Optional[DataFrame[AgenciesTable]]</code> <p>agencies dataframe</p> <code>net</code> <code>Optional[TransitNetwork]</code> <p>TransitNetwork object</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>class Feed(DBModelMixin):\n    \"\"\"Wrapper class around Wrangler flavored GTFS feed.\n\n    Most functionality derives from mixin class DBModelMixin which provides:\n\n    - validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)\n    - validation of fks when setting a table attribute (e.g. self.trips = trips_df)\n    - hashing and deep copy functionality\n    - overload of __eq__ to apply only to tables in table_names.\n    - convenience methods for accessing tables\n\n    Attributes:\n        table_names (list[str]): list of table names in GTFS feed.\n        tables (list[DataFrame]):: list tables as dataframes.\n        stop_times (DataFrame[WranglerStopTimesTable]):: stop_times dataframe with roadway node_ids\n        stops (DataFrame[WranglerStopsTable]):stops dataframe\n        shapes(DataFrame[WranglerShapesTable]): shapes dataframe\n        trips (DataFrame[WranglerTripsTable]): trips dataframe\n        frequencies (DataFrame[WranglerFrequenciesTable]): frequencies dataframe\n        routes (DataFrame[RoutesTable]): route dataframe\n        agencies (Optional[DataFrame[AgenciesTable]]): agencies dataframe\n        net (Optional[TransitNetwork]): TransitNetwork object\n    \"\"\"\n\n    # the ordering here matters because the stops need to be added before stop_times if\n    # stop times needs to be converted\n    _table_models: ClassVar[dict] = {\n        \"agencies\": AgenciesTable,\n        \"frequencies\": WranglerFrequenciesTable,\n        \"routes\": RoutesTable,\n        \"shapes\": WranglerShapesTable,\n        \"stops\": WranglerStopsTable,\n        \"trips\": WranglerTripsTable,\n        \"stop_times\": WranglerStopTimesTable,\n    }\n\n    # Define the converters if the table needs to be converted to a Wrangler table.\n    # Format: \"table_name\": converter_function\n    _converters: ClassVar[dict[str, Callable]] = {}\n\n    table_names: ClassVar[list[str]] = [\n        \"frequencies\",\n        \"routes\",\n        \"shapes\",\n        \"stops\",\n        \"trips\",\n        \"stop_times\",\n    ]\n\n    optional_table_names: ClassVar[list[str]] = [\"agencies\"]\n\n    def __init__(self, **kwargs):\n        \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n        Args:\n            kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n        \"\"\"\n        self._net = None\n        self.feed_path: Path = None\n        self.initialize_tables(**kwargs)\n\n        # Set extra provided attributes but just FYI in logger.\n        extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n        if extra_attr:\n            WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n        for k, v in extra_attr:\n            self.__setattr__(k, v)\n\n    def set_by_id(\n        self,\n        table_name: str,\n        set_df: pd.DataFrame,\n        id_property: str = \"index\",\n        properties: Optional[list[str]] = None,\n    ):\n        \"\"\"Set one or more property values based on an ID property for a given table.\n\n        Args:\n            table_name (str): Name of the table to modify.\n            set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n                values to set for the specified property where `&lt;id_property&gt;` is unique.\n            id_property: Property to use as ID to set by. Defaults to \"index\".\n            properties: List of properties to set which are in set_df. If not specified, will set\n                all properties.\n        \"\"\"\n        if not set_df[id_property].is_unique:\n            msg = f\"{id_property} must be unique in set_df.\"\n            _dupes = set_df[id_property][set_df[id_property].duplicated()]\n            WranglerLogger.error(msg + f\"Found duplicates: {_dupes.sum()}\")\n\n            raise ValueError(msg)\n        table_df = self.get_table(table_name)\n        updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n        self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.Feed.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Create a Feed object from a dictionary of DataFrames representing a GTFS feed.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <p>A dictionary containing DataFrames representing the tables of a GTFS feed.</p> <code>{}</code> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n    Args:\n        kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n    \"\"\"\n    self._net = None\n    self.feed_path: Path = None\n    self.initialize_tables(**kwargs)\n\n    # Set extra provided attributes but just FYI in logger.\n    extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n    if extra_attr:\n        WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n    for k, v in extra_attr:\n        self.__setattr__(k, v)\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.Feed.set_by_id","title":"<code>set_by_id(table_name, set_df, id_property='index', properties=None)</code>","text":"<p>Set one or more property values based on an ID property for a given table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table to modify.</p> required <code>set_df</code> <code>DataFrame</code> <p>DataFrame with columns <code>&lt;id_property&gt;</code> and <code>value</code> containing values to set for the specified property where <code>&lt;id_property&gt;</code> is unique.</p> required <code>id_property</code> <code>str</code> <p>Property to use as ID to set by. Defaults to \u201cindex\u201d.</p> <code>'index'</code> <code>properties</code> <code>Optional[list[str]]</code> <p>List of properties to set which are in set_df. If not specified, will set all properties.</p> <code>None</code> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def set_by_id(\n    self,\n    table_name: str,\n    set_df: pd.DataFrame,\n    id_property: str = \"index\",\n    properties: Optional[list[str]] = None,\n):\n    \"\"\"Set one or more property values based on an ID property for a given table.\n\n    Args:\n        table_name (str): Name of the table to modify.\n        set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n            values to set for the specified property where `&lt;id_property&gt;` is unique.\n        id_property: Property to use as ID to set by. Defaults to \"index\".\n        properties: List of properties to set which are in set_df. If not specified, will set\n            all properties.\n    \"\"\"\n    if not set_df[id_property].is_unique:\n        msg = f\"{id_property} must be unique in set_df.\"\n        _dupes = set_df[id_property][set_df[id_property].duplicated()]\n        WranglerLogger.error(msg + f\"Found duplicates: {_dupes.sum()}\")\n\n        raise ValueError(msg)\n    table_df = self.get_table(table_name)\n    updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n    self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.merge_shapes_to_stop_times","title":"<code>merge_shapes_to_stop_times(stop_times, shapes, trips)</code>","text":"<p>Add shape_id and shape_pt_sequence to stop_times dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>stop_times</code> <code>DataFrame[WranglerStopTimesTable]</code> <p>stop_times dataframe to add shape_id and shape_pt_sequence to.</p> required <code>shapes</code> <code>DataFrame[WranglerShapesTable]</code> <p>shapes dataframe to add to stop_times.</p> required <code>trips</code> <code>DataFrame[WranglerTripsTable]</code> <p>trips dataframe to link stop_times to shapes</p> required <p>Returns:</p> Type Description <code>DataFrame[WranglerStopTimesTable]</code> <p>stop_times dataframe with shape_id and shape_pt_sequence added.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def merge_shapes_to_stop_times(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Add shape_id and shape_pt_sequence to stop_times dataframe.\n\n    Args:\n        stop_times: stop_times dataframe to add shape_id and shape_pt_sequence to.\n        shapes: shapes dataframe to add to stop_times.\n        trips: trips dataframe to link stop_times to shapes\n\n    Returns:\n        stop_times dataframe with shape_id and shape_pt_sequence added.\n    \"\"\"\n    stop_times_w_shape_id = stop_times.merge(\n        trips[[\"trip_id\", \"shape_id\"]], on=\"trip_id\", how=\"left\"\n    )\n\n    stop_times_w_shapes = stop_times_w_shape_id.merge(\n        shapes,\n        how=\"left\",\n        left_on=[\"shape_id\", \"stop_id\"],\n        right_on=[\"shape_id\", \"shape_model_node_id\"],\n    )\n    stop_times_w_shapes = stop_times_w_shapes.drop(columns=[\"shape_model_node_id\"])\n    return stop_times_w_shapes\n</code></pre>"},{"location":"data_models/#network_wrangler.transit.feed.feed.stop_count_by_trip","title":"<code>stop_count_by_trip(stop_times)</code>","text":"<p>Returns dataframe with trip_id and stop_count from stop_times.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def stop_count_by_trip(\n    stop_times: DataFrame[WranglerStopTimesTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe with trip_id and stop_count from stop_times.\"\"\"\n    stops_count = stop_times.groupby(\"trip_id\").size()\n    return stops_count.reset_index(name=\"stop_count\")\n</code></pre>"},{"location":"data_models/#pure-gtfs-tables","title":"Pure GTFS Tables","text":"<p>Models for when you want to use vanilla (non wrangler) GTFS.</p>"},{"location":"data_models/#network_wrangler.models.gtfs.BikesAllowed","title":"<code>BikesAllowed</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates whether bicycles are allowed.</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class BikesAllowed(IntEnum):\n    \"\"\"Indicates whether bicycles are allowed.\"\"\"\n\n    NO_INFORMATION = 0\n    ALLOWED = 1\n    NOT_ALLOWED = 2\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.DirectionID","title":"<code>DirectionID</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the direction of travel for a trip.</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class DirectionID(IntEnum):\n    \"\"\"Indicates the direction of travel for a trip.\"\"\"\n\n    OUTBOUND = 0\n    INBOUND = 1\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.LocationType","title":"<code>LocationType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the type of node the stop record represents.</p> <p>Full documentation: https://gtfs.org/schedule/reference/#stopstxt</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class LocationType(IntEnum):\n    \"\"\"Indicates the type of node the stop record represents.\n\n    Full documentation: https://gtfs.org/schedule/reference/#stopstxt\n    \"\"\"\n\n    STOP_PLATFORM = 0\n    STATION = 1\n    ENTRANCE_EXIT = 2\n    GENERIC_NODE = 3\n    BOARDING_AREA = 4\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.MockPaModel","title":"<code>MockPaModel</code>","text":"<p>Mock model for when Pandera is not installed.</p> Source code in <code>network_wrangler/models/gtfs/__init__.py</code> <pre><code>class MockPaModel:\n    \"\"\"Mock model for when Pandera is not installed.\"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Mock modle initiation.\"\"\"\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.MockPaModel.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Mock modle initiation.</p> Source code in <code>network_wrangler/models/gtfs/__init__.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Mock modle initiation.\"\"\"\n    for key, value in kwargs.items():\n        setattr(self, key, value)\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.PickupDropoffType","title":"<code>PickupDropoffType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the pickup method for passengers at a stop.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class PickupDropoffType(IntEnum):\n    \"\"\"Indicates the pickup method for passengers at a stop.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    REGULAR = 0\n    NONE = 1\n    PHONE_AGENCY = 2\n    COORDINATE_WITH_DRIVER = 3\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.RouteType","title":"<code>RouteType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates the type of transportation used on a route.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class RouteType(IntEnum):\n    \"\"\"Indicates the type of transportation used on a route.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    TRAM = 0\n    SUBWAY = 1\n    RAIL = 2\n    BUS = 3\n    FERRY = 4\n    CABLE_TRAM = 5\n    AERIAL_LIFT = 6\n    FUNICULAR = 7\n    TROLLEYBUS = 11\n    MONORAIL = 12\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.TimepointType","title":"<code>TimepointType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates whether the specified time is exact or approximate.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class TimepointType(IntEnum):\n    \"\"\"Indicates whether the specified time is exact or approximate.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    APPROXIMATE = 0\n    EXACT = 1\n</code></pre>"},{"location":"data_models/#network_wrangler.models.gtfs.WheelchairAccessible","title":"<code>WheelchairAccessible</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Indicates whether the trip is wheelchair accessible.</p> <p>Full documentation: https://gtfs.org/schedule/reference</p> Source code in <code>network_wrangler/models/gtfs/types.py</code> <pre><code>class WheelchairAccessible(IntEnum):\n    \"\"\"Indicates whether the trip is wheelchair accessible.\n\n    Full documentation: https://gtfs.org/schedule/reference\n    \"\"\"\n\n    NO_INFORMATION = 0\n    POSSIBLE = 1\n    NOT_POSSIBLE = 2\n</code></pre>"},{"location":"data_models/#project-cards","title":"Project Cards","text":""},{"location":"data_models/#projects","title":"Projects","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing roadway deletion project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>class RoadwayDeletion(RecordModel):\n    \"\"\"Requirements for describing roadway deletion project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"links\", \"nodes\"]]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    links: Optional[SelectLinksDict] = None\n    nodes: Optional[SelectNodesDict] = None\n    clean_shapes: bool = False\n    clean_nodes: bool = False\n\n    @field_validator(\"links\")\n    @classmethod\n    def set_to_all_modes(cls, links: Optional[SelectLinksDict] = None):\n        \"\"\"Set the search mode to 'any' if not specified explicitly.\"\"\"\n        if links is not None and links.modes == DEFAULT_SEARCH_MODES:\n            links.modes = DEFAULT_DELETE_MODES\n        return links\n</code></pre> <p>               Bases: <code>RecordModel</code></p> <p>Value for setting property value for a time of day and category.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>class RoadPropertyChange(RecordModel):\n    \"\"\"Value for setting property value for a time of day and category.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", exclude_none=True)\n\n    existing: Optional[Any] = None\n    change: Optional[Union[int, float]] = None\n    set: Optional[Any] = None\n    scoped: Optional[Union[None, ScopedPropertySetList]] = None\n    overwrite_scoped: Optional[Literal[\"conflicting\", \"all\", \"error\"]] = None\n    existing_value_conflict: Optional[Literal[\"error\", \"warn\", \"skip\"]] = None\n\n    require_one_of: ClassVar[OneOf] = [\n        [\"change\", \"set\"],\n    ]\n\n    _examples: ClassVar[list] = [\n        {\"set\": 1},\n        {\"existing\": 2, \"change\": -1},\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\"timespan\": [\"6:00\", \"9:00\"], \"value\": 2.0},\n                {\"timespan\": [\"9:00\", \"15:00\"], \"value\": 4.0},\n            ],\n        },\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\n                    \"categories\": [\"hov3\", \"hov2\"],\n                    \"timespan\": [\"6:00\", \"9:00\"],\n                    \"value\": 2.0,\n                },\n                {\"category\": \"truck\", \"timespan\": [\"6:00\", \"9:00\"], \"value\": 4.0},\n            ],\n        },\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\"categories\": [\"hov3\", \"hov2\"], \"value\": 2.0},\n                {\"category\": \"truck\", \"value\": 4.0},\n            ],\n        },\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_changes.RoadwayDeletion.set_to_all_modes","title":"<code>set_to_all_modes(links=None)</code>  <code>classmethod</code>","text":"<p>Set the search mode to \u2018any\u2019 if not specified explicitly.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@field_validator(\"links\")\n@classmethod\ndef set_to_all_modes(cls, links: Optional[SelectLinksDict] = None):\n    \"\"\"Set the search mode to 'any' if not specified explicitly.\"\"\"\n    if links is not None and links.modes == DEFAULT_SEARCH_MODES:\n        links.modes = DEFAULT_DELETE_MODES\n    return links\n</code></pre>"},{"location":"data_models/#roadway-selections","title":"Roadway Selections","text":"<p>Data models for selecting roadway facilities in a project card.</p>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.RoadwaySelectionFormatError","title":"<code>RoadwaySelectionFormatError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with the format of a selection.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class RoadwaySelectionFormatError(Exception):\n    \"\"\"Raised when there is an issue with the format of a selection.\"\"\"\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectFacility","title":"<code>SelectFacility</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Roadway Facility Selection.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectFacility(RecordModel):\n    \"\"\"Roadway Facility Selection.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [\n        [\"links\", \"nodes\", [\"links\", \"from\", \"to\"]],\n    ]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    links: Optional[SelectLinksDict] = None\n    nodes: Optional[SelectNodesDict] = None\n    from_: Annotated[Optional[SelectNodeDict], Field(None, alias=\"from\")]\n    to: Optional[SelectNodeDict] = None\n\n    _examples: ClassVar[list[dict]] = [\n        {\n            \"links\": {\"name\": [\"Main Street\"]},\n            \"from\": {\"model_node_id\": 1},\n            \"to\": {\"model_node_id\": 2},\n        },\n        {\"nodes\": {\"osm_node_id\": [\"1\", \"2\", \"3\"]}},\n        {\"nodes\": {\"model_node_id\": [1, 2, 3]}},\n        {\"links\": {\"model_link_id\": [1, 2, 3]}},\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectLinksDict","title":"<code>SelectLinksDict</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>requirements for describing links in the <code>facility</code> section of a project card.</p> <p>Examples:</p> <pre><code>    {'name': ['Main St'], 'modes': ['drive']}\n    {'osm_link_id': ['123456789']}\n    {'model_link_id': [123456789], 'modes': ['walk']}\n    {'all': 'True', 'modes': ['transit']}\n    {'all': 'True', name': ['Main St']}\n</code></pre> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectLinksDict(RecordModel):\n    \"\"\"requirements for describing links in the `facility` section of a project card.\n\n    Examples:\n    ```python\n        {'name': ['Main St'], 'modes': ['drive']}\n        {'osm_link_id': ['123456789']}\n        {'model_link_id': [123456789], 'modes': ['walk']}\n        {'all': 'True', 'modes': ['transit']}\n        {'all': 'True', name': ['Main St']}\n    ```\n\n    \"\"\"\n\n    require_conflicts: ClassVar[ConflictsWith] = [\n        [\"all\", \"osm_link_id\"],\n        [\"all\", \"model_link_id\"],\n        [\"all\", \"name\"],\n        [\"all\", \"ref\"],\n        [\"osm_link_id\", \"model_link_id\"],\n        [\"osm_link_id\", \"name\"],\n        [\"model_link_id\", \"name\"],\n    ]\n    require_any_of: ClassVar[AnyOf] = [[\"name\", \"ref\", \"osm_link_id\", \"model_link_id\", \"all\"]]\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    all: Optional[bool] = False\n    name: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    ref: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    osm_link_id: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    model_link_id: Annotated[Optional[list[int]], Field(None, min_length=1)]\n    modes: list[str] = DEFAULT_SEARCH_MODES\n    ignore_missing: Optional[bool] = True\n\n    _examples: ClassVar[list[dict]] = [\n        {\"name\": [\"Main St\"], \"modes\": [\"drive\"]},\n        {\"osm_link_id\": [\"123456789\"]},\n        {\"model_link_id\": [123456789], \"modes\": [\"walk\"]},\n        {\"all\": \"True\", \"modes\": [\"transit\"]},\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodeDict","title":"<code>SelectNodeDict</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection of a single roadway node in the <code>facility</code> section of a project card.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectNodeDict(RecordModel):\n    \"\"\"Selection of a single roadway node in the `facility` section of a project card.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [[\"osm_node_id\", \"model_node_id\"]]\n    model_config = ConfigDict(extra=\"allow\")\n\n    osm_node_id: Optional[str] = None\n    model_node_id: Optional[int] = None\n\n    _examples: ClassVar[list[dict]] = [{\"osm_node_id\": \"12345\"}, {\"model_node_id\": 67890}]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.roadway_selection.SelectNodesDict","title":"<code>SelectNodesDict</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple nodes of a project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectNodesDict(RecordModel):\n    \"\"\"Requirements for describing multiple nodes of a project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"osm_node_id\", \"model_node_id\"]]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    all: Optional[bool] = False\n    osm_node_id: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    model_node_id: Annotated[Optional[list[int]], Field(min_length=1)]\n    ignore_missing: Optional[bool] = True\n\n    _examples: ClassVar[list[dict]] = [\n        {\"osm_node_id\": [\"12345\", \"67890\"], \"model_node_id\": [12345, 67890]},\n        {\"osm_node_id\": [\"12345\", \"67890\"]},\n        {\"model_node_id\": [12345, 67890]},\n    ]\n</code></pre>"},{"location":"data_models/#transit-selections","title":"Transit Selections","text":"<p>Data Models for selecting transit trips, nodes, links, and routes.</p>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectRouteProperties","title":"<code>SelectRouteProperties</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit routes.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectRouteProperties(RecordModel):\n    \"\"\"Selection properties for transit routes.\"\"\"\n\n    route_short_name: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    route_long_name: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    agency_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    route_type: Annotated[Optional[list[int]], Field(None, min_length=1)]\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTransitLinks","title":"<code>SelectTransitLinks</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple transit links of a project card.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitLinks(RecordModel):\n    \"\"\"Requirements for describing multiple transit links of a project card.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [\n        [\"ab_nodes\", \"model_link_id\"],\n    ]\n\n    model_link_id: Annotated[Optional[list[int]], Field(min_length=1)] = None\n    ab_nodes: Annotated[Optional[list[TransitABNodesModel]], Field(min_length=1)] = None\n    require: Optional[SelectionRequire] = \"any\"\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n    _examples: ClassVar[list[dict]] = [\n        {\n            \"ab_nodes\": [{\"A\": \"75520\", \"B\": \"66380\"}, {\"A\": \"66380\", \"B\": \"75520\"}],\n            \"type\": \"any\",\n        },\n        {\n            \"model_link_id\": [123, 321],\n            \"type\": \"all\",\n        },\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTransitNodes","title":"<code>SelectTransitNodes</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple transit nodes of a project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitNodes(RecordModel):\n    \"\"\"Requirements for describing multiple transit nodes of a project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [\n        [\n            \"model_node_id\",\n            # \"gtfs_stop_id\", TODO Not implemented\n        ]\n    ]\n\n    # gtfs_stop_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)] TODO Not implemented\n    model_node_id: Annotated[list[int], Field(min_length=1)]\n    require: Optional[SelectionRequire] = \"any\"\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n\n    _examples: ClassVar[list[dict]] = [\n        # {\"gtfstop_id\": [\"stop1\", \"stop2\"], \"require\": \"any\"},  TODO Not implemented\n        {\"model_node_id\": [1, 2], \"require\": \"all\"},\n    ]\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTransitTrips","title":"<code>SelectTransitTrips</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit trips.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitTrips(RecordModel):\n    \"\"\"Selection properties for transit trips.\"\"\"\n\n    trip_properties: Optional[SelectTripProperties] = None\n    route_properties: Optional[SelectRouteProperties] = None\n    timespans: Annotated[Optional[list[TimespanString]], Field(None, min_length=1)]\n    nodes: Optional[SelectTransitNodes] = None\n    links: Optional[SelectTransitLinks] = None\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.SelectTripProperties","title":"<code>SelectTripProperties</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit trips.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTripProperties(RecordModel):\n    \"\"\"Selection properties for transit trips.\"\"\"\n\n    trip_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    shape_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    direction_id: Annotated[Optional[int], Field(None)]\n    service_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    route_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    trip_short_name: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"data_models/#network_wrangler.models.projects.transit_selection.TransitABNodesModel","title":"<code>TransitABNodesModel</code>","text":"<p>               Bases: <code>RecordModel</code></p> <p>Single transit link model.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class TransitABNodesModel(RecordModel):\n    \"\"\"Single transit link model.\"\"\"\n\n    A: Optional[int] = None  # model_node_id\n    B: Optional[int] = None  # model_node_id\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"design/","title":"Design","text":""},{"location":"design/#atomic-parts","title":"Atomic Parts","text":"flowchart TD     subgraph BaseScenario         base_road_net[\"road_net(RoadwayNetwork)\"]         base_transit_net[\"transit_net(TransitNetwork)\"]         applied_projects[\"applied_projects(list)\"]         conflicts[\"conflicts(dict)\"]     end     BaseScenario --&gt; base_scenario     subgraph Scenario     base_scenario[\"base_scenario(dict)\"]     projects[\"projects(ProjectCard`\"]     road_net[\"road_net(RoadwayNetwork)\"]     transit_net[\"transit_net(TransitNetwork)\"]     config[\"config(WranglerConfig)\"]     end <p>NetworkWrangler deals with four primary atomic parts:</p> <p>1. <code>Scenario</code> objects describe a Roadway Network, Transit Network, and collection of Projects. Scenarios manage the addition and construction of projects on the network via projct cards including required pre-requisites, co-requisites, and conflicts. Scenarios can be based on or tiered from other scenarios but must at the very least be based on an existing roadway and/or transit network defined in <code>base_scenario</code>.</p> <p>2. <code>RoadwayNetwork</code> objects stores information about roadway nodes, directed links between nodes, and the shapes of links (note that the same shape can be shared between two or more links). Network Wrangler reads/writes roadway network objects from/to three files: <code>links</code>, <code>shape</code>, and <code>nodes</code>. Their data is stored as GeoDataFrames in the object.</p> <p>3. <code>TransitNetwork</code> objects contain information about the service (represented by the GTFS-compatable <code>Feed</code> object with stops, routes, trips, shapes, stoptimes, and frequencies tables), and how it maps to a <code>RoadwayNetwork</code>, stored as <code>road_net</code> attribute.  Network Wrangler reads/writes transit network information from/to gtfs-like files and stores them as DataFrames within.</p> <p>4.<code>ProjectCard</code> objects store information (including  metadata) about changes to the network.  Network Wrangler uses the <code>projectcard</code> package to read project cards from .yaml-like files and validate them.</p>"},{"location":"design/#applying-projects","title":"Applying Projects","text":"<p>The basic functionality of NetworkWrangler is to apply a set of projects to a scenario.</p> <pre><code>from project_card import read_cards\ncards = read_cards([\n    \"projects/project_a.yml\",\n    \"projects/project_b.yml\",\n    \"projects/project_c.yml\",\n])\nmy_scenario.add_project_cards(cards.values())\nmy_scenario.queued_projects\n&gt;&gt;  [\"project_a\", \"project_b\", \"project_c\"]\nmy_scenario.apply_projects([\"project_a\"])\nmy_scenario.applied_projects\n&gt;&gt; [\"project_a\"]\nmy_scenario.queued_projects\n&gt;&gt;  [\"project_b\", \"project_c\"]\nmy_scenario.apply_all_projects()\nmy_scenario.applied_projects\n&gt;&gt; [\"project_a\", \"project_b\", \"project_c\"]\n</code></pre>"},{"location":"design/#project-dependencies","title":"Project Dependencies","text":"<p>Each project can specify any number of other projects (by project name) as a:</p> <ul> <li><code>prerequisite</code>: list of projects that must be applied before this one.</li> <li><code>corequisite</code>: list of projects that must be applied alongside this one (but not necessarily first).</li> <li><code>conflicts</code>: list of projects that must not be applied to the same scenario as this one.</li> </ul> <p>The Scenario object keeps track of the applied projects to make sure that these dependencies are enforced.</p> <p>Base Scenarios with applied projects</p> <p>Make sure your base scenario contains your applied projects and their conflicts.  This can be easily enforced by either loading a scenario from its .yml file or if you are seeding the base_scenario with an actual Scenario object instead of a dictionary.</p>"},{"location":"design/#order-of-project-application","title":"Order of project application","text":"<p>The order projects are applied defaults to the order they are specified in <code>my_scenario.projects</code>.  If a project card lists another project as a <code>prerequisite</code>, then NetworkWrangler will re-arrange the queued projects to make sure that is applied first.</p> <p>This order can always be reviewed in <code>my_scenario.queued_projects</code>.</p>"},{"location":"design/#existing-values","title":"Existing Values","text":"<p>You can control the behavior of Network Wrangler if existing value is not equal to the <code>existing</code> attribute in a ProjectCard as follows:</p> <ul> <li><code>error</code>: Raise an error.</li> <li><code>skip</code>: Skips applying the project.</li> <li><code>warn</code>: Writes a warning about conflicting values. This is the global default.</li> </ul> <p>These options can be set at the global configuration level by using WranglerConfig.</p> <pre><code>EDITS:\n    EXISTING_VALUE_CONFLICT: warn\n</code></pre> <p>This behavior can be overridden within a project card for a <code>roadway_property_change</code> or <code>transit_property_change</code> project for any individual <code>property_changes</code> item.</p> <pre><code>transit_property_change:\n    property_changes:\n        headway_secs:\n            existing: 360\n            change: -180\n            existing_value_conflict: error # this overrides the setting in WranglerConfig to error if the existing value is not 360.\n</code></pre>"},{"location":"design/#scoped-roadway-property-changes","title":"Scoped Roadway Property Changes","text":"<p>In some cases, properties of a roadway network may apply only during certain times of the day or for certain categories of users (e.g. trucks, HOV2, etc).  The Network Wrangler data model provides the ability to scope each property using the syntax described in the network documentation.</p> <p>The value for a scoped property for a given link record is a list of ScopedLinkValueItem objects.</p> <p>Define the value of a link property for a particular timespan or category.</p> <p>Attributes:</p> Name Type Description <code>`category`</code> <code>str</code> <p>Category or link user that this scoped value applies to, ex: <code>HOV2</code>, <code>truck</code>, etc.  Categories are user-defined with the exception of <code>any</code> which is reserved as the default category. Default is <code>DEFAULT_CATEGORY</code>, which is <code>all</code>.</p> <code>`timespan`</code> <code>list[TimeString]</code> <p>timespan of the link property as defined as a list of two HH:MM(:SS) strings. Default is <code>DEFAULT_TIMESPAN</code>, which is <code>[\"00:00\", \"24:00\"]</code>.</p> <code>`value`</code> <code>Union[float, int, str]</code> <p>Value of the link property for the given category and timespan.</p> <p>Conflicting or matching scopes are not allowed in a list of ScopedLinkValueItems:</p> <ul> <li><code>matching</code>: a scope that could be applied for a given category/timespan combination. This includes the default scopes as well as scopes that are contained within the given category AND timespan combination.</li> <li><code>overlapping</code>: a scope that fully or partially overlaps a given category OR timespan combination.  This includes the default scopes, all <code>matching</code> scopes and all scopes where at least one minute of timespan or one category overlap.</li> <li><code>conflicting</code>: a scope that is overlapping but not matching for a given category/timespan.</li> </ul> <p>NOTE: Default scope values of <code>category: any</code> and <code>timespan:[\"00:00\", \"24:00\"]</code> are not considered conflicting, but are applied to residual scopes.</p> <p>There are a few ways that network wrangler can treat conflicts:</p> <ul> <li><code>conflicting</code> (default behavior):  overwrite any conflicting scoped properties for that property/link with what is given in the project card.</li> <li><code>all</code>: overwrite all scoped properties for that property/link with what is given in the project card.</li> <li><code>error</code>: raise an error when a conflict is detected.</li> </ul> <p>These options can be set at the global configuration level by using WranglerConfig.</p> <pre><code>EDITS:\n    OVERWRITE_SCOPED: error # will default to raising an error if any scoped value in this specific property change conflicts with this scope.\n</code></pre> <p>This behavior can be overridden within a project card for a <code>roadway_property_change</code> project for any individual <code>property_changes</code> item.</p> <pre><code>roadway_property_change:\n    property_changes:\n        sc_myproperty:\n            set: 1\n            scoped:\n                timespan: [[12:00, 15:00]]\n                set: 2\n            overwrite_scoped: all # will overwrite all scopes in a link/property. Useful if you are completely defining something rather than amending.\n</code></pre>"},{"location":"design/#selections","title":"Selections","text":""},{"location":"design/#roadway","title":"Roadway","text":""},{"location":"design/#segment","title":"Segment","text":"<p>Example Segment Facility Searches</p> <pre><code>facility:\n    links:\n        name: [\"6th\", \"Sixth\", \"sixth\"] # find streets that have one of the various forms of 6th\n    from:\n        osm_node_id: \"187899923\"  # start searching for segments at this ID\n    to:\n        osm_node_id\": \"187865924\" # end at this ID\n</code></pre> <pre><code>facility:\n    links:\n        name: [\"6th\", \"Sixth\", \"sixth\"]\n        lanes: [2, 3]  # from the initial connected segment search, only return links that are either 2 OR 3 lanes\n    from:\n        osm_node_id: \"187899923\"\n    to:\n        osm_node_id\": \"187942339\"\n</code></pre> <p>When Network Wrangler conducts a search for a facility, it tries to navigate from the <code>from</code> node to the <code>to</code> node based on a network created from the initial selection values of: <code>name</code>, <code>ref</code>, <code>osm_link_id</code> and <code>model_link_id</code>.</p> <p>If it cannot do so initially, it will expand its search graph several times until it achieves a navigable route \u2013\u00a0or reaches the maximum number of expansions which defaults to <code>roadway.segment.DEFAULT_MAX_SEARCH_BREADTH = 10</code> but can be set higher by running <code>...selection.create_segment(max_search_breadth=BIGGER_NUMBER</code> before returning the values form the selection. In production, you will want to set the search breadth as low as possible while also being successful so that you don\u2019t get strange routes.</p> <p>Pertinent relationships:</p> <ul> <li><code>RoadwayNetwork.selections</code> is a dictionary of stored  <code>RoadwayLinkSelection</code> or <code>RoadwayNodeSelection</code> objects mapped to a hash of the stringified roadway selection dictionary.</li> <li>A <code>RoadwayLinkSelection</code> object which is a <code>segment</code> type of selection will have a single associated <code>Segment</code> object accessed from <code>RoadwayLinkSelection.segment</code> to store relevant functionality.</li> <li><code>Segment.subnet</code> is a single associated <code>Subnet</code> representing the subset of nodes and links that Network Wrangler will search to find a connected graph.  This is because creating a connected graph can be very memory and computationally intensive and we want to limit the size of them substantially.</li> <li><code>Subnet.graph</code> is the associated <code>networkx.MultiDiGraph</code> connected graph object which is used to conduct the shortest path search.</li> </ul> <p>For an interactive demonstration of what this means: <code>notebooks.Roadway Network Search.ipynb</code></p>"},{"location":"design/#organization","title":"Organization","text":"<code>../network_wrangler</code> <code>__init__.py</code> Things that must get done every time <code>network_wrangler</code> is used. <code>bin</code> Executable scripts. <code>configs</code> Structure and default values for user-settable configuration. <code>errors.py</code> User-facing errors. <code>logger.py</code> Logging utilities and the WranglerLogger class. <code>models</code> Pydantic and pandera data models and helper functions for them. <code>params.py</code> Package-wide constants. <code>roadway</code> Classes and functions pertaining to read, write, analyzing and editing roadway networks. <code>scenario.py</code> Scenario object class and helper functions. <code>time.py</code> Time helper functions. <code>transit</code> Classes and functions pertaining to read, write, analyzing and editing transit networks. <code>utils</code> Utility functions. <code>viz.py</code> Visualization helper functions. <code>network_wrangler/roadway</code> <code>links</code> Module for managing roadway links. <code>nodes</code> Module for managing roadway nodes. <code>projects</code> Module with functions to apply various types of roadway projects. <code>shapes</code> Module for managing roadway shapes. <code>clip.py</code> Functions to clip a RoadwayNetwork object to a boundary. <code>graph.py</code> Functions to convert RoadwayNetwork to osmnx graph and perform graph operations. <code>io.py</code> Functions for reading and writing roadway networks. <code>model_roadway.py</code> Functions to create a model roadway network from a roadway network. <code>network.py</code> Roadway Network class and functions for Network Wrangler. <code>segment.py</code> Segment class and related functions for working with segments of a RoadwayNetwork. <code>selection.py</code> Roadway selection classes for selecting links and nodes from a roadway network. <code>subnet.py</code> Subnet class for RoadwayNetwork object. <code>utils.py</code> Utility functions for RoadwayNetwork and ModelRoadwayNetwork classes. <code>validate.py</code> Validates a roadway network to the wrangler data model specifications. <code>viz.py</code> Visualization functions for RoadwayNetwork and RoadwayLinkSelection. <code>network_wrangler/transit</code> <code>feed</code> Relational tables representing transit service. <code>projects</code> Module with functions to apply various types of transit projects. <code>clip.py</code> Functions to clip a TransitNetwork object to a boundary. <code>geo.py</code> Geographic functions for GTFS tables. <code>io.py</code> Functions for reading and writing transit feeds and networks. <code>model_transit.py</code> ModelTransit class and functions for managing consistency between roadway and transit networks. <code>network.py</code> TransitNetwork class for representing a transit network consisting of a schedule <code>Feed</code> mapped to a <code>RoadwayNetwork</code>. <code>selection.py</code> Classes and functions for selecting transit trips from a transit network. <code>validate.py</code> Functions to check for transit network validity and consistency with roadway network."},{"location":"development/","title":"Development","text":""},{"location":"development/#contributing-to-network-wrangler","title":"Contributing to Network Wrangler","text":""},{"location":"development/#setup","title":"Setup","text":""},{"location":"development/#recommended-tools","title":"Recommended Tools","text":"<ul> <li>GitHub desktop to manage access to the main repository.</li> <li>Git to conduct required version control.</li> <li>MiniConda to manage your Python environments.</li> <li>VSCode to edit and test code.</li> <li>Some type of terminal application (note, this comes with Mac/Ubuntu).</li> </ul>"},{"location":"development/#setup-virtual-environment","title":"Setup Virtual Environment","text":"<p>Create and/or activate the virtual environment where you want to install Network Wrangler.</p> <p>Creating and activating a virtual environment using conda</p> <pre><code>conda config --add channels conda-forge\nconda create python=3.11 -n wrangler-dev #if you don't already have a virtual environment\nconda activate wrangler-dev\n</code></pre>"},{"location":"development/#clone","title":"Clone","text":"<p>To effectively work on Network Wrangler locally, install it from a clone by either:</p> <ol> <li>Use the GitHub user interface by clicking on the green button \u201cclone or download\u201d in the main network wrangler repository page.</li> <li>Use the command prompt in a terminal to navigate to the directory that you would like to store your network wrangler clone and then using a git command to clone it.</li> </ol> <p>Clone network wrangler</p> <pre><code>cd path to where you want to put wrangler\ngit clone https://github.com/wsp-sag/network_wrangler\n</code></pre>"},{"location":"development/#install-in-develop-mode","title":"Install in Develop Mode","text":"<p>Install Network Wrangler in \u201cdevelop\u201d mode using the <code>-e</code> flag so that changes to your code will be reflected when you are using and testing network wrangler:</p> <p>Install Network Wrangler from Clone</p> <pre><code>cd network_wrangler\npip install -e .\n</code></pre> <p>Install development dependencies</p> <pre><code>pip install -r requirements.tests.txt\npip install -r requirements.docs.txt\n</code></pre>"},{"location":"development/#ide-settings","title":"IDE Settings","text":""},{"location":"development/#vscode","title":"VSCode","text":"<p>Select conda env as Python interpreter:</p> <pre><code>- `cmd-shift-P`: Python: Select Interpreter\n</code></pre> <p>If you are using VS Code, here are some recommended extensions and settings to leverage the IDE capabilities:</p> Extension Purpose Microsoft Python Pytest integration, code-completion Astral Ruff Linting and formatting Microsoft Jupyter Edit and run python notebooks Microsoft Data Wrangler Review and edit data in pandas dataframes David Anson markdownlint Lint markdown Github Pull Requests Manage github issues and PRs Dvir Yitzchaki parquet-viewer Review parquet data as json Random Fractals Inc. Geo Data Viewer Render geojson data <p>Leveraging these extensions to their full potential may take some configuration. Here are some examples. YMMV.</p> <p><code>settings.json</code> for VS Code</p> <pre><code>{\n    \"[python]\": {\n    \"editor.formatOnSave\": true,\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\",\n    \"editor.codeActionsOnSave\": {\n    \"source.fixAll\": \"explicit\",\n    \"source.organizeImports\": \"explicit\"\n    }\n},\n    \"python.testing.pytestArgs\": [\n        \"tests\"\n    ],\n    \"python.testing.unittestEnabled\": false,\n    \"python.testing.pytestEnabled\": true,\n    \"python.testing.cwd\": \"\",\n    \"python.testing.autoTestDiscoverOnSaveEnabled\": true,\n    \"python.defaultInterpreterPath\": \"/usr/bin/env python\",\n    \"python.testing.pytestPath\": \"/opt/miniconda3/envs/wrangler-dev/bin/pytest\",\n}\n</code></pre> <p>Code &gt; Settings &gt; Settings</p> <p>For tests to run in conda environment, add path to it. To find it, you can run <code>conda info --envs</code></p> <p><code>@id:python.condaPath</code>: <code>opt/miniconda3/envs/wrangler-dev</code></p>"},{"location":"development/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create an issue for any features/bugs that you are working on.</li> <li>Create a branch to work on a new issue (or checkout an existing one where the issue is being worked on).  </li> <li>Develop comprehensive tests in the <code>/tests</code> folder.</li> <li>Modify code including inline documentation such that it passes all  tests (not just your new ones)</li> <li>Lint code using <code>pre-commit run --all-files</code></li> <li>Fill out information in the pull request template</li> <li>Submit all pull requests to the <code>develop</code> branch.</li> <li>Core developer will review your pull request and suggest changes.</li> <li>After requested changes are complete, core developer will sign off on pull-request merge.</li> </ol> <p>Tip</p> <p>Keep pull requests small and focused. One issue is best.</p> <p>Tip</p> <p>Don\u2019t forget to update any associated documentation as well!</p>"},{"location":"development/#documentation","title":"Documentation","text":"<p>Documentation is stored in the <code>/docs</code> folder and created by <code>mkdocs</code> using the <code>material-for-mkdocs</code> theme.</p> <p>Build and locally serve documentation</p> <pre><code>mkdocs serve\n</code></pre> <p>Documentation is deployed using the <code>mike</code> package and Github Actions configured in <code>.github/workflows/</code> for each \u201cref\u201d (i.e. branch) in the network_wrangler repository.</p>"},{"location":"development/#making-sure-your-code-works","title":"Making sure your code works","text":""},{"location":"development/#linting-and-type-checking","title":"Linting and Type Checking","text":"<p>Before even running the tests, its a good idea to lint and check the types of the code using pre-commit:</p> <p>Example</p> <pre><code>pre-commit run --all-files\n</code></pre> <p>Your code must pass the pre-commit tests as a part of continuous integration, so you might as well fix anything now if it arises.</p>"},{"location":"development/#adding-tests","title":"Adding Tests","text":"<p>..to come</p>"},{"location":"development/#running-tests","title":"Running Tests","text":"<p>Tests and test data reside in the <code>/tests</code> directory:</p> <p>Example</p> <pre><code>pytest\n</code></pre> <p>Your code must pass the these tests as a part of continuous integration, so you might as well fix anything now if it arises.</p>"},{"location":"development/#profiling-performance","title":"Profiling Performance","text":"<p>When you run the tests, their performance is profiled using <code>pytest-profiling</code> and profiles for tests are stored in <code>.prof</code> directory. If you want to explore what is taking time in a particular test, you can do so using products like <code>snakviz</code></p> <p>Explore performance of a test</p> <pre><code>snakeviz .prof/&lt;test_name&gt;.prof\n</code></pre> <p>We also benchmark some specific tests (<code>test_benchmarks.py</code>) that we want to compare when reviewing pull requests. If you want to review how you are doing on these benchmarks you can save the benchmarks when you run pytestand compare these numbers to another branch.</p> <p>Compare benchmarks between branches</p> <pre><code>pytest --benchmark-save=branch_1\ngit checkout branch_2\npytest --benchmark-save=branch_2\npytest-benchmark compare branch_1 branch_2\n</code></pre>"},{"location":"development/#evaluate-code-maintainability","title":"Evaluate Code Maintainability","text":"<p>Using Radon</p> <p>Maintainability Index is a software metric which measures how maintainable (easy to support and change) the source code is. The maintainability index is calculated as a factored formula consisting of SLOC (Source Lines Of Code), Cyclomatic Complexity and Halstead volume.</p> <pre><code>radon mi ../network_wrangler -s\n</code></pre> <p>Cyclomatic Complexity corresponds to the number of decisions a block of code contains plus 1. This number (also called McCabe number) is equal to the number of linearly independent paths through the code. This number can be used as a guide when testing conditional logic in blocks.</p> <pre><code>radon cc ../network_wrangler --average\n</code></pre>"},{"location":"development/#continuous-integration","title":"Continuous Integration","text":"<p>Continuous Integration is managed by Github Actions in <code>.github/workflows</code>. All tests other than those with the decorator <code>@pytest.mark.skipci</code> will be run.</p>"},{"location":"development/#project-governance","title":"Project Governance","text":"<p>The project is currently governed by representatives of its two major organizational contributors:</p> <ul> <li>Metropolitan Council (MN)</li> <li>Metropolitan Transportation Commission (California)</li> </ul>"},{"location":"development/#code-of-conduct","title":"Code of Conduct","text":"<p>Contributors to the Network Wrangler Project are expected to read and follow the CODE_OF_CONDUCT for the project.</p>"},{"location":"development/#contributors","title":"Contributors","text":"<ol> <li>Lisa Z. - initial Network Wrangler implementation at SFCTA</li> <li>Billy C. - initial Network Wrangler implementation at SFCTA</li> <li>Elizabeh S.</li> <li>Sijia W.</li> <li>David O.</li> <li>Ashish K.</li> <li>Yue S.</li> </ol> <p>Note</p> <p>There are likely more contributors - feel free to add your name if we missed it!</p>"},{"location":"development/#release-history","title":"Release History","text":""},{"location":"development/#changelog","title":"Changelog","text":"<p>Notable changes and version history.</p> Version Date Comment v1.0-beta-2 20204-10-15 Bug fixes in scenario loading, projectcard API and compatibility of transit net with roadway deletions. Some additional performance improvements. v1.0-beta-1 20204-10-9 Feature-complete for 1.0 v1.0-alpha-2 2024-10-8 Testing for Met Council v1.0-alpha-1 2024-07-17 Full refactor v0.2.0-alpha 2020-09-16 - v0.1.0-alpha 2020-09-09 - 0.0.2 2020-02-05 -"},{"location":"how_to/","title":"How To","text":""},{"location":"how_to/#build-a-scenario-using-api","title":"Build a Scenario using API","text":"<p>Scenario objects manage how a collection of projects is applied to the networks.</p> <p>Scenarios are built from a base scenario and a list of project cards.</p> <p>A project card is a YAML file (or similar) that describes a change to the network. The project card can contain multiple changes, each of which is applied to the network in sequence.</p> <p>additional examples</p> <p>You can see additional scenario creating capabilities in the example jupyter notebook <code>Scenario Building Example.ipynb</code>.</p>"},{"location":"how_to/#network_wrangler.scenario--create-a-scenario","title":"Create a Scenario","text":"<p>Instantiate a scenario by seeding it with a base scenario and optionally some project cards.</p> <pre><code>from network_wrangler import create_scenario\n\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags=[\"baseline2050\"],\n)\n</code></pre> <p>A <code>base_year_scenario</code> is a dictionary representation of key components of a scenario:</p> <ul> <li><code>road_net</code>: RoadwayNetwork instance</li> <li><code>transit_net</code>: TransitNetwork instance</li> <li><code>applied_projects</code>: list of projects that have been applied to the base scenario so that the     scenario knows if there will be conflicts with future projects or if a future project\u2019s     pre-requisite is satisfied.</li> <li><code>conflicts</code>: dictionary of conflicts for project that have been applied to the base scenario so     that the scenario knows if there will be conflicts with future projects.</li> </ul> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_from_roadway_dir(STPAUL_DIR),\n    \"transit_net\": load_transit(STPAUL_DIR),\n    \"applied_projects\": [],\n    \"conflicts\": {},\n}\n</code></pre>"},{"location":"how_to/#network_wrangler.scenario--add-projects-to-a-scenario","title":"Add Projects to a Scenario","text":"<p>In addition to adding projects when you create the scenario, project cards can be added to a scenario using the <code>add_project_cards</code> method.</p> <pre><code>from projectcard import read_cards\n\nproject_card_dict = read_cards(card_location, filter_tags=[\"Baseline2030\"], recursive=True)\nmy_scenario.add_project_cards(project_card_dict.values())\n</code></pre> <p>Where <code>card_location</code> can be a single path, list of paths, a directory, or a glob pattern.</p>"},{"location":"how_to/#network_wrangler.scenario--apply-projects-to-a-scenario","title":"Apply Projects to a Scenario","text":"<p>Projects can be applied to a scenario using the <code>apply_all_projects</code> method. Before applying projects, the scenario will check that all pre-requisites are satisfied, that there are no conflicts, and that the projects are in the planned projects list.</p> <p>If you want to check the order of projects before applying them, you can use the <code>queued_projects</code> prooperty.</p> <pre><code>my_scenario.queued_projects\nmy_scenario.apply_all_projects()\n</code></pre> <p>You can review the resulting scenario, roadway network, and transit networks.</p> <pre><code>my_scenario.applied_projects\nmy_scenario.road_net.links_gdf.explore()\nmy_scenario.transit_net.feed.shapes_gdf.explore()\n</code></pre>"},{"location":"how_to/#network_wrangler.scenario--write-a-scenario-to-disk","title":"Write a Scenario to Disk","text":"<p>Scenarios (and their networks) can be written to disk using the <code>write</code> method which in addition to writing out roadway and transit networks, will serialize the scenario to a yaml-like file and can also write out the project cards that have been applied.</p> <pre><code>my_scenario.write(\n    \"output_dir\",\n    \"scenario_name_to_use\",\n    overwrite=True,\n    projects_write=True,\n    file_format=\"parquet\",\n)\n</code></pre> Example Serialized Scenario File<pre><code>applied_projects: &amp;id001\n- project a\n- project b\nbase_scenario:\napplied_projects: *id001\nroadway:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\n    file_format: geojson\ntransit:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\nconfig:\nCPU:\n    EST_PD_READ_SPEED:\n    csv: 0.03\n    geojson: 0.03\n    json: 0.15\n    parquet: 0.005\n    txt: 0.04\nIDS:\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: &amp;id002 !!python/tuple\n    - 950000\n    - 999999\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: *id002\n    ML_NODE_ID_SCALAR: 15000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\nMODEL_ROADWAY:\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\n    ML_OFFSET_METERS: -10\nconflicts: {}\ncorequisites: {}\nname: first_scenario\nprerequisites: {}\nroadway:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/roadway\nfile_format: parquet\ntransit:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/transit\nfile_format: txt\n</code></pre>"},{"location":"how_to/#network_wrangler.scenario--load-a-scenario-from-disk","title":"Load a scenario from disk","text":"<p>And if you want to reload scenario that you \u201cwrote\u201d, you can use the <code>load_scenario</code> function.</p> <pre><code>from network_wrangler import load_scenario\n\nmy_scenario = load_scenario(\"output_dir/scenario_name_to_use_scenario.yml\")\n</code></pre>"},{"location":"how_to/#build-a-scenario-from-a-scenario-configuration-file","title":"Build a Scenario from a Scenario Configuration File","text":"<p>Scenario configuration for Network Wrangler.</p> <p>You can build a scenario and write out the output from a scenario configuration file using the code below.  This is very useful when you are running a specific scenario with minor variations over again because you can enter your config file into version control.  In addition to the completed roadway and transit files, the output will provide a record of how the scenario was run.</p> Usage <pre><code>    from scenario import build_scenario_from_config\n    my_scenario = build_scenario_from_config(my_scenario_config)\n</code></pre> <p>Where <code>my_scenario_config</code> can be a:</p> <ul> <li>Path to a scenario config file in yaml/toml/json (recommended),</li> <li>Dictionary which is in the same structure of a scenario config file, or</li> <li>A <code>ScenarioConfig()</code>  instance.</li> </ul> <p>Notes on relative paths in scenario configs</p> <ul> <li>Relative paths are recognized by a preceeding \u201c.\u201d.</li> <li>Relative paths within <code>output_scenario</code> for <code>roadway</code>, <code>transit</code>, and <code>project_cards</code> are interpreted to be relative to <code>output_scenario.path</code>.</li> <li>All other relative paths are interpreted to be relative to directory of the scenario config file. (Or if scenario config is provided as a dictionary, relative paths will be interpreted as relative to the current working directory.)</li> </ul> Example Scenario Config<pre><code>name: \"my_scenario\"\nbase_scenario:\n    roadway:\n        dir: \"path/to/roadway_network\"\n        file_format: \"geojson\"\n        read_in_shapes: True\n    transit:\n        dir: \"path/to/transit_network\"\n        file_format: \"txt\"\n    applied_projects:\n        - \"project1\"\n        - \"project2\"\n    conflicts:\n        \"project3\": [\"project1\", \"project2\"]\n        \"project4\": [\"project1\"]\nprojects:\n    project_card_filepath:\n        - \"path/to/projectA.yaml\"\n        - \"path/to/projectB.yaml\"\n    filter_tags:\n        - \"tag1\"\noutput_scenario:\n    overwrite: True\n    roadway:\n        out_dir: \"path/to/output/roadway\"\n        prefix: \"my_scenario\"\n        file_format: \"geojson\"\n        true_shape: False\n    transit:\n        out_dir: \"path/to/output/transit\"\n        prefix: \"my_scenario\"\n        file_format: \"txt\"\n    project_cards:\n        out_dir: \"path/to/output/project_cards\"\n\nwrangler_config: \"path/to/wrangler_config.yaml\"\n</code></pre> Extended Usage <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_scenario_config\n\nmy_scenario_config = load_scenario_config(\"path/to/config.yaml\")\n</code></pre> <p>Access the configuration:</p> <pre><code>my_scenario_config.base_transit_network.path\n&gt;&gt; path/to/transit_network\n</code></pre>"},{"location":"how_to/#change-wrangler-configuration","title":"Change Wrangler Configuration","text":"<p>Configuration for parameters for Network Wrangler.</p> <p>Users can change a handful of parameters which control the way Wrangler runs.  These parameters can be saved as a wrangler config file which can be read in repeatedly to make sure the same parameters are used each time.</p> Usage <p>At runtime, you can specify configurable parameters at the scenario level which will then also be assigned and accessible to the roadway and transit networks.</p> <pre><code>create_scenario(...config = myconfig)\n</code></pre> <p>Or if you are not using Scenario functionality, you can specify the config when you read in a RoadwayNetwork.</p> <pre><code>load_roadway_from_dir(**roadway, config=myconfig)\nload_transit(**transit, config=myconfig)\n</code></pre> <p><code>my_config</code> can be a:</p> <ul> <li>Path to a config file in yaml/toml/json (recommended),</li> <li>List of paths to config files (in case you want to split up various sub-configurations)</li> <li>Dictionary which is in the same structure of a config file, or</li> <li>A <code>WranglerConfig()</code>  instance.</li> </ul> <p>If not provided, Wrangler will use reasonable defaults.</p> Default Wrangler Configuration Values<p>If not explicitly provided, the following default values are used:</p> <pre><code>IDS:\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: (950000, 999999)\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: (950000, 999999)\n    ML_NODE_ID_SCALAR: 15000\nEDITS:\n    EXISTING_VALUE_CONFLIC: warn\n    OVERWRITE_SCOPED: conflicting\nMODEL_ROADWAY:\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\nCPU:\n    EST_PD_READ_SPEED:\n        csv: 0.03\n        parquet: 0.005\n        geojson: 0.03\n        json: 0.15\n        txt: 0.04\n</code></pre> Extended usage <p>Load the default configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n</code></pre> <p>Access the configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS\n&gt;&gt; -10\n</code></pre> <p>Modify the default configuration in-line:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS = 20\n</code></pre> <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_wrangler_config\n\nconfig = load_wrangler_config(\"path/to/config.yaml\")\n</code></pre> <p>Set a configuration value:</p> <pre><code>config.MODEL_ROADWAY.ML_OFFSET_METERS = 10\n</code></pre>"},{"location":"how_to/#network_wrangler.configs.wrangler.CpuConfig","title":"<code>CpuConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>CPU Configuration -  Will not change any outcomes.</p> <p>Attributes:</p> Name Type Description <code>EST_PD_READ_SPEED</code> <code>dict[str, float]</code> <p>Read sec / MB - WILL DEPEND ON SPECIFIC COMPUTER</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass CpuConfig(ConfigItem):\n    \"\"\"CPU Configuration -  Will not change any outcomes.\n\n    Attributes:\n        EST_PD_READ_SPEED: Read sec / MB - WILL DEPEND ON SPECIFIC COMPUTER\n    \"\"\"\n\n    EST_PD_READ_SPEED: dict[str, float] = Field(\n        default_factory=lambda: {\n            \"csv\": 0.03,\n            \"parquet\": 0.005,\n            \"geojson\": 0.03,\n            \"json\": 0.15,\n            \"txt\": 0.04,\n        }\n    )\n</code></pre>"},{"location":"how_to/#network_wrangler.configs.wrangler.EditsConfig","title":"<code>EditsConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for Edits.</p> <p>Attributes:</p> Name Type Description <code>EXISTING_VALUE_CONFLICT</code> <code>Literal['warn', 'error', 'skip']</code> <p>Only used if \u2018existing\u2019 provided in project card and <code>existing</code> doesn\u2019t match the existing network value. One of <code>error</code>, <code>warn</code>, or <code>skip</code>. <code>error</code> will raise an error, <code>warn</code> will warn the user, and <code>skip</code> will skip the change for that specific property (note it will still apply any remaining property changes). Defaults to <code>warn</code>. Can be overridden by setting <code>existing_value_conflict</code> in a <code>roadway_property_change</code> project card.</p> <code>OVERWRITE_SCOPED</code> <code>Literal['conflicting', 'all', 'error']</code> <p>How to handle conflicts with existing values. Should be one of \u201cconflicting\u201d, \u201call\u201d, or False. \u201cconflicting\u201d will only overwrite values where the scope only partially overlaps with the existing value. \u201call\u201d will overwrite all the scoped values. \u201cerror\u201d will error if there is any overlap. Default is \u201cconflicting\u201d. Can be changed at the project-level by setting <code>overwrite_scoped</code> in a <code>roadway_property_change</code> project card.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass EditsConfig(ConfigItem):\n    \"\"\"Configuration for Edits.\n\n    Attributes:\n        EXISTING_VALUE_CONFLICT: Only used if 'existing' provided in project card and\n            `existing` doesn't match the existing network value. One of `error`, `warn`, or `skip`.\n            `error` will raise an error, `warn` will warn the user, and `skip` will skip the change\n            for that specific property (note it will still apply any remaining property changes).\n            Defaults to `warn`. Can be overridden by setting `existing_value_conflict` in\n            a `roadway_property_change` project card.\n\n        OVERWRITE_SCOPED: How to handle conflicts with existing values.\n            Should be one of \"conflicting\", \"all\", or False.\n            \"conflicting\" will only overwrite values where the scope only partially overlaps with\n            the existing value. \"all\" will overwrite all the scoped values. \"error\" will error if\n            there is any overlap. Default is \"conflicting\". Can be changed at the project-level\n            by setting `overwrite_scoped` in a `roadway_property_change` project card.\n    \"\"\"\n\n    EXISTING_VALUE_CONFLICT: Literal[\"warn\", \"error\", \"skip\"] = \"warn\"\n    OVERWRITE_SCOPED: Literal[\"conflicting\", \"all\", \"error\"] = \"conflicting\"\n</code></pre>"},{"location":"how_to/#network_wrangler.configs.wrangler.IdGenerationConfig","title":"<code>IdGenerationConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> Name Type Description <code>TRANSIT_SHAPE_ID_METHOD</code> <code>Literal['scalar']</code> <p>method for creating a shape_id for a transit shape. Should be \u201cscalar\u201d.</p> <code>TRANSIT_SHAPE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a shape_id for a transit shape.</p> <code>ROAD_SHAPE_ID_METHOD</code> <code>Literal['scalar']</code> <p>method for creating a shape_id for a roadway shape. Should be \u201cscalar\u201d.</p> <code>ROAD_SHAPE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a shape_id for a roadway shape.</p> <code>ML_LINK_ID_METHOD</code> <code>Literal['range', 'scalar']</code> <p>method for creating a model_link_id for an associated link for a parallel managed lane.</p> <code>ML_LINK_ID_RANGE</code> <code>tuple[int, int]</code> <p>range of model_link_ids to use when creating an associated link for a parallel managed lane.</p> <code>ML_LINK_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a model_link_id when creating an associated link for a parallel managed lane.</p> <code>ML_NODE_ID_METHOD</code> <code>Literal['range', 'scalar']</code> <p>method for creating a model_node_id for an associated node for a parallel managed lane.</p> <code>ML_NODE_ID_RANGE</code> <code>tuple[int, int]</code> <p>range of model_node_ids to use when creating an associated node for a parallel managed lane.</p> <code>ML_NODE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane node ides create a model_node_id when creating an associated nodes for parallel managed lane.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass IdGenerationConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        TRANSIT_SHAPE_ID_METHOD: method for creating a shape_id for a transit shape.\n            Should be \"scalar\".\n        TRANSIT_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a transit shape.\n        ROAD_SHAPE_ID_METHOD: method for creating a shape_id for a roadway shape.\n            Should be \"scalar\".\n        ROAD_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a roadway shape.\n        ML_LINK_ID_METHOD: method for creating a model_link_id for an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_RANGE: range of model_link_ids to use when creating an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_SCALAR: scalar value to add to general purpose lane to create a\n            model_link_id when creating an associated link for a parallel managed lane.\n        ML_NODE_ID_METHOD: method for creating a model_node_id for an associated node\n            for a parallel managed lane.\n        ML_NODE_ID_RANGE: range of model_node_ids to use when creating an associated\n            node for a parallel managed lane.\n        ML_NODE_ID_SCALAR: scalar value to add to general purpose lane node ides create\n            a model_node_id when creating an associated nodes for parallel managed lane.\n    \"\"\"\n\n    TRANSIT_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    TRANSIT_SHAPE_ID_SCALAR: int = 1000000\n    ROAD_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    ROAD_SHAPE_ID_SCALAR: int = 1000\n    ML_LINK_ID_METHOD: Literal[\"range\", \"scalar\"] = \"scalar\"\n    ML_LINK_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_LINK_ID_SCALAR: int = 3000000\n    ML_NODE_ID_METHOD: Literal[\"range\", \"scalar\"] = \"range\"\n    ML_NODE_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_NODE_ID_SCALAR: int = 15000\n</code></pre>"},{"location":"how_to/#network_wrangler.configs.wrangler.ModelRoadwayConfig","title":"<code>ModelRoadwayConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> Name Type Description <code>ML_OFFSET_METERS</code> <code>int</code> <p>Offset in meters for managed lanes.</p> <code>ADDITIONAL_COPY_FROM_GP_TO_ML</code> <code>list[str]</code> <p>Additional fields to copy from general purpose to managed lanes.</p> <code>ADDITIONAL_COPY_TO_ACCESS_EGRESS</code> <code>list[str]</code> <p>Additional fields to copy to access and egress links.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass ModelRoadwayConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        ML_OFFSET_METERS: Offset in meters for managed lanes.\n        ADDITIONAL_COPY_FROM_GP_TO_ML: Additional fields to copy from general purpose to managed\n            lanes.\n        ADDITIONAL_COPY_TO_ACCESS_EGRESS: Additional fields to copy to access and egress links.\n    \"\"\"\n\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: list[str] = Field(default_factory=list)\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: list[str] = Field(default_factory=list)\n</code></pre>"},{"location":"how_to/#network_wrangler.configs.wrangler.WranglerConfig","title":"<code>WranglerConfig</code>","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for Network Wrangler.</p> <p>Attributes:</p> Name Type Description <code>IDS</code> <code>IdGenerationConfig</code> <p>Parameteters governing how new ids are generated.</p> <code>MODEL_ROADWAY</code> <code>ModelRoadwayConfig</code> <p>Parameters governing how the model roadway is created.</p> <code>CPU</code> <code>CpuConfig</code> <p>Parameters for accessing CPU information. Will not change any outcomes.</p> <code>EDITS</code> <code>EditsConfig</code> <p>Parameters governing how edits are handled.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass WranglerConfig(ConfigItem):\n    \"\"\"Configuration for Network Wrangler.\n\n    Attributes:\n        IDS: Parameteters governing how new ids are generated.\n        MODEL_ROADWAY: Parameters governing how the model roadway is created.\n        CPU: Parameters for accessing CPU information. Will not change any outcomes.\n        EDITS: Parameters governing how edits are handled.\n    \"\"\"\n\n    IDS: IdGenerationConfig = IdGenerationConfig()\n    MODEL_ROADWAY: ModelRoadwayConfig = ModelRoadwayConfig()\n    CPU: CpuConfig = CpuConfig()\n    EDITS: EditsConfig = EditsConfig()\n</code></pre>"},{"location":"how_to/#review-changes-beetween-networks","title":"Review changes beetween networks","text":"<p>Review Added Managed Lanes</p> <pre><code>from network_wrangler import load_roadway_from_dir\nfrom projectcard import read_card\nfrom pathlib import Path\n\nEXAMPLE_DIR = Path.cwd().parent / \"examples\"\nSTPAUL = EXAMPLE_DIR / \"stpaul\"\nSTPAUL_ROAD = load_roadway_from_dir(STPAUL)\n\ncard_path = STPAUL / \"project_cards\" / \"road.prop_change.managed_lanes.yml\"\ncard = read_card(card_path)\nstpaul_build = STPAUL_ROAD.apply(card)\n\nml_map = STPAUL_ROAD.links_df[STPAUL_ROAD.links_df.managed &gt; 0].explore(\n    color=\"blue\",\n    tiles=\"CartoDB positron\",\n    name=\"Managed Lanes\",\n    style_kwds={\"opacity\": 0.6, \"weight\": 20}\n)\n\nadded_managed_lanes = stpaul_build.links_df[(stpaul_build.links_df.managed &gt; 0) &amp; (STPAUL_ROAD.links_df.managed == 0)]\n\nadded_managed_lanes.explore(\n    m=ml_map,\n    color=\"red\",\n    name=\"Added Managed Lanes\",\n    style_kwds={\"opacity\": 0.6, \"weight\": 20}\n)\n</code></pre> <p>additional examples</p> <p>You can see additional scenario review capabilities in the example jupyter notebook <code>Visual Checks.ipynb</code>.</p>"},{"location":"how_to/#review-selected-facilities","title":"Review selected facilities","text":"<p>Review selected links</p> <pre><code>from network_wrangler import load_roadway_from_dir\nfrom pathlib import Path\n\nEXAMPLE_DIR = Path.cwd().parent / \"examples\"\nSTPAUL = EXAMPLE_DIR / \"stpaul\"\n\nSTPAUL_ROAD = load_roadway_from_dir(STPAUL)\nsel_dict = {\n  \"links\": {\n      \"modes\": [\"walk\"],\n      \"name\": [\"Valley Street\"],\n  },\n  \"from\": {\"model_node_id\": 174762},\n  \"to\": {\"model_node_id\": 43041},\n}\nSTPAUL_ROAD.get_selection(sel_dict).selected_links_df.explore(\n  color=\"red\", style_kwds={\"opacity\": 0.6, \"weight\": 20}\n)\n</code></pre> <p>additional examples</p> <p>You can see additional interactive exploration of how selections work and how to review them in the Jupyter notebook <code>Roadway Network Search.ipynb</code>.</p>"},{"location":"how_to/#create-your-own-example-data-from-open-street-map","title":"Create your own example data from Open Street Map","text":"<p>This script builds a basic OpenStreetMap (OSM) road network for a specified place.</p> <p>This script uses the network_wrangler library to build a roadway network from OSM data. It allows you to specify the place name, network type, output path, and file format for the resulting network.</p> Usage <p><code>python build_basic_osm_roadnet.py &lt;place_name&gt; [--type &lt;type&gt;] [--path &lt;path&gt;] [--file_format &lt;file_format&gt;]</code></p> <p>Parameters:</p> Name Type Description Default <code>place_name</code> <code>str</code> <p>Name of the place to build the road network for.</p> required <code>--type</code> <code>Optional[str]</code> <p>Type of network to build Defaults to <code>drive</code>.</p> required <code>--path</code> <code>Optional[str]</code> <p>Path to write the network. Defaults to current working directory.</p> required <code>--file_format</code> <code>Optional[str]</code> <p>File format for writing the network. Defaults to <code>geojson</code>.</p> required Example <pre><code>python build_basic_osm_roadnet.py \"San Francisco, California\" --type \"drive\" --path \"/path/to/output\" --file_format \"geojson\"\n</code></pre> <p>additional examples</p> <p>You can review the process in this script step-wise and interactively create your own networks from OSM with variation in the underlying assumptions in the Jupyter notebook <code>Create Network from OSM.ipynb</code>.</p>"},{"location":"how_to/#review-separated-model-network-managed-lanes","title":"Review separated model network managed lanes","text":"<p>Review model network</p> <pre><code>m_net = stpaul_build.model_net\nmodel_net_map = m_net.gp_links_df.explore(\n    tiles=\"CartoDB positron\",\n    color=\"blue\",\n    style_kwds={\"opacity\": 0.6, \"weight\": 10}\n)\nm_net.ml_links_df.explore(m=model_net_map, color=\"red\", style_kwds={\"opacity\": 0.6, \"weight\": 10})\nm_net.dummy_links_df.explore(m=model_net_map, color=\"green\", style_kwds={\"opacity\": 0.6, \"weight\": 10})\n</code></pre> <p>additional examples</p> <p>You can learn more about visualization of networks in the Jupyter notebook <code>Network Viewer.ipynb</code>.</p> <p>{!   include-markdown(\u201chttps://raw.githubusercontent.com/network-wrangler/projectcard/refs/heads/main/docs/how-to.md\u201d) !}</p>"},{"location":"networks/","title":"Networks","text":""},{"location":"networks/#roadway-network-format","title":"Roadway Network Format","text":"<p>RoadwayNetworks must be defined in the following format, which leverages Open Street Map which uses a tag-based format (e.g. json, xml).  This may be changed in the future to align with the tabular-based General Modeling Network Specification.</p> <p>A network is defined by a set of nodes and links which connect them.  Shapes may be optionally specified for each link in a separate file.</p> <p>file serialization formats</p> <p>While the default serialiation for roadway networks is <code>json</code>/<code>geojson</code> and for transit data is <code>csv</code>, networks can also be stored \u2013 more efficiently \u2013\u00a0in parquet files with a similar structure. Other workable file serializations include shapefiles, csvs, and anything that can be read by pandas or geopandas. This can be noted in most I/O procedures by including the keyword argument <code>file_format = &lt;format&gt;</code>.</p>"},{"location":"networks/#roadway-validation","title":"Roadway Validation","text":"<p>RoadwayNetworks can be validated using the following tools:</p> CLIPython API <p><pre><code>python validate_roadway.py &lt;network_directory&gt; &lt;file_format&gt; [-s] [--output_dir &lt;output_dir&gt;]\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>file_format</code>: The suffices of roadway network file name.</li> <li><code>-s</code>, <code>--strict</code>: Validate the roadway network strictly without parsing and filling in data.</li> <li><code>--output_dir</code>: The output directory for the validation report.</li> </ul> <p><pre><code>from network_wrangler.roadway.validate import validate_roadway_in_dir\nvalidate_roadway_in_dir(\n    directory=&lt;network_directory&gt;,\n    file_format=&lt;file_format&gt;,\n    strict=&lt;strict_bool&gt;&gt;,\n    output_dir=&lt;output_dir&gt;\n)\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>file_format</code>: The suffices of roadway network file name.</li> <li><code>strict</code>: Validate the roadway network strictly without parsing and filling in data.</li> <li><code>output_dir</code>: The output directory for the validation report.</li> </ul>"},{"location":"networks/#examples","title":"Examples","text":"<p>Network Wrangler is packaged with two examples located in the <code>/examples</code> directory:</p> <ul> <li>St Paul, MN</li> <li>Small which is a several block exerpt of St Paul and is infinitely easier to trouble-shoot quickly.</li> </ul>"},{"location":"networks/#road-nodes","title":"Road Nodes","text":"<p>A  valid <code>geojson</code>, <code>shp</code>, or <code>parquet</code> file.</p> <p>Datamodel used to validate if links_df is of correct format and types.</p> <p>Must have a record for each node used by the <code>links</code> table and by the transit <code>shapes</code>, <code>stop_times</code>, and <code>stops</code> tables.</p> <p>Attributes:</p> Name Type Description <code>model_node_id</code> <code>int</code> <p>Unique identifier for the node.</p> <code>osm_node_id</code> <code>Optional[str]</code> <p>Reference to open street map node id. Used for querying. Not guaranteed to be unique.</p> <code>X</code> <code>float</code> <p>Longitude of the node in WGS84. Must be in the range of -180 to 180.</p> <code>Y</code> <code>float</code> <p>Latitude of the node in WGS84. Must be in the range of -90 to 90.</p> <code>geometry</code> <code>GeoSeries</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadNodesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\n\n    Must have a record for each node used by the `links` table and by the transit `shapes`, `stop_times`, and `stops` tables.\n\n    Attributes:\n        model_node_id (int): Unique identifier for the node.\n        osm_node_id (Optional[str]): Reference to open street map node id. Used for querying. Not guaranteed to be unique.\n        X (float): Longitude of the node in WGS84. Must be in the range of -180 to 180.\n        Y (float): Latitude of the node in WGS84. Must be in the range of -90 to 90.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n    \"\"\"\n\n    model_node_id: Series[int] = pa.Field(coerce=True, unique=True, nullable=False)\n    model_node_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True, nullable=False)\n    X: Series[float] = pa.Field(coerce=True, nullable=False)\n    Y: Series[float] = pa.Field(coerce=True, nullable=False)\n    geometry: GeoSeries\n\n    # optional fields\n    osm_node_id: Series[str] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    inboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n    outboundReferenceIds: Optional[Series[list[str]]] = pa.Field(coerce=True, nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadNodesTable.\"\"\"\n\n        add_missing_columns = True\n        coerce = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"model_node_id\"]\n</code></pre>"},{"location":"networks/#road-links","title":"Road Links","text":"<p>A  valid <code>geojson</code>, <code>shp</code>, <code>parquet</code>, or <code>json</code> file.</p> <p>Datamodel used to validate if links_df is of correct format and types.</p> <p>Attributes:</p> Name Type Description <code>model_link_id</code> <code>int</code> <p>Unique identifier for the link.</p> <code>A</code> <code>int</code> <p><code>model_node_id</code> of the link\u2019s start node. Foreign key to <code>road_nodes</code>.</p> <code>B</code> <code>int</code> <p><code>model_node_id</code> of the link\u2019s end node. Foreign key to <code>road_nodes</code>.</p> <code>geometry</code> <code>GeoSeries</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Simple A\u2192B geometry of the link.</p> <code>name</code> <code>str</code> <p>Name of the link.</p> <code>rail_only</code> <code>bool</code> <p>If the link is only for rail. Default is False.</p> <code>bus_only</code> <code>bool</code> <p>If the link is only for buses. Default is False.</p> <code>drive_access</code> <code>bool</code> <p>If the link allows driving. Default is True.</p> <code>bike_access</code> <code>bool</code> <p>If the link allows biking. Default is True.</p> <code>walk_access</code> <code>bool</code> <p>If the link allows walking. Default is True.</p> <code>truck_access</code> <code>bool</code> <p>If the link allows trucks. Default is True.</p> <code>distance</code> <code>float</code> <p>Length of the link.</p> <code>roadway</code> <code>str</code> <p>Type of roadway per OSM definitions. Default is \u201croad\u201d.</p> <code>projects</code> <code>str</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Comma-separated list of project names applied to the link. Default is \u201c\u201d.</p> <code>managed</code> <code>int</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Indicator for the type of managed lane facility. Values can be:</p> <ul> <li>0 indicating no managed lane on this link.</li> <li>1 indicates that there is a managed lane on the link (std network) or that the link is a     managed lane (model network).</li> <li>-1 indicates that there is a parallel managed lane derived from this link (model network).</li> </ul> <code>shape_id</code> <code>str</code> <p>Identifier referencing the primary key of the shapes table. Default is None.</p> <code>lanes</code> <code>int</code> <p>Default number of lanes on the link. Default is 1.</p> <code>sc_lanes</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the number of lanes. Default is None. Example: <code>[{'timespan':['12:00':'15:00'], 'value': 3},{'timespan':['15:00':'19:00'], 'value': 2}]</code>.</p> <code>price</code> <code>float</code> <p>Default price to use the link. Default is 0.</p> <code>sc_price</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the price. Default is None. Example: <code>[{'timespan':['15:00':'19:00'],'category': 'sov', 'value': 2.5}]</code>.</p> <code>ref</code> <code>Optional[str]</code> <p>Reference numbers for link referring to a route or exit number per the OSM definition. Default is None.</p> <code>access</code> <code>Optional[Any]</code> <p>User-defined method to note access restrictions for the link. Default is None.</p> <code>ML_projects</code> <code>Optional[str]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Comma-separated list of project names applied to the managed lane. Default is \u201c\u201d.</p> <code>ML_lanes</code> <code>Optional[int]</code> <p>Default number of lanes on the managed lane. Default is None.</p> <code>ML_price</code> <code>Optional[float]</code> <p>Default price to use the managed lane. Default is 0.</p> <code>ML_access</code> <code>Optional[Any]</code> <p>User-defined method to note access restrictions for the managed lane. Default is None.</p> <code>ML_access_point</code> <code>Optional[bool]</code> <p>If the link is an access point for the managed lane. Default is False.</p> <code>ML_egress_point</code> <code>Optional[bool]</code> <p>If the link is an egress point for the managed lane. Default is False.</p> <code>sc_ML_lanes</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the number of lanes on the managed lane. Default is None.</p> <code>sc_ML_price</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the price of the managed lane. Default is None.</p> <code>sc_ML_access</code> <code>Optional[list[dict]]</code> <p>List of scoped link values for the access restrictions of the managed lane. Default is None.</p> <code>ML_geometry</code> <code>Optional[GeoSeries]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Simple A\u2192B geometry of the managed lane. Default is None.</p> <code>ML_shape_id</code> <code>Optional[str]</code> <p>Identifier referencing the primary key of the shapes table for the managed lane. Default is None.</p> <code>osm_link_id</code> <code>Optional[str]</code> <p>Identifier referencing the OSM link ID. Default is \u201c\u201d.</p> <code>GP_A</code> <code>Optional[int]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Identifier referencing the primary key of the associated general purpose link start node for a managed lane link in a model network. Default is None.</p> <code>GP_B</code> <code>Optional[int]</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Identifier referencing the primary key of the associated general purpose link end node for a managed lane link in a model network. Default is None.</p> <p>User Defined Properties</p> <p>Additional properites may be defined and are assumed to have the same definition of OpenStreetMap if they have overlapping property names.</p>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadLinksTable--properties-for-parallel-managed-lanes","title":"Properties for parallel managed lanes","text":"<p>Properties for parallel managed lanes are prefixed with <code>ML_</code>. (Almost) any property, including an ad-hoc one, can be made to apply to a parallel managed lane by applying the prefix <code>ML_</code>, e.g. <code>ML_lanes</code></p> <p>Warning</p> <p>The following properties should not be assigned an <code>ML_</code> prefix by the user because they are assigned one within networkwrangler:</p> <ul> <li><code>name</code></li> <li><code>A</code></li> <li><code>B</code></li> <li><code>model_link_id</code></li> </ul>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadLinksTable--time-or-category-dependent-properties","title":"Time- or category-dependent properties","text":"<p>The following properties can be time-dependent, category-dependent, or both by adding <code>sc_</code>. The \u201cplain\u201d property without the prefix becomes the default when no scoped property applies.</p> Property # of Lanes Price Default value <code>lanes</code> <code>price</code> Time- and/or category-dependent value <code>sc_lanes</code> <code>sc_price</code> Default value for managed lane <code>ML_lanes</code> <code>ML_price</code> Time- and/or category-dependent value for managed lane <code>sc_ML_lanes</code> <code>sc_ML_price</code> previous format for scoped properties<p>Some previous tooling was developed around a previous method for serializing scoped properties.  In order to retain compatability with this format:</p> <ul> <li><code>load_roadway_from_dir()</code>, <code>read_links()</code>, and associated functions will \u201csniff\u201d the network for the old format and apply the converter function <code>translate_links_df_v0_to_v1()</code></li> <li><code>write_links()</code> has an boolean attribute to <code>convert_complex_properties_to_single_field</code> which can also be invoked from <code>write_roadway()</code> as <code>convert_complex_link_properties_to_single_field</code>.</li> </ul>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadLinksTable--defining-time-dependent-properties","title":"Defining time-dependent properties","text":"<p>Time-dependent properties are defined as a list of dictionaries with timespans and values.</p> <ul> <li>Timespans must be defined as a list of HH:MM or HH:MM:SS using a 24-hour clock: <code>('06:00':'09:00')</code>.</li> <li>Timespans must not intersect.</li> </ul> <p>Time-dependent property</p> <p>$3 peak-period pricing</p> <pre><code># default price\n'price' = 0\n'sc_price':\n[\n    {\n        'time':['06:00':'09:00'],\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'value': 3,\n    }\n]\n</code></pre>"},{"location":"networks/#network_wrangler.models.roadway.tables.RoadLinksTable--defining-time-and-category-dependent-properties","title":"Defining time- and category-dependent properties","text":"<p>Properties co-dependent on time- and category are defined as a list of dictionaries with value, category and time defined.</p> <p>time- and category-dependent property</p> <p>A pricing strategy which only applies in peak period for trucks and sovs:</p> <pre><code># default price\n\"price\": 0\n# price scoped by time of day\n\"sc_price\":\n[\n    {\n        'timespan':['06:00':'09:00'],\n        'category': ('sov','truck'),\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'category': ('sov','truck'),\n        'value': 3,\n    }\n]\n</code></pre> <p>Tip</p> <p>There is no limit on other, user-defined properties being listed as time-dependent or time- and category-dependent.</p> <p>User-defined variable by time of day</p> <p>Define a variable <code>access</code> to represent which categories can access the network and vary it by time of day.</p> <pre><code>#access\n{\n    # default value for access\n    'access': ('any'),\n    # scoped value for access\n    'sc_access': [\n        {\n            'timespan':['06:00':'09:00'],\n            'value': ('no-trucks')\n        },\n        {\n            'timespan':['16:00':'19:00'],\n            'value': ('hov2','hov3','trucks')\n        }\n    ]\n}\n</code></pre> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadLinksTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\n\n    Attributes:\n        model_link_id (int): Unique identifier for the link.\n        A (int): `model_node_id` of the link's start node. Foreign key to `road_nodes`.\n        B (int): `model_node_id` of the link's end node. Foreign key to `road_nodes`.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Simple A--&gt;B geometry of the link.\n        name (str): Name of the link.\n        rail_only (bool): If the link is only for rail. Default is False.\n        bus_only (bool): If the link is only for buses. Default is False.\n        drive_access (bool): If the link allows driving. Default is True.\n        bike_access (bool): If the link allows biking. Default is True.\n        walk_access (bool): If the link allows walking. Default is True.\n        truck_access (bool): If the link allows trucks. Default is True.\n        distance (float): Length of the link.\n        roadway (str): Type of roadway per [OSM definitions](https://wiki.openstreetmap.org/wiki/Key:highway#Roads).\n            Default is \"road\".\n        projects (str): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Comma-separated list of project names applied to the link. Default is \"\".\n        managed (int): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Indicator for the type of managed lane facility. Values can be:\n\n            - 0 indicating no managed lane on this link.\n            - 1 indicates that there is a managed lane on the link (std network) or that the link is a\n                managed lane (model network).\n            - -1 indicates that there is a parallel managed lane derived from this link (model network).\n        shape_id (str): Identifier referencing the primary key of the shapes table. Default is None.\n        lanes (int): Default number of lanes on the link. Default is 1.\n        sc_lanes (Optional[list[dict]]: List of scoped link values for the number of lanes. Default is None.\n            Example: `[{'timespan':['12:00':'15:00'], 'value': 3},{'timespan':['15:00':'19:00'], 'value': 2}]`.\n\n        price (float): Default price to use the link. Default is 0.\n        sc_price (Optional[list[dict]]): List of scoped link values for the price. Default is None.\n            Example: `[{'timespan':['15:00':'19:00'],'category': 'sov', 'value': 2.5}]`.\n        ref (Optional[str]): Reference numbers for link referring to a route or exit number per the\n            [OSM definition](https://wiki.openstreetmap.org/wiki/Key:ref). Default is None.\n        access (Optional[Any]): User-defined method to note access restrictions for the link. Default is None.\n        ML_projects (Optional[str]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Comma-separated list of project names applied to the managed lane. Default is \"\".\n        ML_lanes (Optional[int]): Default number of lanes on the managed lane. Default is None.\n        ML_price (Optional[float]): Default price to use the managed lane. Default is 0.\n        ML_access (Optional[Any]): User-defined method to note access restrictions for the managed lane. Default is None.\n        ML_access_point (Optional[bool]): If the link is an access point for the managed lane. Default is False.\n        ML_egress_point (Optional[bool]): If the link is an egress point for the managed lane. Default is False.\n        sc_ML_lanes (Optional[list[dict]]): List of scoped link values for the number of lanes on the managed lane.\n            Default is None.\n        sc_ML_price (Optional[list[dict]]): List of scoped link values for the price of the managed lane. Default is None.\n        sc_ML_access (Optional[list[dict]]): List of scoped link values for the access restrictions of the managed lane.\n            Default is None.\n        ML_geometry (Optional[GeoSeries]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Simple A--&gt;B geometry of the managed lane. Default is None.\n        ML_shape_id (Optional[str]): Identifier referencing the primary key of the shapes table for the managed lane.\n            Default is None.\n        osm_link_id (Optional[str]): Identifier referencing the OSM link ID. Default is \"\".\n        GP_A (Optional[int]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Identifier referencing the primary key of the associated general purpose link start node for\n            a managed lane link in a model network. Default is None.\n        GP_B (Optional[int]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Identifier referencing the primary key of the associated general purpose link end node for\n            a managed lane link in a model network. Default is None.\n\n    !!! tip \"User Defined Properties\"\n\n        Additional properites may be defined and are assumed to have the same definition of OpenStreetMap if they\n        have overlapping property names.\n\n    ### Properties for parallel managed lanes\n\n    Properties for parallel managed lanes are prefixed with `ML_`. (Almost) any property,\n    including an ad-hoc one, can be made to apply to a parallel managed lane by applying\n    the prefix `ML_`, e.g. `ML_lanes`\n\n    !!! warning\n\n        The following properties should **not** be assigned an `ML_` prefix by the user\n        because they are assigned one within networkwrangler:\n\n        - `name`\n        - `A`\n        - `B`\n        - `model_link_id`\n\n    ### Time- or category-dependent properties\n\n    The following properties can be time-dependent, category-dependent, or both by adding `sc_`.\n    The \"plain\" property without the prefix becomes the default when no scoped property applies.\n\n    | Property | # of Lanes | Price |\n    | -----------| ----------------- | ---------------- |\n    | Default value | `lanes` | `price` |\n    | Time- and/or category-dependent value | `sc_lanes` | `sc_price` |\n    | Default value for managed lane | `ML_lanes` | `ML_price` |\n    | Time- and/or category-dependent value for managed lane | `sc_ML_lanes` | `sc_ML_price` |\n\n\n    ??? note \"previous format for scoped properties\"\n\n        Some previous tooling was developed around a previous method for serializing scoped properties.  In order to retain compatability with this format:\n\n        - `load_roadway_from_dir()`, `read_links()`, and associated functions will \"sniff\" the network for the old format and apply the converter function `translate_links_df_v0_to_v1()`\n        - `write_links()` has an boolean attribute to `convert_complex_properties_to_single_field` which can also be invoked from `write_roadway()` as `convert_complex_link_properties_to_single_field`.\n\n    #### Defining time-dependent properties\n\n    Time-dependent properties are defined as a list of dictionaries with timespans and values.\n\n    - Timespans must be defined as a list of HH:MM or HH:MM:SS using a 24-hour clock: `('06:00':'09:00')`.\n    - Timespans must not intersect.\n\n    !!! example  \"Time-dependent property\"\n\n        $3 peak-period pricing\n\n        ```python\n        # default price\n        'price' = 0\n        'sc_price':\n        [\n            {\n                'time':['06:00':'09:00'],\n                'value': 3\n            },\n            {\n                'timespan':['16:00':'19:00'],\n                'value': 3,\n            }\n        ]\n        ```\n\n    #### Defining time- and category-dependent properties\n\n    Properties co-dependent on time- and category are defined as a list of dictionaries with value, category and time defined.\n\n    !!! example \"time- and category-dependent property\"\n\n        A pricing strategy which only applies in peak period for trucks and sovs:\n\n        ```python\n        # default price\n        \"price\": 0\n        # price scoped by time of day\n        \"sc_price\":\n        [\n            {\n                'timespan':['06:00':'09:00'],\n                'category': ('sov','truck'),\n                'value': 3\n            },\n            {\n                'timespan':['16:00':'19:00'],\n                'category': ('sov','truck'),\n                'value': 3,\n            }\n        ]\n        ```\n\n    !!! tip\n\n        There is no limit on other, user-defined properties being listed as time-dependent or time- and category-dependent.\n\n    !!! example \"User-defined variable by time of day\"\n\n        Define a variable `access` to represent which categories can access the network and vary it by time of day.\n\n        ```python\n        #access\n        {\n            # default value for access\n            'access': ('any'),\n            # scoped value for access\n            'sc_access': [\n                {\n                    'timespan':['06:00':'09:00'],\n                    'value': ('no-trucks')\n                },\n                {\n                    'timespan':['16:00':'19:00'],\n                    'value': ('hov2','hov3','trucks')\n                }\n            ]\n        }\n        ```\n    \"\"\"\n\n    model_link_id: Series[int] = pa.Field(coerce=True, unique=True)\n    model_link_id_idx: Optional[Series[int]] = pa.Field(coerce=True, unique=True)\n    A: Series[int] = pa.Field(nullable=False, coerce=True)\n    B: Series[int] = pa.Field(nullable=False, coerce=True)\n    geometry: GeoSeries = pa.Field(nullable=False)\n    name: Series[str] = pa.Field(nullable=False, default=\"unknown\")\n    rail_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    bus_only: Series[bool] = pa.Field(coerce=True, nullable=False, default=False)\n    drive_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    bike_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    walk_access: Series[bool] = pa.Field(coerce=True, nullable=False, default=True)\n    distance: Series[float] = pa.Field(coerce=True, nullable=False)\n\n    roadway: Series[str] = pa.Field(nullable=False, default=\"road\")\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    managed: Series[int] = pa.Field(coerce=True, nullable=False, default=0)\n\n    shape_id: Series[str] = pa.Field(coerce=True, nullable=True)\n    lanes: Series[int] = pa.Field(coerce=True, nullable=False)\n    price: Series[float] = pa.Field(coerce=True, nullable=False, default=0)\n\n    # Optional Fields\n    ref: Optional[Series[str]] = pa.Field(coerce=True, nullable=True, default=None)\n    access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    sc_lanes: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n    sc_price: Optional[Series[object]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    ML_projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    ML_lanes: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    ML_price: Optional[Series[float]] = pa.Field(coerce=True, nullable=True, default=0)\n    ML_access: Optional[Series[Any]] = pa.Field(coerce=True, nullable=True, default=True)\n    ML_access_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    ML_egress_point: Optional[Series[bool]] = pa.Field(\n        coerce=True,\n        default=False,\n    )\n    sc_ML_lanes: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_price: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_access: Optional[Series[object]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n\n    ML_geometry: Optional[GeoSeries] = pa.Field(nullable=True, coerce=True, default=None)\n    ML_shape_id: Optional[Series[str]] = pa.Field(nullable=True, coerce=True, default=None)\n\n    truck_access: Optional[Series[bool]] = pa.Field(coerce=True, nullable=True, default=True)\n    osm_link_id: Series[str] = pa.Field(coerce=True, nullable=True, default=\"\")\n    # todo this should be List[dict] but ranch output something else so had to have it be Any.\n    locationReferences: Optional[Series[Any]] = pa.Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n\n    GP_A: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n    GP_B: Optional[Series[Int64]] = pa.Field(coerce=True, nullable=True, default=None)\n\n    class Config:\n        \"\"\"Config for RoadLinksTable.\"\"\"\n\n        add_missing_columns = True\n        coerce = True\n        unique: ClassVar[list[str]] = [\"A\", \"B\"]\n\n    @pa.check(\"sc_*\", regex=True, element_wise=True)\n    def check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n        \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n        Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n        against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n        \"\"\"\n        if scoped_value is None or (not isinstance(scoped_value, list) and pd.isna(scoped_value)):\n            return True\n        return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"networks/#road-shapes","title":"Road Shapes","text":"<p>A  valid <code>geojson</code>, <code>shp</code>, or <code>parquet</code> file with <code>LineString</code> geometry features and the folowing <code>properties</code>.</p> <p>Datamodel used to validate if shapes_df is of correct format and types.</p> <p>Should have a record for each <code>shape_id</code> referenced in <code>links</code> table.</p> <p>Attributes:</p> Name Type Description <code>shape_id</code> <code>str</code> <p>Unique identifier for the shape.</p> <code>geometry</code> <code>GeoSeries</code> <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Geometry of the shape.</p> <code>ref_shape_id</code> <code>Optional[str]</code> <p>Reference to another <code>shape_id</code> that it may have been created from. Default is None.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadShapesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if shapes_df is of correct format and types.\n\n    Should have a record for each `shape_id` referenced in `links` table.\n\n    Attributes:\n        shape_id (str): Unique identifier for the shape.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Geometry of the shape.\n        ref_shape_id (Optional[str]): Reference to another `shape_id` that it may\n            have been created from. Default is None.\n    \"\"\"\n\n    shape_id: Series[str] = pa.Field(unique=True)\n    shape_id_idx: Optional[Series[int]] = pa.Field(unique=True)\n\n    geometry: GeoSeries = pa.Field()\n    ref_shape_id: Optional[Series] = pa.Field(nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadShapesTable.\"\"\"\n\n        coerce = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"shape_id\"]\n</code></pre>"},{"location":"networks/#transit-network-format","title":"Transit Network Format","text":"<p>Data models for various GTFS tables using pandera library.</p> <p>The module includes the following classes:</p> <ul> <li>AgencyTable: Optional. Represents the Agency table in the GTFS dataset.</li> <li>WranglerStopsTable: Represents the Stops table in the GTFS dataset.</li> <li>RoutesTable: Represents the Routes table in the GTFS dataset.</li> <li>WranglerShapesTable: Represents the Shapes table in the GTFS dataset.</li> <li>WranglerStopTimesTable: Represents the Stop Times table in the GTFS dataset.</li> <li>WranglerTripsTable: Represents the Trips table in the GTFS dataset.</li> </ul> <p>Each table model leverages the Pydantic data models defined in the records module to define the data model for the corresponding table. The classes also include additional configurations for, such as uniqueness constraints.</p> <p>Validating a table to the WranglerStopsTable</p> <pre><code>from network_wrangler.models.gtfs.tables import WranglerStopsTable\nfrom network_wrangler.utils.modesl import validate_df_to_model\n\nvalidated_stops_df = validate_df_to_model(stops_df, WranglerStopsTable)\n</code></pre> <p>Transit Networks must use the the GTFS Schedule format with the following additional constraints:</p> <ol> <li>At this time, only frequency-based schedules are supported.</li> <li>Each <code>stop_id</code> must be a node in the RoadwayNetwork.</li> <li><code>shapes.txt</code> is required (it is optional in GTFS) and must have the added field <code>model_node_id</code> associating a specific location with a node on the <code>RoadwayNetwork</code>.</li> </ol>"},{"location":"networks/#stops","title":"Stops","text":"<p>Wrangler flavor of GTFS StopsTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#stopstxt</p> <p>Attributes:</p> Name Type Description <code>stop_id</code> <code>int</code> <p>The stop_id. Primary key. Required to be unique. Wrangler assumes that this is a reference to a roadway node and as such must be an integer</p> <code>stop_lat</code> <code>float</code> <p>The stop latitude.</p> <code>stop_lon</code> <code>float</code> <p>The stop longitude.</p> <code>wheelchair_boarding</code> <code>Optional[int]</code> <p>The wheelchair boarding.</p> <code>stop_code</code> <code>Optional[str]</code> <p>The stop code.</p> <code>stop_name</code> <code>Optional[str]</code> <p>The stop name.</p> <code>tts_stop_name</code> <code>Optional[str]</code> <p>The text-to-speech stop name.</p> <code>stop_desc</code> <code>Optional[str]</code> <p>The stop description.</p> <code>zone_id</code> <code>Optional[str]</code> <p>The zone id.</p> <code>stop_url</code> <code>Optional[str]</code> <p>The stop URL.</p> <code>location_type</code> <code>Optional[LocationType]</code> <p>The location type. Values can be: - 0: stop platform - 1: station - 2: entrance/exit - 3: generic node - 4: boarding area Default of blank assumes a stop platform.</p> <code>parent_station</code> <code>Optional[int]</code> <p>The <code>stop_id</code> of the parent station. Since stop_id is an integer in Wrangler, this field is also an integer</p> <code>stop_timezone</code> <code>Optional[str]</code> <p>The stop timezone.</p> <code>stop_id_GTFS</code> <code>Optional[str]</code> <p>The stop_id from the GTFS data.</p> <code>projects</code> <code>str</code> <p>A comma-separated string value for projects that have been applied to this stop.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerStopsTable(StopsTable):\n    \"\"\"Wrangler flavor of GTFS StopsTable.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#stopstxt&gt;\n\n    Attributes:\n        stop_id (int): The stop_id. Primary key. Required to be unique. **Wrangler assumes that this is a reference to a roadway node and as such must be an integer**\n        stop_lat (float): The stop latitude.\n        stop_lon (float): The stop longitude.\n        wheelchair_boarding (Optional[int]): The wheelchair boarding.\n        stop_code (Optional[str]): The stop code.\n        stop_name (Optional[str]): The stop name.\n        tts_stop_name (Optional[str]): The text-to-speech stop name.\n        stop_desc (Optional[str]): The stop description.\n        zone_id (Optional[str]): The zone id.\n        stop_url (Optional[str]): The stop URL.\n        location_type (Optional[LocationType]): The location type. Values can be:\n            - 0: stop platform\n            - 1: station\n            - 2: entrance/exit\n            - 3: generic node\n            - 4: boarding area\n            Default of blank assumes a stop platform.\n        parent_station (Optional[int]): The `stop_id` of the parent station. **Since stop_id is an integer in Wrangler, this field is also an integer**\n        stop_timezone (Optional[str]): The stop timezone.\n        stop_id_GTFS (Optional[str]): The stop_id from the GTFS data.\n        projects (str): A comma-separated string value for projects that have been applied to this stop.\n    \"\"\"\n\n    stop_id: Series[int] = pa.Field(\n        coerce=True, nullable=False, unique=True, description=\"The model_node_id.\"\n    )\n    stop_id_GTFS: Series[str] = pa.Field(\n        coerce=True,\n        nullable=True,\n        description=\"The stop_id from the GTFS data\",\n    )\n    stop_lat: Series[float] = pa.Field(coerce=True, nullable=True, ge=-90, le=90)\n    stop_lon: Series[float] = pa.Field(coerce=True, nullable=True, ge=-180, le=180)\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n</code></pre>"},{"location":"networks/#routes","title":"Routes","text":"<p>Represents the Routes table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#routestxt</p> <p>Attributes:</p> Name Type Description <code>route_id</code> <code>str</code> <p>The route_id. Primary key. Required to be unique.</p> <code>route_short_name</code> <code>Optional[str]</code> <p>The route short name.</p> <code>route_long_name</code> <code>Optional[str]</code> <p>The route long name.</p> <code>route_type</code> <code>RouteType</code> <p>The route type. Required. Values can be: - 0: Tram, Streetcar, Light rail - 1: Subway, Metro - 2: Rail - 3: Bus</p> <code>agency_id</code> <code>Optional[str]</code> <p>The agency_id. Foreign key to agency_id in the agencies table.</p> <code>route_desc</code> <code>Optional[str]</code> <p>The route description.</p> <code>route_url</code> <code>Optional[str]</code> <p>The route URL.</p> <code>route_color</code> <code>Optional[str]</code> <p>The route color.</p> <code>route_text_color</code> <code>Optional[str]</code> <p>The route text color.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class RoutesTable(pa.DataFrameModel):\n    \"\"\"Represents the Routes table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#routestxt&gt;\n\n    Attributes:\n        route_id (str): The route_id. Primary key. Required to be unique.\n        route_short_name (Optional[str]): The route short name.\n        route_long_name (Optional[str]): The route long name.\n        route_type (RouteType): The route type. Required. Values can be:\n            - 0: Tram, Streetcar, Light rail\n            - 1: Subway, Metro\n            - 2: Rail\n            - 3: Bus\n        agency_id (Optional[str]): The agency_id. Foreign key to agency_id in the agencies table.\n        route_desc (Optional[str]): The route description.\n        route_url (Optional[str]): The route URL.\n        route_color (Optional[str]): The route color.\n        route_text_color (Optional[str]): The route text color.\n    \"\"\"\n\n    route_id: Series[str] = pa.Field(nullable=False, unique=True, coerce=True)\n    route_short_name: Series[str] = pa.Field(nullable=True, coerce=True)\n    route_long_name: Series[str] = pa.Field(nullable=True, coerce=True)\n    route_type: Series[Category] = pa.Field(\n        dtype_kwargs={\"categories\": RouteType}, coerce=True, nullable=False\n    )\n\n    # Optional Fields\n    agency_id: Optional[Series[str]] = pa.Field(nullable=True, coerce=True)\n    route_desc: Optional[Series[str]] = pa.Field(nullable=True, coerce=True)\n    route_url: Optional[Series[str]] = pa.Field(nullable=True, coerce=True)\n    route_color: Optional[Series[str]] = pa.Field(nullable=True, coerce=True)\n    route_text_color: Optional[Series[str]] = pa.Field(nullable=True, coerce=True)\n\n    class Config:\n        \"\"\"Config for the RoutesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"route_id\"]\n        _fk: ClassVar[TableForeignKeys] = {\"agency_id\": (\"agencies\", \"agency_id\")}\n</code></pre>"},{"location":"networks/#trips","title":"Trips","text":"<p>Represents the Trips table in the Wrangler feed, adding projects list.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#tripstxt</p> <p>Attributes:</p> Name Type Description <code>trip_id</code> <code>str</code> <p>Primary key. Required to be unique.</p> <code>shape_id</code> <code>str</code> <p>Foreign key to <code>shape_id</code> in the shapes table.</p> <code>direction_id</code> <code>DirectionID</code> <p>The direction id. Required. Values can be: - 0: Outbound - 1: Inbound</p> <code>service_id</code> <code>str</code> <p>The service id.</p> <code>route_id</code> <code>str</code> <p>The route id. Foreign key to <code>route_id</code> in the routes table.</p> <code>trip_short_name</code> <code>Optional[str]</code> <p>The trip short name.</p> <code>trip_headsign</code> <code>Optional[str]</code> <p>The trip headsign.</p> <code>block_id</code> <code>Optional[str]</code> <p>The block id.</p> <code>wheelchair_accessible</code> <code>Optional[int]</code> <p>The wheelchair accessible. Values can be: - 0: No information - 1: Allowed - 2: Not allowed</p> <code>bikes_allowed</code> <code>Optional[int]</code> <p>The bikes allowed. Values can be: - 0: No information - 1: Allowed - 2: Not allowed</p> <code>projects</code> <code>str</code> <p>A comma-separated string value for projects that have been applied to this trip.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerTripsTable(TripsTable):\n    \"\"\"Represents the Trips table in the Wrangler feed, adding projects list.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#tripstxt&gt;\n\n    Attributes:\n        trip_id (str): Primary key. Required to be unique.\n        shape_id (str): Foreign key to `shape_id` in the shapes table.\n        direction_id (DirectionID): The direction id. Required. Values can be:\n            - 0: Outbound\n            - 1: Inbound\n        service_id (str): The service id.\n        route_id (str): The route id. Foreign key to `route_id` in the routes table.\n        trip_short_name (Optional[str]): The trip short name.\n        trip_headsign (Optional[str]): The trip headsign.\n        block_id (Optional[str]): The block id.\n        wheelchair_accessible (Optional[int]): The wheelchair accessible. Values can be:\n            - 0: No information\n            - 1: Allowed\n            - 2: Not allowed\n        bikes_allowed (Optional[int]): The bikes allowed. Values can be:\n            - 0: No information\n            - 1: Allowed\n            - 2: Not allowed\n        projects (str): A comma-separated string value for projects that have been applied to this trip.\n    \"\"\"\n\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n\n    class Config:\n        \"\"\"Config for the WranglerTripsTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\"]\n        _fk: ClassVar[TableForeignKeys] = {\"route_id\": (\"routes\", \"route_id\")}\n</code></pre>"},{"location":"networks/#stop_times","title":"Stop_times","text":"<p>Wrangler flavor of GTFS StopTimesTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#stop_timestxt</p> <p>The primary key of this table is a composite key of <code>trip_id</code> and <code>stop_sequence</code>.</p> <p>Attributes:</p> Name Type Description <code>trip_id</code> <code>str</code> <p>Foreign key to <code>trip_id</code> in the trips table.</p> <code>stop_id</code> <code>int</code> <p>Foreign key to <code>stop_id</code> in the stops table.</p> <code>stop_sequence</code> <code>int</code> <p>The stop sequence.</p> <code>pickup_type</code> <code>PickupDropoffType</code> <p>The pickup type. Values can be: - 0: Regularly scheduled pickup - 1: No pickup available - 2: Must phone agency to arrange pickup - 3: Must coordinate with driver to arrange pickup</p> <code>drop_off_type</code> <code>PickupDropoffType</code> <p>The drop off type. Values can be: - 0: Regularly scheduled drop off - 1: No drop off available - 2: Must phone agency to arrange drop off - 3: Must coordinate with driver to arrange drop off</p> <code>arrival_time</code> <code>datetime</code> <p>The arrival time in datetime format.</p> <code>departure_time</code> <code>datetime</code> <p>The departure time in datetime format.</p> <code>shape_dist_traveled</code> <code>Optional[float]</code> <p>The shape distance traveled.</p> <code>timepoint</code> <code>Optional[TimepointType]</code> <p>The timepoint type. Values can be: - 0: The stop is not a timepoint - 1: The stop is a timepoint</p> <code>projects</code> <code>str</code> <p>A comma-separated string value for projects that have been applied to this stop.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerStopTimesTable(StopTimesTable):\n    \"\"\"Wrangler flavor of GTFS StopTimesTable.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#stop_timestxt&gt;\n\n    The primary key of this table is a composite key of `trip_id` and `stop_sequence`.\n\n    Attributes:\n        trip_id (str): Foreign key to `trip_id` in the trips table.\n        stop_id (int): Foreign key to `stop_id` in the stops table.\n        stop_sequence (int): The stop sequence.\n        pickup_type (PickupDropoffType): The pickup type. Values can be:\n            - 0: Regularly scheduled pickup\n            - 1: No pickup available\n            - 2: Must phone agency to arrange pickup\n            - 3: Must coordinate with driver to arrange pickup\n        drop_off_type (PickupDropoffType): The drop off type. Values can be:\n            - 0: Regularly scheduled drop off\n            - 1: No drop off available\n            - 2: Must phone agency to arrange drop off\n            - 3: Must coordinate with driver to arrange drop off\n        arrival_time (datetime.datetime): The arrival time in datetime format.\n        departure_time (datetime.datetime): The departure time in datetime format.\n        shape_dist_traveled (Optional[float]): The shape distance traveled.\n        timepoint (Optional[TimepointType]): The timepoint type. Values can be:\n            - 0: The stop is not a timepoint\n            - 1: The stop is a timepoint\n        projects (str): A comma-separated string value for projects that have been applied to this stop.\n    \"\"\"\n\n    stop_id: Series[int] = pa.Field(nullable=False, coerce=True, description=\"The model_node_id.\")\n    arrival_time: Series[Timestamp] = pa.Field(nullable=True, default=pd.NaT, coerce=False)\n    departure_time: Series[Timestamp] = pa.Field(nullable=True, default=pd.NaT, coerce=False)\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n\n    @pa.dataframe_parser\n    def parse_times(cls, df):\n        \"\"\"Parse arrival and departure times.\n\n        - Check that all times are timestamps &lt;24h.\n        - Check that arrival_time and departure_time are not both \"00:00:00\".  If so, set\n            them to NaT.\n\n        \"\"\"\n        # if arrival_time and departure_time are not set or are both set to \"00:00:00\", set them to NaT\n        if \"arrival_time\" not in df.columns:\n            df[\"arrival_time\"] = pd.NaT\n        if \"departure_time\" not in df.columns:\n            df[\"departure_time\"] = pd.NaT\n        msg = f\"stop_times before parsing: \\n {df[['arrival_time', 'departure_time']]}\"\n        # WranglerLogger.debug(msg)\n        filler_timestrings = (df[\"arrival_time\"] == Timestamp(\"00:00:00\")) &amp; (\n            df[\"departure_time\"] == Timestamp(\"00:00:00\")\n        )\n\n        df.loc[filler_timestrings, \"arrival_time\"] = pd.NaT\n        df.loc[filler_timestrings, \"departure_time\"] = pd.NaT\n        msg = f\"stop_times after filling with NaT: \\n {df[['arrival_time', 'departure_time']]}\"\n        # WranglerLogger.debug(msg)\n        df[\"arrival_time\"] = str_to_time_series(df[\"arrival_time\"])\n        df[\"departure_time\"] = str_to_time_series(df[\"departure_time\"])\n        msg = f\"stop_times after parsing: \\n{df[['arrival_time', 'departure_time']]}\"\n        # WranglerLogger.debug(msg)\n        return df\n\n    class Config:\n        \"\"\"Config for the StopTimesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\", \"stop_sequence\"]\n        _fk: ClassVar[TableForeignKeys] = {\n            \"trip_id\": (\"trips\", \"trip_id\"),\n            \"stop_id\": (\"stops\", \"stop_id\"),\n        }\n\n        unique: ClassVar[list[str]] = [\"trip_id\", \"stop_sequence\"]\n</code></pre>"},{"location":"networks/#shapes","title":"Shapes","text":"<p>Wrangler flavor of GTFS ShapesTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#shapestxt</p> <p>Attributes:</p> Name Type Description <code>shape_id</code> <code>str</code> <p>The shape_id. Primary key. Required to be unique.</p> <code>shape_pt_lat</code> <code>float</code> <p>The shape point latitude.</p> <code>shape_pt_lon</code> <code>float</code> <p>The shape point longitude.</p> <code>shape_pt_sequence</code> <code>int</code> <p>The shape point sequence.</p> <code>shape_dist_traveled</code> <code>Optional[float]</code> <p>The shape distance traveled.</p> <code>shape_model_node_id</code> <code>int</code> <p>The model_node_id of the shape point. Foreign key to the model_node_id in the nodes table.</p> <code>projects</code> <code>str</code> <p>A comma-separated string value for projects that have been applied to this shape.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerShapesTable(ShapesTable):\n    \"\"\"Wrangler flavor of GTFS ShapesTable.\n\n     For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#shapestxt&gt;\n\n    Attributes:\n        shape_id (str): The shape_id. Primary key. Required to be unique.\n        shape_pt_lat (float): The shape point latitude.\n        shape_pt_lon (float): The shape point longitude.\n        shape_pt_sequence (int): The shape point sequence.\n        shape_dist_traveled (Optional[float]): The shape distance traveled.\n        shape_model_node_id (int): The model_node_id of the shape point. Foreign key to the model_node_id in the nodes table.\n        projects (str): A comma-separated string value for projects that have been applied to this shape.\n    \"\"\"\n\n    shape_model_node_id: Series[int] = pa.Field(coerce=True, nullable=False)\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n</code></pre>"},{"location":"networks/#frequencies","title":"Frequencies","text":"<p>Wrangler flavor of GTFS FrequenciesTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#frequenciestxt</p> <p>The primary key of this table is a composite key of <code>trip_id</code> and <code>start_time</code>.</p> <p>Attributes:</p> Name Type Description <code>trip_id</code> <code>str</code> <p>Foreign key to <code>trip_id</code> in the trips table.</p> <code>start_time</code> <code>datetime</code> <p>The start time in datetime format.</p> <code>end_time</code> <code>datetime</code> <p>The end time in datetime format.</p> <code>headway_secs</code> <code>int</code> <p>The headway in seconds.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerFrequenciesTable(FrequenciesTable):\n    \"\"\"Wrangler flavor of GTFS FrequenciesTable.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#frequenciestxt&gt;\n\n    The primary key of this table is a composite key of `trip_id` and `start_time`.\n\n    Attributes:\n        trip_id (str): Foreign key to `trip_id` in the trips table.\n        start_time (datetime.datetime): The start time in datetime format.\n        end_time (datetime.datetime): The end time in datetime format.\n        headway_secs (int): The headway in seconds.\n    \"\"\"\n\n    projects: Series[str] = pa.Field(coerce=True, default=\"\")\n    start_time: Series = pa.Field(\n        nullable=False, coerce=True, default=str_to_time(DEFAULT_TIMESPAN[0])\n    )\n    end_time: Series = pa.Field(\n        nullable=False, coerce=True, default=str_to_time(DEFAULT_TIMESPAN[1])\n    )\n\n    class Config:\n        \"\"\"Config for the FrequenciesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        unique: ClassVar[list[str]] = [\"trip_id\", \"start_time\"]\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\", \"start_time\"]\n        _fk: ClassVar[TableForeignKeys] = {\"trip_id\": (\"trips\", \"trip_id\")}\n\n    @pa.parser(\"start_time\")\n    def st_to_timestamp(cls, series: Series) -&gt; Series[Timestamp]:\n        \"\"\"Check that start time is timestamp.\"\"\"\n        series = series.fillna(str_to_time(DEFAULT_TIMESPAN[0]))\n        if series.dtype == \"datetime64[ns]\":\n            return series\n        series = str_to_time_series(series)\n        return series.astype(\"datetime64[ns]\")\n\n    @pa.parser(\"end_time\")\n    def et_to_timestamp(cls, series: Series) -&gt; Series[Timestamp]:\n        \"\"\"Check that start time is timestamp.\"\"\"\n        series = series.fillna(str_to_time(DEFAULT_TIMESPAN[1]))\n        if series.dtype == \"datetime64[ns]\":\n            return series\n        return str_to_time_series(series)\n</code></pre>"},{"location":"networks/#agencies","title":"Agencies","text":"<p>Represents the Agency table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#agencytxt</p> <p>Attributes:</p> Name Type Description <code>agency_id</code> <code>str</code> <p>The agency_id. Primary key. Required to be unique.</p> <code>agency_name</code> <code>str</code> <p>The agency name.</p> <code>agency_url</code> <code>str</code> <p>The agency URL.</p> <code>agency_timezone</code> <code>str</code> <p>The agency timezone.</p> <code>agency_lang</code> <code>str</code> <p>The agency language.</p> <code>agency_phone</code> <code>str</code> <p>The agency phone number.</p> <code>agency_fare_url</code> <code>str</code> <p>The agency fare URL.</p> <code>agency_email</code> <code>str</code> <p>The agency email.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class AgenciesTable(pa.DataFrameModel):\n    \"\"\"Represents the Agency table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#agencytxt&gt;\n\n    Attributes:\n        agency_id (str): The agency_id. Primary key. Required to be unique.\n        agency_name (str): The agency name.\n        agency_url (str): The agency URL.\n        agency_timezone (str): The agency timezone.\n        agency_lang (str): The agency language.\n        agency_phone (str): The agency phone number.\n        agency_fare_url (str): The agency fare URL.\n        agency_email (str): The agency email.\n    \"\"\"\n\n    agency_id: Series[str] = pa.Field(coerce=True, nullable=False, unique=True)\n    agency_name: Series[str] = pa.Field(coerce=True, nullable=True)\n    agency_url: Series[HttpURL] = pa.Field(coerce=True, nullable=True)\n    agency_timezone: Series[str] = pa.Field(coerce=True, nullable=True)\n    agency_lang: Series[str] = pa.Field(coerce=True, nullable=True)\n    agency_phone: Series[str] = pa.Field(coerce=True, nullable=True)\n    agency_fare_url: Series[str] = pa.Field(coerce=True, nullable=True)\n    agency_email: Series[str] = pa.Field(coerce=True, nullable=True)\n\n    class Config:\n        \"\"\"Config for the AgenciesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"agency_id\"]\n</code></pre>"},{"location":"networks/#transit-validation","title":"Transit Validation","text":"<p>TransitNetworks can be validated using the following tools:</p> CLIPython API <p><pre><code>python validate_transit.py &lt;network_dir&gt; &lt;file_format&gt; [-s] [--output_dir &lt;output_dir&gt;] [--road_dir &lt;road_dir&gt;] [--road_file_format &lt;road_file_format]\n</code></pre> Where:</p> <ul> <li><code>network_dir</code>: The transit network file directory.</li> <li><code>file_format</code>: The suffices of transit network .</li> <li><code>--output_dir</code>: The output directory for the validation report.</li> <li><code>--road_dir</code>: The directory roadway network. if want to validate the transit network to it.</li> <li><code>--road_file_format</code>: The file format for roadway network. Defaults to \u2018geojson\u2019.</li> </ul> <p><pre><code>from network_wrangler.transit.validate import validate_transit_in_dir\nvalidate_transit_in_dir(\n    dir=&lt;network_dir&gt;,\n    file_format=&lt;network_file_format&gt;,\n    road_dir=&lt;road_dir&gt;,\n    road_file_format=&lt;road_file_format,\n)\n</code></pre> Where:</p> <ul> <li><code>network_dir</code>: The roadway network file directory.</li> <li><code>network_file_format</code>: The file format of the transit files.</li> <li><code>road_dir</code>: The directory roadway network. if want to validate the transit network to it.</li> <li><code>road_file_format</code>: The file format for roadway network. Defaults to \u2018geojson\u2019.</li> </ul>"},{"location":"networks/#project-cards","title":"Project Cards","text":"<p>Project Cards, which define changes to the roadway and transit networks must use the ProjectCard standard.</p>"},{"location":"networks/#model-roadway-network-export-format","title":"Model Roadway Network Export Format","text":"<p>In order to separately calculate the delay when the networks are assigned in static roadway network assignment the roadway network must be exported with separate managed lane links.</p> <p>To acheive this, RoadwayNetwork objects have the option to be exported in the ModelRoadwayNetwork format, which separates a link into two: set of managed lanes and a set of general purpose lanes which are connected by a set of dummy connector links.  </p>"},{"location":"networks/#managed-lane-links","title":"Managed Lane Links","text":"<p>All properties preceded by <code>ML_</code> will be copied, without that prefix, to the managed lane links.</p> <p>The following are controlled by parameters which can be set using WranglerConfig:</p> <p>Geometry of managed lanes will be defined as a shape offset by the parameter <code>ML_OFFSET_METERS</code>. Properties defined in the parameter <code>ADDITIONAL_COPY_FROM_GP_TO_ML</code> are also copied from the parent link.</p> <p>New <code>model_node_id</code> s and <code>model_link_ids</code> are generated based either on ranges or using a scalar from the GP link based on: <code>ML_LINK_ID_METHOD</code>, <code>ML_NODE_ID_METHOD</code>, <code>ML_LINK_ID_RANGE</code>, <code>ML_NODE_ID_RANGE</code>, <code>ML_LINK_ID_SCALAR</code>, <code>ML_NODE_ID_SCALAR</code></p> <p><code>name</code> is created as \u201cmanaged lane of <code>name of GP link</code>\u201c</p> <p>Relationship to the general purpose lanes is retained using the fields <code>GP_A</code>, <code>GP_B</code>, <code>GP_model_link_id</code>.</p> <p>Managed-lane link-ids are generated as multiples of 10.</p>"},{"location":"networks/#dummy-connector-links","title":"Dummy Connector Links","text":"<p>Dummy connector links are generated between the general purpose lane links and managed lane links at points defined by the variable <code>ML_access_point</code> and <code>ML_egress_point</code>.  If a managed lane is created without explictly setting these values, network wrangler will assume that the managed lanes can be accessed at any node.</p> <p>The parameter <code>ADDITIONAL_COPY_TO_ACCESS_EGRESS</code> defines what additional attributes are copied from the general purpose lane to the access and egress links.</p> <p><code>name</code> is created as \u201c dummy link\u201d <p><code>model_link_id</code> is created as follows, noting that <code>model_link_id</code> s for managed lanes will be multiples of 10:</p> <ul> <li>1 + managed lane\u2019s <code>model_link_id</code> for access links</li> <li>2 + managed lane\u2019s <code>model_link_id</code> for access links</li> </ul> <p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> Name Type Description <code>ML_OFFSET_METERS</code> <code>int</code> <p>Offset in meters for managed lanes.</p> <code>ADDITIONAL_COPY_FROM_GP_TO_ML</code> <code>list[str]</code> <p>Additional fields to copy from general purpose to managed lanes.</p> <code>ADDITIONAL_COPY_TO_ACCESS_EGRESS</code> <code>list[str]</code> <p>Additional fields to copy to access and egress links.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass ModelRoadwayConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        ML_OFFSET_METERS: Offset in meters for managed lanes.\n        ADDITIONAL_COPY_FROM_GP_TO_ML: Additional fields to copy from general purpose to managed\n            lanes.\n        ADDITIONAL_COPY_TO_ACCESS_EGRESS: Additional fields to copy to access and egress links.\n    \"\"\"\n\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: list[str] = Field(default_factory=list)\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: list[str] = Field(default_factory=list)\n</code></pre> <p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> Name Type Description <code>TRANSIT_SHAPE_ID_METHOD</code> <code>Literal['scalar']</code> <p>method for creating a shape_id for a transit shape. Should be \u201cscalar\u201d.</p> <code>TRANSIT_SHAPE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a shape_id for a transit shape.</p> <code>ROAD_SHAPE_ID_METHOD</code> <code>Literal['scalar']</code> <p>method for creating a shape_id for a roadway shape. Should be \u201cscalar\u201d.</p> <code>ROAD_SHAPE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a shape_id for a roadway shape.</p> <code>ML_LINK_ID_METHOD</code> <code>Literal['range', 'scalar']</code> <p>method for creating a model_link_id for an associated link for a parallel managed lane.</p> <code>ML_LINK_ID_RANGE</code> <code>tuple[int, int]</code> <p>range of model_link_ids to use when creating an associated link for a parallel managed lane.</p> <code>ML_LINK_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane to create a model_link_id when creating an associated link for a parallel managed lane.</p> <code>ML_NODE_ID_METHOD</code> <code>Literal['range', 'scalar']</code> <p>method for creating a model_node_id for an associated node for a parallel managed lane.</p> <code>ML_NODE_ID_RANGE</code> <code>tuple[int, int]</code> <p>range of model_node_ids to use when creating an associated node for a parallel managed lane.</p> <code>ML_NODE_ID_SCALAR</code> <code>int</code> <p>scalar value to add to general purpose lane node ides create a model_node_id when creating an associated nodes for parallel managed lane.</p> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass IdGenerationConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        TRANSIT_SHAPE_ID_METHOD: method for creating a shape_id for a transit shape.\n            Should be \"scalar\".\n        TRANSIT_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a transit shape.\n        ROAD_SHAPE_ID_METHOD: method for creating a shape_id for a roadway shape.\n            Should be \"scalar\".\n        ROAD_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a roadway shape.\n        ML_LINK_ID_METHOD: method for creating a model_link_id for an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_RANGE: range of model_link_ids to use when creating an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_SCALAR: scalar value to add to general purpose lane to create a\n            model_link_id when creating an associated link for a parallel managed lane.\n        ML_NODE_ID_METHOD: method for creating a model_node_id for an associated node\n            for a parallel managed lane.\n        ML_NODE_ID_RANGE: range of model_node_ids to use when creating an associated\n            node for a parallel managed lane.\n        ML_NODE_ID_SCALAR: scalar value to add to general purpose lane node ides create\n            a model_node_id when creating an associated nodes for parallel managed lane.\n    \"\"\"\n\n    TRANSIT_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    TRANSIT_SHAPE_ID_SCALAR: int = 1000000\n    ROAD_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    ROAD_SHAPE_ID_SCALAR: int = 1000\n    ML_LINK_ID_METHOD: Literal[\"range\", \"scalar\"] = \"scalar\"\n    ML_LINK_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_LINK_ID_SCALAR: int = 3000000\n    ML_NODE_ID_METHOD: Literal[\"range\", \"scalar\"] = \"range\"\n    ML_NODE_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_NODE_ID_SCALAR: int = 15000\n</code></pre>"},{"location":"networks/#network-management","title":"Network Management","text":"<p>Several functions assist in managing networks themselves including converting serialization formats and clipping to various geographic bounds.</p>"},{"location":"networks/#viewing","title":"Viewing","text":"<p>Because the roadway network is already in GeoDataFrames, they can be easily viewed in Jupyter Notebooks using commands such as:</p> <pre><code>my_small_net = SMALL_ROAD.links_df).explore(tiles=\"CartoDB positron\")\nSMALL_ROAD.nodes_df.explore(m=my_small_net, color=\"grey\")\nmy_small_net\n</code></pre> <p>For larger networks, you might want to sample objects if you are just trying to get the general picture in order to save memory.</p> <pre><code>stpaul_net = STPAUL_ROAD.links_df.sample(300).explore(tiles=\"CartoDB positron\")\nSTPAUL_ROAD.nodes_df.sample(300).explore(m=stpaul_net, color=\"grey\")\nstpaul_net\n</code></pre> <p>For transit, you have access to GeoDataFrames for both shapes and stops:</p> <pre><code>STPAUL_TRANSIT.shapes_gdf.explore(m=stpaul_net, color=\"limegreen\")\nSTPAUL_TRANSIT.stops_gdf.explore(m=stpaul_net, color=\"limegreen\")\nstpaul_net\n</code></pre>"},{"location":"networks/#clipping","title":"Clipping","text":"<p>There are two options for getting networks that are subsets of the larger one:</p> <ol> <li>clipping networks already loaded from files. Useful when you are already manipulating the objects.</li> <li>filtering the network when it is read in.</li> </ol> <p>In both instances, you have the option to filter based on one of three methods:</p> <ol> <li><code>boundary_file</code> which is a geojson or shapefile that you want to filter to.</li> <li><code>boundary_gdf</code> passing a geodataframe with a single polygon record that you want to filter to.</li> <li><code>boundary_geocode</code> which queries open streetmap for a jurisdiction matching the provided name, e.g. \u201cSt Paul, MN, USA\u201d.</li> </ol> <p>Transit additionally has the option to be filtered to a roadway network.</p>"},{"location":"networks/#clipping-loaded-networks","title":"Clipping loaded networks","text":"<p>If your network is already loaded from disk into a RoadwayNetwork or TransitNetwork, you can clip it using <code>clip_roadway()</code> or <code>clip_transit()</code>:</p> <pre><code>from network_wrangler.roadway import clip_roadway\nclipped_road_eco = clip_roadway(STPAUL_ROAD, boundary_file=TEST_DATA / \"ecolab.geojson\")\nclipped_road_eco.links_df.explore(m= color=\"hotpink\")\n</code></pre> <pre><code>from network_wrangler.transit.clip import clip_transit\nclipped_transit_eco = clip_transit(STPAUL_TRANSIT, roadway_net=clipped_road_eco)\n</code></pre>"},{"location":"networks/#filtering-on-being-read-from-disk","title":"Filtering on being read from disk","text":"<p>To filter roadway networks on being read-in, you can use the same parameters (<code>boundary_gdf</code>, <code>boundary_geocode</code> or <code>boundary_file</code>, available in <code>load_roadway_from_dir</code>, and all associated methods.  </p> <pre><code>downtown_net = load_roadway_from_dir(STPAUL_DIR, boundary_geocode=\"Downtown, St Paul, MN, USA\")\n</code></pre> <p>This feature is not yet implemented in transit.</p>"},{"location":"networks/#converting-serialization","title":"Converting Serialization","text":"<p>To convert file serialization without reading it into objects, you can use the method <code>convert_roadway_file_serialization()</code>:</p> <pre><code>from roadway.io import convert_roadway_file_serialization\n\nconvert_roadway_file_serialization(\n    my_dir, # the path to the input directory.\n    \"geojson\", # the file format of the input files. Defaults to \"geojson\".\n    my_new_dir, # the path were the output will be saved.\n    \"parquet\", # the format of the output files. Defaults to \"parquet\".\n    \"new\", # the name prefix of the roadway files that will be generated. Defaults to \"\".\n    overwrite = True, # if True, will overwrite the files if they already exist. Defaults to True.\n)\n</code></pre> <p>clip to</p> <p>Note you can also pass one of <code>boundary_geocode</code>, <code>boundary_gdf</code> or <code>boundary_file</code> to clip while you are converting the file serialization.</p>"}]}